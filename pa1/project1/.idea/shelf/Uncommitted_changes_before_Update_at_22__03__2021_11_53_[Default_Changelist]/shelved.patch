Index: martin.py
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.BaseRevisionTextPatchEP
<+>import hashlib\r\nimport requests\r\nimport sys\r\nimport database.db as database\r\n\r\n######## HTML CONTENT #########\r\nurl = 'https://www.google.com/'\r\nr = requests.get(url)\r\na = r.text\r\n#print(a)\r\n########### end ##############\r\n\r\n\r\n############### HASH ####################\r\nhash_object = hashlib.sha256(a.encode())\r\nhex_dig = hash_object.hexdigest()\r\n#print(hex_dig)\r\n############## end ###############\r\n\r\n\r\n############### ARGUMENTI ####################\r\n#crawders = (sys.argv[1])\r\n#if int(crawders) < 1:\r\n#    crawders = 1\r\n#print(crawders)\r\n############## end ###############\r\n\r\n\r\n############### BAZA PROVERIKA ####################\r\ndb = database.DB()\r\ndb.connectDB()\r\ndb.createTables()\r\nsite_id = db.insertSite('www.facebook.com', None, None)\r\ndb.insertPage(site_id, 'DUPLICATE', 'www.insta.com', 'htlm<>blabla', '123', None)\r\n############## end ###############
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/martin.py b/martin.py
--- a/martin.py	(revision 872b39a88a8c47659be6e1235dd4e7934b2ca1fe)
+++ b/martin.py	(date 1616410274553)
@@ -1,7 +1,8 @@
 import hashlib
-import requests
 import sys
+from pip._vendor import requests
 import database.db as database
+import urllib.robotparser
 
 ######## HTML CONTENT #########
 url = 'https://www.google.com/'
@@ -27,9 +28,18 @@
 
 
 ############### BAZA PROVERIKA ####################
-db = database.DB()
-db.connectDB()
-db.createTables()
-site_id = db.insertSite('www.facebook.com', None, None)
-db.insertPage(site_id, 'DUPLICATE', 'www.insta.com', 'htlm<>blabla', '123', None)
-############## end ###############
\ No newline at end of file
+#db = database.DB()
+#db.connectDB()
+#db.createTables()
+#site_id = db.insertSite('www.facebook.com', None, None)
+#db.insertPage(site_id, 'DUPLICATE', 'www.insta.com', 'htlm<>blabla', '123', None)
+############## end ###############
+
+
+############### ROBOT ####################
+rp = urllib.robotparser.RobotFileParser()
+rp.set_url("http://www.gov.si/robots.txt")
+rp.read()
+#print(rp.site_maps())
+############## end ###############
+
Index: .idea/misc.xml
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.BaseRevisionTextPatchEP
<+><?xml version=\"1.0\" encoding=\"UTF-8\"?>\r\n<project version=\"4\">\r\n  <component name=\"ProjectRootManager\" version=\"2\" project-jdk-name=\"Python 3.6 (project1)\" project-jdk-type=\"Python SDK\" />\r\n</project>
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/.idea/misc.xml b/.idea/misc.xml
--- a/.idea/misc.xml	(revision 872b39a88a8c47659be6e1235dd4e7934b2ca1fe)
+++ b/.idea/misc.xml	(date 1616409189195)
@@ -1,4 +1,4 @@
 <?xml version="1.0" encoding="UTF-8"?>
 <project version="4">
-  <component name="ProjectRootManager" version="2" project-jdk-name="Python 3.6 (project1)" project-jdk-type="Python SDK" />
+  <component name="ProjectRootManager" version="2" project-jdk-name="Python 3.9 (project1)" project-jdk-type="Python SDK" />
 </project>
\ No newline at end of file
Index: venv/Lib/site-packages/tests/web_client/test_requests_client.py
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/venv/Lib/site-packages/tests/web_client/test_requests_client.py b/venv/Lib/site-packages/tests/web_client/test_requests_client.py
new file mode 100644
--- /dev/null	(date 1616406051465)
+++ b/venv/Lib/site-packages/tests/web_client/test_requests_client.py	(date 1616406051465)
@@ -0,0 +1,142 @@
+import socket
+from http import HTTPStatus
+from unittest import TestCase
+
+import requests_mock
+
+from usp.__about__ import __version__
+from usp.web_client.abstract_client import (
+    AbstractWebClientSuccessResponse,
+    WebClientErrorResponse,
+)
+from usp.web_client.requests_client import RequestsWebClient
+
+
+class TestRequestsClient(TestCase):
+    TEST_BASE_URL = 'http://test_ultimate_sitemap_parser.com'  # mocked by HTTPretty
+    TEST_CONTENT_TYPE = 'text/html'
+
+    __slots__ = [
+        '__client',
+    ]
+
+    def setUp(self) -> None:
+        super().setUp()
+
+        self.__client = RequestsWebClient()
+
+    def test_get(self):
+        with requests_mock.Mocker() as m:
+            test_url = self.TEST_BASE_URL + '/'
+            test_content = 'This is a homepage.'
+
+            m.get(
+                test_url,
+                headers={'Content-Type': self.TEST_CONTENT_TYPE},
+                text=test_content,
+            )
+
+            response = self.__client.get(test_url)
+
+            assert response
+            assert isinstance(response, AbstractWebClientSuccessResponse)
+            assert response.status_code() == HTTPStatus.OK.value
+            assert response.status_message() == HTTPStatus.OK.phrase
+            assert response.header('Content-Type') == self.TEST_CONTENT_TYPE
+            assert response.header('content-type') == self.TEST_CONTENT_TYPE
+            assert response.header('nonexistent') is None
+            assert response.raw_data().decode('utf-8') == test_content
+
+    def test_get_user_agent(self):
+        with requests_mock.Mocker() as m:
+            test_url = self.TEST_BASE_URL + '/'
+
+            def content_user_agent(request, context):
+                context.status_code = HTTPStatus.OK.value
+                return request.headers.get('User-Agent', 'unknown')
+
+            m.get(
+                test_url,
+                text=content_user_agent,
+            )
+
+            response = self.__client.get(test_url)
+
+            assert response
+            assert isinstance(response, AbstractWebClientSuccessResponse)
+
+            content = response.raw_data().decode('utf-8')
+            assert content == 'ultimate_sitemap_parser/{}'.format(__version__)
+
+    def test_get_not_found(self):
+        with requests_mock.Mocker() as m:
+            test_url = self.TEST_BASE_URL + '/404.html'
+
+            m.get(
+                test_url,
+                status_code=HTTPStatus.NOT_FOUND.value,
+                reason=HTTPStatus.NOT_FOUND.phrase,
+                headers={'Content-Type': self.TEST_CONTENT_TYPE},
+                text='This page does not exist.',
+            )
+
+            response = self.__client.get(test_url)
+
+            assert response
+            assert isinstance(response, WebClientErrorResponse)
+            assert response.retryable() is False
+
+    def test_get_nonexistent_domain(self):
+        test_url = 'http://www.totallydoesnotexisthjkfsdhkfsd.com/some_page.html'
+
+        response = self.__client.get(test_url)
+
+        assert response
+        assert isinstance(response, WebClientErrorResponse)
+        assert response.retryable() is False
+        assert 'Failed to establish a new connection' in response.message()
+
+    def test_get_timeout(self):
+        sock = socket.socket()
+        sock.bind(('', 0))
+        socket_port = sock.getsockname()[1]
+        assert socket_port
+        sock.listen(1)
+
+        test_timeout = 1
+        test_url = 'http://127.0.0.1:{}/slow_page.html'.format(socket_port)
+
+        self.__client.set_timeout(test_timeout)
+
+        response = self.__client.get(test_url)
+
+        sock.close()
+
+        assert response
+        assert isinstance(response, WebClientErrorResponse)
+        assert response.retryable() is True
+        assert 'Read timed out' in response.message()
+
+    def test_get_max_response_data_length(self):
+        with requests_mock.Mocker() as m:
+            actual_length = 1024 * 1024
+            max_length = 1024 * 512
+
+            test_url = self.TEST_BASE_URL + '/huge_page.html'
+            test_content = 'a' * actual_length
+
+            m.get(
+                test_url,
+                headers={'Content-Type': self.TEST_CONTENT_TYPE},
+                text=test_content,
+            )
+
+            self.__client.set_max_response_data_length(max_length)
+
+            response = self.__client.get(test_url)
+
+            assert response
+            assert isinstance(response, AbstractWebClientSuccessResponse)
+
+            response_length = len(response.raw_data())
+            assert response_length == max_length
Index: .idea/project1.iml
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.BaseRevisionTextPatchEP
<+><?xml version=\"1.0\" encoding=\"UTF-8\"?>\r\n<module type=\"PYTHON_MODULE\" version=\"4\">\r\n  <component name=\"NewModuleRootManager\">\r\n    <content url=\"file://$MODULE_DIR$\">\r\n      <excludeFolder url=\"file://$MODULE_DIR$/venv\" />\r\n    </content>\r\n    <orderEntry type=\"inheritedJdk\" />\r\n    <orderEntry type=\"sourceFolder\" forTests=\"false\" />\r\n  </component>\r\n  <component name=\"TestRunnerService\">\r\n    <option name=\"PROJECT_TEST_RUNNER\" value=\"Unittests\" />\r\n  </component>\r\n</module>
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/.idea/project1.iml b/.idea/project1.iml
--- a/.idea/project1.iml	(revision 872b39a88a8c47659be6e1235dd4e7934b2ca1fe)
+++ b/.idea/project1.iml	(date 1616409189005)
@@ -3,8 +3,9 @@
   <component name="NewModuleRootManager">
     <content url="file://$MODULE_DIR$">
       <excludeFolder url="file://$MODULE_DIR$/venv" />
+      <excludeFolder url="file://$MODULE_DIR$/latest" />
     </content>
-    <orderEntry type="inheritedJdk" />
+    <orderEntry type="jdk" jdkName="Python 3.9 (project1)" jdkType="Python SDK" />
     <orderEntry type="sourceFolder" forTests="false" />
   </component>
   <component name="TestRunnerService">
Index: venv/Lib/site-packages/usp/exceptions.py
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/venv/Lib/site-packages/usp/exceptions.py b/venv/Lib/site-packages/usp/exceptions.py
new file mode 100644
--- /dev/null	(date 1616406051465)
+++ b/venv/Lib/site-packages/usp/exceptions.py	(date 1616406051465)
@@ -0,0 +1,29 @@
+"""Exceptions used by the sitemap parser."""
+
+
+class SitemapException(Exception):
+    """
+    Problem due to which we can't run further, e.g. wrong input parameters.
+    """
+    pass
+
+
+class SitemapXMLParsingException(Exception):
+    """
+    XML parsing exception to be handled gracefully.
+    """
+    pass
+
+
+class GunzipException(Exception):
+    """
+    gunzip() exception.
+    """
+    pass
+
+
+class StripURLToHomepageException(Exception):
+    """
+    strip_url_to_homepage() exception.
+    """
+    pass
Index: venv/Lib/site-packages/usp/fetch_parse.py
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/venv/Lib/site-packages/usp/fetch_parse.py b/venv/Lib/site-packages/usp/fetch_parse.py
new file mode 100644
--- /dev/null	(date 1616406051465)
+++ b/venv/Lib/site-packages/usp/fetch_parse.py	(date 1616406051465)
@@ -0,0 +1,953 @@
+"""Sitemap fetchers and parsers."""
+
+import abc
+import re
+import xml.parsers.expat
+from collections import OrderedDict
+from decimal import Decimal
+from typing import Optional, Dict
+
+from .exceptions import SitemapException, SitemapXMLParsingException
+from .helpers import (
+    html_unescape_strip,
+    parse_iso8601_date,
+    get_url_retry_on_client_errors,
+    ungzipped_response_content,
+    is_http_url,
+    parse_rfc2822_date,
+)
+from .log import create_logger
+from .objects.page import (
+    SitemapPage,
+    SitemapNewsStory,
+    SitemapPageChangeFrequency,
+    SITEMAP_PAGE_DEFAULT_PRIORITY,
+)
+from .objects.sitemap import (
+    AbstractSitemap,
+    InvalidSitemap,
+    IndexRobotsTxtSitemap,
+    IndexXMLSitemap,
+    PagesXMLSitemap,
+    PagesTextSitemap,
+    PagesRSSSitemap,
+    PagesAtomSitemap,
+)
+from .web_client.abstract_client import (
+    AbstractWebClient,
+    AbstractWebClientSuccessResponse,
+    WebClientErrorResponse,
+)
+from .web_client.requests_client import RequestsWebClient
+
+log = create_logger(__name__)
+
+
+class SitemapFetcher(object):
+    """robots.txt / XML / plain text sitemap fetcher."""
+
+    __MAX_SITEMAP_SIZE = 100 * 1024 * 1024
+    """Max. uncompressed sitemap size.
+
+    Spec says it might be up to 50 MB but let's go for the full 100 MB here."""
+
+    __MAX_RECURSION_LEVEL = 10
+    """Max. recursion level in iterating over sub-sitemaps."""
+
+    __slots__ = [
+        '_url',
+        '_recursion_level',
+        '_web_client',
+    ]
+
+    def __init__(self, url: str, recursion_level: int, web_client: Optional[AbstractWebClient] = None):
+
+        if recursion_level > self.__MAX_RECURSION_LEVEL:
+            raise SitemapException("Recursion level exceeded {} for URL {}.".format(self.__MAX_RECURSION_LEVEL, url))
+
+        if not is_http_url(url):
+            raise SitemapException("URL {} is not a HTTP(s) URL.".format(url))
+
+        if not web_client:
+            web_client = RequestsWebClient()
+
+        web_client.set_max_response_data_length(self.__MAX_SITEMAP_SIZE)
+
+        self._url = url
+        self._web_client = web_client
+        self._recursion_level = recursion_level
+
+    def sitemap(self) -> AbstractSitemap:
+        log.info("Fetching level {} sitemap from {}...".format(self._recursion_level, self._url))
+        response = get_url_retry_on_client_errors(url=self._url, web_client=self._web_client)
+
+        if isinstance(response, WebClientErrorResponse):
+            return InvalidSitemap(
+                url=self._url,
+                reason="Unable to fetch sitemap from {}: {}".format(self._url, response.message()),
+            )
+
+        assert isinstance(response, AbstractWebClientSuccessResponse)
+
+        response_content = ungzipped_response_content(url=self._url, response=response)
+
+        # MIME types returned in Content-Type are unpredictable, so peek into the content instead
+        if response_content[:20].strip().startswith('<'):
+            # XML sitemap (the specific kind is to be determined later)
+            parser = XMLSitemapParser(
+                url=self._url,
+                content=response_content,
+                recursion_level=self._recursion_level,
+                web_client=self._web_client,
+            )
+
+        else:
+            # Assume that it's some sort of a text file (robots.txt or plain text sitemap)
+            if self._url.endswith('/robots.txt'):
+                parser = IndexRobotsTxtSitemapParser(
+                    url=self._url,
+                    content=response_content,
+                    recursion_level=self._recursion_level,
+                    web_client=self._web_client,
+                )
+            else:
+                parser = PlainTextSitemapParser(
+                    url=self._url,
+                    content=response_content,
+                    recursion_level=self._recursion_level,
+                    web_client=self._web_client,
+                )
+
+        log.info("Parsing sitemap from URL {}...".format(self._url))
+        sitemap = parser.sitemap()
+
+        return sitemap
+
+
+class AbstractSitemapParser(object, metaclass=abc.ABCMeta):
+    """Abstract robots.txt / XML / plain text sitemap parser."""
+
+    __slots__ = [
+        '_url',
+        '_content',
+        '_web_client',
+        '_recursion_level',
+    ]
+
+    def __init__(self, url: str, content: str, recursion_level: int, web_client: AbstractWebClient):
+        self._url = url
+        self._content = content
+        self._recursion_level = recursion_level
+        self._web_client = web_client
+
+    @abc.abstractmethod
+    def sitemap(self) -> AbstractSitemap:
+        raise NotImplementedError("Abstract method.")
+
+
+class IndexRobotsTxtSitemapParser(AbstractSitemapParser):
+    """robots.txt index sitemap parser."""
+
+    def __init__(self, url: str, content: str, recursion_level: int, web_client: AbstractWebClient):
+        super().__init__(url=url, content=content, recursion_level=recursion_level, web_client=web_client)
+
+        if not self._url.endswith('/robots.txt'):
+            raise SitemapException("URL does not look like robots.txt URL: {}".format(self._url))
+
+    def sitemap(self) -> AbstractSitemap:
+
+        # Serves as an ordered set because we want to deduplicate URLs but also retain the order
+        sitemap_urls = OrderedDict()
+
+        for robots_txt_line in self._content.splitlines():
+            robots_txt_line = robots_txt_line.strip()
+            # robots.txt is supposed to be case sensitive but who cares in these Node.js times?
+            robots_txt_line = robots_txt_line.lower()
+            sitemap_match = re.search(r'^site-?map:\s*(.+?)$', robots_txt_line, flags=re.IGNORECASE)
+            if sitemap_match:
+                sitemap_url = sitemap_match.group(1)
+                if is_http_url(sitemap_url):
+                    sitemap_urls[sitemap_url] = True
+                else:
+                    log.warning("Sitemap URL {} doesn't look like an URL, skipping".format(sitemap_url))
+
+        sub_sitemaps = []
+
+        for sitemap_url in sitemap_urls.keys():
+            fetcher = SitemapFetcher(
+                url=sitemap_url,
+                recursion_level=self._recursion_level,
+                web_client=self._web_client,
+            )
+            fetched_sitemap = fetcher.sitemap()
+            sub_sitemaps.append(fetched_sitemap)
+
+        index_sitemap = IndexRobotsTxtSitemap(url=self._url, sub_sitemaps=sub_sitemaps)
+
+        return index_sitemap
+
+
+class PlainTextSitemapParser(AbstractSitemapParser):
+    """Plain text sitemap parser."""
+
+    def sitemap(self) -> AbstractSitemap:
+
+        story_urls = OrderedDict()
+
+        for story_url in self._content.splitlines():
+            story_url = story_url.strip()
+            if not story_url:
+                continue
+            if is_http_url(story_url):
+                story_urls[story_url] = True
+            else:
+                log.warning("Story URL {} doesn't look like an URL, skipping".format(story_url))
+
+        pages = []
+        for page_url in story_urls.keys():
+            page = SitemapPage(url=page_url)
+            pages.append(page)
+
+        text_sitemap = PagesTextSitemap(url=self._url, pages=pages)
+
+        return text_sitemap
+
+
+class XMLSitemapParser(AbstractSitemapParser):
+    """XML sitemap parser."""
+
+    __XML_NAMESPACE_SEPARATOR = ' '
+
+    __slots__ = [
+        '_concrete_parser',
+    ]
+
+    def __init__(self, url: str, content: str, recursion_level: int, web_client: AbstractWebClient):
+        super().__init__(url=url, content=content, recursion_level=recursion_level, web_client=web_client)
+
+        # Will be initialized when the type of sitemap is known
+        self._concrete_parser = None
+
+    def sitemap(self) -> AbstractSitemap:
+
+        parser = xml.parsers.expat.ParserCreate(namespace_separator=self.__XML_NAMESPACE_SEPARATOR)
+        parser.StartElementHandler = self._xml_element_start
+        parser.EndElementHandler = self._xml_element_end
+        parser.CharacterDataHandler = self._xml_char_data
+
+        try:
+            is_final = True
+            parser.Parse(self._content, is_final)
+        except Exception as ex:
+            # Some sitemap XML files might end abruptly because webservers might be timing out on returning huge XML
+            # files so don't return InvalidSitemap() but try to get as much pages as possible
+            log.error("Parsing sitemap from URL {} failed: {}".format(self._url, ex))
+
+        if not self._concrete_parser:
+            return InvalidSitemap(
+                url=self._url,
+                reason="No parsers support sitemap from {}".format(self._url),
+            )
+
+        return self._concrete_parser.sitemap()
+
+    @classmethod
+    def __normalize_xml_element_name(cls, name: str):
+        """
+        Replace the namespace URL in the argument element name with internal namespace.
+
+        * Elements from http://www.sitemaps.org/schemas/sitemap/0.9 namespace will be prefixed with "sitemap:",
+          e.g. "<loc>" will become "<sitemap:loc>"
+
+        * Elements from http://www.google.com/schemas/sitemap-news/0.9 namespace will be prefixed with "news:",
+          e.g. "<publication>" will become "<news:publication>"
+
+        For non-sitemap namespaces, return the element name with the namespace stripped.
+
+        :param name: Namespace URL plus XML element name, e.g. "http://www.sitemaps.org/schemas/sitemap/0.9 loc"
+        :return: Internal namespace name plus element name, e.g. "sitemap loc"
+        """
+
+        name_parts = name.split(cls.__XML_NAMESPACE_SEPARATOR)
+
+        if len(name_parts) == 1:
+            namespace_url = ''
+            name = name_parts[0]
+
+        elif len(name_parts) == 2:
+            namespace_url = name_parts[0]
+            name = name_parts[1]
+
+        else:
+            raise SitemapXMLParsingException("Unable to determine namespace for element '{}'".format(name))
+
+        if '/sitemap/' in namespace_url:
+            name = 'sitemap:{}'.format(name)
+        elif '/sitemap-news/' in namespace_url:
+            name = 'news:{}'.format(name)
+        else:
+            # We don't care about the rest of the namespaces, so just keep the plain element name
+            pass
+
+        return name
+
+    def _xml_element_start(self, name: str, attrs: Dict[str, str]) -> None:
+
+        name = self.__normalize_xml_element_name(name)
+
+        if self._concrete_parser:
+            self._concrete_parser.xml_element_start(name=name, attrs=attrs)
+
+        else:
+
+            # Root element -- initialize concrete parser
+            if name == 'sitemap:urlset':
+                self._concrete_parser = PagesXMLSitemapParser(
+                    url=self._url,
+                )
+
+            elif name == 'sitemap:sitemapindex':
+                self._concrete_parser = IndexXMLSitemapParser(
+                    url=self._url,
+                    web_client=self._web_client,
+                    recursion_level=self._recursion_level,
+                )
+
+            elif name == 'rss':
+                self._concrete_parser = PagesRSSSitemapParser(
+                    url=self._url,
+                )
+
+            elif name == 'feed':
+                self._concrete_parser = PagesAtomSitemapParser(
+                    url=self._url,
+                )
+
+            else:
+                raise SitemapXMLParsingException("Unsupported root element '{}'.".format(name))
+
+    def _xml_element_end(self, name: str) -> None:
+
+        name = self.__normalize_xml_element_name(name)
+
+        if not self._concrete_parser:
+            raise SitemapXMLParsingException("Concrete sitemap parser should be set by now.")
+
+        self._concrete_parser.xml_element_end(name=name)
+
+    def _xml_char_data(self, data: str) -> None:
+
+        if not self._concrete_parser:
+            raise SitemapXMLParsingException("Concrete sitemap parser should be set by now.")
+
+        self._concrete_parser.xml_char_data(data=data)
+
+
+class AbstractXMLSitemapParser(object, metaclass=abc.ABCMeta):
+    """
+    Abstract XML sitemap parser.
+    """
+
+    __slots__ = [
+        # URL of the sitemap that is being parsed
+        '_url',
+
+        # Last encountered character data
+        '_last_char_data',
+
+        '_last_handler_call_was_xml_char_data',
+    ]
+
+    def __init__(self, url: str):
+        self._url = url
+        self._last_char_data = ''
+        self._last_handler_call_was_xml_char_data = False
+
+    def xml_element_start(self, name: str, attrs: Dict[str, str]) -> None:
+        self._last_handler_call_was_xml_char_data = False
+        pass
+
+    def xml_element_end(self, name: str) -> None:
+        # End of any element always resets last encountered character data
+        self._last_char_data = ''
+        self._last_handler_call_was_xml_char_data = False
+
+    def xml_char_data(self, data: str) -> None:
+        # Handler might be called multiple times for what essentially is a single string, e.g. in case of entities
+        # ("ABC &amp; DEF"), so this is why we're appending
+        if self._last_handler_call_was_xml_char_data:
+            self._last_char_data += data
+        else:
+            self._last_char_data = data
+
+        self._last_handler_call_was_xml_char_data = True
+
+    @abc.abstractmethod
+    def sitemap(self) -> AbstractSitemap:
+        raise NotImplementedError("Abstract method.")
+
+
+class IndexXMLSitemapParser(AbstractXMLSitemapParser):
+    """
+    Index XML sitemap parser.
+    """
+
+    __slots__ = [
+        '_web_client',
+        '_recursion_level',
+
+        # List of sub-sitemap URLs found in this index sitemap
+        '_sub_sitemap_urls',
+    ]
+
+    def __init__(self, url: str, web_client: AbstractWebClient, recursion_level: int):
+        super().__init__(url=url)
+
+        self._web_client = web_client
+        self._recursion_level = recursion_level
+        self._sub_sitemap_urls = []
+
+    def xml_element_end(self, name: str) -> None:
+
+        if name == 'sitemap:loc':
+            sub_sitemap_url = html_unescape_strip(self._last_char_data)
+            if not is_http_url(sub_sitemap_url):
+                log.warning("Sub-sitemap URL does not look like one: {}".format(sub_sitemap_url))
+
+            else:
+                if sub_sitemap_url not in self._sub_sitemap_urls:
+                    self._sub_sitemap_urls.append(sub_sitemap_url)
+
+        super().xml_element_end(name=name)
+
+    def sitemap(self) -> AbstractSitemap:
+
+        sub_sitemaps = []
+
+        for sub_sitemap_url in self._sub_sitemap_urls:
+
+            # URL might be invalid, or recursion limit might have been reached
+            try:
+                fetcher = SitemapFetcher(url=sub_sitemap_url,
+                                         recursion_level=self._recursion_level + 1,
+                                         web_client=self._web_client)
+                fetched_sitemap = fetcher.sitemap()
+            except Exception as ex:
+                fetched_sitemap = InvalidSitemap(
+                    url=sub_sitemap_url,
+                    reason="Unable to add sub-sitemap from URL {}: {}".format(sub_sitemap_url, str(ex)),
+                )
+
+            sub_sitemaps.append(fetched_sitemap)
+
+        index_sitemap = IndexXMLSitemap(url=self._url, sub_sitemaps=sub_sitemaps)
+
+        return index_sitemap
+
+
+class PagesXMLSitemapParser(AbstractXMLSitemapParser):
+    """
+    Pages XML sitemap parser.
+    """
+
+    class Page(object):
+        """Simple data class for holding various properties for a single <url> entry while parsing."""
+
+        __slots__ = [
+            'url',
+            'last_modified',
+            'change_frequency',
+            'priority',
+            'news_title',
+            'news_publish_date',
+            'news_publication_name',
+            'news_publication_language',
+            'news_access',
+            'news_genres',
+            'news_keywords',
+            'news_stock_tickers',
+        ]
+
+        def __init__(self):
+            self.url = None
+            self.last_modified = None
+            self.change_frequency = None
+            self.priority = None
+            self.news_title = None
+            self.news_publish_date = None
+            self.news_publication_name = None
+            self.news_publication_language = None
+            self.news_access = None
+            self.news_genres = None
+            self.news_keywords = None
+            self.news_stock_tickers = None
+
+        def __hash__(self):
+            return hash((
+                # Hash only the URL to be able to find unique ones
+                self.url,
+            ))
+
+        def page(self) -> Optional[SitemapPage]:
+            """Return constructed sitemap page if one has been completed, otherwise None."""
+
+            # Required
+            url = html_unescape_strip(self.url)
+            if not url:
+                log.error("URL is unset")
+                return None
+
+            last_modified = html_unescape_strip(self.last_modified)
+            if last_modified:
+                last_modified = parse_iso8601_date(last_modified)
+
+            change_frequency = html_unescape_strip(self.change_frequency)
+            if change_frequency:
+                change_frequency = change_frequency.lower()
+                if SitemapPageChangeFrequency.has_value(change_frequency):
+                    change_frequency = SitemapPageChangeFrequency(change_frequency)
+                else:
+                    log.warning("Invalid change frequency, defaulting to 'always'.".format(change_frequency))
+                    change_frequency = SitemapPageChangeFrequency.ALWAYS
+                assert isinstance(change_frequency, SitemapPageChangeFrequency)
+
+            priority = html_unescape_strip(self.priority)
+            if priority:
+                priority = Decimal(priority)
+
+                comp_zero = priority.compare(Decimal('0.0'))
+                comp_one = priority.compare(Decimal('1.0'))
+                if comp_zero in (Decimal('0'), Decimal('1') and comp_one in (Decimal('0'), Decimal('-1'))):
+                    # 0 <= priority <= 1
+                    pass
+                else:
+                    log.warning("Priority is not within 0 and 1: {}".format(priority))
+                    priority = SITEMAP_PAGE_DEFAULT_PRIORITY
+
+            else:
+                priority = SITEMAP_PAGE_DEFAULT_PRIORITY
+
+            news_title = html_unescape_strip(self.news_title)
+
+            news_publish_date = html_unescape_strip(self.news_publish_date)
+            if news_publish_date:
+                news_publish_date = parse_iso8601_date(date_string=news_publish_date)
+
+            news_publication_name = html_unescape_strip(self.news_publication_name)
+            news_publication_language = html_unescape_strip(self.news_publication_language)
+            news_access = html_unescape_strip(self.news_access)
+
+            news_genres = html_unescape_strip(self.news_genres)
+            if news_genres:
+                news_genres = [x.strip() for x in news_genres.split(',')]
+            else:
+                news_genres = []
+
+            news_keywords = html_unescape_strip(self.news_keywords)
+            if news_keywords:
+                news_keywords = [x.strip() for x in news_keywords.split(',')]
+            else:
+                news_keywords = []
+
+            news_stock_tickers = html_unescape_strip(self.news_stock_tickers)
+            if news_stock_tickers:
+                news_stock_tickers = [x.strip() for x in news_stock_tickers.split(',')]
+            else:
+                news_stock_tickers = []
+
+            sitemap_news_story = None
+            if news_title and news_publish_date:
+                sitemap_news_story = SitemapNewsStory(
+                    title=news_title,
+                    publish_date=news_publish_date,
+                    publication_name=news_publication_name,
+                    publication_language=news_publication_language,
+                    access=news_access,
+                    genres=news_genres,
+                    keywords=news_keywords,
+                    stock_tickers=news_stock_tickers,
+                )
+
+            return SitemapPage(
+                url=url,
+                last_modified=last_modified,
+                change_frequency=change_frequency,
+                priority=priority,
+                news_story=sitemap_news_story,
+            )
+
+    __slots__ = [
+        '_current_page',
+        '_pages',
+    ]
+
+    def __init__(self, url: str):
+        super().__init__(url=url)
+
+        self._current_page = None
+        self._pages = []
+
+    def xml_element_start(self, name: str, attrs: Dict[str, str]) -> None:
+
+        super().xml_element_start(name=name, attrs=attrs)
+
+        if name == 'sitemap:url':
+            if self._current_page:
+                raise SitemapXMLParsingException("Page is expected to be unset by <url>.")
+            self._current_page = self.Page()
+
+    def __require_last_char_data_to_be_set(self, name: str) -> None:
+        if not self._last_char_data:
+            raise SitemapXMLParsingException(
+                "Character data is expected to be set at the end of <{}>.".format(name)
+            )
+
+    def xml_element_end(self, name: str) -> None:
+
+        if not self._current_page and name != 'sitemap:urlset':
+            raise SitemapXMLParsingException("Page is expected to be set at the end of <{}>.".format(name))
+
+        if name == 'sitemap:url':
+            if self._current_page not in self._pages:
+                self._pages.append(self._current_page)
+            self._current_page = None
+
+        else:
+
+            if name == 'sitemap:loc':
+                # Every entry must have <loc>
+                self.__require_last_char_data_to_be_set(name=name)
+                self._current_page.url = self._last_char_data
+
+            elif name == 'sitemap:lastmod':
+                # Element might be present but character data might be empty
+                self._current_page.last_modified = self._last_char_data
+
+            elif name == 'sitemap:changefreq':
+                # Element might be present but character data might be empty
+                self._current_page.change_frequency = self._last_char_data
+
+            elif name == 'sitemap:priority':
+                # Element might be present but character data might be empty
+                self._current_page.priority = self._last_char_data
+
+            elif name == 'news:name':  # news/publication/name
+                # Element might be present but character data might be empty
+                self._current_page.news_publication_name = self._last_char_data
+
+            elif name == 'news:language':  # news/publication/language
+                # Element might be present but character data might be empty
+                self._current_page.news_publication_language = self._last_char_data
+
+            elif name == 'news:publication_date':
+                # Element might be present but character data might be empty
+                self._current_page.news_publish_date = self._last_char_data
+
+            elif name == 'news:title':
+                # Every Google News sitemap entry must have <title>
+                self.__require_last_char_data_to_be_set(name=name)
+                self._current_page.news_title = self._last_char_data
+
+            elif name == 'news:access':
+                # Element might be present but character data might be empty
+                self._current_page.news_access = self._last_char_data
+
+            elif name == 'news:keywords':
+                # Element might be present but character data might be empty
+                self._current_page.news_keywords = self._last_char_data
+
+            elif name == 'news:stock_tickers':
+                # Element might be present but character data might be empty
+                self._current_page.news_stock_tickers = self._last_char_data
+
+        super().xml_element_end(name=name)
+
+    def sitemap(self) -> AbstractSitemap:
+
+        pages = []
+
+        for page_row in self._pages:
+            page = page_row.page()
+            if page:
+                pages.append(page)
+
+        pages_sitemap = PagesXMLSitemap(url=self._url, pages=pages)
+
+        return pages_sitemap
+
+
+class PagesRSSSitemapParser(AbstractXMLSitemapParser):
+    """
+    Pages RSS 2.0 sitemap parser.
+
+    https://validator.w3.org/feed/docs/rss2.html
+    """
+
+    class Page(object):
+        """
+        Simple data class for holding various properties for a single <item> entry while parsing.
+        """
+
+        __slots__ = [
+            'link',
+            'title',
+            'description',
+            'publication_date',
+        ]
+
+        def __init__(self):
+            self.link = None
+            self.title = None
+            self.description = None
+            self.publication_date = None
+
+        def __hash__(self):
+            return hash((
+                # Hash only the URL
+                self.link,
+            ))
+
+        def page(self) -> Optional[SitemapPage]:
+            """Return constructed sitemap page if one has been completed, otherwise None."""
+
+            # Required
+            link = html_unescape_strip(self.link)
+            if not link:
+                log.error("Link is unset")
+                return None
+
+            title = html_unescape_strip(self.title)
+            description = html_unescape_strip(self.description)
+            if not (title or description):
+                log.error("Both title and description are unset")
+                return None
+
+            publication_date = html_unescape_strip(self.publication_date)
+            if publication_date:
+                publication_date = parse_rfc2822_date(publication_date)
+
+            return SitemapPage(
+                url=link,
+                news_story=SitemapNewsStory(
+                    title=title or description,
+                    publish_date=publication_date,
+                ),
+            )
+
+    __slots__ = [
+        '_current_page',
+        '_pages',
+    ]
+
+    def __init__(self, url: str):
+        super().__init__(url=url)
+
+        self._current_page = None
+        self._pages = []
+
+    def xml_element_start(self, name: str, attrs: Dict[str, str]) -> None:
+
+        super().xml_element_start(name=name, attrs=attrs)
+
+        if name == 'item':
+            if self._current_page:
+                raise SitemapXMLParsingException("Page is expected to be unset by <item>.")
+            self._current_page = self.Page()
+
+    def __require_last_char_data_to_be_set(self, name: str) -> None:
+        if not self._last_char_data:
+            raise SitemapXMLParsingException(
+                "Character data is expected to be set at the end of <{}>.".format(name)
+            )
+
+    def xml_element_end(self, name: str) -> None:
+
+        # If within <item> already
+        if self._current_page:
+
+            if name == 'item':
+                if self._current_page not in self._pages:
+                    self._pages.append(self._current_page)
+                self._current_page = None
+
+            else:
+
+                if name == 'link':
+                    # Every entry must have <link>
+                    self.__require_last_char_data_to_be_set(name=name)
+                    self._current_page.link = self._last_char_data
+
+                elif name == 'title':
+                    # Title (if set) can't be empty
+                    self.__require_last_char_data_to_be_set(name=name)
+                    self._current_page.title = self._last_char_data
+
+                elif name == 'description':
+                    # Description (if set) can't be empty
+                    self.__require_last_char_data_to_be_set(name=name)
+                    self._current_page.description = self._last_char_data
+
+                elif name == 'pubDate':
+                    # Element might be present but character data might be empty
+                    self._current_page.publication_date = self._last_char_data
+
+        super().xml_element_end(name=name)
+
+    def sitemap(self) -> AbstractSitemap:
+
+        pages = []
+
+        for page_row in self._pages:
+            page = page_row.page()
+            if page:
+                pages.append(page)
+
+        pages_sitemap = PagesRSSSitemap(url=self._url, pages=pages)
+
+        return pages_sitemap
+
+
+class PagesAtomSitemapParser(AbstractXMLSitemapParser):
+    """
+    Pages Atom 0.3 / 1.0 sitemap parser.
+
+    https://github.com/simplepie/simplepie-ng/wiki/Spec:-Atom-0.3
+    https://www.ietf.org/rfc/rfc4287.txt
+    http://rakaz.nl/2005/07/moving-from-atom-03-to-10.html
+    """
+
+    # FIXME merge with RSS parser class as there are too many similarities
+
+    class Page(object):
+        """Simple data class for holding various properties for a single <entry> entry while parsing."""
+
+        __slots__ = [
+            'link',
+            'title',
+            'description',
+            'publication_date',
+        ]
+
+        def __init__(self):
+            self.link = None
+            self.title = None
+            self.description = None
+            self.publication_date = None
+
+        def __hash__(self):
+            return hash((
+                # Hash only the URL
+                self.link,
+            ))
+
+        def page(self) -> Optional[SitemapPage]:
+            """Return constructed sitemap page if one has been completed, otherwise None."""
+
+            # Required
+            link = html_unescape_strip(self.link)
+            if not link:
+                log.error("Link is unset")
+                return None
+
+            title = html_unescape_strip(self.title)
+            description = html_unescape_strip(self.description)
+            if not (title or description):
+                log.error("Both title and description are unset")
+                return None
+
+            publication_date = html_unescape_strip(self.publication_date)
+            if publication_date:
+                publication_date = parse_rfc2822_date(publication_date)
+
+            return SitemapPage(
+                url=link,
+                news_story=SitemapNewsStory(
+                    title=title or description,
+                    publish_date=publication_date,
+                ),
+            )
+
+    __slots__ = [
+        '_current_page',
+        '_pages',
+        '_last_link_rel_self_href',
+    ]
+
+    def __init__(self, url: str):
+        super().__init__(url=url)
+
+        self._current_page = None
+        self._pages = []
+        self._last_link_rel_self_href = None
+
+    def xml_element_start(self, name: str, attrs: Dict[str, str]) -> None:
+
+        super().xml_element_start(name=name, attrs=attrs)
+
+        if name == 'entry':
+            if self._current_page:
+                raise SitemapXMLParsingException("Page is expected to be unset by <entry>.")
+            self._current_page = self.Page()
+
+        elif name == 'link':
+            if self._current_page:
+                if attrs.get('rel', 'self').lower() == 'self' or self._last_link_rel_self_href is None:
+                    self._last_link_rel_self_href = attrs.get('href', None)
+
+    def __require_last_char_data_to_be_set(self, name: str) -> None:
+        if not self._last_char_data:
+            raise SitemapXMLParsingException(
+                "Character data is expected to be set at the end of <{}>.".format(name)
+            )
+
+    def xml_element_end(self, name: str) -> None:
+
+        # If within <entry> already
+        if self._current_page:
+
+            if name == 'entry':
+
+                if self._last_link_rel_self_href:
+                    self._current_page.link = self._last_link_rel_self_href
+                    self._last_link_rel_self_href = None
+
+                    if self._current_page not in self._pages:
+                        self._pages.append(self._current_page)
+
+                self._current_page = None
+
+            else:
+
+                if name == 'title':
+                    # Title (if set) can't be empty
+                    self.__require_last_char_data_to_be_set(name=name)
+                    self._current_page.title = self._last_char_data
+
+                elif name == 'tagline' or name == 'summary':
+                    # Description (if set) can't be empty
+                    self.__require_last_char_data_to_be_set(name=name)
+                    self._current_page.description = self._last_char_data
+
+                elif name == 'issued' or name == 'published':
+                    # Element might be present but character data might be empty
+                    self._current_page.publication_date = self._last_char_data
+
+                elif name == 'updated':
+                    # No 'issued' or 'published' were set before
+                    if not self._current_page.publication_date:
+                        self._current_page.publication_date = self._last_char_data
+
+        super().xml_element_end(name=name)
+
+    def sitemap(self) -> AbstractSitemap:
+
+        pages = []
+
+        for page_row in self._pages:
+            page = page_row.page()
+            if page:
+                pages.append(page)
+
+        pages_sitemap = PagesAtomSitemap(url=self._url, pages=pages)
+
+        return pages_sitemap
Index: venv/Lib/site-packages/usp/helpers.py
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/venv/Lib/site-packages/usp/helpers.py b/venv/Lib/site-packages/usp/helpers.py
new file mode 100644
--- /dev/null	(date 1616406051465)
+++ b/venv/Lib/site-packages/usp/helpers.py	(date 1616406051465)
@@ -0,0 +1,257 @@
+"""Helper utilities."""
+
+import datetime
+import gzip as gzip_lib
+import html
+import re
+import time
+from typing import Optional
+from urllib.parse import urlparse, unquote_plus, urlunparse
+
+from dateutil.parser import parse as dateutil_parse
+
+from .exceptions import SitemapException, GunzipException, StripURLToHomepageException
+from .log import create_logger
+from .web_client.abstract_client import (
+    AbstractWebClient,
+    AbstractWebClientSuccessResponse,
+    WebClientErrorResponse,
+    AbstractWebClientResponse,
+)
+
+log = create_logger(__name__)
+
+__URL_REGEX = re.compile(r'^https?://[^\s/$.?#].[^\s]*$', re.IGNORECASE)
+"""Regular expression to match HTTP(s) URLs."""
+
+
+def is_http_url(url: str) -> bool:
+    """
+    Returns true if URL is of the "http" ("https") scheme.
+
+    :param url: URL to test.
+    :return: True if argument URL is of the "http" ("https") scheme.
+    """
+    if url is None:
+        log.debug("URL is None")
+        return False
+    if len(url) == 0:
+        log.debug("URL is empty")
+        return False
+
+    log.debug("Testing if URL '{}' is HTTP(s) URL".format(url))
+
+    if not re.search(__URL_REGEX, url):
+        log.debug("URL '{}' does not match URL's regexp".format(url))
+        return False
+
+    try:
+        # Try parsing the URL
+        uri = urlparse(url)
+        _ = urlunparse(uri)
+
+    except Exception as ex:
+        log.debug("Cannot parse URL {}: {}".format(url, ex))
+        return False
+
+    if not uri.scheme:
+        log.debug("Scheme is undefined for URL {}.".format(url))
+        return False
+    if not uri.scheme.lower() in ['http', 'https']:
+        log.debug("Scheme is not HTTP(s) for URL {}.".format(url))
+        return False
+    if not uri.hostname:
+        log.debug("Host is undefined for URL {}.".format(url))
+        return False
+
+    return True
+
+
+def html_unescape_strip(string: Optional[str]) -> Optional[str]:
+    """
+    Decode HTML entities, strip string, set to None if it's empty; ignore None as input.
+
+    :param string: String to decode HTML entities in.
+    :return: Stripped string with HTML entities decoded; None if parameter string was empty or None.
+    """
+    if string:
+        string = html.unescape(string)
+        string = string.strip()
+        if not string:
+            string = None
+    return string
+
+
+def parse_iso8601_date(date_string: str) -> datetime.datetime:
+    """
+    Parse ISO 8601 date (e.g. from sitemap's <publication_date>) into datetime.datetime object.
+
+    :param date_string: ISO 8601 date, e.g. "2018-01-12T21:57:27Z" or "1997-07-16T19:20:30+01:00".
+    :return: datetime.datetime object of a parsed date.
+    """
+    # FIXME parse known date formats faster
+
+    if not date_string:
+        raise SitemapException("Date string is unset.")
+
+    date = dateutil_parse(date_string)
+
+    return date
+
+
+def parse_rfc2822_date(date_string: str) -> datetime.datetime:
+    """
+    Parse RFC 2822 date (e.g. from Atom's <issued>) into datetime.datetime object.
+
+    :param date_string: RFC 2822 date, e.g. "Tue, 10 Aug 2010 20:43:53 -0000".
+    :return: datetime.datetime object of a parsed date.
+    """
+    # FIXME parse known date formats faster
+    return parse_iso8601_date(date_string)
+
+
+def get_url_retry_on_client_errors(url: str,
+                                   web_client: AbstractWebClient,
+                                   retry_count: int = 5,
+                                   sleep_between_retries: int = 1) -> AbstractWebClientResponse:
+    """
+    Fetch URL, retry on retryable errors.
+
+    :param url: URL to fetch.
+    :param web_client: Web client object to use for fetching.
+    :param retry_count: How many times to retry fetching the same URL.
+    :param sleep_between_retries: How long to sleep between retries, in seconds.
+    :return: Web client response object.
+    """
+    assert retry_count > 0, "Retry count must be positive."
+
+    response = None
+    for retry in range(0, retry_count):
+        log.info("Fetching URL {}...".format(url))
+        response = web_client.get(url)
+
+        if isinstance(response, WebClientErrorResponse):
+            log.warning(
+                "Request for URL {} failed: {}".format(
+                    url, response.message()
+                )
+            )
+
+            if response.retryable():
+                log.info("Retrying URL {} in {} seconds...".format(url, sleep_between_retries))
+                time.sleep(sleep_between_retries)
+
+            else:
+                log.info("Not retrying for URL {}".format(url))
+                return response
+
+        else:
+            return response
+
+    log.info("Giving up on URL {}".format(url))
+    return response
+
+
+def __response_is_gzipped_data(url: str, response: AbstractWebClientSuccessResponse) -> bool:
+    """
+    Return True if Response looks like it's gzipped.
+
+    :param url: URL the response was fetched from.
+    :param response: Response object.
+    :return: True if response looks like it might contain gzipped data.
+    """
+    uri = urlparse(url)
+    url_path = unquote_plus(uri.path)
+    content_type = response.header('content-type') or ''
+
+    if url_path.lower().endswith('.gz') or 'gzip' in content_type.lower():
+        return True
+
+    else:
+        return False
+
+
+def gunzip(data: bytes) -> bytes:
+    """
+    Gunzip data.
+
+    :param data: Gzipped data.
+    :return: Gunzipped data.
+    """
+
+    if data is None:
+        raise GunzipException("Data is None.")
+
+    if not isinstance(data, bytes):
+        raise GunzipException("Data is not bytes: %s" % str(data))
+
+    if len(data) == 0:
+        raise GunzipException("Data is empty (no way an empty string is a valid Gzip archive).")
+
+    try:
+        gunzipped_data = gzip_lib.decompress(data)
+    except Exception as ex:
+        raise GunzipException("Unable to gunzip data: %s" % str(ex))
+
+    if gunzipped_data is None:
+        raise GunzipException("Gunzipped data is None.")
+
+    if not isinstance(gunzipped_data, bytes):
+        raise GunzipException("Gunzipped data is not bytes.")
+
+    return gunzipped_data
+
+
+def ungzipped_response_content(url: str, response: AbstractWebClientSuccessResponse) -> str:
+    """
+    Return HTTP response's decoded content, gunzip it if necessary.
+
+    :param url: URL the response was fetched from.
+    :param response: Response object.
+    :return: Decoded and (if necessary) gunzipped response string.
+    """
+
+    data = response.raw_data()
+
+    if __response_is_gzipped_data(url=url, response=response):
+        try:
+            data = gunzip(data)
+        except GunzipException as ex:
+            # In case of an error, just assume that it's one of the non-gzipped sitemaps with ".gz" extension
+            log.error("Unable to gunzip response {}, maybe it's a non-gzipped sitemap: {}".format(response, ex))
+
+    # FIXME other encodings
+    data = data.decode('utf-8-sig', errors='replace')
+
+    assert isinstance(data, str)
+
+    return data
+
+
+def strip_url_to_homepage(url: str) -> str:
+    """
+    Strip URL to its homepage.
+
+    :param url: URL to strip, e.g. "http://www.example.com/page.html".
+    :return: Stripped homepage URL, e.g. "http://www.example.com/"
+    """
+    if not url:
+        raise StripURLToHomepageException("URL is empty.")
+
+    try:
+        uri = urlparse(url)
+        assert uri.scheme, "Scheme must be set."
+        assert uri.scheme.lower() in ['http', 'https'], "Scheme must be http:// or https://"
+        uri = (
+            uri.scheme,
+            uri.netloc,
+            '/',  # path
+            '',  # params
+            '',  # query
+            '',  # fragment
+        )
+        url = urlunparse(uri)
+    except Exception as ex:
+        raise StripURLToHomepageException("Unable to parse URL {}: {}".format(url, ex))
+
+    return url
Index: venv/Lib/site-packages/usp/log.py
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/venv/Lib/site-packages/usp/log.py b/venv/Lib/site-packages/usp/log.py
new file mode 100644
--- /dev/null	(date 1616406051465)
+++ b/venv/Lib/site-packages/usp/log.py	(date 1616406051465)
@@ -0,0 +1,91 @@
+"""Logging utilities."""
+
+import logging
+
+
+class Logger(object):
+    """
+    Logging helper class.
+    """
+
+    __LEVELS = {
+        'CRITICAL': logging.CRITICAL,
+        'ERROR': logging.ERROR,
+        'WARNING': logging.WARNING,
+        'INFO': logging.INFO,
+        'DEBUG': logging.DEBUG,
+    }
+    """Valid logging levels and their "logging" counterparts."""
+
+    __DEFAULT_LEVEL = 'INFO'
+    """Default logging level."""
+
+    __slots__ = [
+        # "logging" object
+        '__l',
+    ]
+
+    def __init__(self, name: str):
+        """
+        Initialize logger object for a given name.
+
+        :param name: Module name that the logger should be initialized for.
+        """
+
+        self.__l = logging.getLogger(name)
+        if not self.__l.handlers:
+            formatter = logging.Formatter(
+                fmt='%(asctime)s %(levelname)s %(name)s [%(process)d/%(threadName)s]: %(message)s'
+            )
+
+            handler = logging.StreamHandler()
+            handler.setFormatter(formatter)
+            self.__l.addHandler(handler)
+
+            self.__l.setLevel(self.__LEVELS[self.__DEFAULT_LEVEL])
+
+            # Don't propagate handler to root logger
+            # (http://stackoverflow.com/a/21127526/200603)
+            self.__l.propagate = False
+
+    def error(self, message: str) -> None:
+        """
+        Log error message.
+
+        :param message: Message to log.
+        """
+        self.__l.error(message)
+
+    def warning(self, message: str) -> None:
+        """
+        Log warning message.
+
+        :param message: Message to log.
+        """
+        self.__l.warning(message)
+
+    def info(self, message: str) -> None:
+        """
+        Log informational message.
+
+        :param message: Message to log.
+        """
+        self.__l.info(message)
+
+    def debug(self, message: str) -> None:
+        """
+        Log debugging message.
+
+        :param message: Message to log.
+        """
+        self.__l.debug(message)
+
+
+def create_logger(name: str) -> Logger:
+    """
+    Create and return Logger object.
+
+    :param name: Module name that the logger should be initialized for.
+    :return: Logger object.
+    """
+    return Logger(name=name)
Index: venv/Lib/site-packages/usp/tree.py
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/venv/Lib/site-packages/usp/tree.py b/venv/Lib/site-packages/usp/tree.py
new file mode 100644
--- /dev/null	(date 1616406051465)
+++ b/venv/Lib/site-packages/usp/tree.py	(date 1616406051465)
@@ -0,0 +1,80 @@
+"""Helpers to generate a sitemap tree."""
+
+from typing import Optional
+
+from .exceptions import SitemapException
+from .fetch_parse import SitemapFetcher
+from .helpers import is_http_url, strip_url_to_homepage
+from .log import create_logger
+from .objects.sitemap import AbstractSitemap, InvalidSitemap, IndexWebsiteSitemap, IndexRobotsTxtSitemap
+from .web_client.abstract_client import AbstractWebClient
+
+log = create_logger(__name__)
+
+_UNPUBLISHED_SITEMAP_PATHS = {
+    'sitemap.xml',
+    'sitemap.xml.gz',
+    'sitemap_index.xml',
+    'sitemap-index.xml',
+    'sitemap_index.xml.gz',
+    'sitemap-index.xml.gz',
+    '.sitemap.xml',
+    'sitemap',
+    'admin/config/search/xmlsitemap',
+    'sitemap/sitemap-index.xml',
+}
+"""Paths which are not exposed in robots.txt but might still contain a sitemap."""
+
+
+def sitemap_tree_for_homepage(homepage_url: str, web_client: Optional[AbstractWebClient] = None) -> AbstractSitemap:
+    """
+    Using a homepage URL, fetch the tree of sitemaps and pages listed in them.
+
+    :param homepage_url: Homepage URL of a website to fetch the sitemap tree for, e.g. "http://www.example.com/".
+    :param web_client: Web client implementation to use for fetching sitemaps.
+    :return: Root sitemap object of the fetched sitemap tree.
+    """
+
+    if not is_http_url(homepage_url):
+        raise SitemapException("URL {} is not a HTTP(s) URL.".format(homepage_url))
+
+    stripped_homepage_url = strip_url_to_homepage(url=homepage_url)
+    if homepage_url != stripped_homepage_url:
+        log.warning("Assuming that the homepage of {} is {}".format(homepage_url, stripped_homepage_url))
+        homepage_url = stripped_homepage_url
+
+    if not homepage_url.endswith('/'):
+        homepage_url += '/'
+    robots_txt_url = homepage_url + 'robots.txt'
+
+    sitemaps = []
+
+    robots_txt_fetcher = SitemapFetcher(url=robots_txt_url, web_client=web_client, recursion_level=0)
+    robots_txt_sitemap = robots_txt_fetcher.sitemap()
+    sitemaps.append(robots_txt_sitemap)
+
+    sitemap_urls_found_in_robots_txt = set()
+    if isinstance(robots_txt_sitemap, IndexRobotsTxtSitemap):
+        for sub_sitemap in robots_txt_sitemap.sub_sitemaps:
+            sitemap_urls_found_in_robots_txt.add(sub_sitemap.url)
+
+    for unpublished_sitemap_path in _UNPUBLISHED_SITEMAP_PATHS:
+        unpublished_sitemap_url = homepage_url + unpublished_sitemap_path
+
+        # Don't refetch URLs already found in robots.txt
+        if unpublished_sitemap_url not in sitemap_urls_found_in_robots_txt:
+
+            unpublished_sitemap_fetcher = SitemapFetcher(
+                url=unpublished_sitemap_url,
+                web_client=web_client,
+                recursion_level=0,
+            )
+            unpublished_sitemap = unpublished_sitemap_fetcher.sitemap()
+
+            # Skip the ones that weren't found
+            if not isinstance(unpublished_sitemap, InvalidSitemap):
+                sitemaps.append(unpublished_sitemap)
+
+    index_sitemap = IndexWebsiteSitemap(url=homepage_url, sub_sitemaps=sitemaps)
+
+    return index_sitemap
Index: venv/Lib/site-packages/usp/__about__.py
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/venv/Lib/site-packages/usp/__about__.py b/venv/Lib/site-packages/usp/__about__.py
new file mode 100644
--- /dev/null	(date 1616406051465)
+++ b/venv/Lib/site-packages/usp/__about__.py	(date 1616406051465)
@@ -0,0 +1,3 @@
+"""Package version."""
+
+__version__ = "0.5"
Index: venv/Lib/site-packages/usp/__init__.py
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/venv/Lib/site-packages/usp/__init__.py b/venv/Lib/site-packages/usp/__init__.py
new file mode 100644
--- /dev/null	(date 1616406051465)
+++ b/venv/Lib/site-packages/usp/__init__.py	(date 1616406051465)
@@ -0,0 +1,1 @@
+__all__ = ["tree"]
Index: venv/Lib/site-packages/usp/objects/page.py
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/venv/Lib/site-packages/usp/objects/page.py b/venv/Lib/site-packages/usp/objects/page.py
new file mode 100644
--- /dev/null	(date 1616406051465)
+++ b/venv/Lib/site-packages/usp/objects/page.py	(date 1616406051465)
@@ -0,0 +1,328 @@
+"""Objects that represent a page found in one of the sitemaps."""
+
+import datetime
+from decimal import Decimal
+from enum import Enum, unique
+from typing import List, Optional
+
+SITEMAP_PAGE_DEFAULT_PRIORITY = Decimal('0.5')
+"""Default sitemap page priority, as per the spec."""
+
+
+class SitemapNewsStory(object):
+    """
+    Single story derived from Google News XML sitemap.
+    """
+
+    __slots__ = [
+        '__title',
+        '__publish_date',
+        '__publication_name',
+        '__publication_language',
+        '__access',
+        '__genres',
+        '__keywords',
+        '__stock_tickers',
+    ]
+
+    def __init__(self,
+                 title: str,
+                 publish_date: datetime.datetime,
+                 publication_name: Optional[str] = None,
+                 publication_language: Optional[str] = None,
+                 access: Optional[str] = None,
+                 genres: List[str] = None,
+                 keywords: List[str] = None,
+                 stock_tickers: List[str] = None):
+        """
+        Initialize a new Google News story.
+
+        :param title: Story title.
+        :param publish_date: Story publication date.
+        :param publication_name: Name of the news publication in which the article appears in.
+        :param publication_language: Primary language of the news publication in which the article appears in.
+        :param access: Accessibility of the article.
+        :param genres: List of properties characterizing the content of the article.
+        :param keywords: List of keywords describing the topic of the article.
+        :param stock_tickers: List of up to 5 stock tickers that are the main subject of the article.
+        """
+
+        # Spec defines that some of the properties below are "required" but in practice not every website provides the
+        # required properties. So, we require only "title" and "publish_date" to be set.
+
+        self.__title = title
+        self.__publish_date = publish_date
+        self.__publication_name = publication_name
+        self.__publication_language = publication_language
+        self.__access = access
+        self.__genres = genres if genres else []
+        self.__keywords = keywords if keywords else []
+        self.__stock_tickers = stock_tickers if stock_tickers else []
+
+    def __eq__(self, other) -> bool:
+        if not isinstance(other, SitemapNewsStory):
+            raise NotImplemented
+
+        if self.title != other.title:
+            return False
+
+        if self.publish_date != other.publish_date:
+            return False
+
+        if self.publication_name != other.publication_name:
+            return False
+
+        if self.publication_language != other.publication_language:
+            return False
+
+        if self.access != other.access:
+            return False
+
+        if self.genres != other.genres:
+            return False
+
+        if self.keywords != other.keywords:
+            return False
+
+        if self.stock_tickers != other.stock_tickers:
+            return False
+
+        return True
+
+    def __hash__(self):
+        return hash((
+            self.title,
+            self.publish_date,
+            self.publication_name,
+            self.publication_language,
+            self.access,
+            self.genres,
+            self.keywords,
+            self.stock_tickers,
+        ))
+
+    def __repr__(self):
+        return (
+            "{self.__class__.__name__}("
+            "title={self.title}, "
+            "publish_date={self.publish_date}, "
+            "publication_name={self.publication_name}, "
+            "publication_language={self.publication_language}, "
+            "access={self.access}, "
+            "genres={self.genres}, "
+            "keywords={self.keywords}, "
+            "stock_tickers={self.stock_tickers}"
+            ")"
+        ).format(self=self)
+
+    @property
+    def title(self) -> str:
+        """
+        Return story title.
+
+        :return: Story title.
+        """
+        return self.__title
+
+    @property
+    def publish_date(self) -> datetime.datetime:
+        """
+        Return story publication date.
+
+        :return: Story publication date.
+        """
+        return self.__publish_date
+
+    @property
+    def publication_name(self) -> Optional[str]:
+        """
+        Return name of the news publication in which the article appears in.
+
+        :return: Name of the news publication in which the article appears in.
+        """
+        return self.__publication_name
+
+    @property
+    def publication_language(self) -> Optional[str]:
+        """Return primary language of the news publication in which the article appears in.
+
+        It should be an ISO 639 Language Code (either 2 or 3 letters).
+
+        :return: Primary language of the news publication in which the article appears in.
+        """
+        return self.__publication_language
+
+    @property
+    def access(self) -> Optional[str]:
+        """
+        Return accessibility of the article.
+
+        :return: Accessibility of the article.
+        """
+        return self.__access
+
+    @property
+    def genres(self) -> List[str]:
+        """
+        Return list of properties characterizing the content of the article.
+
+        Returns genres such as "PressRelease" or "UserGenerated".
+
+        :return: List of properties characterizing the content of the article
+        """
+        return self.__genres
+
+    @property
+    def keywords(self) -> List[str]:
+        """
+        Return list of keywords describing the topic of the article.
+
+        :return: List of keywords describing the topic of the article.
+        """
+        return self.__keywords
+
+    @property
+    def stock_tickers(self) -> List[str]:
+        """
+        Return list of up to 5 stock tickers that are the main subject of the article.
+
+        Each ticker must be prefixed by the name of its stock exchange, and must match its entry in Google Finance.
+        For example, "NASDAQ:AMAT" (but not "NASD:AMAT"), or "BOM:500325" (but not "BOM:RIL").
+
+        :return: List of up to 5 stock tickers that are the main subject of the article.
+        """
+        return self.__stock_tickers
+
+
+@unique
+class SitemapPageChangeFrequency(Enum):
+    """Change frequency of a sitemap URL."""
+
+    ALWAYS = 'always'
+    HOURLY = 'hourly'
+    DAILY = 'daily'
+    WEEKLY = 'weekly'
+    MONTHLY = 'monthly'
+    YEARLY = 'yearly'
+    NEVER = 'never'
+
+    @classmethod
+    def has_value(cls, value: str) -> bool:
+        """Test if enum has specified value."""
+        return any(value == item.value for item in cls)
+
+
+class SitemapPage(object):
+    """Single sitemap-derived page."""
+
+    __slots__ = [
+        '__url',
+        '__priority',
+        '__last_modified',
+        '__change_frequency',
+        '__news_story',
+    ]
+
+    def __init__(self,
+                 url: str,
+                 priority: Decimal = SITEMAP_PAGE_DEFAULT_PRIORITY,
+                 last_modified: Optional[datetime.datetime] = None,
+                 change_frequency: Optional[SitemapPageChangeFrequency] = None,
+                 news_story: Optional[SitemapNewsStory] = None):
+        """
+        Initialize a new sitemap-derived page.
+
+        :param url: Page URL.
+        :param priority: Priority of this URL relative to other URLs on your site.
+        :param last_modified: Date of last modification of the URL.
+        :param change_frequency: Change frequency of a sitemap URL.
+        :param news_story: Google News story attached to the URL.
+        """
+        self.__url = url
+        self.__priority = priority
+        self.__last_modified = last_modified
+        self.__change_frequency = change_frequency
+        self.__news_story = news_story
+
+    def __eq__(self, other) -> bool:
+        if not isinstance(other, SitemapPage):
+            raise NotImplemented
+
+        if self.url != other.url:
+            return False
+
+        if self.priority != other.priority:
+            return False
+
+        if self.last_modified != other.last_modified:
+            return False
+
+        if self.change_frequency != other.change_frequency:
+            return False
+
+        if self.news_story != other.news_story:
+            return False
+
+        return True
+
+    def __hash__(self):
+        return hash((
+            # Hash only the URL to be able to find unique pages later on
+            self.url,
+        ))
+
+    def __repr__(self):
+        return (
+            "{self.__class__.__name__}("
+            "url={self.url}, "
+            "priority={self.priority}, "
+            "last_modified={self.last_modified}, "
+            "change_frequency={self.change_frequency}, "
+            "news_story={self.news_story}"
+            ")"
+        ).format(self=self)
+
+    @property
+    def url(self) -> str:
+        """
+        Return page URL.
+
+        :return: Page URL.
+        """
+        return self.__url
+
+    @property
+    def priority(self) -> Decimal:
+        """
+        Return priority of this URL relative to other URLs on your site.
+
+        :return: Priority of this URL relative to other URLs on your site.
+        """
+        return self.__priority
+
+    @property
+    def last_modified(self) -> Optional[datetime.datetime]:
+        """
+        Return date of last modification of the URL.
+
+        :return: Date of last modification of the URL.
+        """
+        return self.__last_modified
+
+    @property
+    def change_frequency(self) -> Optional[SitemapPageChangeFrequency]:
+        """
+        Return change frequency of a sitemap URL.
+
+        :return: Change frequency of a sitemap URL.
+        """
+        return self.__change_frequency
+
+    @property
+    def news_story(self) -> Optional[SitemapNewsStory]:
+        """
+        Return Google News story attached to the URL.
+
+        :return: Google News story attached to the URL.
+        """
+        return self.__news_story
Index: venv/Lib/site-packages/usp/objects/sitemap.py
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/venv/Lib/site-packages/usp/objects/sitemap.py b/venv/Lib/site-packages/usp/objects/sitemap.py
new file mode 100644
--- /dev/null	(date 1616406051465)
+++ b/venv/Lib/site-packages/usp/objects/sitemap.py	(date 1616406051465)
@@ -0,0 +1,293 @@
+"""Objects that represent one of the found sitemaps."""
+
+import abc
+import os
+import pickle
+import tempfile
+from typing import List, Iterator
+
+from .page import SitemapPage
+
+
+class AbstractSitemap(object, metaclass=abc.ABCMeta):
+    """
+    Abstract sitemap.
+    """
+
+    __slots__ = [
+        '__url',
+    ]
+
+    def __init__(self, url: str):
+        """
+        Initialize a new sitemap.
+
+        :param url: Sitemap URL.
+        """
+        self.__url = url
+
+    def __eq__(self, other) -> bool:
+        if not isinstance(other, AbstractSitemap):
+            raise NotImplemented
+
+        if self.url != other.url:
+            return False
+
+        return True
+
+    def __hash__(self):
+        return hash((
+            self.url,
+        ))
+
+    def __repr__(self):
+        return (
+            "{self.__class__.__name__}("
+            "url={self.url}"
+            ")"
+        ).format(self=self)
+
+    @property
+    def url(self) -> str:
+        """
+        Return sitemap URL.
+
+        :return: Sitemap URL.
+        """
+        return self.__url
+
+    @abc.abstractmethod
+    def all_pages(self) -> Iterator[SitemapPage]:
+        """
+        Return iterator which yields all pages of this sitemap and linked sitemaps (if any).
+
+        :return: Iterator which yields all pages of this sitemap and linked sitemaps (if any).
+        """
+        raise NotImplementedError("Abstract method")
+
+
+class InvalidSitemap(AbstractSitemap):
+    """Invalid sitemap, e.g. the one that can't be parsed."""
+
+    __slots__ = [
+        '__reason',
+    ]
+
+    def __init__(self, url: str, reason: str):
+        """
+        Initialize a new invalid sitemap.
+
+        :param url: Sitemap URL.
+        :param reason: Reason why the sitemap is deemed invalid.
+        """
+        super().__init__(url=url)
+        self.__reason = reason
+
+    def __eq__(self, other) -> bool:
+        if not isinstance(other, InvalidSitemap):
+            raise NotImplemented
+
+        if self.url != other.url:
+            return False
+
+        if self.reason != other.reason:
+            return False
+
+        return True
+
+    def __repr__(self):
+        return (
+            "{self.__class__.__name__}("
+            "url={self.url}, "
+            "reason={self.reason}"
+            ")"
+        ).format(self=self)
+
+    @property
+    def reason(self) -> str:
+        """
+        Return reason why the sitemap is deemed invalid.
+
+        :return: Reason why the sitemap is deemed invalid.
+        """
+        return self.__reason
+
+    def all_pages(self) -> Iterator[SitemapPage]:
+        """
+        Return iterator which yields all pages of this sitemap and linked sitemaps (if any).
+
+        :return: Iterator which yields all pages of this sitemap and linked sitemaps (if any).
+        """
+        yield from []
+
+
+class AbstractPagesSitemap(AbstractSitemap, metaclass=abc.ABCMeta):
+    """Abstract sitemap that contains URLs to pages."""
+
+    __slots__ = [
+        '__pages_temp_file_path',
+    ]
+
+    def __init__(self, url: str, pages: List[SitemapPage]):
+        """
+        Initialize new pages sitemap.
+
+        :param url: Sitemap URL.
+        :param pages: List of pages found in a sitemap.
+        """
+        super().__init__(url=url)
+
+        temp_file, self.__pages_temp_file_path = tempfile.mkstemp()
+        with os.fdopen(temp_file, 'wb') as tmp:
+            pickle.dump(pages, tmp, protocol=pickle.HIGHEST_PROTOCOL)
+
+    def __del__(self):
+        os.unlink(self.__pages_temp_file_path)
+
+    def __eq__(self, other) -> bool:
+        if not isinstance(other, AbstractPagesSitemap):
+            raise NotImplemented
+
+        if self.url != other.url:
+            return False
+
+        if self.pages != other.pages:
+            return False
+
+        return True
+
+    def __repr__(self):
+        return (
+            "{self.__class__.__name__}("
+            "url={self.url}, "
+            "pages={self.pages}"
+            ")"
+        ).format(self=self)
+
+    @property
+    def pages(self) -> List[SitemapPage]:
+        """
+        Return list of pages found in a sitemap.
+
+        :return: List of pages found in a sitemap.
+        """
+        with open(self.__pages_temp_file_path, 'rb') as tmp:
+            pages = pickle.load(tmp)
+        return pages
+
+    def all_pages(self) -> Iterator[SitemapPage]:
+        """
+        Return iterator which yields all pages of this sitemap and linked sitemaps (if any).
+
+        :return: Iterator which yields all pages of this sitemap and linked sitemaps (if any).
+        """
+        for page in self.pages:
+            yield page
+
+
+class PagesXMLSitemap(AbstractPagesSitemap):
+    """
+    XML sitemap that contains URLs to pages.
+    """
+    pass
+
+
+class PagesTextSitemap(AbstractPagesSitemap):
+    """
+    Plain text sitemap that contains URLs to pages.
+    """
+    pass
+
+
+class PagesRSSSitemap(AbstractPagesSitemap):
+    """
+    RSS 2.0 sitemap that contains URLs to pages.
+    """
+    pass
+
+
+class PagesAtomSitemap(AbstractPagesSitemap):
+    """
+    RSS 0.3 / 1.0 sitemap that contains URLs to pages.
+    """
+    pass
+
+
+class AbstractIndexSitemap(AbstractSitemap):
+    """
+    Abstract sitemap with URLs to other sitemaps.
+    """
+
+    __slots__ = [
+        '__sub_sitemaps',
+    ]
+
+    def __init__(self, url: str, sub_sitemaps: List[AbstractSitemap]):
+        """
+        Initialize index sitemap.
+
+        :param url: Sitemap URL.
+        :param sub_sitemaps: Sub-sitemaps that are linked to from this sitemap.
+        """
+        super().__init__(url=url)
+        self.__sub_sitemaps = sub_sitemaps
+
+    def __eq__(self, other) -> bool:
+        if not isinstance(other, AbstractIndexSitemap):
+            raise NotImplemented
+
+        if self.url != other.url:
+            return False
+
+        if self.sub_sitemaps != other.sub_sitemaps:
+            return False
+
+        return True
+
+    def __repr__(self):
+        return (
+            "{self.__class__.__name__}("
+            "url={self.url}, "
+            "sub_sitemaps={self.sub_sitemaps}"
+            ")"
+        ).format(self=self)
+
+    @property
+    def sub_sitemaps(self) -> List[AbstractSitemap]:
+        """
+        Return sub-sitemaps that are linked to from this sitemap.
+
+        :return: Sub-sitemaps that are linked to from this sitemap.
+        """
+        return self.__sub_sitemaps
+
+    def all_pages(self) -> Iterator[SitemapPage]:
+        """
+        Return iterator which yields all pages of this sitemap and linked sitemaps (if any).
+
+        :return: Iterator which yields all pages of this sitemap and linked sitemaps (if any).
+        """
+        for sub_sitemap in self.sub_sitemaps:
+            for page in sub_sitemap.all_pages():
+                yield page
+
+
+class IndexWebsiteSitemap(AbstractIndexSitemap):
+    """
+    Website's root sitemaps, including robots.txt and extra ones.
+    """
+    pass
+
+
+class IndexXMLSitemap(AbstractIndexSitemap):
+    """
+    XML sitemap with URLs to other sitemaps.
+    """
+    pass
+
+
+class IndexRobotsTxtSitemap(AbstractIndexSitemap):
+    """
+    robots.txt sitemap with URLs to other sitemaps.
+    """
+    pass
Index: venv/Lib/site-packages/usp/web_client/abstract_client.py
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/venv/Lib/site-packages/usp/web_client/abstract_client.py b/venv/Lib/site-packages/usp/web_client/abstract_client.py
new file mode 100644
--- /dev/null	(date 1616406051465)
+++ b/venv/Lib/site-packages/usp/web_client/abstract_client.py	(date 1616406051465)
@@ -0,0 +1,183 @@
+"""Abstract web client class."""
+
+import abc
+from http import HTTPStatus
+from typing import Optional
+
+RETRYABLE_HTTP_STATUS_CODES = {
+
+    # Some servers return "400 Bad Request" initially but upon retry start working again, no idea why
+    HTTPStatus.BAD_REQUEST.value,
+
+    # If we timed out requesting stuff, we can just try again
+    HTTPStatus.REQUEST_TIMEOUT.value,
+
+    # If we got rate limited, it makes sense to wait a bit
+    HTTPStatus.TOO_MANY_REQUESTS.value,
+
+    # Server might be just fine on a subsequent attempt
+    HTTPStatus.INTERNAL_SERVER_ERROR.value,
+
+    # Upstream might reappear on a retry
+    HTTPStatus.BAD_GATEWAY.value,
+
+    # Service might become available again on a retry
+    HTTPStatus.SERVICE_UNAVAILABLE.value,
+
+    # Upstream might reappear on a retry
+    HTTPStatus.GATEWAY_TIMEOUT.value,
+
+    # (unofficial) 509 Bandwidth Limit Exceeded (Apache Web Server/cPanel)
+    509,
+
+    # (unofficial) 598 Network read timeout error
+    598,
+
+    # (unofficial, nginx) 499 Client Closed Request
+    499,
+
+    # (unofficial, Cloudflare) 520 Unknown Error
+    520,
+
+    # (unofficial, Cloudflare) 521 Web Server Is Down
+    521,
+
+    # (unofficial, Cloudflare) 522 Connection Timed Out
+    522,
+
+    # (unofficial, Cloudflare) 523 Origin Is Unreachable
+    523,
+
+    # (unofficial, Cloudflare) 524 A Timeout Occurred
+    524,
+
+    # (unofficial, Cloudflare) 525 SSL Handshake Failed
+    525,
+
+    # (unofficial, Cloudflare) 526 Invalid SSL Certificate
+    526,
+
+    # (unofficial, Cloudflare) 527 Railgun Error
+    527,
+
+    # (unofficial, Cloudflare) 530 Origin DNS Error
+    530,
+
+}
+"""HTTP status codes on which a request should be retried."""
+
+
+class AbstractWebClientResponse(object, metaclass=abc.ABCMeta):
+    """
+    Abstract response.
+    """
+    pass
+
+
+class AbstractWebClientSuccessResponse(AbstractWebClientResponse, metaclass=abc.ABCMeta):
+    """
+    Successful response.
+    """
+
+    @abc.abstractmethod
+    def status_code(self) -> int:
+        """
+        Return HTTP status code of the response.
+
+        :return: HTTP status code of the response, e.g. 200.
+        """
+        raise NotImplementedError("Abstract method.")
+
+    @abc.abstractmethod
+    def status_message(self) -> str:
+        """
+        Return HTTP status message of the response.
+
+        :return: HTTP status message of the response, e.g. "OK".
+        """
+        raise NotImplementedError("Abstract method.")
+
+    @abc.abstractmethod
+    def header(self, case_insensitive_name: str) -> Optional[str]:
+        """
+        Return HTTP header value for a given case-insensitive name, or None if such header wasn't set.
+
+        :param case_insensitive_name: HTTP header's name, e.g. "Content-Type".
+        :return: HTTP header's value, or None if it was unset.
+        """
+        raise NotImplementedError("Abstract method.")
+
+    @abc.abstractmethod
+    def raw_data(self) -> bytes:
+        """
+        Return encoded raw data of the response.
+
+        :return: Encoded raw data of the response.
+        """
+        raise NotImplementedError("Abstract method.")
+
+
+class WebClientErrorResponse(AbstractWebClientResponse, metaclass=abc.ABCMeta):
+    """
+    Error response.
+    """
+
+    __slots__ = [
+        '_message',
+        '_retryable',
+    ]
+
+    def __init__(self, message: str, retryable: bool):
+        """
+        Constructor.
+
+        :param message: Message describing what went wrong.
+        :param retryable: True if the request should be retried.
+        """
+        super().__init__()
+        self._message = message
+        self._retryable = retryable
+
+    def message(self) -> str:
+        """
+        Return message describing what went wrong.
+
+        :return: Message describing what went wrong.
+        """
+        return self._message
+
+    def retryable(self) -> bool:
+        """
+        Return True if request should be retried.
+
+        :return: True if request should be retried.
+        """
+        return self._retryable
+
+
+class AbstractWebClient(object, metaclass=abc.ABCMeta):
+    """
+    Abstract web client to be used by the sitemap fetcher.
+    """
+
+    @abc.abstractmethod
+    def set_max_response_data_length(self, max_response_data_length: int) -> None:
+        """
+        Set the maximum number of bytes that the web client will fetch.
+
+        :param max_response_data_length: Maximum number of bytes that the web client will fetch.
+        """
+        raise NotImplementedError("Abstract method.")
+
+    @abc.abstractmethod
+    def get(self, url: str) -> AbstractWebClientResponse:
+        """
+        Fetch an URL and return a response.
+
+        Method shouldn't throw exceptions on connection errors (including timeouts); instead, such errors should be
+        reported via Response object.
+
+        :param url: URL to fetch.
+        :return: Response object.
+        """
+        raise NotImplementedError("Abstract method.")
Index: venv/Lib/site-packages/usp/web_client/requests_client.py
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/venv/Lib/site-packages/usp/web_client/requests_client.py b/venv/Lib/site-packages/usp/web_client/requests_client.py
new file mode 100644
--- /dev/null	(date 1616406051465)
+++ b/venv/Lib/site-packages/usp/web_client/requests_client.py	(date 1616406051465)
@@ -0,0 +1,119 @@
+"""requests-based implementation of web client class."""
+
+from http import HTTPStatus
+from typing import Optional
+
+import requests
+
+from .abstract_client import (
+    AbstractWebClient,
+    AbstractWebClientResponse,
+    AbstractWebClientSuccessResponse,
+    WebClientErrorResponse,
+    RETRYABLE_HTTP_STATUS_CODES,
+)
+from usp.__about__ import __version__
+
+
+class RequestsWebClientSuccessResponse(AbstractWebClientSuccessResponse):
+    """
+    requests-based successful response.
+    """
+
+    __slots__ = [
+        '__requests_response',
+        '__max_response_data_length',
+    ]
+
+    def __init__(self, requests_response: requests.Response, max_response_data_length: Optional[int] = None):
+        self.__requests_response = requests_response
+        self.__max_response_data_length = max_response_data_length
+
+    def status_code(self) -> int:
+        return int(self.__requests_response.status_code)
+
+    def status_message(self) -> str:
+        message = self.__requests_response.reason
+        if not message:
+            message = HTTPStatus(self.status_code(), None).phrase
+        return message
+
+    def header(self, case_insensitive_name: str) -> Optional[str]:
+        return self.__requests_response.headers.get(case_insensitive_name.lower(), None)
+
+    def raw_data(self) -> bytes:
+        if self.__max_response_data_length:
+            data = self.__requests_response.content[:self.__max_response_data_length]
+        else:
+            data = self.__requests_response.content
+
+        return data
+
+
+class RequestsWebClientErrorResponse(WebClientErrorResponse):
+    """
+    requests-based error response.
+    """
+    pass
+
+
+class RequestsWebClient(AbstractWebClient):
+    """requests-based web client to be used by the sitemap fetcher."""
+
+    __USER_AGENT = 'ultimate_sitemap_parser/{}'.format(__version__)
+
+    __HTTP_REQUEST_TIMEOUT = 60
+    """
+    HTTP request timeout.
+
+    Some webservers might be generating huge sitemaps on the fly, so this is why it's rather big.
+    """
+
+    __slots__ = [
+        '__max_response_data_length',
+        '__timeout',
+    ]
+
+    def __init__(self):
+        self.__max_response_data_length = None
+        self.__timeout = self.__HTTP_REQUEST_TIMEOUT
+
+    def set_timeout(self, timeout: int) -> None:
+        """Set HTTP request timeout."""
+        # Used mostly for testing
+        self.__timeout = timeout
+
+    def set_max_response_data_length(self, max_response_data_length: int) -> None:
+        self.__max_response_data_length = max_response_data_length
+
+    def get(self, url: str) -> AbstractWebClientResponse:
+        try:
+            response = requests.get(
+                url,
+                timeout=self.__timeout,
+                stream=True,
+                headers={'User-Agent': self.__USER_AGENT},
+            )
+        except requests.exceptions.Timeout as ex:
+            # Retryable timeouts
+            return RequestsWebClientErrorResponse(message=str(ex), retryable=True)
+
+        except requests.exceptions.RequestException as ex:
+            # Other errors, e.g. redirect loops
+            return RequestsWebClientErrorResponse(message=str(ex), retryable=False)
+
+        else:
+
+            if 200 <= response.status_code < 300:
+                return RequestsWebClientSuccessResponse(
+                    requests_response=response,
+                    max_response_data_length=self.__max_response_data_length,
+                )
+            else:
+
+                message = '{} {}'.format(response.status_code, response.reason)
+
+                if response.status_code in RETRYABLE_HTTP_STATUS_CODES:
+                    return RequestsWebClientErrorResponse(message=message, retryable=True)
+                else:
+                    return RequestsWebClientErrorResponse(message=message, retryable=False)
Index: latest/Lib/site-packages/psycopg2/compat.py
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/latest/Lib/site-packages/psycopg2/compat.py b/latest/Lib/site-packages/psycopg2/compat.py
new file mode 100644
--- /dev/null	(date 1616409347254)
+++ b/latest/Lib/site-packages/psycopg2/compat.py	(date 1616409347254)
@@ -0,0 +1,19 @@
+import sys
+
+__all__ = ['string_types', 'text_type', 'lru_cache']
+
+if sys.version_info[0] == 2:
+    # Python 2
+    PY2 = True
+    PY3 = False
+    string_types = basestring,
+    text_type = unicode
+    from ._lru_cache import lru_cache
+
+else:
+    # Python 3
+    PY2 = False
+    PY3 = True
+    string_types = str,
+    text_type = str
+    from functools import lru_cache
Index: latest/Lib/site-packages/psycopg2/errorcodes.py
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/latest/Lib/site-packages/psycopg2/errorcodes.py b/latest/Lib/site-packages/psycopg2/errorcodes.py
new file mode 100644
--- /dev/null	(date 1616409347256)
+++ b/latest/Lib/site-packages/psycopg2/errorcodes.py	(date 1616409347256)
@@ -0,0 +1,447 @@
+"""Error codes for PostgresSQL
+
+This module contains symbolic names for all PostgreSQL error codes.
+"""
+# psycopg2/errorcodes.py - PostgreSQL error codes
+#
+# Copyright (C) 2006-2019 Johan Dahlin  <jdahlin@async.com.br>
+# Copyright (C) 2020 The Psycopg Team
+#
+# psycopg2 is free software: you can redistribute it and/or modify it
+# under the terms of the GNU Lesser General Public License as published
+# by the Free Software Foundation, either version 3 of the License, or
+# (at your option) any later version.
+#
+# In addition, as a special exception, the copyright holders give
+# permission to link this program with the OpenSSL library (or with
+# modified versions of OpenSSL that use the same license as OpenSSL),
+# and distribute linked combinations including the two.
+#
+# You must obey the GNU Lesser General Public License in all respects for
+# all of the code used other than OpenSSL.
+#
+# psycopg2 is distributed in the hope that it will be useful, but WITHOUT
+# ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or
+# FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public
+# License for more details.
+#
+# Based on:
+#
+#   https://www.postgresql.org/docs/current/static/errcodes-appendix.html
+#
+
+
+def lookup(code, _cache={}):
+    """Lookup an error code or class code and return its symbolic name.
+
+    Raise `KeyError` if the code is not found.
+    """
+    if _cache:
+        return _cache[code]
+
+    # Generate the lookup map at first usage.
+    tmp = {}
+    for k, v in globals().items():
+        if isinstance(v, str) and len(v) in (2, 5):
+            # Strip trailing underscore used to disambiguate duplicate values
+            tmp[v] = k.rstrip("_")
+
+    assert tmp
+
+    # Atomic update, to avoid race condition on import (bug #382)
+    _cache.update(tmp)
+
+    return _cache[code]
+
+
+# autogenerated data: do not edit below this point.
+
+# Error classes
+CLASS_SUCCESSFUL_COMPLETION = '00'
+CLASS_WARNING = '01'
+CLASS_NO_DATA = '02'
+CLASS_SQL_STATEMENT_NOT_YET_COMPLETE = '03'
+CLASS_CONNECTION_EXCEPTION = '08'
+CLASS_TRIGGERED_ACTION_EXCEPTION = '09'
+CLASS_FEATURE_NOT_SUPPORTED = '0A'
+CLASS_INVALID_TRANSACTION_INITIATION = '0B'
+CLASS_LOCATOR_EXCEPTION = '0F'
+CLASS_INVALID_GRANTOR = '0L'
+CLASS_INVALID_ROLE_SPECIFICATION = '0P'
+CLASS_DIAGNOSTICS_EXCEPTION = '0Z'
+CLASS_CASE_NOT_FOUND = '20'
+CLASS_CARDINALITY_VIOLATION = '21'
+CLASS_DATA_EXCEPTION = '22'
+CLASS_INTEGRITY_CONSTRAINT_VIOLATION = '23'
+CLASS_INVALID_CURSOR_STATE = '24'
+CLASS_INVALID_TRANSACTION_STATE = '25'
+CLASS_INVALID_SQL_STATEMENT_NAME = '26'
+CLASS_TRIGGERED_DATA_CHANGE_VIOLATION = '27'
+CLASS_INVALID_AUTHORIZATION_SPECIFICATION = '28'
+CLASS_DEPENDENT_PRIVILEGE_DESCRIPTORS_STILL_EXIST = '2B'
+CLASS_INVALID_TRANSACTION_TERMINATION = '2D'
+CLASS_SQL_ROUTINE_EXCEPTION = '2F'
+CLASS_INVALID_CURSOR_NAME = '34'
+CLASS_EXTERNAL_ROUTINE_EXCEPTION = '38'
+CLASS_EXTERNAL_ROUTINE_INVOCATION_EXCEPTION = '39'
+CLASS_SAVEPOINT_EXCEPTION = '3B'
+CLASS_INVALID_CATALOG_NAME = '3D'
+CLASS_INVALID_SCHEMA_NAME = '3F'
+CLASS_TRANSACTION_ROLLBACK = '40'
+CLASS_SYNTAX_ERROR_OR_ACCESS_RULE_VIOLATION = '42'
+CLASS_WITH_CHECK_OPTION_VIOLATION = '44'
+CLASS_INSUFFICIENT_RESOURCES = '53'
+CLASS_PROGRAM_LIMIT_EXCEEDED = '54'
+CLASS_OBJECT_NOT_IN_PREREQUISITE_STATE = '55'
+CLASS_OPERATOR_INTERVENTION = '57'
+CLASS_SYSTEM_ERROR = '58'
+CLASS_SNAPSHOT_FAILURE = '72'
+CLASS_CONFIGURATION_FILE_ERROR = 'F0'
+CLASS_FOREIGN_DATA_WRAPPER_ERROR = 'HV'
+CLASS_PL_PGSQL_ERROR = 'P0'
+CLASS_INTERNAL_ERROR = 'XX'
+
+# Class 00 - Successful Completion
+SUCCESSFUL_COMPLETION = '00000'
+
+# Class 01 - Warning
+WARNING = '01000'
+NULL_VALUE_ELIMINATED_IN_SET_FUNCTION = '01003'
+STRING_DATA_RIGHT_TRUNCATION_ = '01004'
+PRIVILEGE_NOT_REVOKED = '01006'
+PRIVILEGE_NOT_GRANTED = '01007'
+IMPLICIT_ZERO_BIT_PADDING = '01008'
+DYNAMIC_RESULT_SETS_RETURNED = '0100C'
+DEPRECATED_FEATURE = '01P01'
+
+# Class 02 - No Data (this is also a warning class per the SQL standard)
+NO_DATA = '02000'
+NO_ADDITIONAL_DYNAMIC_RESULT_SETS_RETURNED = '02001'
+
+# Class 03 - SQL Statement Not Yet Complete
+SQL_STATEMENT_NOT_YET_COMPLETE = '03000'
+
+# Class 08 - Connection Exception
+CONNECTION_EXCEPTION = '08000'
+SQLCLIENT_UNABLE_TO_ESTABLISH_SQLCONNECTION = '08001'
+CONNECTION_DOES_NOT_EXIST = '08003'
+SQLSERVER_REJECTED_ESTABLISHMENT_OF_SQLCONNECTION = '08004'
+CONNECTION_FAILURE = '08006'
+TRANSACTION_RESOLUTION_UNKNOWN = '08007'
+PROTOCOL_VIOLATION = '08P01'
+
+# Class 09 - Triggered Action Exception
+TRIGGERED_ACTION_EXCEPTION = '09000'
+
+# Class 0A - Feature Not Supported
+FEATURE_NOT_SUPPORTED = '0A000'
+
+# Class 0B - Invalid Transaction Initiation
+INVALID_TRANSACTION_INITIATION = '0B000'
+
+# Class 0F - Locator Exception
+LOCATOR_EXCEPTION = '0F000'
+INVALID_LOCATOR_SPECIFICATION = '0F001'
+
+# Class 0L - Invalid Grantor
+INVALID_GRANTOR = '0L000'
+INVALID_GRANT_OPERATION = '0LP01'
+
+# Class 0P - Invalid Role Specification
+INVALID_ROLE_SPECIFICATION = '0P000'
+
+# Class 0Z - Diagnostics Exception
+DIAGNOSTICS_EXCEPTION = '0Z000'
+STACKED_DIAGNOSTICS_ACCESSED_WITHOUT_ACTIVE_HANDLER = '0Z002'
+
+# Class 20 - Case Not Found
+CASE_NOT_FOUND = '20000'
+
+# Class 21 - Cardinality Violation
+CARDINALITY_VIOLATION = '21000'
+
+# Class 22 - Data Exception
+DATA_EXCEPTION = '22000'
+STRING_DATA_RIGHT_TRUNCATION = '22001'
+NULL_VALUE_NO_INDICATOR_PARAMETER = '22002'
+NUMERIC_VALUE_OUT_OF_RANGE = '22003'
+NULL_VALUE_NOT_ALLOWED_ = '22004'
+ERROR_IN_ASSIGNMENT = '22005'
+INVALID_DATETIME_FORMAT = '22007'
+DATETIME_FIELD_OVERFLOW = '22008'
+INVALID_TIME_ZONE_DISPLACEMENT_VALUE = '22009'
+ESCAPE_CHARACTER_CONFLICT = '2200B'
+INVALID_USE_OF_ESCAPE_CHARACTER = '2200C'
+INVALID_ESCAPE_OCTET = '2200D'
+ZERO_LENGTH_CHARACTER_STRING = '2200F'
+MOST_SPECIFIC_TYPE_MISMATCH = '2200G'
+SEQUENCE_GENERATOR_LIMIT_EXCEEDED = '2200H'
+NOT_AN_XML_DOCUMENT = '2200L'
+INVALID_XML_DOCUMENT = '2200M'
+INVALID_XML_CONTENT = '2200N'
+INVALID_XML_COMMENT = '2200S'
+INVALID_XML_PROCESSING_INSTRUCTION = '2200T'
+INVALID_INDICATOR_PARAMETER_VALUE = '22010'
+SUBSTRING_ERROR = '22011'
+DIVISION_BY_ZERO = '22012'
+INVALID_PRECEDING_OR_FOLLOWING_SIZE = '22013'
+INVALID_ARGUMENT_FOR_NTILE_FUNCTION = '22014'
+INTERVAL_FIELD_OVERFLOW = '22015'
+INVALID_ARGUMENT_FOR_NTH_VALUE_FUNCTION = '22016'
+INVALID_CHARACTER_VALUE_FOR_CAST = '22018'
+INVALID_ESCAPE_CHARACTER = '22019'
+INVALID_REGULAR_EXPRESSION = '2201B'
+INVALID_ARGUMENT_FOR_LOGARITHM = '2201E'
+INVALID_ARGUMENT_FOR_POWER_FUNCTION = '2201F'
+INVALID_ARGUMENT_FOR_WIDTH_BUCKET_FUNCTION = '2201G'
+INVALID_ROW_COUNT_IN_LIMIT_CLAUSE = '2201W'
+INVALID_ROW_COUNT_IN_RESULT_OFFSET_CLAUSE = '2201X'
+INVALID_LIMIT_VALUE = '22020'
+CHARACTER_NOT_IN_REPERTOIRE = '22021'
+INDICATOR_OVERFLOW = '22022'
+INVALID_PARAMETER_VALUE = '22023'
+UNTERMINATED_C_STRING = '22024'
+INVALID_ESCAPE_SEQUENCE = '22025'
+STRING_DATA_LENGTH_MISMATCH = '22026'
+TRIM_ERROR = '22027'
+ARRAY_SUBSCRIPT_ERROR = '2202E'
+INVALID_TABLESAMPLE_REPEAT = '2202G'
+INVALID_TABLESAMPLE_ARGUMENT = '2202H'
+DUPLICATE_JSON_OBJECT_KEY_VALUE = '22030'
+INVALID_ARGUMENT_FOR_SQL_JSON_DATETIME_FUNCTION = '22031'
+INVALID_JSON_TEXT = '22032'
+INVALID_SQL_JSON_SUBSCRIPT = '22033'
+MORE_THAN_ONE_SQL_JSON_ITEM = '22034'
+NO_SQL_JSON_ITEM = '22035'
+NON_NUMERIC_SQL_JSON_ITEM = '22036'
+NON_UNIQUE_KEYS_IN_A_JSON_OBJECT = '22037'
+SINGLETON_SQL_JSON_ITEM_REQUIRED = '22038'
+SQL_JSON_ARRAY_NOT_FOUND = '22039'
+SQL_JSON_MEMBER_NOT_FOUND = '2203A'
+SQL_JSON_NUMBER_NOT_FOUND = '2203B'
+SQL_JSON_OBJECT_NOT_FOUND = '2203C'
+TOO_MANY_JSON_ARRAY_ELEMENTS = '2203D'
+TOO_MANY_JSON_OBJECT_MEMBERS = '2203E'
+SQL_JSON_SCALAR_REQUIRED = '2203F'
+FLOATING_POINT_EXCEPTION = '22P01'
+INVALID_TEXT_REPRESENTATION = '22P02'
+INVALID_BINARY_REPRESENTATION = '22P03'
+BAD_COPY_FILE_FORMAT = '22P04'
+UNTRANSLATABLE_CHARACTER = '22P05'
+NONSTANDARD_USE_OF_ESCAPE_CHARACTER = '22P06'
+
+# Class 23 - Integrity Constraint Violation
+INTEGRITY_CONSTRAINT_VIOLATION = '23000'
+RESTRICT_VIOLATION = '23001'
+NOT_NULL_VIOLATION = '23502'
+FOREIGN_KEY_VIOLATION = '23503'
+UNIQUE_VIOLATION = '23505'
+CHECK_VIOLATION = '23514'
+EXCLUSION_VIOLATION = '23P01'
+
+# Class 24 - Invalid Cursor State
+INVALID_CURSOR_STATE = '24000'
+
+# Class 25 - Invalid Transaction State
+INVALID_TRANSACTION_STATE = '25000'
+ACTIVE_SQL_TRANSACTION = '25001'
+BRANCH_TRANSACTION_ALREADY_ACTIVE = '25002'
+INAPPROPRIATE_ACCESS_MODE_FOR_BRANCH_TRANSACTION = '25003'
+INAPPROPRIATE_ISOLATION_LEVEL_FOR_BRANCH_TRANSACTION = '25004'
+NO_ACTIVE_SQL_TRANSACTION_FOR_BRANCH_TRANSACTION = '25005'
+READ_ONLY_SQL_TRANSACTION = '25006'
+SCHEMA_AND_DATA_STATEMENT_MIXING_NOT_SUPPORTED = '25007'
+HELD_CURSOR_REQUIRES_SAME_ISOLATION_LEVEL = '25008'
+NO_ACTIVE_SQL_TRANSACTION = '25P01'
+IN_FAILED_SQL_TRANSACTION = '25P02'
+IDLE_IN_TRANSACTION_SESSION_TIMEOUT = '25P03'
+
+# Class 26 - Invalid SQL Statement Name
+INVALID_SQL_STATEMENT_NAME = '26000'
+
+# Class 27 - Triggered Data Change Violation
+TRIGGERED_DATA_CHANGE_VIOLATION = '27000'
+
+# Class 28 - Invalid Authorization Specification
+INVALID_AUTHORIZATION_SPECIFICATION = '28000'
+INVALID_PASSWORD = '28P01'
+
+# Class 2B - Dependent Privilege Descriptors Still Exist
+DEPENDENT_PRIVILEGE_DESCRIPTORS_STILL_EXIST = '2B000'
+DEPENDENT_OBJECTS_STILL_EXIST = '2BP01'
+
+# Class 2D - Invalid Transaction Termination
+INVALID_TRANSACTION_TERMINATION = '2D000'
+
+# Class 2F - SQL Routine Exception
+SQL_ROUTINE_EXCEPTION = '2F000'
+MODIFYING_SQL_DATA_NOT_PERMITTED_ = '2F002'
+PROHIBITED_SQL_STATEMENT_ATTEMPTED_ = '2F003'
+READING_SQL_DATA_NOT_PERMITTED_ = '2F004'
+FUNCTION_EXECUTED_NO_RETURN_STATEMENT = '2F005'
+
+# Class 34 - Invalid Cursor Name
+INVALID_CURSOR_NAME = '34000'
+
+# Class 38 - External Routine Exception
+EXTERNAL_ROUTINE_EXCEPTION = '38000'
+CONTAINING_SQL_NOT_PERMITTED = '38001'
+MODIFYING_SQL_DATA_NOT_PERMITTED = '38002'
+PROHIBITED_SQL_STATEMENT_ATTEMPTED = '38003'
+READING_SQL_DATA_NOT_PERMITTED = '38004'
+
+# Class 39 - External Routine Invocation Exception
+EXTERNAL_ROUTINE_INVOCATION_EXCEPTION = '39000'
+INVALID_SQLSTATE_RETURNED = '39001'
+NULL_VALUE_NOT_ALLOWED = '39004'
+TRIGGER_PROTOCOL_VIOLATED = '39P01'
+SRF_PROTOCOL_VIOLATED = '39P02'
+EVENT_TRIGGER_PROTOCOL_VIOLATED = '39P03'
+
+# Class 3B - Savepoint Exception
+SAVEPOINT_EXCEPTION = '3B000'
+INVALID_SAVEPOINT_SPECIFICATION = '3B001'
+
+# Class 3D - Invalid Catalog Name
+INVALID_CATALOG_NAME = '3D000'
+
+# Class 3F - Invalid Schema Name
+INVALID_SCHEMA_NAME = '3F000'
+
+# Class 40 - Transaction Rollback
+TRANSACTION_ROLLBACK = '40000'
+SERIALIZATION_FAILURE = '40001'
+TRANSACTION_INTEGRITY_CONSTRAINT_VIOLATION = '40002'
+STATEMENT_COMPLETION_UNKNOWN = '40003'
+DEADLOCK_DETECTED = '40P01'
+
+# Class 42 - Syntax Error or Access Rule Violation
+SYNTAX_ERROR_OR_ACCESS_RULE_VIOLATION = '42000'
+INSUFFICIENT_PRIVILEGE = '42501'
+SYNTAX_ERROR = '42601'
+INVALID_NAME = '42602'
+INVALID_COLUMN_DEFINITION = '42611'
+NAME_TOO_LONG = '42622'
+DUPLICATE_COLUMN = '42701'
+AMBIGUOUS_COLUMN = '42702'
+UNDEFINED_COLUMN = '42703'
+UNDEFINED_OBJECT = '42704'
+DUPLICATE_OBJECT = '42710'
+DUPLICATE_ALIAS = '42712'
+DUPLICATE_FUNCTION = '42723'
+AMBIGUOUS_FUNCTION = '42725'
+GROUPING_ERROR = '42803'
+DATATYPE_MISMATCH = '42804'
+WRONG_OBJECT_TYPE = '42809'
+INVALID_FOREIGN_KEY = '42830'
+CANNOT_COERCE = '42846'
+UNDEFINED_FUNCTION = '42883'
+GENERATED_ALWAYS = '428C9'
+RESERVED_NAME = '42939'
+UNDEFINED_TABLE = '42P01'
+UNDEFINED_PARAMETER = '42P02'
+DUPLICATE_CURSOR = '42P03'
+DUPLICATE_DATABASE = '42P04'
+DUPLICATE_PREPARED_STATEMENT = '42P05'
+DUPLICATE_SCHEMA = '42P06'
+DUPLICATE_TABLE = '42P07'
+AMBIGUOUS_PARAMETER = '42P08'
+AMBIGUOUS_ALIAS = '42P09'
+INVALID_COLUMN_REFERENCE = '42P10'
+INVALID_CURSOR_DEFINITION = '42P11'
+INVALID_DATABASE_DEFINITION = '42P12'
+INVALID_FUNCTION_DEFINITION = '42P13'
+INVALID_PREPARED_STATEMENT_DEFINITION = '42P14'
+INVALID_SCHEMA_DEFINITION = '42P15'
+INVALID_TABLE_DEFINITION = '42P16'
+INVALID_OBJECT_DEFINITION = '42P17'
+INDETERMINATE_DATATYPE = '42P18'
+INVALID_RECURSION = '42P19'
+WINDOWING_ERROR = '42P20'
+COLLATION_MISMATCH = '42P21'
+INDETERMINATE_COLLATION = '42P22'
+
+# Class 44 - WITH CHECK OPTION Violation
+WITH_CHECK_OPTION_VIOLATION = '44000'
+
+# Class 53 - Insufficient Resources
+INSUFFICIENT_RESOURCES = '53000'
+DISK_FULL = '53100'
+OUT_OF_MEMORY = '53200'
+TOO_MANY_CONNECTIONS = '53300'
+CONFIGURATION_LIMIT_EXCEEDED = '53400'
+
+# Class 54 - Program Limit Exceeded
+PROGRAM_LIMIT_EXCEEDED = '54000'
+STATEMENT_TOO_COMPLEX = '54001'
+TOO_MANY_COLUMNS = '54011'
+TOO_MANY_ARGUMENTS = '54023'
+
+# Class 55 - Object Not In Prerequisite State
+OBJECT_NOT_IN_PREREQUISITE_STATE = '55000'
+OBJECT_IN_USE = '55006'
+CANT_CHANGE_RUNTIME_PARAM = '55P02'
+LOCK_NOT_AVAILABLE = '55P03'
+UNSAFE_NEW_ENUM_VALUE_USAGE = '55P04'
+
+# Class 57 - Operator Intervention
+OPERATOR_INTERVENTION = '57000'
+QUERY_CANCELED = '57014'
+ADMIN_SHUTDOWN = '57P01'
+CRASH_SHUTDOWN = '57P02'
+CANNOT_CONNECT_NOW = '57P03'
+DATABASE_DROPPED = '57P04'
+
+# Class 58 - System Error (errors external to PostgreSQL itself)
+SYSTEM_ERROR = '58000'
+IO_ERROR = '58030'
+UNDEFINED_FILE = '58P01'
+DUPLICATE_FILE = '58P02'
+
+# Class 72 - Snapshot Failure
+SNAPSHOT_TOO_OLD = '72000'
+
+# Class F0 - Configuration File Error
+CONFIG_FILE_ERROR = 'F0000'
+LOCK_FILE_EXISTS = 'F0001'
+
+# Class HV - Foreign Data Wrapper Error (SQL/MED)
+FDW_ERROR = 'HV000'
+FDW_OUT_OF_MEMORY = 'HV001'
+FDW_DYNAMIC_PARAMETER_VALUE_NEEDED = 'HV002'
+FDW_INVALID_DATA_TYPE = 'HV004'
+FDW_COLUMN_NAME_NOT_FOUND = 'HV005'
+FDW_INVALID_DATA_TYPE_DESCRIPTORS = 'HV006'
+FDW_INVALID_COLUMN_NAME = 'HV007'
+FDW_INVALID_COLUMN_NUMBER = 'HV008'
+FDW_INVALID_USE_OF_NULL_POINTER = 'HV009'
+FDW_INVALID_STRING_FORMAT = 'HV00A'
+FDW_INVALID_HANDLE = 'HV00B'
+FDW_INVALID_OPTION_INDEX = 'HV00C'
+FDW_INVALID_OPTION_NAME = 'HV00D'
+FDW_OPTION_NAME_NOT_FOUND = 'HV00J'
+FDW_REPLY_HANDLE = 'HV00K'
+FDW_UNABLE_TO_CREATE_EXECUTION = 'HV00L'
+FDW_UNABLE_TO_CREATE_REPLY = 'HV00M'
+FDW_UNABLE_TO_ESTABLISH_CONNECTION = 'HV00N'
+FDW_NO_SCHEMAS = 'HV00P'
+FDW_SCHEMA_NOT_FOUND = 'HV00Q'
+FDW_TABLE_NOT_FOUND = 'HV00R'
+FDW_FUNCTION_SEQUENCE_ERROR = 'HV010'
+FDW_TOO_MANY_HANDLES = 'HV014'
+FDW_INCONSISTENT_DESCRIPTOR_INFORMATION = 'HV021'
+FDW_INVALID_ATTRIBUTE_VALUE = 'HV024'
+FDW_INVALID_STRING_LENGTH_OR_BUFFER_LENGTH = 'HV090'
+FDW_INVALID_DESCRIPTOR_FIELD_IDENTIFIER = 'HV091'
+
+# Class P0 - PL/pgSQL Error
+PLPGSQL_ERROR = 'P0000'
+RAISE_EXCEPTION = 'P0001'
+NO_DATA_FOUND = 'P0002'
+TOO_MANY_ROWS = 'P0003'
+ASSERT_FAILURE = 'P0004'
+
+# Class XX - Internal Error
+INTERNAL_ERROR = 'XX000'
+DATA_CORRUPTED = 'XX001'
+INDEX_CORRUPTED = 'XX002'
Index: venv/Lib/site-packages/python_dateutil-2.8.1.dist-info/INSTALLER
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/venv/Lib/site-packages/python_dateutil-2.8.1.dist-info/INSTALLER b/venv/Lib/site-packages/python_dateutil-2.8.1.dist-info/INSTALLER
new file mode 100644
--- /dev/null	(date 1616406053742)
+++ b/venv/Lib/site-packages/python_dateutil-2.8.1.dist-info/INSTALLER	(date 1616406053742)
@@ -0,0 +1,1 @@
+pip
Index: latest/Lib/site-packages/psycopg2/errors.py
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/latest/Lib/site-packages/psycopg2/errors.py b/latest/Lib/site-packages/psycopg2/errors.py
new file mode 100644
--- /dev/null	(date 1616409347257)
+++ b/latest/Lib/site-packages/psycopg2/errors.py	(date 1616409347257)
@@ -0,0 +1,38 @@
+"""Error classes for PostgreSQL error codes
+"""
+
+# psycopg/errors.py - SQLSTATE and DB-API exceptions
+#
+# Copyright (C) 2018-2019 Daniele Varrazzo  <daniele.varrazzo@gmail.com>
+# Copyright (C) 2020 The Psycopg Team
+#
+# psycopg2 is free software: you can redistribute it and/or modify it
+# under the terms of the GNU Lesser General Public License as published
+# by the Free Software Foundation, either version 3 of the License, or
+# (at your option) any later version.
+#
+# In addition, as a special exception, the copyright holders give
+# permission to link this program with the OpenSSL library (or with
+# modified versions of OpenSSL that use the same license as OpenSSL),
+# and distribute linked combinations including the two.
+#
+# You must obey the GNU Lesser General Public License in all respects for
+# all of the code used other than OpenSSL.
+#
+# psycopg2 is distributed in the hope that it will be useful, but WITHOUT
+# ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or
+# FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public
+# License for more details.
+
+#
+# NOTE: the exceptions are injected into this module by the C extention.
+#
+
+
+def lookup(code):
+    """Lookup an error code and return its exception class.
+
+    Raise `!KeyError` if the code is not found.
+    """
+    from psycopg2._psycopg import sqlstate_errors   # avoid circular import
+    return sqlstate_errors[code]
Index: latest/Lib/site-packages/psycopg2/extensions.py
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/latest/Lib/site-packages/psycopg2/extensions.py b/latest/Lib/site-packages/psycopg2/extensions.py
new file mode 100644
--- /dev/null	(date 1616409347259)
+++ b/latest/Lib/site-packages/psycopg2/extensions.py	(date 1616409347259)
@@ -0,0 +1,221 @@
+"""psycopg extensions to the DBAPI-2.0
+
+This module holds all the extensions to the DBAPI-2.0 provided by psycopg.
+
+- `connection` -- the new-type inheritable connection class
+- `cursor` -- the new-type inheritable cursor class
+- `lobject` -- the new-type inheritable large object class
+- `adapt()` -- exposes the PEP-246_ compatible adapting mechanism used
+  by psycopg to adapt Python types to PostgreSQL ones
+
+.. _PEP-246: https://www.python.org/dev/peps/pep-0246/
+"""
+# psycopg/extensions.py - DBAPI-2.0 extensions specific to psycopg
+#
+# Copyright (C) 2003-2019 Federico Di Gregorio  <fog@debian.org>
+# Copyright (C) 2020 The Psycopg Team
+#
+# psycopg2 is free software: you can redistribute it and/or modify it
+# under the terms of the GNU Lesser General Public License as published
+# by the Free Software Foundation, either version 3 of the License, or
+# (at your option) any later version.
+#
+# In addition, as a special exception, the copyright holders give
+# permission to link this program with the OpenSSL library (or with
+# modified versions of OpenSSL that use the same license as OpenSSL),
+# and distribute linked combinations including the two.
+#
+# You must obey the GNU Lesser General Public License in all respects for
+# all of the code used other than OpenSSL.
+#
+# psycopg2 is distributed in the hope that it will be useful, but WITHOUT
+# ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or
+# FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public
+# License for more details.
+
+import re as _re
+
+from psycopg2._psycopg import (                             # noqa
+    BINARYARRAY, BOOLEAN, BOOLEANARRAY, BYTES, BYTESARRAY, DATE, DATEARRAY,
+    DATETIMEARRAY, DECIMAL, DECIMALARRAY, FLOAT, FLOATARRAY, INTEGER,
+    INTEGERARRAY, INTERVAL, INTERVALARRAY, LONGINTEGER, LONGINTEGERARRAY,
+    ROWIDARRAY, STRINGARRAY, TIME, TIMEARRAY, UNICODE, UNICODEARRAY,
+    AsIs, Binary, Boolean, Float, Int, QuotedString, )
+
+try:
+    from psycopg2._psycopg import (                         # noqa
+        MXDATE, MXDATETIME, MXDATETIMETZ, MXINTERVAL, MXTIME, MXDATEARRAY,
+        MXDATETIMEARRAY, MXDATETIMETZARRAY, MXINTERVALARRAY, MXTIMEARRAY,
+        DateFromMx, TimeFromMx, TimestampFromMx, IntervalFromMx, )
+except ImportError:
+    pass
+
+from psycopg2._psycopg import (                         # noqa
+    PYDATE, PYDATETIME, PYDATETIMETZ, PYINTERVAL, PYTIME, PYDATEARRAY,
+    PYDATETIMEARRAY, PYDATETIMETZARRAY, PYINTERVALARRAY, PYTIMEARRAY,
+    DateFromPy, TimeFromPy, TimestampFromPy, IntervalFromPy, )
+
+from psycopg2._psycopg import (                             # noqa
+    adapt, adapters, encodings, connection, cursor,
+    lobject, Xid, libpq_version, parse_dsn, quote_ident,
+    string_types, binary_types, new_type, new_array_type, register_type,
+    ISQLQuote, Notify, Diagnostics, Column, ConnectionInfo,
+    QueryCanceledError, TransactionRollbackError,
+    set_wait_callback, get_wait_callback, encrypt_password, )
+
+
+"""Isolation level values."""
+ISOLATION_LEVEL_AUTOCOMMIT = 0
+ISOLATION_LEVEL_READ_UNCOMMITTED = 4
+ISOLATION_LEVEL_READ_COMMITTED = 1
+ISOLATION_LEVEL_REPEATABLE_READ = 2
+ISOLATION_LEVEL_SERIALIZABLE = 3
+ISOLATION_LEVEL_DEFAULT = None
+
+
+"""psycopg connection status values."""
+STATUS_SETUP = 0
+STATUS_READY = 1
+STATUS_BEGIN = 2
+STATUS_SYNC = 3  # currently unused
+STATUS_ASYNC = 4  # currently unused
+STATUS_PREPARED = 5
+
+# This is a useful mnemonic to check if the connection is in a transaction
+STATUS_IN_TRANSACTION = STATUS_BEGIN
+
+
+"""psycopg asynchronous connection polling values"""
+POLL_OK = 0
+POLL_READ = 1
+POLL_WRITE = 2
+POLL_ERROR = 3
+
+
+"""Backend transaction status values."""
+TRANSACTION_STATUS_IDLE = 0
+TRANSACTION_STATUS_ACTIVE = 1
+TRANSACTION_STATUS_INTRANS = 2
+TRANSACTION_STATUS_INERROR = 3
+TRANSACTION_STATUS_UNKNOWN = 4
+
+
+def register_adapter(typ, callable):
+    """Register 'callable' as an ISQLQuote adapter for type 'typ'."""
+    adapters[(typ, ISQLQuote)] = callable
+
+
+# The SQL_IN class is the official adapter for tuples starting from 2.0.6.
+class SQL_IN(object):
+    """Adapt any iterable to an SQL quotable object."""
+    def __init__(self, seq):
+        self._seq = seq
+        self._conn = None
+
+    def prepare(self, conn):
+        self._conn = conn
+
+    def getquoted(self):
+        # this is the important line: note how every object in the
+        # list is adapted and then how getquoted() is called on it
+        pobjs = [adapt(o) for o in self._seq]
+        if self._conn is not None:
+            for obj in pobjs:
+                if hasattr(obj, 'prepare'):
+                    obj.prepare(self._conn)
+        qobjs = [o.getquoted() for o in pobjs]
+        return b'(' + b', '.join(qobjs) + b')'
+
+    def __str__(self):
+        return str(self.getquoted())
+
+
+class NoneAdapter(object):
+    """Adapt None to NULL.
+
+    This adapter is not used normally as a fast path in mogrify uses NULL,
+    but it makes easier to adapt composite types.
+    """
+    def __init__(self, obj):
+        pass
+
+    def getquoted(self, _null=b"NULL"):
+        return _null
+
+
+def make_dsn(dsn=None, **kwargs):
+    """Convert a set of keywords into a connection strings."""
+    if dsn is None and not kwargs:
+        return ''
+
+    # If no kwarg is specified don't mung the dsn, but verify it
+    if not kwargs:
+        parse_dsn(dsn)
+        return dsn
+
+    # Override the dsn with the parameters
+    if 'database' in kwargs:
+        if 'dbname' in kwargs:
+            raise TypeError(
+                "you can't specify both 'database' and 'dbname' arguments")
+        kwargs['dbname'] = kwargs.pop('database')
+
+    # Drop the None arguments
+    kwargs = {k: v for (k, v) in kwargs.items() if v is not None}
+
+    if dsn is not None:
+        tmp = parse_dsn(dsn)
+        tmp.update(kwargs)
+        kwargs = tmp
+
+    dsn = " ".join(["%s=%s" % (k, _param_escape(str(v)))
+        for (k, v) in kwargs.items()])
+
+    # verify that the returned dsn is valid
+    parse_dsn(dsn)
+
+    return dsn
+
+
+def _param_escape(s,
+        re_escape=_re.compile(r"([\\'])"),
+        re_space=_re.compile(r'\s')):
+    """
+    Apply the escaping rule required by PQconnectdb
+    """
+    if not s:
+        return "''"
+
+    s = re_escape.sub(r'\\\1', s)
+    if re_space.search(s):
+        s = "'" + s + "'"
+
+    return s
+
+
+# Create default json typecasters for PostgreSQL 9.2 oids
+from psycopg2._json import register_default_json, register_default_jsonb    # noqa
+
+try:
+    JSON, JSONARRAY = register_default_json()
+    JSONB, JSONBARRAY = register_default_jsonb()
+except ImportError:
+    pass
+
+del register_default_json, register_default_jsonb
+
+
+# Create default Range typecasters
+from psycopg2. _range import Range                              # noqa
+del Range
+
+
+# Add the "cleaned" version of the encodings to the key.
+# When the encoding is set its name is cleaned up from - and _ and turned
+# uppercase, so an encoding not respecting these rules wouldn't be found in the
+# encodings keys and would raise an exception with the unicode typecaster
+for k, v in list(encodings.items()):
+    k = k.replace('_', '').replace('-', '').upper()
+    encodings[k] = v
+
+del k, v
Index: venv/Lib/site-packages/python_dateutil-2.8.1.dist-info/LICENSE
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/venv/Lib/site-packages/python_dateutil-2.8.1.dist-info/LICENSE b/venv/Lib/site-packages/python_dateutil-2.8.1.dist-info/LICENSE
new file mode 100644
--- /dev/null	(date 1616406051845)
+++ b/venv/Lib/site-packages/python_dateutil-2.8.1.dist-info/LICENSE	(date 1616406051845)
@@ -0,0 +1,54 @@
+Copyright 2017- Paul Ganssle <paul@ganssle.io>
+Copyright 2017- dateutil contributors (see AUTHORS file)
+
+   Licensed under the Apache License, Version 2.0 (the "License");
+   you may not use this file except in compliance with the License.
+   You may obtain a copy of the License at
+
+       http://www.apache.org/licenses/LICENSE-2.0
+
+   Unless required by applicable law or agreed to in writing, software
+   distributed under the License is distributed on an "AS IS" BASIS,
+   WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+   See the License for the specific language governing permissions and
+   limitations under the License.
+
+The above license applies to all contributions after 2017-12-01, as well as
+all contributions that have been re-licensed (see AUTHORS file for the list of
+contributors who have re-licensed their code).
+--------------------------------------------------------------------------------
+dateutil - Extensions to the standard Python datetime module.
+
+Copyright (c) 2003-2011 - Gustavo Niemeyer <gustavo@niemeyer.net>
+Copyright (c) 2012-2014 - Tomi Pievilinen <tomi.pievilainen@iki.fi>
+Copyright (c) 2014-2016 - Yaron de Leeuw <me@jarondl.net>
+Copyright (c) 2015-     - Paul Ganssle <paul@ganssle.io>
+Copyright (c) 2015-     - dateutil contributors (see AUTHORS file)
+
+All rights reserved.
+
+Redistribution and use in source and binary forms, with or without
+modification, are permitted provided that the following conditions are met:
+
+    * Redistributions of source code must retain the above copyright notice,
+      this list of conditions and the following disclaimer.
+    * Redistributions in binary form must reproduce the above copyright notice,
+      this list of conditions and the following disclaimer in the documentation
+      and/or other materials provided with the distribution.
+    * Neither the name of the copyright holder nor the names of its
+      contributors may be used to endorse or promote products derived from
+      this software without specific prior written permission.
+
+THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS
+"AS IS" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT
+LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR
+A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT OWNER OR
+CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL,
+EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO,
+PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR
+PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF
+LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING
+NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS
+SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
+
+The above BSD License Applies to all code, even that also covered by Apache 2.0.
\ No newline at end of file
Index: latest/Lib/site-packages/psycopg2/extras.py
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/latest/Lib/site-packages/psycopg2/extras.py b/latest/Lib/site-packages/psycopg2/extras.py
new file mode 100644
--- /dev/null	(date 1616409347261)
+++ b/latest/Lib/site-packages/psycopg2/extras.py	(date 1616409347261)
@@ -0,0 +1,1328 @@
+"""Miscellaneous goodies for psycopg2
+
+This module is a generic place used to hold little helper functions
+and classes until a better place in the distribution is found.
+"""
+# psycopg/extras.py - miscellaneous extra goodies for psycopg
+#
+# Copyright (C) 2003-2019 Federico Di Gregorio  <fog@debian.org>
+# Copyright (C) 2020 The Psycopg Team
+#
+# psycopg2 is free software: you can redistribute it and/or modify it
+# under the terms of the GNU Lesser General Public License as published
+# by the Free Software Foundation, either version 3 of the License, or
+# (at your option) any later version.
+#
+# In addition, as a special exception, the copyright holders give
+# permission to link this program with the OpenSSL library (or with
+# modified versions of OpenSSL that use the same license as OpenSSL),
+# and distribute linked combinations including the two.
+#
+# You must obey the GNU Lesser General Public License in all respects for
+# all of the code used other than OpenSSL.
+#
+# psycopg2 is distributed in the hope that it will be useful, but WITHOUT
+# ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or
+# FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public
+# License for more details.
+
+import os as _os
+import time as _time
+import re as _re
+from collections import namedtuple, OrderedDict
+
+import logging as _logging
+
+import psycopg2
+from psycopg2 import extensions as _ext
+from .extensions import cursor as _cursor
+from .extensions import connection as _connection
+from .extensions import adapt as _A, quote_ident
+from .compat import PY2, PY3, lru_cache
+
+from psycopg2._psycopg import (                             # noqa
+    REPLICATION_PHYSICAL, REPLICATION_LOGICAL,
+    ReplicationConnection as _replicationConnection,
+    ReplicationCursor as _replicationCursor,
+    ReplicationMessage)
+
+
+# expose the json adaptation stuff into the module
+from psycopg2._json import (                                # noqa
+    json, Json, register_json, register_default_json, register_default_jsonb)
+
+
+# Expose range-related objects
+from psycopg2._range import (                               # noqa
+    Range, NumericRange, DateRange, DateTimeRange, DateTimeTZRange,
+    register_range, RangeAdapter, RangeCaster)
+
+
+# Expose ipaddress-related objects
+from psycopg2._ipaddress import register_ipaddress          # noqa
+
+
+class DictCursorBase(_cursor):
+    """Base class for all dict-like cursors."""
+
+    def __init__(self, *args, **kwargs):
+        if 'row_factory' in kwargs:
+            row_factory = kwargs['row_factory']
+            del kwargs['row_factory']
+        else:
+            raise NotImplementedError(
+                "DictCursorBase can't be instantiated without a row factory.")
+        super(DictCursorBase, self).__init__(*args, **kwargs)
+        self._query_executed = False
+        self._prefetch = False
+        self.row_factory = row_factory
+
+    def fetchone(self):
+        if self._prefetch:
+            res = super(DictCursorBase, self).fetchone()
+        if self._query_executed:
+            self._build_index()
+        if not self._prefetch:
+            res = super(DictCursorBase, self).fetchone()
+        return res
+
+    def fetchmany(self, size=None):
+        if self._prefetch:
+            res = super(DictCursorBase, self).fetchmany(size)
+        if self._query_executed:
+            self._build_index()
+        if not self._prefetch:
+            res = super(DictCursorBase, self).fetchmany(size)
+        return res
+
+    def fetchall(self):
+        if self._prefetch:
+            res = super(DictCursorBase, self).fetchall()
+        if self._query_executed:
+            self._build_index()
+        if not self._prefetch:
+            res = super(DictCursorBase, self).fetchall()
+        return res
+
+    def __iter__(self):
+        try:
+            if self._prefetch:
+                res = super(DictCursorBase, self).__iter__()
+                first = next(res)
+            if self._query_executed:
+                self._build_index()
+            if not self._prefetch:
+                res = super(DictCursorBase, self).__iter__()
+                first = next(res)
+
+            yield first
+            while True:
+                yield next(res)
+        except StopIteration:
+            return
+
+
+class DictConnection(_connection):
+    """A connection that uses `DictCursor` automatically."""
+    def cursor(self, *args, **kwargs):
+        kwargs.setdefault('cursor_factory', self.cursor_factory or DictCursor)
+        return super(DictConnection, self).cursor(*args, **kwargs)
+
+
+class DictCursor(DictCursorBase):
+    """A cursor that keeps a list of column name -> index mappings__.
+
+    .. __: https://docs.python.org/glossary.html#term-mapping
+    """
+
+    def __init__(self, *args, **kwargs):
+        kwargs['row_factory'] = DictRow
+        super(DictCursor, self).__init__(*args, **kwargs)
+        self._prefetch = True
+
+    def execute(self, query, vars=None):
+        self.index = OrderedDict()
+        self._query_executed = True
+        return super(DictCursor, self).execute(query, vars)
+
+    def callproc(self, procname, vars=None):
+        self.index = OrderedDict()
+        self._query_executed = True
+        return super(DictCursor, self).callproc(procname, vars)
+
+    def _build_index(self):
+        if self._query_executed and self.description:
+            for i in range(len(self.description)):
+                self.index[self.description[i][0]] = i
+            self._query_executed = False
+
+
+class DictRow(list):
+    """A row object that allow by-column-name access to data."""
+
+    __slots__ = ('_index',)
+
+    def __init__(self, cursor):
+        self._index = cursor.index
+        self[:] = [None] * len(cursor.description)
+
+    def __getitem__(self, x):
+        if not isinstance(x, (int, slice)):
+            x = self._index[x]
+        return super(DictRow, self).__getitem__(x)
+
+    def __setitem__(self, x, v):
+        if not isinstance(x, (int, slice)):
+            x = self._index[x]
+        super(DictRow, self).__setitem__(x, v)
+
+    def items(self):
+        g = super(DictRow, self).__getitem__
+        return ((n, g(self._index[n])) for n in self._index)
+
+    def keys(self):
+        return iter(self._index)
+
+    def values(self):
+        g = super(DictRow, self).__getitem__
+        return (g(self._index[n]) for n in self._index)
+
+    def get(self, x, default=None):
+        try:
+            return self[x]
+        except Exception:
+            return default
+
+    def copy(self):
+        return OrderedDict(self.items())
+
+    def __contains__(self, x):
+        return x in self._index
+
+    def __reduce__(self):
+        # this is apparently useless, but it fixes #1073
+        return super(DictRow, self).__reduce__()
+
+    def __getstate__(self):
+        return self[:], self._index.copy()
+
+    def __setstate__(self, data):
+        self[:] = data[0]
+        self._index = data[1]
+
+    if PY2:
+        iterkeys = keys
+        itervalues = values
+        iteritems = items
+        has_key = __contains__
+
+        def keys(self):
+            return list(self.iterkeys())
+
+        def values(self):
+            return tuple(self.itervalues())
+
+        def items(self):
+            return list(self.iteritems())
+
+
+class RealDictConnection(_connection):
+    """A connection that uses `RealDictCursor` automatically."""
+    def cursor(self, *args, **kwargs):
+        kwargs.setdefault('cursor_factory', self.cursor_factory or RealDictCursor)
+        return super(RealDictConnection, self).cursor(*args, **kwargs)
+
+
+class RealDictCursor(DictCursorBase):
+    """A cursor that uses a real dict as the base type for rows.
+
+    Note that this cursor is extremely specialized and does not allow
+    the normal access (using integer indices) to fetched data. If you need
+    to access database rows both as a dictionary and a list, then use
+    the generic `DictCursor` instead of `!RealDictCursor`.
+    """
+    def __init__(self, *args, **kwargs):
+        kwargs['row_factory'] = RealDictRow
+        super(RealDictCursor, self).__init__(*args, **kwargs)
+
+    def execute(self, query, vars=None):
+        self.column_mapping = []
+        self._query_executed = True
+        return super(RealDictCursor, self).execute(query, vars)
+
+    def callproc(self, procname, vars=None):
+        self.column_mapping = []
+        self._query_executed = True
+        return super(RealDictCursor, self).callproc(procname, vars)
+
+    def _build_index(self):
+        if self._query_executed and self.description:
+            self.column_mapping = [d[0] for d in self.description]
+            self._query_executed = False
+
+
+class RealDictRow(OrderedDict):
+    """A `!dict` subclass representing a data record."""
+
+    def __init__(self, *args, **kwargs):
+        if args and isinstance(args[0], _cursor):
+            cursor = args[0]
+            args = args[1:]
+        else:
+            cursor = None
+
+        super(RealDictRow, self).__init__(*args, **kwargs)
+
+        if cursor is not None:
+            # Required for named cursors
+            if cursor.description and not cursor.column_mapping:
+                cursor._build_index()
+
+            # Store the cols mapping in the dict itself until the row is fully
+            # populated, so we don't need to add attributes to the class
+            # (hence keeping its maintenance, special pickle support, etc.)
+            self[RealDictRow] = cursor.column_mapping
+
+    def __setitem__(self, key, value):
+        if RealDictRow in self:
+            # We are in the row building phase
+            mapping = self[RealDictRow]
+            super(RealDictRow, self).__setitem__(mapping[key], value)
+            if key == len(mapping) - 1:
+                # Row building finished
+                del self[RealDictRow]
+            return
+
+        super(RealDictRow, self).__setitem__(key, value)
+
+
+class NamedTupleConnection(_connection):
+    """A connection that uses `NamedTupleCursor` automatically."""
+    def cursor(self, *args, **kwargs):
+        kwargs.setdefault('cursor_factory', self.cursor_factory or NamedTupleCursor)
+        return super(NamedTupleConnection, self).cursor(*args, **kwargs)
+
+
+class NamedTupleCursor(_cursor):
+    """A cursor that generates results as `~collections.namedtuple`.
+
+    `!fetch*()` methods will return named tuples instead of regular tuples, so
+    their elements can be accessed both as regular numeric items as well as
+    attributes.
+
+        >>> nt_cur = conn.cursor(cursor_factory=psycopg2.extras.NamedTupleCursor)
+        >>> rec = nt_cur.fetchone()
+        >>> rec
+        Record(id=1, num=100, data="abc'def")
+        >>> rec[1]
+        100
+        >>> rec.data
+        "abc'def"
+    """
+    Record = None
+    MAX_CACHE = 1024
+
+    def execute(self, query, vars=None):
+        self.Record = None
+        return super(NamedTupleCursor, self).execute(query, vars)
+
+    def executemany(self, query, vars):
+        self.Record = None
+        return super(NamedTupleCursor, self).executemany(query, vars)
+
+    def callproc(self, procname, vars=None):
+        self.Record = None
+        return super(NamedTupleCursor, self).callproc(procname, vars)
+
+    def fetchone(self):
+        t = super(NamedTupleCursor, self).fetchone()
+        if t is not None:
+            nt = self.Record
+            if nt is None:
+                nt = self.Record = self._make_nt()
+            return nt._make(t)
+
+    def fetchmany(self, size=None):
+        ts = super(NamedTupleCursor, self).fetchmany(size)
+        nt = self.Record
+        if nt is None:
+            nt = self.Record = self._make_nt()
+        return list(map(nt._make, ts))
+
+    def fetchall(self):
+        ts = super(NamedTupleCursor, self).fetchall()
+        nt = self.Record
+        if nt is None:
+            nt = self.Record = self._make_nt()
+        return list(map(nt._make, ts))
+
+    def __iter__(self):
+        try:
+            it = super(NamedTupleCursor, self).__iter__()
+            t = next(it)
+
+            nt = self.Record
+            if nt is None:
+                nt = self.Record = self._make_nt()
+
+            yield nt._make(t)
+
+            while True:
+                yield nt._make(next(it))
+        except StopIteration:
+            return
+
+    # ascii except alnum and underscore
+    _re_clean = _re.compile(
+        '[' + _re.escape(' !"#$%&\'()*+,-./:;<=>?@[\\]^`{|}~') + ']')
+
+    def _make_nt(self):
+        key = tuple(d[0] for d in self.description) if self.description else ()
+        return self._cached_make_nt(key)
+
+    @classmethod
+    def _do_make_nt(cls, key):
+        fields = []
+        for s in key:
+            s = cls._re_clean.sub('_', s)
+            # Python identifier cannot start with numbers, namedtuple fields
+            # cannot start with underscore. So...
+            if s[0] == '_' or '0' <= s[0] <= '9':
+                s = 'f' + s
+            fields.append(s)
+
+        nt = namedtuple("Record", fields)
+        return nt
+
+
+@lru_cache(512)
+def _cached_make_nt(cls, key):
+    return cls._do_make_nt(key)
+
+
+# Exposed for testability, and if someone wants to monkeypatch to tweak
+# the cache size.
+NamedTupleCursor._cached_make_nt = classmethod(_cached_make_nt)
+
+
+class LoggingConnection(_connection):
+    """A connection that logs all queries to a file or logger__ object.
+
+    .. __: https://docs.python.org/library/logging.html
+    """
+
+    def initialize(self, logobj):
+        """Initialize the connection to log to `!logobj`.
+
+        The `!logobj` parameter can be an open file object or a Logger/LoggerAdapter
+        instance from the standard logging module.
+        """
+        self._logobj = logobj
+        if _logging and isinstance(
+                logobj, (_logging.Logger, _logging.LoggerAdapter)):
+            self.log = self._logtologger
+        else:
+            self.log = self._logtofile
+
+    def filter(self, msg, curs):
+        """Filter the query before logging it.
+
+        This is the method to overwrite to filter unwanted queries out of the
+        log or to add some extra data to the output. The default implementation
+        just does nothing.
+        """
+        return msg
+
+    def _logtofile(self, msg, curs):
+        msg = self.filter(msg, curs)
+        if msg:
+            if PY3 and isinstance(msg, bytes):
+                msg = msg.decode(_ext.encodings[self.encoding], 'replace')
+            self._logobj.write(msg + _os.linesep)
+
+    def _logtologger(self, msg, curs):
+        msg = self.filter(msg, curs)
+        if msg:
+            self._logobj.debug(msg)
+
+    def _check(self):
+        if not hasattr(self, '_logobj'):
+            raise self.ProgrammingError(
+                "LoggingConnection object has not been initialize()d")
+
+    def cursor(self, *args, **kwargs):
+        self._check()
+        kwargs.setdefault('cursor_factory', self.cursor_factory or LoggingCursor)
+        return super(LoggingConnection, self).cursor(*args, **kwargs)
+
+
+class LoggingCursor(_cursor):
+    """A cursor that logs queries using its connection logging facilities."""
+
+    def execute(self, query, vars=None):
+        try:
+            return super(LoggingCursor, self).execute(query, vars)
+        finally:
+            self.connection.log(self.query, self)
+
+    def callproc(self, procname, vars=None):
+        try:
+            return super(LoggingCursor, self).callproc(procname, vars)
+        finally:
+            self.connection.log(self.query, self)
+
+
+class MinTimeLoggingConnection(LoggingConnection):
+    """A connection that logs queries based on execution time.
+
+    This is just an example of how to sub-class `LoggingConnection` to
+    provide some extra filtering for the logged queries. Both the
+    `initialize()` and `filter()` methods are overwritten to make sure
+    that only queries executing for more than ``mintime`` ms are logged.
+
+    Note that this connection uses the specialized cursor
+    `MinTimeLoggingCursor`.
+    """
+    def initialize(self, logobj, mintime=0):
+        LoggingConnection.initialize(self, logobj)
+        self._mintime = mintime
+
+    def filter(self, msg, curs):
+        t = (_time.time() - curs.timestamp) * 1000
+        if t > self._mintime:
+            if PY3 and isinstance(msg, bytes):
+                msg = msg.decode(_ext.encodings[self.encoding], 'replace')
+            return msg + _os.linesep + "  (execution time: %d ms)" % t
+
+    def cursor(self, *args, **kwargs):
+        kwargs.setdefault('cursor_factory',
+            self.cursor_factory or MinTimeLoggingCursor)
+        return LoggingConnection.cursor(self, *args, **kwargs)
+
+
+class MinTimeLoggingCursor(LoggingCursor):
+    """The cursor sub-class companion to `MinTimeLoggingConnection`."""
+
+    def execute(self, query, vars=None):
+        self.timestamp = _time.time()
+        return LoggingCursor.execute(self, query, vars)
+
+    def callproc(self, procname, vars=None):
+        self.timestamp = _time.time()
+        return LoggingCursor.callproc(self, procname, vars)
+
+
+class LogicalReplicationConnection(_replicationConnection):
+
+    def __init__(self, *args, **kwargs):
+        kwargs['replication_type'] = REPLICATION_LOGICAL
+        super(LogicalReplicationConnection, self).__init__(*args, **kwargs)
+
+
+class PhysicalReplicationConnection(_replicationConnection):
+
+    def __init__(self, *args, **kwargs):
+        kwargs['replication_type'] = REPLICATION_PHYSICAL
+        super(PhysicalReplicationConnection, self).__init__(*args, **kwargs)
+
+
+class StopReplication(Exception):
+    """
+    Exception used to break out of the endless loop in
+    `~ReplicationCursor.consume_stream()`.
+
+    Subclass of `~exceptions.Exception`.  Intentionally *not* inherited from
+    `~psycopg2.Error` as occurrence of this exception does not indicate an
+    error.
+    """
+    pass
+
+
+class ReplicationCursor(_replicationCursor):
+    """A cursor used for communication on replication connections."""
+
+    def create_replication_slot(self, slot_name, slot_type=None, output_plugin=None):
+        """Create streaming replication slot."""
+
+        command = "CREATE_REPLICATION_SLOT %s " % quote_ident(slot_name, self)
+
+        if slot_type is None:
+            slot_type = self.connection.replication_type
+
+        if slot_type == REPLICATION_LOGICAL:
+            if output_plugin is None:
+                raise psycopg2.ProgrammingError(
+                    "output plugin name is required to create "
+                    "logical replication slot")
+
+            command += "LOGICAL %s" % quote_ident(output_plugin, self)
+
+        elif slot_type == REPLICATION_PHYSICAL:
+            if output_plugin is not None:
+                raise psycopg2.ProgrammingError(
+                    "cannot specify output plugin name when creating "
+                    "physical replication slot")
+
+            command += "PHYSICAL"
+
+        else:
+            raise psycopg2.ProgrammingError(
+                "unrecognized replication type: %s" % repr(slot_type))
+
+        self.execute(command)
+
+    def drop_replication_slot(self, slot_name):
+        """Drop streaming replication slot."""
+
+        command = "DROP_REPLICATION_SLOT %s" % quote_ident(slot_name, self)
+        self.execute(command)
+
+    def start_replication(
+            self, slot_name=None, slot_type=None, start_lsn=0,
+            timeline=0, options=None, decode=False, status_interval=10):
+        """Start replication stream."""
+
+        command = "START_REPLICATION "
+
+        if slot_type is None:
+            slot_type = self.connection.replication_type
+
+        if slot_type == REPLICATION_LOGICAL:
+            if slot_name:
+                command += "SLOT %s " % quote_ident(slot_name, self)
+            else:
+                raise psycopg2.ProgrammingError(
+                    "slot name is required for logical replication")
+
+            command += "LOGICAL "
+
+        elif slot_type == REPLICATION_PHYSICAL:
+            if slot_name:
+                command += "SLOT %s " % quote_ident(slot_name, self)
+            # don't add "PHYSICAL", before 9.4 it was just START_REPLICATION XXX/XXX
+
+        else:
+            raise psycopg2.ProgrammingError(
+                "unrecognized replication type: %s" % repr(slot_type))
+
+        if type(start_lsn) is str:
+            lsn = start_lsn.split('/')
+            lsn = "%X/%08X" % (int(lsn[0], 16), int(lsn[1], 16))
+        else:
+            lsn = "%X/%08X" % ((start_lsn >> 32) & 0xFFFFFFFF,
+                               start_lsn & 0xFFFFFFFF)
+
+        command += lsn
+
+        if timeline != 0:
+            if slot_type == REPLICATION_LOGICAL:
+                raise psycopg2.ProgrammingError(
+                    "cannot specify timeline for logical replication")
+
+            command += " TIMELINE %d" % timeline
+
+        if options:
+            if slot_type == REPLICATION_PHYSICAL:
+                raise psycopg2.ProgrammingError(
+                    "cannot specify output plugin options for physical replication")
+
+            command += " ("
+            for k, v in options.items():
+                if not command.endswith('('):
+                    command += ", "
+                command += "%s %s" % (quote_ident(k, self), _A(str(v)))
+            command += ")"
+
+        self.start_replication_expert(
+            command, decode=decode, status_interval=status_interval)
+
+    # allows replication cursors to be used in select.select() directly
+    def fileno(self):
+        return self.connection.fileno()
+
+
+# a dbtype and adapter for Python UUID type
+
+class UUID_adapter(object):
+    """Adapt Python's uuid.UUID__ type to PostgreSQL's uuid__.
+
+    .. __: https://docs.python.org/library/uuid.html
+    .. __: https://www.postgresql.org/docs/current/static/datatype-uuid.html
+    """
+
+    def __init__(self, uuid):
+        self._uuid = uuid
+
+    def __conform__(self, proto):
+        if proto is _ext.ISQLQuote:
+            return self
+
+    def getquoted(self):
+        return ("'%s'::uuid" % self._uuid).encode('utf8')
+
+    def __str__(self):
+        return "'%s'::uuid" % self._uuid
+
+
+def register_uuid(oids=None, conn_or_curs=None):
+    """Create the UUID type and an uuid.UUID adapter.
+
+    :param oids: oid for the PostgreSQL :sql:`uuid` type, or 2-items sequence
+        with oids of the type and the array. If not specified, use PostgreSQL
+        standard oids.
+    :param conn_or_curs: where to register the typecaster. If not specified,
+        register it globally.
+    """
+
+    import uuid
+
+    if not oids:
+        oid1 = 2950
+        oid2 = 2951
+    elif isinstance(oids, (list, tuple)):
+        oid1, oid2 = oids
+    else:
+        oid1 = oids
+        oid2 = 2951
+
+    _ext.UUID = _ext.new_type((oid1, ), "UUID",
+            lambda data, cursor: data and uuid.UUID(data) or None)
+    _ext.UUIDARRAY = _ext.new_array_type((oid2,), "UUID[]", _ext.UUID)
+
+    _ext.register_type(_ext.UUID, conn_or_curs)
+    _ext.register_type(_ext.UUIDARRAY, conn_or_curs)
+    _ext.register_adapter(uuid.UUID, UUID_adapter)
+
+    return _ext.UUID
+
+
+# a type, dbtype and adapter for PostgreSQL inet type
+
+class Inet(object):
+    """Wrap a string to allow for correct SQL-quoting of inet values.
+
+    Note that this adapter does NOT check the passed value to make
+    sure it really is an inet-compatible address but DOES call adapt()
+    on it to make sure it is impossible to execute an SQL-injection
+    by passing an evil value to the initializer.
+    """
+    def __init__(self, addr):
+        self.addr = addr
+
+    def __repr__(self):
+        return "%s(%r)" % (self.__class__.__name__, self.addr)
+
+    def prepare(self, conn):
+        self._conn = conn
+
+    def getquoted(self):
+        obj = _A(self.addr)
+        if hasattr(obj, 'prepare'):
+            obj.prepare(self._conn)
+        return obj.getquoted() + b"::inet"
+
+    def __conform__(self, proto):
+        if proto is _ext.ISQLQuote:
+            return self
+
+    def __str__(self):
+        return str(self.addr)
+
+
+def register_inet(oid=None, conn_or_curs=None):
+    """Create the INET type and an Inet adapter.
+
+    :param oid: oid for the PostgreSQL :sql:`inet` type, or 2-items sequence
+        with oids of the type and the array. If not specified, use PostgreSQL
+        standard oids.
+    :param conn_or_curs: where to register the typecaster. If not specified,
+        register it globally.
+    """
+    import warnings
+    warnings.warn(
+        "the inet adapter is deprecated, it's not very useful",
+        DeprecationWarning)
+
+    if not oid:
+        oid1 = 869
+        oid2 = 1041
+    elif isinstance(oid, (list, tuple)):
+        oid1, oid2 = oid
+    else:
+        oid1 = oid
+        oid2 = 1041
+
+    _ext.INET = _ext.new_type((oid1, ), "INET",
+            lambda data, cursor: data and Inet(data) or None)
+    _ext.INETARRAY = _ext.new_array_type((oid2, ), "INETARRAY", _ext.INET)
+
+    _ext.register_type(_ext.INET, conn_or_curs)
+    _ext.register_type(_ext.INETARRAY, conn_or_curs)
+
+    return _ext.INET
+
+
+def wait_select(conn):
+    """Wait until a connection or cursor has data available.
+
+    The function is an example of a wait callback to be registered with
+    `~psycopg2.extensions.set_wait_callback()`. This function uses
+    :py:func:`~select.select()` to wait for data to become available, and
+    therefore is able to handle/receive SIGINT/KeyboardInterrupt.
+    """
+    import select
+    from psycopg2.extensions import POLL_OK, POLL_READ, POLL_WRITE
+
+    while True:
+        try:
+            state = conn.poll()
+            if state == POLL_OK:
+                break
+            elif state == POLL_READ:
+                select.select([conn.fileno()], [], [])
+            elif state == POLL_WRITE:
+                select.select([], [conn.fileno()], [])
+            else:
+                raise conn.OperationalError("bad state from poll: %s" % state)
+        except KeyboardInterrupt:
+            conn.cancel()
+            # the loop will be broken by a server error
+            continue
+
+
+def _solve_conn_curs(conn_or_curs):
+    """Return the connection and a DBAPI cursor from a connection or cursor."""
+    if conn_or_curs is None:
+        raise psycopg2.ProgrammingError("no connection or cursor provided")
+
+    if hasattr(conn_or_curs, 'execute'):
+        conn = conn_or_curs.connection
+        curs = conn.cursor(cursor_factory=_cursor)
+    else:
+        conn = conn_or_curs
+        curs = conn.cursor(cursor_factory=_cursor)
+
+    return conn, curs
+
+
+class HstoreAdapter(object):
+    """Adapt a Python dict to the hstore syntax."""
+    def __init__(self, wrapped):
+        self.wrapped = wrapped
+
+    def prepare(self, conn):
+        self.conn = conn
+
+        # use an old-style getquoted implementation if required
+        if conn.info.server_version < 90000:
+            self.getquoted = self._getquoted_8
+
+    def _getquoted_8(self):
+        """Use the operators available in PG pre-9.0."""
+        if not self.wrapped:
+            return b"''::hstore"
+
+        adapt = _ext.adapt
+        rv = []
+        for k, v in self.wrapped.items():
+            k = adapt(k)
+            k.prepare(self.conn)
+            k = k.getquoted()
+
+            if v is not None:
+                v = adapt(v)
+                v.prepare(self.conn)
+                v = v.getquoted()
+            else:
+                v = b'NULL'
+
+            # XXX this b'ing is painfully inefficient!
+            rv.append(b"(" + k + b" => " + v + b")")
+
+        return b"(" + b'||'.join(rv) + b")"
+
+    def _getquoted_9(self):
+        """Use the hstore(text[], text[]) function."""
+        if not self.wrapped:
+            return b"''::hstore"
+
+        k = _ext.adapt(list(self.wrapped.keys()))
+        k.prepare(self.conn)
+        v = _ext.adapt(list(self.wrapped.values()))
+        v.prepare(self.conn)
+        return b"hstore(" + k.getquoted() + b", " + v.getquoted() + b")"
+
+    getquoted = _getquoted_9
+
+    _re_hstore = _re.compile(r"""
+        # hstore key:
+        # a string of normal or escaped chars
+        "((?: [^"\\] | \\. )*)"
+        \s*=>\s* # hstore value
+        (?:
+            NULL # the value can be null - not catched
+            # or a quoted string like the key
+            | "((?: [^"\\] | \\. )*)"
+        )
+        (?:\s*,\s*|$) # pairs separated by comma or end of string.
+    """, _re.VERBOSE)
+
+    @classmethod
+    def parse(self, s, cur, _bsdec=_re.compile(r"\\(.)")):
+        """Parse an hstore representation in a Python string.
+
+        The hstore is represented as something like::
+
+            "a"=>"1", "b"=>"2"
+
+        with backslash-escaped strings.
+        """
+        if s is None:
+            return None
+
+        rv = {}
+        start = 0
+        for m in self._re_hstore.finditer(s):
+            if m is None or m.start() != start:
+                raise psycopg2.InterfaceError(
+                    "error parsing hstore pair at char %d" % start)
+            k = _bsdec.sub(r'\1', m.group(1))
+            v = m.group(2)
+            if v is not None:
+                v = _bsdec.sub(r'\1', v)
+
+            rv[k] = v
+            start = m.end()
+
+        if start < len(s):
+            raise psycopg2.InterfaceError(
+                "error parsing hstore: unparsed data after char %d" % start)
+
+        return rv
+
+    @classmethod
+    def parse_unicode(self, s, cur):
+        """Parse an hstore returning unicode keys and values."""
+        if s is None:
+            return None
+
+        s = s.decode(_ext.encodings[cur.connection.encoding])
+        return self.parse(s, cur)
+
+    @classmethod
+    def get_oids(self, conn_or_curs):
+        """Return the lists of OID of the hstore and hstore[] types.
+        """
+        conn, curs = _solve_conn_curs(conn_or_curs)
+
+        # Store the transaction status of the connection to revert it after use
+        conn_status = conn.status
+
+        # column typarray not available before PG 8.3
+        typarray = conn.info.server_version >= 80300 and "typarray" or "NULL"
+
+        rv0, rv1 = [], []
+
+        # get the oid for the hstore
+        curs.execute("""\
+SELECT t.oid, %s
+FROM pg_type t JOIN pg_namespace ns
+    ON typnamespace = ns.oid
+WHERE typname = 'hstore';
+""" % typarray)
+        for oids in curs:
+            rv0.append(oids[0])
+            rv1.append(oids[1])
+
+        # revert the status of the connection as before the command
+        if (conn_status != _ext.STATUS_IN_TRANSACTION
+        and not conn.autocommit):
+            conn.rollback()
+
+        return tuple(rv0), tuple(rv1)
+
+
+def register_hstore(conn_or_curs, globally=False, unicode=False,
+                    oid=None, array_oid=None):
+    r"""Register adapter and typecaster for `!dict`\-\ |hstore| conversions.
+
+    :param conn_or_curs: a connection or cursor: the typecaster will be
+        registered only on this object unless *globally* is set to `!True`
+    :param globally: register the adapter globally, not only on *conn_or_curs*
+    :param unicode: if `!True`, keys and values returned from the database
+        will be `!unicode` instead of `!str`. The option is not available on
+        Python 3
+    :param oid: the OID of the |hstore| type if known. If not, it will be
+        queried on *conn_or_curs*.
+    :param array_oid: the OID of the |hstore| array type if known. If not, it
+        will be queried on *conn_or_curs*.
+
+    The connection or cursor passed to the function will be used to query the
+    database and look for the OID of the |hstore| type (which may be different
+    across databases). If querying is not desirable (e.g. with
+    :ref:`asynchronous connections <async-support>`) you may specify it in the
+    *oid* parameter, which can be found using a query such as :sql:`SELECT
+    'hstore'::regtype::oid`. Analogously you can obtain a value for *array_oid*
+    using a query such as :sql:`SELECT 'hstore[]'::regtype::oid`.
+
+    Note that, when passing a dictionary from Python to the database, both
+    strings and unicode keys and values are supported. Dictionaries returned
+    from the database have keys/values according to the *unicode* parameter.
+
+    The |hstore| contrib module must be already installed in the database
+    (executing the ``hstore.sql`` script in your ``contrib`` directory).
+    Raise `~psycopg2.ProgrammingError` if the type is not found.
+    """
+    if oid is None:
+        oid = HstoreAdapter.get_oids(conn_or_curs)
+        if oid is None or not oid[0]:
+            raise psycopg2.ProgrammingError(
+                "hstore type not found in the database. "
+                "please install it from your 'contrib/hstore.sql' file")
+        else:
+            array_oid = oid[1]
+            oid = oid[0]
+
+    if isinstance(oid, int):
+        oid = (oid,)
+
+    if array_oid is not None:
+        if isinstance(array_oid, int):
+            array_oid = (array_oid,)
+        else:
+            array_oid = tuple([x for x in array_oid if x])
+
+    # create and register the typecaster
+    if PY2 and unicode:
+        cast = HstoreAdapter.parse_unicode
+    else:
+        cast = HstoreAdapter.parse
+
+    HSTORE = _ext.new_type(oid, "HSTORE", cast)
+    _ext.register_type(HSTORE, not globally and conn_or_curs or None)
+    _ext.register_adapter(dict, HstoreAdapter)
+
+    if array_oid:
+        HSTOREARRAY = _ext.new_array_type(array_oid, "HSTOREARRAY", HSTORE)
+        _ext.register_type(HSTOREARRAY, not globally and conn_or_curs or None)
+
+
+class CompositeCaster(object):
+    """Helps conversion of a PostgreSQL composite type into a Python object.
+
+    The class is usually created by the `register_composite()` function.
+    You may want to create and register manually instances of the class if
+    querying the database at registration time is not desirable (such as when
+    using an :ref:`asynchronous connections <async-support>`).
+
+    """
+    def __init__(self, name, oid, attrs, array_oid=None, schema=None):
+        self.name = name
+        self.schema = schema
+        self.oid = oid
+        self.array_oid = array_oid
+
+        self.attnames = [a[0] for a in attrs]
+        self.atttypes = [a[1] for a in attrs]
+        self._create_type(name, self.attnames)
+        self.typecaster = _ext.new_type((oid,), name, self.parse)
+        if array_oid:
+            self.array_typecaster = _ext.new_array_type(
+                (array_oid,), "%sARRAY" % name, self.typecaster)
+        else:
+            self.array_typecaster = None
+
+    def parse(self, s, curs):
+        if s is None:
+            return None
+
+        tokens = self.tokenize(s)
+        if len(tokens) != len(self.atttypes):
+            raise psycopg2.DataError(
+                "expecting %d components for the type %s, %d found instead" %
+                (len(self.atttypes), self.name, len(tokens)))
+
+        values = [curs.cast(oid, token)
+            for oid, token in zip(self.atttypes, tokens)]
+
+        return self.make(values)
+
+    def make(self, values):
+        """Return a new Python object representing the data being casted.
+
+        *values* is the list of attributes, already casted into their Python
+        representation.
+
+        You can subclass this method to :ref:`customize the composite cast
+        <custom-composite>`.
+        """
+
+        return self._ctor(values)
+
+    _re_tokenize = _re.compile(r"""
+  \(? ([,)])                        # an empty token, representing NULL
+| \(? " ((?: [^"] | "")*) " [,)]    # or a quoted string
+| \(? ([^",)]+) [,)]                # or an unquoted string
+    """, _re.VERBOSE)
+
+    _re_undouble = _re.compile(r'(["\\])\1')
+
+    @classmethod
+    def tokenize(self, s):
+        rv = []
+        for m in self._re_tokenize.finditer(s):
+            if m is None:
+                raise psycopg2.InterfaceError("can't parse type: %r" % s)
+            if m.group(1) is not None:
+                rv.append(None)
+            elif m.group(2) is not None:
+                rv.append(self._re_undouble.sub(r"\1", m.group(2)))
+            else:
+                rv.append(m.group(3))
+
+        return rv
+
+    def _create_type(self, name, attnames):
+        self.type = namedtuple(name, attnames)
+        self._ctor = self.type._make
+
+    @classmethod
+    def _from_db(self, name, conn_or_curs):
+        """Return a `CompositeCaster` instance for the type *name*.
+
+        Raise `ProgrammingError` if the type is not found.
+        """
+        conn, curs = _solve_conn_curs(conn_or_curs)
+
+        # Store the transaction status of the connection to revert it after use
+        conn_status = conn.status
+
+        # Use the correct schema
+        if '.' in name:
+            schema, tname = name.split('.', 1)
+        else:
+            tname = name
+            schema = 'public'
+
+        # column typarray not available before PG 8.3
+        typarray = conn.info.server_version >= 80300 and "typarray" or "NULL"
+
+        # get the type oid and attributes
+        curs.execute("""\
+SELECT t.oid, %s, attname, atttypid
+FROM pg_type t
+JOIN pg_namespace ns ON typnamespace = ns.oid
+JOIN pg_attribute a ON attrelid = typrelid
+WHERE typname = %%s AND nspname = %%s
+    AND attnum > 0 AND NOT attisdropped
+ORDER BY attnum;
+""" % typarray, (tname, schema))
+
+        recs = curs.fetchall()
+
+        # revert the status of the connection as before the command
+        if (conn_status != _ext.STATUS_IN_TRANSACTION
+        and not conn.autocommit):
+            conn.rollback()
+
+        if not recs:
+            raise psycopg2.ProgrammingError(
+                "PostgreSQL type '%s' not found" % name)
+
+        type_oid = recs[0][0]
+        array_oid = recs[0][1]
+        type_attrs = [(r[2], r[3]) for r in recs]
+
+        return self(tname, type_oid, type_attrs,
+            array_oid=array_oid, schema=schema)
+
+
+def register_composite(name, conn_or_curs, globally=False, factory=None):
+    """Register a typecaster to convert a composite type into a tuple.
+
+    :param name: the name of a PostgreSQL composite type, e.g. created using
+        the |CREATE TYPE|_ command
+    :param conn_or_curs: a connection or cursor used to find the type oid and
+        components; the typecaster is registered in a scope limited to this
+        object, unless *globally* is set to `!True`
+    :param globally: if `!False` (default) register the typecaster only on
+        *conn_or_curs*, otherwise register it globally
+    :param factory: if specified it should be a `CompositeCaster` subclass: use
+        it to :ref:`customize how to cast composite types <custom-composite>`
+    :return: the registered `CompositeCaster` or *factory* instance
+        responsible for the conversion
+    """
+    if factory is None:
+        factory = CompositeCaster
+
+    caster = factory._from_db(name, conn_or_curs)
+    _ext.register_type(caster.typecaster, not globally and conn_or_curs or None)
+
+    if caster.array_typecaster is not None:
+        _ext.register_type(
+            caster.array_typecaster, not globally and conn_or_curs or None)
+
+    return caster
+
+
+def _paginate(seq, page_size):
+    """Consume an iterable and return it in chunks.
+
+    Every chunk is at most `page_size`. Never return an empty chunk.
+    """
+    page = []
+    it = iter(seq)
+    while True:
+        try:
+            for i in range(page_size):
+                page.append(next(it))
+            yield page
+            page = []
+        except StopIteration:
+            if page:
+                yield page
+            return
+
+
+def execute_batch(cur, sql, argslist, page_size=100):
+    r"""Execute groups of statements in fewer server roundtrips.
+
+    Execute *sql* several times, against all parameters set (sequences or
+    mappings) found in *argslist*.
+
+    The function is semantically similar to
+
+    .. parsed-literal::
+
+        *cur*\.\ `~cursor.executemany`\ (\ *sql*\ , *argslist*\ )
+
+    but has a different implementation: Psycopg will join the statements into
+    fewer multi-statement commands, each one containing at most *page_size*
+    statements, resulting in a reduced number of server roundtrips.
+
+    After the execution of the function the `cursor.rowcount` property will
+    **not** contain a total result.
+
+    """
+    for page in _paginate(argslist, page_size=page_size):
+        sqls = [cur.mogrify(sql, args) for args in page]
+        cur.execute(b";".join(sqls))
+
+
+def execute_values(cur, sql, argslist, template=None, page_size=100, fetch=False):
+    '''Execute a statement using :sql:`VALUES` with a sequence of parameters.
+
+    :param cur: the cursor to use to execute the query.
+
+    :param sql: the query to execute. It must contain a single ``%s``
+        placeholder, which will be replaced by a `VALUES list`__.
+        Example: ``"INSERT INTO mytable (id, f1, f2) VALUES %s"``.
+
+    :param argslist: sequence of sequences or dictionaries with the arguments
+        to send to the query. The type and content must be consistent with
+        *template*.
+
+    :param template: the snippet to merge to every item in *argslist* to
+        compose the query.
+
+        - If the *argslist* items are sequences it should contain positional
+          placeholders (e.g. ``"(%s, %s, %s)"``, or ``"(%s, %s, 42)``" if there
+          are constants value...).
+
+        - If the *argslist* items are mappings it should contain named
+          placeholders (e.g. ``"(%(id)s, %(f1)s, 42)"``).
+
+        If not specified, assume the arguments are sequence and use a simple
+        positional template (i.e.  ``(%s, %s, ...)``), with the number of
+        placeholders sniffed by the first element in *argslist*.
+
+    :param page_size: maximum number of *argslist* items to include in every
+        statement. If there are more items the function will execute more than
+        one statement.
+
+    :param fetch: if `!True` return the query results into a list (like in a
+        `~cursor.fetchall()`).  Useful for queries with :sql:`RETURNING`
+        clause.
+
+    .. __: https://www.postgresql.org/docs/current/static/queries-values.html
+
+    After the execution of the function the `cursor.rowcount` property will
+    **not** contain a total result.
+
+    While :sql:`INSERT` is an obvious candidate for this function it is
+    possible to use it with other statements, for example::
+
+        >>> cur.execute(
+        ... "create table test (id int primary key, v1 int, v2 int)")
+
+        >>> execute_values(cur,
+        ... "INSERT INTO test (id, v1, v2) VALUES %s",
+        ... [(1, 2, 3), (4, 5, 6), (7, 8, 9)])
+
+        >>> execute_values(cur,
+        ... """UPDATE test SET v1 = data.v1 FROM (VALUES %s) AS data (id, v1)
+        ... WHERE test.id = data.id""",
+        ... [(1, 20), (4, 50)])
+
+        >>> cur.execute("select * from test order by id")
+        >>> cur.fetchall()
+        [(1, 20, 3), (4, 50, 6), (7, 8, 9)])
+
+    '''
+    from psycopg2.sql import Composable
+    if isinstance(sql, Composable):
+        sql = sql.as_string(cur)
+
+    # we can't just use sql % vals because vals is bytes: if sql is bytes
+    # there will be some decoding error because of stupid codec used, and Py3
+    # doesn't implement % on bytes.
+    if not isinstance(sql, bytes):
+        sql = sql.encode(_ext.encodings[cur.connection.encoding])
+    pre, post = _split_sql(sql)
+
+    result = [] if fetch else None
+    for page in _paginate(argslist, page_size=page_size):
+        if template is None:
+            template = b'(' + b','.join([b'%s'] * len(page[0])) + b')'
+        parts = pre[:]
+        for args in page:
+            parts.append(cur.mogrify(template, args))
+            parts.append(b',')
+        parts[-1:] = post
+        cur.execute(b''.join(parts))
+        if fetch:
+            result.extend(cur.fetchall())
+
+    return result
+
+
+def _split_sql(sql):
+    """Split *sql* on a single ``%s`` placeholder.
+
+    Split on the %s, perform %% replacement and return pre, post lists of
+    snippets.
+    """
+    curr = pre = []
+    post = []
+    tokens = _re.split(br'(%.)', sql)
+    for token in tokens:
+        if len(token) != 2 or token[:1] != b'%':
+            curr.append(token)
+            continue
+
+        if token[1:] == b's':
+            if curr is pre:
+                curr = post
+            else:
+                raise ValueError(
+                    "the query contains more than one '%s' placeholder")
+        elif token[1:] == b'%':
+            curr.append(b'%')
+        else:
+            raise ValueError("unsupported format character: '%s'"
+                % token[1:].decode('ascii', 'replace'))
+
+    if curr is pre:
+        raise ValueError("the query doesn't contain any '%s' placeholder")
+
+    return pre, post
Index: venv/Lib/site-packages/python_dateutil-2.8.1.dist-info/METADATA
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/venv/Lib/site-packages/python_dateutil-2.8.1.dist-info/METADATA b/venv/Lib/site-packages/python_dateutil-2.8.1.dist-info/METADATA
new file mode 100644
--- /dev/null	(date 1616406051845)
+++ b/venv/Lib/site-packages/python_dateutil-2.8.1.dist-info/METADATA	(date 1616406051845)
@@ -0,0 +1,200 @@
+Metadata-Version: 2.1
+Name: python-dateutil
+Version: 2.8.1
+Summary: Extensions to the standard Python datetime module
+Home-page: https://dateutil.readthedocs.io
+Author: Gustavo Niemeyer
+Author-email: gustavo@niemeyer.net
+Maintainer: Paul Ganssle
+Maintainer-email: dateutil@python.org
+License: Dual License
+Platform: UNKNOWN
+Classifier: Development Status :: 5 - Production/Stable
+Classifier: Intended Audience :: Developers
+Classifier: License :: OSI Approved :: BSD License
+Classifier: License :: OSI Approved :: Apache Software License
+Classifier: Programming Language :: Python
+Classifier: Programming Language :: Python :: 2
+Classifier: Programming Language :: Python :: 2.7
+Classifier: Programming Language :: Python :: 3
+Classifier: Programming Language :: Python :: 3.3
+Classifier: Programming Language :: Python :: 3.4
+Classifier: Programming Language :: Python :: 3.5
+Classifier: Programming Language :: Python :: 3.6
+Classifier: Programming Language :: Python :: 3.7
+Classifier: Programming Language :: Python :: 3.8
+Classifier: Topic :: Software Development :: Libraries
+Requires-Python: !=3.0.*,!=3.1.*,!=3.2.*,>=2.7
+Description-Content-Type: text/x-rst
+Requires-Dist: six (>=1.5)
+
+dateutil - powerful extensions to datetime
+==========================================
+
+|pypi| |support| |licence|
+
+|gitter| |readthedocs|
+
+|travis| |appveyor| |pipelines| |coverage|
+
+.. |pypi| image:: https://img.shields.io/pypi/v/python-dateutil.svg?style=flat-square
+    :target: https://pypi.org/project/python-dateutil/
+    :alt: pypi version
+
+.. |support| image:: https://img.shields.io/pypi/pyversions/python-dateutil.svg?style=flat-square
+    :target: https://pypi.org/project/python-dateutil/
+    :alt: supported Python version
+
+.. |travis| image:: https://img.shields.io/travis/dateutil/dateutil/master.svg?style=flat-square&label=Travis%20Build
+    :target: https://travis-ci.org/dateutil/dateutil
+    :alt: travis build status
+
+.. |appveyor| image:: https://img.shields.io/appveyor/ci/dateutil/dateutil/master.svg?style=flat-square&logo=appveyor
+    :target: https://ci.appveyor.com/project/dateutil/dateutil
+    :alt: appveyor build status
+
+.. |pipelines| image:: https://dev.azure.com/pythondateutilazure/dateutil/_apis/build/status/dateutil.dateutil?branchName=master
+    :target: https://dev.azure.com/pythondateutilazure/dateutil/_build/latest?definitionId=1&branchName=master
+    :alt: azure pipelines build status
+
+.. |coverage| image:: https://codecov.io/github/dateutil/dateutil/coverage.svg?branch=master
+    :target: https://codecov.io/github/dateutil/dateutil?branch=master
+    :alt: Code coverage
+
+.. |gitter| image:: https://badges.gitter.im/dateutil/dateutil.svg
+   :alt: Join the chat at https://gitter.im/dateutil/dateutil
+   :target: https://gitter.im/dateutil/dateutil
+
+.. |licence| image:: https://img.shields.io/pypi/l/python-dateutil.svg?style=flat-square
+    :target: https://pypi.org/project/python-dateutil/
+    :alt: licence
+
+.. |readthedocs| image:: https://img.shields.io/readthedocs/dateutil/latest.svg?style=flat-square&label=Read%20the%20Docs
+   :alt: Read the documentation at https://dateutil.readthedocs.io/en/latest/
+   :target: https://dateutil.readthedocs.io/en/latest/
+
+The `dateutil` module provides powerful extensions to
+the standard `datetime` module, available in Python.
+
+Installation
+============
+`dateutil` can be installed from PyPI using `pip` (note that the package name is
+different from the importable name)::
+
+    pip install python-dateutil
+
+Download
+========
+dateutil is available on PyPI
+https://pypi.org/project/python-dateutil/
+
+The documentation is hosted at:
+https://dateutil.readthedocs.io/en/stable/
+
+Code
+====
+The code and issue tracker are hosted on GitHub:
+https://github.com/dateutil/dateutil/
+
+Features
+========
+
+* Computing of relative deltas (next month, next year,
+  next Monday, last week of month, etc);
+* Computing of relative deltas between two given
+  date and/or datetime objects;
+* Computing of dates based on very flexible recurrence rules,
+  using a superset of the `iCalendar <https://www.ietf.org/rfc/rfc2445.txt>`_
+  specification. Parsing of RFC strings is supported as well.
+* Generic parsing of dates in almost any string format;
+* Timezone (tzinfo) implementations for tzfile(5) format
+  files (/etc/localtime, /usr/share/zoneinfo, etc), TZ
+  environment string (in all known formats), iCalendar
+  format files, given ranges (with help from relative deltas),
+  local machine timezone, fixed offset timezone, UTC timezone,
+  and Windows registry-based time zones.
+* Internal up-to-date world timezone information based on
+  Olson's database.
+* Computing of Easter Sunday dates for any given year,
+  using Western, Orthodox or Julian algorithms;
+* A comprehensive test suite.
+
+Quick example
+=============
+Here's a snapshot, just to give an idea about the power of the
+package. For more examples, look at the documentation.
+
+Suppose you want to know how much time is left, in
+years/months/days/etc, before the next easter happening on a
+year with a Friday 13th in August, and you want to get today's
+date out of the "date" unix system command. Here is the code:
+
+.. code-block:: python3
+
+    >>> from dateutil.relativedelta import *
+    >>> from dateutil.easter import *
+    >>> from dateutil.rrule import *
+    >>> from dateutil.parser import *
+    >>> from datetime import *
+    >>> now = parse("Sat Oct 11 17:13:46 UTC 2003")
+    >>> today = now.date()
+    >>> year = rrule(YEARLY,dtstart=now,bymonth=8,bymonthday=13,byweekday=FR)[0].year
+    >>> rdelta = relativedelta(easter(year), today)
+    >>> print("Today is: %s" % today)
+    Today is: 2003-10-11
+    >>> print("Year with next Aug 13th on a Friday is: %s" % year)
+    Year with next Aug 13th on a Friday is: 2004
+    >>> print("How far is the Easter of that year: %s" % rdelta)
+    How far is the Easter of that year: relativedelta(months=+6)
+    >>> print("And the Easter of that year is: %s" % (today+rdelta))
+    And the Easter of that year is: 2004-04-11
+
+Being exactly 6 months ahead was **really** a coincidence :)
+
+Contributing
+============
+
+We welcome many types of contributions - bug reports, pull requests (code, infrastructure or documentation fixes). For more information about how to contribute to the project, see the ``CONTRIBUTING.md`` file in the repository.
+
+
+Author
+======
+The dateutil module was written by Gustavo Niemeyer <gustavo@niemeyer.net>
+in 2003.
+
+It is maintained by:
+
+* Gustavo Niemeyer <gustavo@niemeyer.net> 2003-2011
+* Tomi Pievilinen <tomi.pievilainen@iki.fi> 2012-2014
+* Yaron de Leeuw <me@jarondl.net> 2014-2016
+* Paul Ganssle <paul@ganssle.io> 2015-
+
+Starting with version 2.4.1, all source and binary distributions will be signed
+by a PGP key that has, at the very least, been signed by the key which made the
+previous release. A table of release signing keys can be found below:
+
+===========  ============================
+Releases     Signing key fingerprint
+===========  ============================
+2.4.1-       `6B49 ACBA DCF6 BD1C A206 67AB CD54 FCE3 D964 BEFB`_ (|pgp_mirror|_)
+===========  ============================
+
+
+Contact
+=======
+Our mailing list is available at `dateutil@python.org <https://mail.python.org/mailman/listinfo/dateutil>`_. As it is hosted by the PSF, it is subject to the `PSF code of
+conduct <https://www.python.org/psf/codeofconduct/>`_.
+
+License
+=======
+
+All contributions after December 1, 2017 released under dual license - either `Apache 2.0 License <https://www.apache.org/licenses/LICENSE-2.0>`_ or the `BSD 3-Clause License <https://opensource.org/licenses/BSD-3-Clause>`_. Contributions before December 1, 2017 - except those those explicitly relicensed - are released only under the BSD 3-Clause License.
+
+
+.. _6B49 ACBA DCF6 BD1C A206 67AB CD54 FCE3 D964 BEFB:
+   https://pgp.mit.edu/pks/lookup?op=vindex&search=0xCD54FCE3D964BEFB
+
+.. |pgp_mirror| replace:: mirror
+.. _pgp_mirror: https://sks-keyservers.net/pks/lookup?op=vindex&search=0xCD54FCE3D964BEFB
+
+
Index: latest/Lib/site-packages/psycopg2/pool.py
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/latest/Lib/site-packages/psycopg2/pool.py b/latest/Lib/site-packages/psycopg2/pool.py
new file mode 100644
--- /dev/null	(date 1616409347263)
+++ b/latest/Lib/site-packages/psycopg2/pool.py	(date 1616409347263)
@@ -0,0 +1,187 @@
+"""Connection pooling for psycopg2
+
+This module implements thread-safe (and not) connection pools.
+"""
+# psycopg/pool.py - pooling code for psycopg
+#
+# Copyright (C) 2003-2019 Federico Di Gregorio  <fog@debian.org>
+# Copyright (C) 2020 The Psycopg Team
+#
+# psycopg2 is free software: you can redistribute it and/or modify it
+# under the terms of the GNU Lesser General Public License as published
+# by the Free Software Foundation, either version 3 of the License, or
+# (at your option) any later version.
+#
+# In addition, as a special exception, the copyright holders give
+# permission to link this program with the OpenSSL library (or with
+# modified versions of OpenSSL that use the same license as OpenSSL),
+# and distribute linked combinations including the two.
+#
+# You must obey the GNU Lesser General Public License in all respects for
+# all of the code used other than OpenSSL.
+#
+# psycopg2 is distributed in the hope that it will be useful, but WITHOUT
+# ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or
+# FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public
+# License for more details.
+
+import psycopg2
+from psycopg2 import extensions as _ext
+
+
+class PoolError(psycopg2.Error):
+    pass
+
+
+class AbstractConnectionPool(object):
+    """Generic key-based pooling code."""
+
+    def __init__(self, minconn, maxconn, *args, **kwargs):
+        """Initialize the connection pool.
+
+        New 'minconn' connections are created immediately calling 'connfunc'
+        with given parameters. The connection pool will support a maximum of
+        about 'maxconn' connections.
+        """
+        self.minconn = int(minconn)
+        self.maxconn = int(maxconn)
+        self.closed = False
+
+        self._args = args
+        self._kwargs = kwargs
+
+        self._pool = []
+        self._used = {}
+        self._rused = {}    # id(conn) -> key map
+        self._keys = 0
+
+        for i in range(self.minconn):
+            self._connect()
+
+    def _connect(self, key=None):
+        """Create a new connection and assign it to 'key' if not None."""
+        conn = psycopg2.connect(*self._args, **self._kwargs)
+        if key is not None:
+            self._used[key] = conn
+            self._rused[id(conn)] = key
+        else:
+            self._pool.append(conn)
+        return conn
+
+    def _getkey(self):
+        """Return a new unique key."""
+        self._keys += 1
+        return self._keys
+
+    def _getconn(self, key=None):
+        """Get a free connection and assign it to 'key' if not None."""
+        if self.closed:
+            raise PoolError("connection pool is closed")
+        if key is None:
+            key = self._getkey()
+
+        if key in self._used:
+            return self._used[key]
+
+        if self._pool:
+            self._used[key] = conn = self._pool.pop()
+            self._rused[id(conn)] = key
+            return conn
+        else:
+            if len(self._used) == self.maxconn:
+                raise PoolError("connection pool exhausted")
+            return self._connect(key)
+
+    def _putconn(self, conn, key=None, close=False):
+        """Put away a connection."""
+        if self.closed:
+            raise PoolError("connection pool is closed")
+
+        if key is None:
+            key = self._rused.get(id(conn))
+            if key is None:
+                raise PoolError("trying to put unkeyed connection")
+
+        if len(self._pool) < self.minconn and not close:
+            # Return the connection into a consistent state before putting
+            # it back into the pool
+            if not conn.closed:
+                status = conn.info.transaction_status
+                if status == _ext.TRANSACTION_STATUS_UNKNOWN:
+                    # server connection lost
+                    conn.close()
+                elif status != _ext.TRANSACTION_STATUS_IDLE:
+                    # connection in error or in transaction
+                    conn.rollback()
+                    self._pool.append(conn)
+                else:
+                    # regular idle connection
+                    self._pool.append(conn)
+            # If the connection is closed, we just discard it.
+        else:
+            conn.close()
+
+        # here we check for the presence of key because it can happen that a
+        # thread tries to put back a connection after a call to close
+        if not self.closed or key in self._used:
+            del self._used[key]
+            del self._rused[id(conn)]
+
+    def _closeall(self):
+        """Close all connections.
+
+        Note that this can lead to some code fail badly when trying to use
+        an already closed connection. If you call .closeall() make sure
+        your code can deal with it.
+        """
+        if self.closed:
+            raise PoolError("connection pool is closed")
+        for conn in self._pool + list(self._used.values()):
+            try:
+                conn.close()
+            except Exception:
+                pass
+        self.closed = True
+
+
+class SimpleConnectionPool(AbstractConnectionPool):
+    """A connection pool that can't be shared across different threads."""
+
+    getconn = AbstractConnectionPool._getconn
+    putconn = AbstractConnectionPool._putconn
+    closeall = AbstractConnectionPool._closeall
+
+
+class ThreadedConnectionPool(AbstractConnectionPool):
+    """A connection pool that works with the threading module."""
+
+    def __init__(self, minconn, maxconn, *args, **kwargs):
+        """Initialize the threading lock."""
+        import threading
+        AbstractConnectionPool.__init__(
+            self, minconn, maxconn, *args, **kwargs)
+        self._lock = threading.Lock()
+
+    def getconn(self, key=None):
+        """Get a free connection and assign it to 'key' if not None."""
+        self._lock.acquire()
+        try:
+            return self._getconn(key)
+        finally:
+            self._lock.release()
+
+    def putconn(self, conn=None, key=None, close=False):
+        """Put away an unused connection."""
+        self._lock.acquire()
+        try:
+            self._putconn(conn, key, close)
+        finally:
+            self._lock.release()
+
+    def closeall(self):
+        """Close all connections (even the one currently in use.)"""
+        self._lock.acquire()
+        try:
+            self._closeall()
+        finally:
+            self._lock.release()
Index: venv/Lib/site-packages/python_dateutil-2.8.1.dist-info/RECORD
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/venv/Lib/site-packages/python_dateutil-2.8.1.dist-info/RECORD b/venv/Lib/site-packages/python_dateutil-2.8.1.dist-info/RECORD
new file mode 100644
--- /dev/null	(date 1616406053757)
+++ b/venv/Lib/site-packages/python_dateutil-2.8.1.dist-info/RECORD	(date 1616406053757)
@@ -0,0 +1,44 @@
+dateutil/__init__.py,sha256=lXElASqwYGwqlrSWSeX19JwF5Be9tNecDa9ebk-0gmk,222
+dateutil/__pycache__/__init__.cpython-36.pyc,,
+dateutil/__pycache__/_common.cpython-36.pyc,,
+dateutil/__pycache__/_version.cpython-36.pyc,,
+dateutil/__pycache__/easter.cpython-36.pyc,,
+dateutil/__pycache__/relativedelta.cpython-36.pyc,,
+dateutil/__pycache__/rrule.cpython-36.pyc,,
+dateutil/__pycache__/tzwin.cpython-36.pyc,,
+dateutil/__pycache__/utils.cpython-36.pyc,,
+dateutil/_common.py,sha256=77w0yytkrxlYbSn--lDVPUMabUXRR9I3lBv_vQRUqUY,932
+dateutil/_version.py,sha256=U1JNX8P5pUNBtcStwfGyAUIMMHGZXhiTDTVXgAUWxs4,116
+dateutil/easter.py,sha256=0liVsgqSx-NPhaFevOJaYgEbrSu2oQQ2o9m_OEBdc-s,2684
+dateutil/parser/__init__.py,sha256=wWk6GFuxTpjoggCGtgkceJoti4pVjl4_fHQXpNOaSYg,1766
+dateutil/parser/__pycache__/__init__.cpython-36.pyc,,
+dateutil/parser/__pycache__/_parser.cpython-36.pyc,,
+dateutil/parser/__pycache__/isoparser.cpython-36.pyc,,
+dateutil/parser/_parser.py,sha256=F0w8h9txvatnYAmeJ1MMbIAvZHRzy3iFjv-AZqRovNs,58804
+dateutil/parser/isoparser.py,sha256=BeEEqIeqhcgik5Cp1_G5Aztsqayp-MAr3aVqAKo1XRc,13098
+dateutil/relativedelta.py,sha256=GjVxqpAVWnG67rdbf7pkoIlJvQqmju9NSfGCcqblc7U,24904
+dateutil/rrule.py,sha256=dStRcOIj8jul-BurMKguc_IBckY-Qci1K6EYqNW8eUg,66514
+dateutil/tz/__init__.py,sha256=F-Mz13v6jYseklQf9Te9J6nzcLDmq47gORa61K35_FA,444
+dateutil/tz/__pycache__/__init__.cpython-36.pyc,,
+dateutil/tz/__pycache__/_common.cpython-36.pyc,,
+dateutil/tz/__pycache__/_factories.cpython-36.pyc,,
+dateutil/tz/__pycache__/tz.cpython-36.pyc,,
+dateutil/tz/__pycache__/win.cpython-36.pyc,,
+dateutil/tz/_common.py,sha256=cgzDTANsOXvEc86cYF77EsliuSab8Puwpsl5-bX3_S4,12977
+dateutil/tz/_factories.py,sha256=unb6XQNXrPMveksTCU-Ag8jmVZs4SojoPUcAHpWnrvU,2569
+dateutil/tz/tz.py,sha256=npaGnA2M2LGUUerXzAml9rMM-BE771igYFcFETeC3JE,62851
+dateutil/tz/win.py,sha256=xJszWgSwE1xPx_HJj4ZkepyukC_hNy016WMcXhbRaB8,12935
+dateutil/tzwin.py,sha256=7Ar4vdQCnnM0mKR3MUjbIKsZrBVfHgdwsJZc_mGYRew,59
+dateutil/utils.py,sha256=Agvhi7i3HuJdwHYCe9lDS63l_LNFUUlB2hmR3ZKNYwE,1959
+dateutil/zoneinfo/__init__.py,sha256=KYg0pthCMjcp5MXSEiBJn3nMjZeNZav7rlJw5-tz1S4,5889
+dateutil/zoneinfo/__pycache__/__init__.cpython-36.pyc,,
+dateutil/zoneinfo/__pycache__/rebuild.cpython-36.pyc,,
+dateutil/zoneinfo/dateutil-zoneinfo.tar.gz,sha256=6bZJKrN3mhnCqMgQgFSllQNNbtld9AnuPaRIXWoSH4o,153315
+dateutil/zoneinfo/rebuild.py,sha256=2uFJQiW3Fl8fVogrSXisJMpLeHI1zGwpvBFF43QdeF0,1719
+python_dateutil-2.8.1.dist-info/INSTALLER,sha256=zuuue4knoyJ-UwPPXg8fezS7VCrXJQrAP7zeNuwvFQg,4
+python_dateutil-2.8.1.dist-info/LICENSE,sha256=ugD1Gg2SgjtaHN4n2LW50jIeZ-2NqbwWPv-W1eF-V34,2889
+python_dateutil-2.8.1.dist-info/METADATA,sha256=u7pGPxvY3bP0MsvsWab9OeTybTnbLX011vZxRW12I1Y,7988
+python_dateutil-2.8.1.dist-info/RECORD,,
+python_dateutil-2.8.1.dist-info/WHEEL,sha256=8zNYZbwQSXoB9IfXOjPfeNwvAsALAjffgk27FqvCWbo,110
+python_dateutil-2.8.1.dist-info/top_level.txt,sha256=4tjdWkhRZvF7LA_BYe_L9gB2w_p2a-z5y6ArjaRkot8,9
+python_dateutil-2.8.1.dist-info/zip-safe,sha256=AbpHGcgLb-kRsJGnwFEktk7uzpZOCcBY74-YBdrKVGs,1
Index: venv/Lib/site-packages/python_dateutil-2.8.1.dist-info/top_level.txt
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/venv/Lib/site-packages/python_dateutil-2.8.1.dist-info/top_level.txt b/venv/Lib/site-packages/python_dateutil-2.8.1.dist-info/top_level.txt
new file mode 100644
--- /dev/null	(date 1616406051861)
+++ b/venv/Lib/site-packages/python_dateutil-2.8.1.dist-info/top_level.txt	(date 1616406051861)
@@ -0,0 +1,1 @@
+dateutil
Index: latest/Lib/site-packages/psycopg2/sql.py
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/latest/Lib/site-packages/psycopg2/sql.py b/latest/Lib/site-packages/psycopg2/sql.py
new file mode 100644
--- /dev/null	(date 1616409347265)
+++ b/latest/Lib/site-packages/psycopg2/sql.py	(date 1616409347265)
@@ -0,0 +1,456 @@
+"""SQL composition utility module
+"""
+
+# psycopg/sql.py - SQL composition utility module
+#
+# Copyright (C) 2016-2019 Daniele Varrazzo  <daniele.varrazzo@gmail.com>
+# Copyright (C) 2020 The Psycopg Team
+#
+# psycopg2 is free software: you can redistribute it and/or modify it
+# under the terms of the GNU Lesser General Public License as published
+# by the Free Software Foundation, either version 3 of the License, or
+# (at your option) any later version.
+#
+# In addition, as a special exception, the copyright holders give
+# permission to link this program with the OpenSSL library (or with
+# modified versions of OpenSSL that use the same license as OpenSSL),
+# and distribute linked combinations including the two.
+#
+# You must obey the GNU Lesser General Public License in all respects for
+# all of the code used other than OpenSSL.
+#
+# psycopg2 is distributed in the hope that it will be useful, but WITHOUT
+# ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or
+# FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public
+# License for more details.
+
+import string
+
+from psycopg2 import extensions as ext
+from psycopg2.compat import PY3, string_types
+
+
+_formatter = string.Formatter()
+
+
+class Composable(object):
+    """
+    Abstract base class for objects that can be used to compose an SQL string.
+
+    `!Composable` objects can be passed directly to `~cursor.execute()`,
+    `~cursor.executemany()`, `~cursor.copy_expert()` in place of the query
+    string.
+
+    `!Composable` objects can be joined using the ``+`` operator: the result
+    will be a `Composed` instance containing the objects joined. The operator
+    ``*`` is also supported with an integer argument: the result is a
+    `!Composed` instance containing the left argument repeated as many times as
+    requested.
+    """
+    def __init__(self, wrapped):
+        self._wrapped = wrapped
+
+    def __repr__(self):
+        return "%s(%r)" % (self.__class__.__name__, self._wrapped)
+
+    def as_string(self, context):
+        """
+        Return the string value of the object.
+
+        :param context: the context to evaluate the string into.
+        :type context: `connection` or `cursor`
+
+        The method is automatically invoked by `~cursor.execute()`,
+        `~cursor.executemany()`, `~cursor.copy_expert()` if a `!Composable` is
+        passed instead of the query string.
+        """
+        raise NotImplementedError
+
+    def __add__(self, other):
+        if isinstance(other, Composed):
+            return Composed([self]) + other
+        if isinstance(other, Composable):
+            return Composed([self]) + Composed([other])
+        else:
+            return NotImplemented
+
+    def __mul__(self, n):
+        return Composed([self] * n)
+
+    def __eq__(self, other):
+        return type(self) is type(other) and self._wrapped == other._wrapped
+
+    def __ne__(self, other):
+        return not self.__eq__(other)
+
+
+class Composed(Composable):
+    """
+    A `Composable` object made of a sequence of `!Composable`.
+
+    The object is usually created using `!Composable` operators and methods.
+    However it is possible to create a `!Composed` directly specifying a
+    sequence of `!Composable` as arguments.
+
+    Example::
+
+        >>> comp = sql.Composed(
+        ...     [sql.SQL("insert into "), sql.Identifier("table")])
+        >>> print(comp.as_string(conn))
+        insert into "table"
+
+    `!Composed` objects are iterable (so they can be used in `SQL.join` for
+    instance).
+    """
+    def __init__(self, seq):
+        wrapped = []
+        for i in seq:
+            if not isinstance(i, Composable):
+                raise TypeError(
+                    "Composed elements must be Composable, got %r instead" % i)
+            wrapped.append(i)
+
+        super(Composed, self).__init__(wrapped)
+
+    @property
+    def seq(self):
+        """The list of the content of the `!Composed`."""
+        return list(self._wrapped)
+
+    def as_string(self, context):
+        rv = []
+        for i in self._wrapped:
+            rv.append(i.as_string(context))
+        return ''.join(rv)
+
+    def __iter__(self):
+        return iter(self._wrapped)
+
+    def __add__(self, other):
+        if isinstance(other, Composed):
+            return Composed(self._wrapped + other._wrapped)
+        if isinstance(other, Composable):
+            return Composed(self._wrapped + [other])
+        else:
+            return NotImplemented
+
+    def join(self, joiner):
+        """
+        Return a new `!Composed` interposing the *joiner* with the `!Composed` items.
+
+        The *joiner* must be a `SQL` or a string which will be interpreted as
+        an `SQL`.
+
+        Example::
+
+            >>> fields = sql.Identifier('foo') + sql.Identifier('bar')  # a Composed
+            >>> print(fields.join(', ').as_string(conn))
+            "foo", "bar"
+
+        """
+        if isinstance(joiner, string_types):
+            joiner = SQL(joiner)
+        elif not isinstance(joiner, SQL):
+            raise TypeError(
+                "Composed.join() argument must be a string or an SQL")
+
+        return joiner.join(self)
+
+
+class SQL(Composable):
+    """
+    A `Composable` representing a snippet of SQL statement.
+
+    `!SQL` exposes `join()` and `format()` methods useful to create a template
+    where to merge variable parts of a query (for instance field or table
+    names).
+
+    The *string* doesn't undergo any form of escaping, so it is not suitable to
+    represent variable identifiers or values: you should only use it to pass
+    constant strings representing templates or snippets of SQL statements; use
+    other objects such as `Identifier` or `Literal` to represent variable
+    parts.
+
+    Example::
+
+        >>> query = sql.SQL("select {0} from {1}").format(
+        ...    sql.SQL(', ').join([sql.Identifier('foo'), sql.Identifier('bar')]),
+        ...    sql.Identifier('table'))
+        >>> print(query.as_string(conn))
+        select "foo", "bar" from "table"
+    """
+    def __init__(self, string):
+        if not isinstance(string, string_types):
+            raise TypeError("SQL values must be strings")
+        super(SQL, self).__init__(string)
+
+    @property
+    def string(self):
+        """The string wrapped by the `!SQL` object."""
+        return self._wrapped
+
+    def as_string(self, context):
+        return self._wrapped
+
+    def format(self, *args, **kwargs):
+        """
+        Merge `Composable` objects into a template.
+
+        :param `Composable` args: parameters to replace to numbered
+            (``{0}``, ``{1}``) or auto-numbered (``{}``) placeholders
+        :param `Composable` kwargs: parameters to replace to named (``{name}``)
+            placeholders
+        :return: the union of the `!SQL` string with placeholders replaced
+        :rtype: `Composed`
+
+        The method is similar to the Python `str.format()` method: the string
+        template supports auto-numbered (``{}``), numbered (``{0}``,
+        ``{1}``...), and named placeholders (``{name}``), with positional
+        arguments replacing the numbered placeholders and keywords replacing
+        the named ones. However placeholder modifiers (``{0!r}``, ``{0:<10}``)
+        are not supported. Only `!Composable` objects can be passed to the
+        template.
+
+        Example::
+
+            >>> print(sql.SQL("select * from {} where {} = %s")
+            ...     .format(sql.Identifier('people'), sql.Identifier('id'))
+            ...     .as_string(conn))
+            select * from "people" where "id" = %s
+
+            >>> print(sql.SQL("select * from {tbl} where {pkey} = %s")
+            ...     .format(tbl=sql.Identifier('people'), pkey=sql.Identifier('id'))
+            ...     .as_string(conn))
+            select * from "people" where "id" = %s
+
+        """
+        rv = []
+        autonum = 0
+        for pre, name, spec, conv in _formatter.parse(self._wrapped):
+            if spec:
+                raise ValueError("no format specification supported by SQL")
+            if conv:
+                raise ValueError("no format conversion supported by SQL")
+            if pre:
+                rv.append(SQL(pre))
+
+            if name is None:
+                continue
+
+            if name.isdigit():
+                if autonum:
+                    raise ValueError(
+                        "cannot switch from automatic field numbering to manual")
+                rv.append(args[int(name)])
+                autonum = None
+
+            elif not name:
+                if autonum is None:
+                    raise ValueError(
+                        "cannot switch from manual field numbering to automatic")
+                rv.append(args[autonum])
+                autonum += 1
+
+            else:
+                rv.append(kwargs[name])
+
+        return Composed(rv)
+
+    def join(self, seq):
+        """
+        Join a sequence of `Composable`.
+
+        :param seq: the elements to join.
+        :type seq: iterable of `!Composable`
+
+        Use the `!SQL` object's *string* to separate the elements in *seq*.
+        Note that `Composed` objects are iterable too, so they can be used as
+        argument for this method.
+
+        Example::
+
+            >>> snip = sql.SQL(', ').join(
+            ...     sql.Identifier(n) for n in ['foo', 'bar', 'baz'])
+            >>> print(snip.as_string(conn))
+            "foo", "bar", "baz"
+        """
+        rv = []
+        it = iter(seq)
+        try:
+            rv.append(next(it))
+        except StopIteration:
+            pass
+        else:
+            for i in it:
+                rv.append(self)
+                rv.append(i)
+
+        return Composed(rv)
+
+
+class Identifier(Composable):
+    """
+    A `Composable` representing an SQL identifier or a dot-separated sequence.
+
+    Identifiers usually represent names of database objects, such as tables or
+    fields. PostgreSQL identifiers follow `different rules`__ than SQL string
+    literals for escaping (e.g. they use double quotes instead of single).
+
+    .. __: https://www.postgresql.org/docs/current/static/sql-syntax-lexical.html# \
+        SQL-SYNTAX-IDENTIFIERS
+
+    Example::
+
+        >>> t1 = sql.Identifier("foo")
+        >>> t2 = sql.Identifier("ba'r")
+        >>> t3 = sql.Identifier('ba"z')
+        >>> print(sql.SQL(', ').join([t1, t2, t3]).as_string(conn))
+        "foo", "ba'r", "ba""z"
+
+    Multiple strings can be passed to the object to represent a qualified name,
+    i.e. a dot-separated sequence of identifiers.
+
+    Example::
+
+        >>> query = sql.SQL("select {} from {}").format(
+        ...     sql.Identifier("table", "field"),
+        ...     sql.Identifier("schema", "table"))
+        >>> print(query.as_string(conn))
+        select "table"."field" from "schema"."table"
+
+    """
+    def __init__(self, *strings):
+        if not strings:
+            raise TypeError("Identifier cannot be empty")
+
+        for s in strings:
+            if not isinstance(s, string_types):
+                raise TypeError("SQL identifier parts must be strings")
+
+        super(Identifier, self).__init__(strings)
+
+    @property
+    def strings(self):
+        """A tuple with the strings wrapped by the `Identifier`."""
+        return self._wrapped
+
+    @property
+    def string(self):
+        """The string wrapped by the `Identifier`.
+        """
+        if len(self._wrapped) == 1:
+            return self._wrapped[0]
+        else:
+            raise AttributeError(
+                "the Identifier wraps more than one than one string")
+
+    def __repr__(self):
+        return "%s(%s)" % (
+            self.__class__.__name__,
+            ', '.join(map(repr, self._wrapped)))
+
+    def as_string(self, context):
+        return '.'.join(ext.quote_ident(s, context) for s in self._wrapped)
+
+
+class Literal(Composable):
+    """
+    A `Composable` representing an SQL value to include in a query.
+
+    Usually you will want to include placeholders in the query and pass values
+    as `~cursor.execute()` arguments. If however you really really need to
+    include a literal value in the query you can use this object.
+
+    The string returned by `!as_string()` follows the normal :ref:`adaptation
+    rules <python-types-adaptation>` for Python objects.
+
+    Example::
+
+        >>> s1 = sql.Literal("foo")
+        >>> s2 = sql.Literal("ba'r")
+        >>> s3 = sql.Literal(42)
+        >>> print(sql.SQL(', ').join([s1, s2, s3]).as_string(conn))
+        'foo', 'ba''r', 42
+
+    """
+    @property
+    def wrapped(self):
+        """The object wrapped by the `!Literal`."""
+        return self._wrapped
+
+    def as_string(self, context):
+        # is it a connection or cursor?
+        if isinstance(context, ext.connection):
+            conn = context
+        elif isinstance(context, ext.cursor):
+            conn = context.connection
+        else:
+            raise TypeError("context must be a connection or a cursor")
+
+        a = ext.adapt(self._wrapped)
+        if hasattr(a, 'prepare'):
+            a.prepare(conn)
+
+        rv = a.getquoted()
+        if PY3 and isinstance(rv, bytes):
+            rv = rv.decode(ext.encodings[conn.encoding])
+
+        return rv
+
+
+class Placeholder(Composable):
+    """A `Composable` representing a placeholder for query parameters.
+
+    If the name is specified, generate a named placeholder (e.g. ``%(name)s``),
+    otherwise generate a positional placeholder (e.g. ``%s``).
+
+    The object is useful to generate SQL queries with a variable number of
+    arguments.
+
+    Examples::
+
+        >>> names = ['foo', 'bar', 'baz']
+
+        >>> q1 = sql.SQL("insert into table ({}) values ({})").format(
+        ...     sql.SQL(', ').join(map(sql.Identifier, names)),
+        ...     sql.SQL(', ').join(sql.Placeholder() * len(names)))
+        >>> print(q1.as_string(conn))
+        insert into table ("foo", "bar", "baz") values (%s, %s, %s)
+
+        >>> q2 = sql.SQL("insert into table ({}) values ({})").format(
+        ...     sql.SQL(', ').join(map(sql.Identifier, names)),
+        ...     sql.SQL(', ').join(map(sql.Placeholder, names)))
+        >>> print(q2.as_string(conn))
+        insert into table ("foo", "bar", "baz") values (%(foo)s, %(bar)s, %(baz)s)
+
+    """
+
+    def __init__(self, name=None):
+        if isinstance(name, string_types):
+            if ')' in name:
+                raise ValueError("invalid name: %r" % name)
+
+        elif name is not None:
+            raise TypeError("expected string or None as name, got %r" % name)
+
+        super(Placeholder, self).__init__(name)
+
+    @property
+    def name(self):
+        """The name of the `!Placeholder`."""
+        return self._wrapped
+
+    def __repr__(self):
+        return "Placeholder(%r)" % (
+            self._wrapped if self._wrapped is not None else '',)
+
+    def as_string(self, context):
+        if self._wrapped is not None:
+            return "%%(%s)s" % self._wrapped
+        else:
+            return "%s"
+
+
+# Literals
+NULL = SQL("NULL")
+DEFAULT = SQL("DEFAULT")
Index: venv/Lib/site-packages/python_dateutil-2.8.1.dist-info/WHEEL
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/venv/Lib/site-packages/python_dateutil-2.8.1.dist-info/WHEEL b/venv/Lib/site-packages/python_dateutil-2.8.1.dist-info/WHEEL
new file mode 100644
--- /dev/null	(date 1616406051845)
+++ b/venv/Lib/site-packages/python_dateutil-2.8.1.dist-info/WHEEL	(date 1616406051845)
@@ -0,0 +1,6 @@
+Wheel-Version: 1.0
+Generator: bdist_wheel (0.33.6)
+Root-Is-Purelib: true
+Tag: py2-none-any
+Tag: py3-none-any
+
Index: latest/Lib/site-packages/psycopg2/tz.py
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/latest/Lib/site-packages/psycopg2/tz.py b/latest/Lib/site-packages/psycopg2/tz.py
new file mode 100644
--- /dev/null	(date 1616409347266)
+++ b/latest/Lib/site-packages/psycopg2/tz.py	(date 1616409347266)
@@ -0,0 +1,139 @@
+"""tzinfo implementations for psycopg2
+
+This module holds two different tzinfo implementations that can be used as
+the 'tzinfo' argument to datetime constructors, directly passed to psycopg
+functions or used to set the .tzinfo_factory attribute in cursors.
+"""
+# psycopg/tz.py - tzinfo implementation
+#
+# Copyright (C) 2003-2019 Federico Di Gregorio  <fog@debian.org>
+# Copyright (C) 2020 The Psycopg Team
+#
+# psycopg2 is free software: you can redistribute it and/or modify it
+# under the terms of the GNU Lesser General Public License as published
+# by the Free Software Foundation, either version 3 of the License, or
+# (at your option) any later version.
+#
+# In addition, as a special exception, the copyright holders give
+# permission to link this program with the OpenSSL library (or with
+# modified versions of OpenSSL that use the same license as OpenSSL),
+# and distribute linked combinations including the two.
+#
+# You must obey the GNU Lesser General Public License in all respects for
+# all of the code used other than OpenSSL.
+#
+# psycopg2 is distributed in the hope that it will be useful, but WITHOUT
+# ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or
+# FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public
+# License for more details.
+
+import datetime
+import time
+
+ZERO = datetime.timedelta(0)
+
+
+class FixedOffsetTimezone(datetime.tzinfo):
+    """Fixed offset in minutes east from UTC.
+
+    This is exactly the implementation__ found in Python 2.3.x documentation,
+    with a small change to the `!__init__()` method to allow for pickling
+    and a default name in the form ``sHH:MM`` (``s`` is the sign.).
+
+    The implementation also caches instances. During creation, if a
+    FixedOffsetTimezone instance has previously been created with the same
+    offset and name that instance will be returned. This saves memory and
+    improves comparability.
+
+    .. __: https://docs.python.org/library/datetime.html
+    """
+    _name = None
+    _offset = ZERO
+
+    _cache = {}
+
+    def __init__(self, offset=None, name=None):
+        if offset is not None:
+            self._offset = datetime.timedelta(minutes=offset)
+        if name is not None:
+            self._name = name
+
+    def __new__(cls, offset=None, name=None):
+        """Return a suitable instance created earlier if it exists
+        """
+        key = (offset, name)
+        try:
+            return cls._cache[key]
+        except KeyError:
+            tz = super(FixedOffsetTimezone, cls).__new__(cls, offset, name)
+            cls._cache[key] = tz
+            return tz
+
+    def __repr__(self):
+        offset_mins = self._offset.seconds // 60 + self._offset.days * 24 * 60
+        return "psycopg2.tz.FixedOffsetTimezone(offset=%r, name=%r)" \
+            % (offset_mins, self._name)
+
+    def __getinitargs__(self):
+        offset_mins = self._offset.seconds // 60 + self._offset.days * 24 * 60
+        return offset_mins, self._name
+
+    def utcoffset(self, dt):
+        return self._offset
+
+    def tzname(self, dt):
+        if self._name is not None:
+            return self._name
+        else:
+            seconds = self._offset.seconds + self._offset.days * 86400
+            hours, seconds = divmod(seconds, 3600)
+            minutes = seconds / 60
+            if minutes:
+                return "%+03d:%d" % (hours, minutes)
+            else:
+                return "%+03d" % hours
+
+    def dst(self, dt):
+        return ZERO
+
+
+STDOFFSET = datetime.timedelta(seconds=-time.timezone)
+if time.daylight:
+    DSTOFFSET = datetime.timedelta(seconds=-time.altzone)
+else:
+    DSTOFFSET = STDOFFSET
+DSTDIFF = DSTOFFSET - STDOFFSET
+
+
+class LocalTimezone(datetime.tzinfo):
+    """Platform idea of local timezone.
+
+    This is the exact implementation from the Python 2.3 documentation.
+    """
+    def utcoffset(self, dt):
+        if self._isdst(dt):
+            return DSTOFFSET
+        else:
+            return STDOFFSET
+
+    def dst(self, dt):
+        if self._isdst(dt):
+            return DSTDIFF
+        else:
+            return ZERO
+
+    def tzname(self, dt):
+        return time.tzname[self._isdst(dt)]
+
+    def _isdst(self, dt):
+        tt = (dt.year, dt.month, dt.day,
+              dt.hour, dt.minute, dt.second,
+              dt.weekday(), 0, -1)
+        stamp = time.mktime(tt)
+        tt = time.localtime(stamp)
+        return tt.tm_isdst > 0
+
+
+LOCAL = LocalTimezone()
+
+# TODO: pre-generate some interesting time zones?
Index: venv/Lib/site-packages/python_dateutil-2.8.1.dist-info/zip-safe
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/venv/Lib/site-packages/python_dateutil-2.8.1.dist-info/zip-safe b/venv/Lib/site-packages/python_dateutil-2.8.1.dist-info/zip-safe
new file mode 100644
--- /dev/null	(date 1616406051861)
+++ b/venv/Lib/site-packages/python_dateutil-2.8.1.dist-info/zip-safe	(date 1616406051861)
@@ -0,0 +1,1 @@
+
Index: latest/Lib/site-packages/psycopg2/_ipaddress.py
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/latest/Lib/site-packages/psycopg2/_ipaddress.py b/latest/Lib/site-packages/psycopg2/_ipaddress.py
new file mode 100644
--- /dev/null	(date 1616409347223)
+++ b/latest/Lib/site-packages/psycopg2/_ipaddress.py	(date 1616409347223)
@@ -0,0 +1,91 @@
+"""Implementation of the ipaddres-based network types adaptation
+"""
+
+# psycopg/_ipaddress.py - Ipaddres-based network types adaptation
+#
+# Copyright (C) 2016-2019 Daniele Varrazzo  <daniele.varrazzo@gmail.com>
+# Copyright (C) 2020 The Psycopg Team
+#
+# psycopg2 is free software: you can redistribute it and/or modify it
+# under the terms of the GNU Lesser General Public License as published
+# by the Free Software Foundation, either version 3 of the License, or
+# (at your option) any later version.
+#
+# In addition, as a special exception, the copyright holders give
+# permission to link this program with the OpenSSL library (or with
+# modified versions of OpenSSL that use the same license as OpenSSL),
+# and distribute linked combinations including the two.
+#
+# You must obey the GNU Lesser General Public License in all respects for
+# all of the code used other than OpenSSL.
+#
+# psycopg2 is distributed in the hope that it will be useful, but WITHOUT
+# ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or
+# FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public
+# License for more details.
+
+from psycopg2.extensions import (
+    new_type, new_array_type, register_type, register_adapter, QuotedString)
+from psycopg2.compat import text_type
+
+# The module is imported on register_ipaddress
+ipaddress = None
+
+# The typecasters are created only once
+_casters = None
+
+
+def register_ipaddress(conn_or_curs=None):
+    """
+    Register conversion support between `ipaddress` objects and `network types`__.
+
+    :param conn_or_curs: the scope where to register the type casters.
+        If `!None` register them globally.
+
+    After the function is called, PostgreSQL :sql:`inet` values will be
+    converted into `~ipaddress.IPv4Interface` or `~ipaddress.IPv6Interface`
+    objects, :sql:`cidr` values into into `~ipaddress.IPv4Network` or
+    `~ipaddress.IPv6Network`.
+
+    .. __: https://www.postgresql.org/docs/current/static/datatype-net-types.html
+    """
+    global ipaddress
+    import ipaddress
+
+    global _casters
+    if _casters is None:
+        _casters = _make_casters()
+
+    for c in _casters:
+        register_type(c, conn_or_curs)
+
+    for t in [ipaddress.IPv4Interface, ipaddress.IPv6Interface,
+              ipaddress.IPv4Network, ipaddress.IPv6Network]:
+        register_adapter(t, adapt_ipaddress)
+
+
+def _make_casters():
+    inet = new_type((869,), 'INET', cast_interface)
+    ainet = new_array_type((1041,), 'INET[]', inet)
+
+    cidr = new_type((650,), 'CIDR', cast_network)
+    acidr = new_array_type((651,), 'CIDR[]', cidr)
+
+    return [inet, ainet, cidr, acidr]
+
+
+def cast_interface(s, cur=None):
+    if s is None:
+        return None
+    # Py2 version force the use of unicode. meh.
+    return ipaddress.ip_interface(text_type(s))
+
+
+def cast_network(s, cur=None):
+    if s is None:
+        return None
+    return ipaddress.ip_network(text_type(s))
+
+
+def adapt_ipaddress(obj):
+    return QuotedString(str(obj))
Index: latest/Lib/site-packages/psycopg2/_json.py
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/latest/Lib/site-packages/psycopg2/_json.py b/latest/Lib/site-packages/psycopg2/_json.py
new file mode 100644
--- /dev/null	(date 1616409347225)
+++ b/latest/Lib/site-packages/psycopg2/_json.py	(date 1616409347225)
@@ -0,0 +1,204 @@
+"""Implementation of the JSON adaptation objects
+
+This module exists to avoid a circular import problem: pyscopg2.extras depends
+on psycopg2.extension, so I can't create the default JSON typecasters in
+extensions importing register_json from extras.
+"""
+
+# psycopg/_json.py - Implementation of the JSON adaptation objects
+#
+# Copyright (C) 2012-2019 Daniele Varrazzo  <daniele.varrazzo@gmail.com>
+# Copyright (C) 2020 The Psycopg Team
+#
+# psycopg2 is free software: you can redistribute it and/or modify it
+# under the terms of the GNU Lesser General Public License as published
+# by the Free Software Foundation, either version 3 of the License, or
+# (at your option) any later version.
+#
+# In addition, as a special exception, the copyright holders give
+# permission to link this program with the OpenSSL library (or with
+# modified versions of OpenSSL that use the same license as OpenSSL),
+# and distribute linked combinations including the two.
+#
+# You must obey the GNU Lesser General Public License in all respects for
+# all of the code used other than OpenSSL.
+#
+# psycopg2 is distributed in the hope that it will be useful, but WITHOUT
+# ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or
+# FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public
+# License for more details.
+
+import json
+
+from psycopg2._psycopg import ISQLQuote, QuotedString
+from psycopg2._psycopg import new_type, new_array_type, register_type
+from psycopg2.compat import PY2
+
+
+# oids from PostgreSQL 9.2
+JSON_OID = 114
+JSONARRAY_OID = 199
+
+# oids from PostgreSQL 9.4
+JSONB_OID = 3802
+JSONBARRAY_OID = 3807
+
+
+class Json(object):
+    """
+    An `~psycopg2.extensions.ISQLQuote` wrapper to adapt a Python object to
+    :sql:`json` data type.
+
+    `!Json` can be used to wrap any object supported by the provided *dumps*
+    function. If none is provided, the standard :py:func:`json.dumps()` is
+    used.
+
+    """
+    def __init__(self, adapted, dumps=None):
+        self.adapted = adapted
+        self._conn = None
+        self._dumps = dumps or json.dumps
+
+    def __conform__(self, proto):
+        if proto is ISQLQuote:
+            return self
+
+    def dumps(self, obj):
+        """Serialize *obj* in JSON format.
+
+        The default is to call `!json.dumps()` or the *dumps* function
+        provided in the constructor. You can override this method to create a
+        customized JSON wrapper.
+        """
+        return self._dumps(obj)
+
+    def prepare(self, conn):
+        self._conn = conn
+
+    def getquoted(self):
+        s = self.dumps(self.adapted)
+        qs = QuotedString(s)
+        if self._conn is not None:
+            qs.prepare(self._conn)
+        return qs.getquoted()
+
+    if PY2:
+        def __str__(self):
+            return self.getquoted()
+    else:
+        def __str__(self):
+            # getquoted is binary in Py3
+            return self.getquoted().decode('ascii', 'replace')
+
+
+def register_json(conn_or_curs=None, globally=False, loads=None,
+                  oid=None, array_oid=None, name='json'):
+    """Create and register typecasters converting :sql:`json` type to Python objects.
+
+    :param conn_or_curs: a connection or cursor used to find the :sql:`json`
+        and :sql:`json[]` oids; the typecasters are registered in a scope
+        limited to this object, unless *globally* is set to `!True`. It can be
+        `!None` if the oids are provided
+    :param globally: if `!False` register the typecasters only on
+        *conn_or_curs*, otherwise register them globally
+    :param loads: the function used to parse the data into a Python object. If
+        `!None` use `!json.loads()`, where `!json` is the module chosen
+        according to the Python version (see above)
+    :param oid: the OID of the :sql:`json` type if known; If not, it will be
+        queried on *conn_or_curs*
+    :param array_oid: the OID of the :sql:`json[]` array type if known;
+        if not, it will be queried on *conn_or_curs*
+    :param name: the name of the data type to look for in *conn_or_curs*
+
+    The connection or cursor passed to the function will be used to query the
+    database and look for the OID of the :sql:`json` type (or an alternative
+    type if *name* if provided). No query is performed if *oid* and *array_oid*
+    are provided.  Raise `~psycopg2.ProgrammingError` if the type is not found.
+
+    """
+    if oid is None:
+        oid, array_oid = _get_json_oids(conn_or_curs, name)
+
+    JSON, JSONARRAY = _create_json_typecasters(
+        oid, array_oid, loads=loads, name=name.upper())
+
+    register_type(JSON, not globally and conn_or_curs or None)
+
+    if JSONARRAY is not None:
+        register_type(JSONARRAY, not globally and conn_or_curs or None)
+
+    return JSON, JSONARRAY
+
+
+def register_default_json(conn_or_curs=None, globally=False, loads=None):
+    """
+    Create and register :sql:`json` typecasters for PostgreSQL 9.2 and following.
+
+    Since PostgreSQL 9.2 :sql:`json` is a builtin type, hence its oid is known
+    and fixed. This function allows specifying a customized *loads* function
+    for the default :sql:`json` type without querying the database.
+    All the parameters have the same meaning of `register_json()`.
+    """
+    return register_json(conn_or_curs=conn_or_curs, globally=globally,
+        loads=loads, oid=JSON_OID, array_oid=JSONARRAY_OID)
+
+
+def register_default_jsonb(conn_or_curs=None, globally=False, loads=None):
+    """
+    Create and register :sql:`jsonb` typecasters for PostgreSQL 9.4 and following.
+
+    As in `register_default_json()`, the function allows to register a
+    customized *loads* function for the :sql:`jsonb` type at its known oid for
+    PostgreSQL 9.4 and following versions.  All the parameters have the same
+    meaning of `register_json()`.
+    """
+    return register_json(conn_or_curs=conn_or_curs, globally=globally,
+        loads=loads, oid=JSONB_OID, array_oid=JSONBARRAY_OID, name='jsonb')
+
+
+def _create_json_typecasters(oid, array_oid, loads=None, name='JSON'):
+    """Create typecasters for json data type."""
+    if loads is None:
+        loads = json.loads
+
+    def typecast_json(s, cur):
+        if s is None:
+            return None
+        return loads(s)
+
+    JSON = new_type((oid, ), name, typecast_json)
+    if array_oid is not None:
+        JSONARRAY = new_array_type((array_oid, ), "%sARRAY" % name, JSON)
+    else:
+        JSONARRAY = None
+
+    return JSON, JSONARRAY
+
+
+def _get_json_oids(conn_or_curs, name='json'):
+    # lazy imports
+    from psycopg2.extensions import STATUS_IN_TRANSACTION
+    from psycopg2.extras import _solve_conn_curs
+
+    conn, curs = _solve_conn_curs(conn_or_curs)
+
+    # Store the transaction status of the connection to revert it after use
+    conn_status = conn.status
+
+    # column typarray not available before PG 8.3
+    typarray = conn.info.server_version >= 80300 and "typarray" or "NULL"
+
+    # get the oid for the hstore
+    curs.execute(
+        "SELECT t.oid, %s FROM pg_type t WHERE t.typname = %%s;"
+        % typarray, (name,))
+    r = curs.fetchone()
+
+    # revert the status of the connection as before the command
+    if conn_status != STATUS_IN_TRANSACTION and not conn.autocommit:
+        conn.rollback()
+
+    if not r:
+        raise conn.ProgrammingError("%s data type not found" % name)
+
+    return r
Index: venv/Lib/site-packages/ultimate_sitemap_parser-0.5.dist-info/INSTALLER
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/venv/Lib/site-packages/ultimate_sitemap_parser-0.5.dist-info/INSTALLER b/venv/Lib/site-packages/ultimate_sitemap_parser-0.5.dist-info/INSTALLER
new file mode 100644
--- /dev/null	(date 1616406053976)
+++ b/venv/Lib/site-packages/ultimate_sitemap_parser-0.5.dist-info/INSTALLER	(date 1616406053976)
@@ -0,0 +1,1 @@
+pip
Index: venv/Lib/site-packages/ultimate_sitemap_parser-0.5.dist-info/LICENSE.txt
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/venv/Lib/site-packages/ultimate_sitemap_parser-0.5.dist-info/LICENSE.txt b/venv/Lib/site-packages/ultimate_sitemap_parser-0.5.dist-info/LICENSE.txt
new file mode 100644
--- /dev/null	(date 1616406051465)
+++ b/venv/Lib/site-packages/ultimate_sitemap_parser-0.5.dist-info/LICENSE.txt	(date 1616406051465)
@@ -0,0 +1,11 @@
+Copyright (C) 2018 Linas Valiukas, Hal Roberts, 2018 Media Cloud project
+
+This program is free software: you can redistribute it and/or modify
+it under the terms of the GNU General Public License as published by
+the Free Software Foundation, either version 3 of the License, or
+any later version.
+
+This program is distributed in the hope that it will be useful,
+but WITHOUT ANY WARRANTY; without even the implied warranty of
+MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+GNU General Public License for more details <http://www.gnu.org/licenses/>.
Index: latest/Lib/site-packages/psycopg2/_lru_cache.py
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/latest/Lib/site-packages/psycopg2/_lru_cache.py b/latest/Lib/site-packages/psycopg2/_lru_cache.py
new file mode 100644
--- /dev/null	(date 1616409347226)
+++ b/latest/Lib/site-packages/psycopg2/_lru_cache.py	(date 1616409347226)
@@ -0,0 +1,104 @@
+"""
+LRU cache implementation for Python 2.7
+
+Ported from http://code.activestate.com/recipes/578078/ and simplified for our
+use (only support maxsize > 0 and positional arguments).
+"""
+
+from collections import namedtuple
+from functools import update_wrapper
+from threading import RLock
+
+_CacheInfo = namedtuple("CacheInfo", ["hits", "misses", "maxsize", "currsize"])
+
+
+def lru_cache(maxsize=100):
+    """Least-recently-used cache decorator.
+
+    Arguments to the cached function must be hashable.
+
+    See:  http://en.wikipedia.org/wiki/Cache_algorithms#Least_Recently_Used
+
+    """
+    def decorating_function(user_function):
+
+        cache = dict()
+        stats = [0, 0]                  # make statistics updateable non-locally
+        HITS, MISSES = 0, 1             # names for the stats fields
+        cache_get = cache.get           # bound method to lookup key or return None
+        _len = len                      # localize the global len() function
+        lock = RLock()                  # linkedlist updates aren't threadsafe
+        root = []                       # root of the circular doubly linked list
+        root[:] = [root, root, None, None]      # initialize by pointing to self
+        nonlocal_root = [root]                  # make updateable non-locally
+        PREV, NEXT, KEY, RESULT = 0, 1, 2, 3    # names for the link fields
+
+        assert maxsize and maxsize > 0, "maxsize %s not supported" % maxsize
+
+        def wrapper(*args):
+            # size limited caching that tracks accesses by recency
+            key = args
+            with lock:
+                link = cache_get(key)
+                if link is not None:
+                    # record recent use of the key by moving it to the
+                    # front of the list
+                    root, = nonlocal_root
+                    link_prev, link_next, key, result = link
+                    link_prev[NEXT] = link_next
+                    link_next[PREV] = link_prev
+                    last = root[PREV]
+                    last[NEXT] = root[PREV] = link
+                    link[PREV] = last
+                    link[NEXT] = root
+                    stats[HITS] += 1
+                    return result
+            result = user_function(*args)
+            with lock:
+                root, = nonlocal_root
+                if key in cache:
+                    # getting here means that this same key was added to the
+                    # cache while the lock was released.  since the link
+                    # update is already done, we need only return the
+                    # computed result and update the count of misses.
+                    pass
+                elif _len(cache) >= maxsize:
+                    # use the old root to store the new key and result
+                    oldroot = root
+                    oldroot[KEY] = key
+                    oldroot[RESULT] = result
+                    # empty the oldest link and make it the new root
+                    root = nonlocal_root[0] = oldroot[NEXT]
+                    oldkey = root[KEY]
+                    # oldvalue = root[RESULT]
+                    root[KEY] = root[RESULT] = None
+                    # now update the cache dictionary for the new links
+                    del cache[oldkey]
+                    cache[key] = oldroot
+                else:
+                    # put result in a new link at the front of the list
+                    last = root[PREV]
+                    link = [last, root, key, result]
+                    last[NEXT] = root[PREV] = cache[key] = link
+                stats[MISSES] += 1
+            return result
+
+        def cache_info():
+            """Report cache statistics"""
+            with lock:
+                return _CacheInfo(stats[HITS], stats[MISSES], maxsize, len(cache))
+
+        def cache_clear():
+            """Clear the cache and cache statistics"""
+            with lock:
+                cache.clear()
+                root = nonlocal_root[0]
+                root[:] = [root, root, None, None]
+                stats[:] = [0, 0]
+
+        wrapper.__wrapped__ = user_function
+        wrapper.cache_info = cache_info
+        wrapper.cache_clear = cache_clear
+        return update_wrapper(wrapper, user_function)
+
+    return decorating_function
Index: venv/Lib/site-packages/ultimate_sitemap_parser-0.5.dist-info/METADATA
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/venv/Lib/site-packages/ultimate_sitemap_parser-0.5.dist-info/METADATA b/venv/Lib/site-packages/ultimate_sitemap_parser-0.5.dist-info/METADATA
new file mode 100644
--- /dev/null	(date 1616406051481)
+++ b/venv/Lib/site-packages/ultimate_sitemap_parser-0.5.dist-info/METADATA	(date 1616406051481)
@@ -0,0 +1,106 @@
+Metadata-Version: 2.1
+Name: ultimate-sitemap-parser
+Version: 0.5
+Summary: Ultimate Sitemap Parser
+Home-page: https://github.com/berkmancenter/mediacloud-ultimate_sitemap_parser
+Author: Linas Valiukas, Hal Roberts, Media Cloud project
+Author-email: linas@media.mit.edu, hroberts@cyber.law.harvard.edu
+License: GPLv3+
+Keywords: sitemap sitemap-xml parser
+Platform: UNKNOWN
+Classifier: Development Status :: 3 - Alpha
+Classifier: Intended Audience :: Developers
+Classifier: Intended Audience :: Information Technology
+Classifier: License :: OSI Approved :: GNU General Public License v3 or later (GPLv3+)
+Classifier: Programming Language :: Python
+Classifier: Operating System :: OS Independent
+Classifier: Programming Language :: Python :: 3.5
+Classifier: Programming Language :: Python :: 3.6
+Classifier: Programming Language :: Python :: 3.7
+Classifier: Programming Language :: Python :: 3.8
+Classifier: Programming Language :: Python :: 3 :: Only
+Classifier: Programming Language :: Python :: Implementation :: PyPy
+Classifier: Topic :: Internet :: WWW/HTTP :: Indexing/Search
+Classifier: Topic :: Text Processing :: Indexing
+Classifier: Topic :: Text Processing :: Markup :: XML
+Requires-Python: >=3.5
+Requires-Dist: python-dateutil (<3.0.0,>=2.1)
+Requires-Dist: requests (>=2.2.1)
+Provides-Extra: test
+Requires-Dist: requests-mock (<2.0,>=1.6.0) ; extra == 'test'
+Requires-Dist: pytest (>=2.8) ; extra == 'test'
+
+.. image:: https://travis-ci.org/berkmancenter/mediacloud-ultimate_sitemap_parser.svg?branch=develop
+    :target: https://travis-ci.org/berkmancenter/mediacloud-ultimate_sitemap_parser
+    :alt: Build Status
+
+.. image:: https://readthedocs.org/projects/ultimate-sitemap-parser/badge/?version=latest
+    :target: https://ultimate-sitemap-parser.readthedocs.io/en/latest/?badge=latest
+    :alt: Documentation Status
+
+.. image:: https://coveralls.io/repos/github/berkmancenter/mediacloud-ultimate_sitemap_parser/badge.svg?branch=develop
+    :target: https://coveralls.io/github/berkmancenter/mediacloud-ultimate_sitemap_parser?branch=develop
+    :alt: Coverage Status
+
+.. image:: https://badge.fury.io/py/ultimate-sitemap-parser.svg
+    :target: https://badge.fury.io/py/ultimate-sitemap-parser
+    :alt: PyPI package
+
+
+Website sitemap parser for Python 3.5+.
+
+
+Features
+========
+
+- Supports all sitemap formats:
+
+  - `XML sitemaps <https://www.sitemaps.org/protocol.html#xmlTagDefinitions>`_
+  - `Google News sitemaps <https://support.google.com/news/publisher-center/answer/74288?hl=en>`_
+  - `plain text sitemaps <https://www.sitemaps.org/protocol.html#otherformats>`_
+  - `RSS 2.0 / Atom 0.3 / Atom 1.0 sitemaps <https://www.sitemaps.org/protocol.html#otherformats>`_
+  - `Sitemaps linked from robots.txt <https://developers.google.com/search/reference/robots_txt#sitemap>`_
+
+- Field-tested with ~1 million URLs as part of the `Media Cloud project <https://mediacloud.org/>`_
+- Error-tolerant with more common sitemap bugs
+- Tries to find sitemaps not listed in ``robots.txt``
+- Uses fast and memory efficient Expat XML parsing
+- Doesn't consume much memory even with massive sitemap hierarchies
+- Provides a generated sitemap tree as easy to use object tree
+- Supports using a custom web client
+- Uses a small number of actively maintained third-party modules
+- Reasonably tested
+
+
+Installation
+============
+
+.. code:: sh
+
+    pip install ultimate_sitemap_parser
+
+
+Usage
+=====
+
+.. code:: python
+
+    from usp.tree import sitemap_tree_for_homepage
+
+    tree = sitemap_tree_for_homepage('https://www.nytimes.com/')
+    print(tree)
+
+``sitemap_tree_for_homepage()`` will return a tree of ``AbstractSitemap`` subclass objects that represent the sitemap
+hierarchy found on the website; see a `reference of AbstractSitemap subclasses <https://ultimate-sitemap-parser.readthedocs.io/en/latest/usp.objects.html#module-usp.objects.sitemap>`_.
+
+If you'd like to just list all the pages found in all of the sitemaps within the website, consider using ``all_pages()`` method:
+
+.. code:: python
+
+    # all_pages() returns an Iterator
+    for page in tree.all_pages():
+        print(page)
+
+``all_pages()`` method will return an iterator yielding ``SitemapPage`` objects; see a `reference of SitemapPage <https://ultimate-sitemap-parser.readthedocs.io/en/latest/usp.objects.html#module-usp.objects.page>`_.
+
+
Index: venv/Lib/site-packages/ultimate_sitemap_parser-0.5.dist-info/RECORD
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/venv/Lib/site-packages/ultimate_sitemap_parser-0.5.dist-info/RECORD b/venv/Lib/site-packages/ultimate_sitemap_parser-0.5.dist-info/RECORD
new file mode 100644
--- /dev/null	(date 1616406053976)
+++ b/venv/Lib/site-packages/ultimate_sitemap_parser-0.5.dist-info/RECORD	(date 1616406053976)
@@ -0,0 +1,37 @@
+tests/web_client/__init__.py,sha256=47DEQpj8HBSa-_TImW-5JCeuQeRkm5NMpJWZG3hSuFU,0
+tests/web_client/__pycache__/__init__.cpython-36.pyc,,
+tests/web_client/__pycache__/test_requests_client.cpython-36.pyc,,
+tests/web_client/test_requests_client.py,sha256=mvOkZoNFRQ3Fcf0yMlTvlQkAQzJWgK3UKULR8rXxQAU,4555
+ultimate_sitemap_parser-0.5.dist-info/INSTALLER,sha256=zuuue4knoyJ-UwPPXg8fezS7VCrXJQrAP7zeNuwvFQg,4
+ultimate_sitemap_parser-0.5.dist-info/LICENSE.txt,sha256=Lxmp2QWPY2vwKV3zBqXnBgUgO4eGkVFbq1D-Ku7ZM9o,563
+ultimate_sitemap_parser-0.5.dist-info/METADATA,sha256=vZuBo09fLOhKl_HobzO6EdZE_39CSI-Bq2exyKIqHH8,4311
+ultimate_sitemap_parser-0.5.dist-info/RECORD,,
+ultimate_sitemap_parser-0.5.dist-info/WHEEL,sha256=h_aVn5OB2IERUjMbi2pucmR_zzWJtk303YXvhh60NJ8,110
+ultimate_sitemap_parser-0.5.dist-info/top_level.txt,sha256=6N_xHi3dkDlyZGtjAScqpFvW7pWn_-DKc_enuOgJ9pc,10
+ultimate_sitemap_parser-0.5.dist-info/zip-safe,sha256=AbpHGcgLb-kRsJGnwFEktk7uzpZOCcBY74-YBdrKVGs,1
+usp/__about__.py,sha256=JO_svODkyyw_sJSP6bLSaugifIq-x9R1fy6R2iUm350,44
+usp/__init__.py,sha256=ArqlCCgLAwY-stWooojyWBI5iedyb6gSz9Y7wkCNr2M,19
+usp/__pycache__/__about__.cpython-36.pyc,,
+usp/__pycache__/__init__.cpython-36.pyc,,
+usp/__pycache__/exceptions.cpython-36.pyc,,
+usp/__pycache__/fetch_parse.cpython-36.pyc,,
+usp/__pycache__/helpers.cpython-36.pyc,,
+usp/__pycache__/log.cpython-36.pyc,,
+usp/__pycache__/tree.cpython-36.pyc,,
+usp/exceptions.py,sha256=kxftRkYOCUw0O-p0U0rHmq9b1ZdCSClWyCz8SqNotJE,504
+usp/fetch_parse.py,sha256=Xcj6lxHHLK3Nq-vJaEyIz5iFs5XIpNTAqhtAOWgQaEM,32997
+usp/helpers.py,sha256=MxVmoec0-CNr6qlmbZ4slubNKb4xvmrbAfGD2G9BXkw,7729
+usp/log.py,sha256=DVgABM2yWPx-HFfqoGBzg_t92oR5CFo2qjPQjzttmfI,2181
+usp/objects/__init__.py,sha256=47DEQpj8HBSa-_TImW-5JCeuQeRkm5NMpJWZG3hSuFU,0
+usp/objects/__pycache__/__init__.cpython-36.pyc,,
+usp/objects/__pycache__/page.cpython-36.pyc,,
+usp/objects/__pycache__/sitemap.cpython-36.pyc,,
+usp/objects/page.py,sha256=-8fxw_nduDxmWLI72-yGJr8VtuPGiHEvaGNPcYxxx9s,9820
+usp/objects/sitemap.py,sha256=XXbJ91kBORxmmNb_lGSJZ9TbXImCNATkx--qvjIrSlk,7055
+usp/tree.py,sha256=qKQsxXy6ZeDs8OwOulsxoosMF7iyV_tLjyz1dxzkITg,3044
+usp/web_client/__init__.py,sha256=47DEQpj8HBSa-_TImW-5JCeuQeRkm5NMpJWZG3hSuFU,0
+usp/web_client/__pycache__/__init__.cpython-36.pyc,,
+usp/web_client/__pycache__/abstract_client.cpython-36.pyc,,
+usp/web_client/__pycache__/requests_client.cpython-36.pyc,,
+usp/web_client/abstract_client.py,sha256=zl4jJvgfyMfSow1GUm2CIMpd3YTd3JlF_3PcYeB6lpk,4886
+usp/web_client/requests_client.py,sha256=VN7lbMG-eb06aIsNYJKSumIGvh-m5IKZPOyGpHVEpPU,3789
Index: latest/Lib/site-packages/psycopg2/_range.py
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/latest/Lib/site-packages/psycopg2/_range.py b/latest/Lib/site-packages/psycopg2/_range.py
new file mode 100644
--- /dev/null	(date 1616409347252)
+++ b/latest/Lib/site-packages/psycopg2/_range.py	(date 1616409347252)
@@ -0,0 +1,539 @@
+"""Implementation of the Range type and adaptation
+
+"""
+
+# psycopg/_range.py - Implementation of the Range type and adaptation
+#
+# Copyright (C) 2012-2019 Daniele Varrazzo  <daniele.varrazzo@gmail.com>
+# Copyright (C) 2020 The Psycopg Team
+#
+# psycopg2 is free software: you can redistribute it and/or modify it
+# under the terms of the GNU Lesser General Public License as published
+# by the Free Software Foundation, either version 3 of the License, or
+# (at your option) any later version.
+#
+# In addition, as a special exception, the copyright holders give
+# permission to link this program with the OpenSSL library (or with
+# modified versions of OpenSSL that use the same license as OpenSSL),
+# and distribute linked combinations including the two.
+#
+# You must obey the GNU Lesser General Public License in all respects for
+# all of the code used other than OpenSSL.
+#
+# psycopg2 is distributed in the hope that it will be useful, but WITHOUT
+# ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or
+# FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public
+# License for more details.
+
+import re
+
+from psycopg2._psycopg import ProgrammingError, InterfaceError
+from psycopg2.extensions import ISQLQuote, adapt, register_adapter
+from psycopg2.extensions import new_type, new_array_type, register_type
+from psycopg2.compat import string_types
+
+
+class Range(object):
+    """Python representation for a PostgreSQL |range|_ type.
+
+    :param lower: lower bound for the range. `!None` means unbound
+    :param upper: upper bound for the range. `!None` means unbound
+    :param bounds: one of the literal strings ``()``, ``[)``, ``(]``, ``[]``,
+        representing whether the lower or upper bounds are included
+    :param empty: if `!True`, the range is empty
+
+    """
+    __slots__ = ('_lower', '_upper', '_bounds')
+
+    def __init__(self, lower=None, upper=None, bounds='[)', empty=False):
+        if not empty:
+            if bounds not in ('[)', '(]', '()', '[]'):
+                raise ValueError("bound flags not valid: %r" % bounds)
+
+            self._lower = lower
+            self._upper = upper
+            self._bounds = bounds
+        else:
+            self._lower = self._upper = self._bounds = None
+
+    def __repr__(self):
+        if self._bounds is None:
+            return "%s(empty=True)" % self.__class__.__name__
+        else:
+            return "%s(%r, %r, %r)" % (self.__class__.__name__,
+                self._lower, self._upper, self._bounds)
+
+    def __str__(self):
+        if self._bounds is None:
+            return 'empty'
+
+        items = [
+            self._bounds[0],
+            str(self._lower),
+            ', ',
+            str(self._upper),
+            self._bounds[1]
+        ]
+        return ''.join(items)
+
+    @property
+    def lower(self):
+        """The lower bound of the range. `!None` if empty or unbound."""
+        return self._lower
+
+    @property
+    def upper(self):
+        """The upper bound of the range. `!None` if empty or unbound."""
+        return self._upper
+
+    @property
+    def isempty(self):
+        """`!True` if the range is empty."""
+        return self._bounds is None
+
+    @property
+    def lower_inf(self):
+        """`!True` if the range doesn't have a lower bound."""
+        if self._bounds is None:
+            return False
+        return self._lower is None
+
+    @property
+    def upper_inf(self):
+        """`!True` if the range doesn't have an upper bound."""
+        if self._bounds is None:
+            return False
+        return self._upper is None
+
+    @property
+    def lower_inc(self):
+        """`!True` if the lower bound is included in the range."""
+        if self._bounds is None or self._lower is None:
+            return False
+        return self._bounds[0] == '['
+
+    @property
+    def upper_inc(self):
+        """`!True` if the upper bound is included in the range."""
+        if self._bounds is None or self._upper is None:
+            return False
+        return self._bounds[1] == ']'
+
+    def __contains__(self, x):
+        if self._bounds is None:
+            return False
+
+        if self._lower is not None:
+            if self._bounds[0] == '[':
+                if x < self._lower:
+                    return False
+            else:
+                if x <= self._lower:
+                    return False
+
+        if self._upper is not None:
+            if self._bounds[1] == ']':
+                if x > self._upper:
+                    return False
+            else:
+                if x >= self._upper:
+                    return False
+
+        return True
+
+    def __bool__(self):
+        return self._bounds is not None
+
+    def __nonzero__(self):
+        # Python 2 compatibility
+        return type(self).__bool__(self)
+
+    def __eq__(self, other):
+        if not isinstance(other, Range):
+            return False
+        return (self._lower == other._lower
+            and self._upper == other._upper
+            and self._bounds == other._bounds)
+
+    def __ne__(self, other):
+        return not self.__eq__(other)
+
+    def __hash__(self):
+        return hash((self._lower, self._upper, self._bounds))
+
+    # as the postgres docs describe for the server-side stuff,
+    # ordering is rather arbitrary, but will remain stable
+    # and consistent.
+
+    def __lt__(self, other):
+        if not isinstance(other, Range):
+            return NotImplemented
+        for attr in ('_lower', '_upper', '_bounds'):
+            self_value = getattr(self, attr)
+            other_value = getattr(other, attr)
+            if self_value == other_value:
+                pass
+            elif self_value is None:
+                return True
+            elif other_value is None:
+                return False
+            else:
+                return self_value < other_value
+        return False
+
+    def __le__(self, other):
+        if self == other:
+            return True
+        else:
+            return self.__lt__(other)
+
+    def __gt__(self, other):
+        if isinstance(other, Range):
+            return other.__lt__(self)
+        else:
+            return NotImplemented
+
+    def __ge__(self, other):
+        if self == other:
+            return True
+        else:
+            return self.__gt__(other)
+
+    def __getstate__(self):
+        return {slot: getattr(self, slot)
+            for slot in self.__slots__ if hasattr(self, slot)}
+
+    def __setstate__(self, state):
+        for slot, value in state.items():
+            setattr(self, slot, value)
+
+
+def register_range(pgrange, pyrange, conn_or_curs, globally=False):
+    """Create and register an adapter and the typecasters to convert between
+    a PostgreSQL |range|_ type and a PostgreSQL `Range` subclass.
+
+    :param pgrange: the name of the PostgreSQL |range| type. Can be
+        schema-qualified
+    :param pyrange: a `Range` strict subclass, or just a name to give to a new
+        class
+    :param conn_or_curs: a connection or cursor used to find the oid of the
+        range and its subtype; the typecaster is registered in a scope limited
+        to this object, unless *globally* is set to `!True`
+    :param globally: if `!False` (default) register the typecaster only on
+        *conn_or_curs*, otherwise register it globally
+    :return: `RangeCaster` instance responsible for the conversion
+
+    If a string is passed to *pyrange*, a new `Range` subclass is created
+    with such name and will be available as the `~RangeCaster.range` attribute
+    of the returned `RangeCaster` object.
+
+    The function queries the database on *conn_or_curs* to inspect the
+    *pgrange* type and raises `~psycopg2.ProgrammingError` if the type is not
+    found.  If querying the database is not advisable, use directly the
+    `RangeCaster` class and register the adapter and typecasters using the
+    provided functions.
+
+    """
+    caster = RangeCaster._from_db(pgrange, pyrange, conn_or_curs)
+    caster._register(not globally and conn_or_curs or None)
+    return caster
+
+
+class RangeAdapter(object):
+    """`ISQLQuote` adapter for `Range` subclasses.
+
+    This is an abstract class: concrete classes must set a `name` class
+    attribute or override `getquoted()`.
+    """
+    name = None
+
+    def __init__(self, adapted):
+        self.adapted = adapted
+
+    def __conform__(self, proto):
+        if self._proto is ISQLQuote:
+            return self
+
+    def prepare(self, conn):
+        self._conn = conn
+
+    def getquoted(self):
+        if self.name is None:
+            raise NotImplementedError(
+                'RangeAdapter must be subclassed overriding its name '
+                'or the getquoted() method')
+
+        r = self.adapted
+        if r.isempty:
+            return b"'empty'::" + self.name.encode('utf8')
+
+        if r.lower is not None:
+            a = adapt(r.lower)
+            if hasattr(a, 'prepare'):
+                a.prepare(self._conn)
+            lower = a.getquoted()
+        else:
+            lower = b'NULL'
+
+        if r.upper is not None:
+            a = adapt(r.upper)
+            if hasattr(a, 'prepare'):
+                a.prepare(self._conn)
+            upper = a.getquoted()
+        else:
+            upper = b'NULL'
+
+        return self.name.encode('utf8') + b'(' + lower + b', ' + upper \
+            + b", '" + r._bounds.encode('utf8') + b"')"
+
+
+class RangeCaster(object):
+    """Helper class to convert between `Range` and PostgreSQL range types.
+
+    Objects of this class are usually created by `register_range()`. Manual
+    creation could be useful if querying the database is not advisable: in
+    this case the oids must be provided.
+    """
+    def __init__(self, pgrange, pyrange, oid, subtype_oid, array_oid=None):
+        self.subtype_oid = subtype_oid
+        self._create_ranges(pgrange, pyrange)
+
+        name = self.adapter.name or self.adapter.__class__.__name__
+
+        self.typecaster = new_type((oid,), name, self.parse)
+
+        if array_oid is not None:
+            self.array_typecaster = new_array_type(
+                (array_oid,), name + "ARRAY", self.typecaster)
+        else:
+            self.array_typecaster = None
+
+    def _create_ranges(self, pgrange, pyrange):
+        """Create Range and RangeAdapter classes if needed."""
+        # if got a string create a new RangeAdapter concrete type (with a name)
+        # else take it as an adapter. Passing an adapter should be considered
+        # an implementation detail and is not documented. It is currently used
+        # for the numeric ranges.
+        self.adapter = None
+        if isinstance(pgrange, string_types):
+            self.adapter = type(pgrange, (RangeAdapter,), {})
+            self.adapter.name = pgrange
+        else:
+            try:
+                if issubclass(pgrange, RangeAdapter) \
+                        and pgrange is not RangeAdapter:
+                    self.adapter = pgrange
+            except TypeError:
+                pass
+
+        if self.adapter is None:
+            raise TypeError(
+                'pgrange must be a string or a RangeAdapter strict subclass')
+
+        self.range = None
+        try:
+            if isinstance(pyrange, string_types):
+                self.range = type(pyrange, (Range,), {})
+            if issubclass(pyrange, Range) and pyrange is not Range:
+                self.range = pyrange
+        except TypeError:
+            pass
+
+        if self.range is None:
+            raise TypeError(
+                'pyrange must be a type or a Range strict subclass')
+
+    @classmethod
+    def _from_db(self, name, pyrange, conn_or_curs):
+        """Return a `RangeCaster` instance for the type *pgrange*.
+
+        Raise `ProgrammingError` if the type is not found.
+        """
+        from psycopg2.extensions import STATUS_IN_TRANSACTION
+        from psycopg2.extras import _solve_conn_curs
+        conn, curs = _solve_conn_curs(conn_or_curs)
+
+        if conn.info.server_version < 90200:
+            raise ProgrammingError("range types not available in version %s"
+                % conn.info.server_version)
+
+        # Store the transaction status of the connection to revert it after use
+        conn_status = conn.status
+
+        # Use the correct schema
+        if '.' in name:
+            schema, tname = name.split('.', 1)
+        else:
+            tname = name
+            schema = 'public'
+
+        # get the type oid and attributes
+        try:
+            curs.execute("""\
+select rngtypid, rngsubtype,
+    (select typarray from pg_type where oid = rngtypid)
+from pg_range r
+join pg_type t on t.oid = rngtypid
+join pg_namespace ns on ns.oid = typnamespace
+where typname = %s and ns.nspname = %s;
+""", (tname, schema))
+
+        except ProgrammingError:
+            if not conn.autocommit:
+                conn.rollback()
+            raise
+        else:
+            rec = curs.fetchone()
+
+            # revert the status of the connection as before the command
+            if (conn_status != STATUS_IN_TRANSACTION
+            and not conn.autocommit):
+                conn.rollback()
+
+        if not rec:
+            raise ProgrammingError(
+                "PostgreSQL type '%s' not found" % name)
+
+        type, subtype, array = rec
+
+        return RangeCaster(name, pyrange,
+            oid=type, subtype_oid=subtype, array_oid=array)
+
+    _re_range = re.compile(r"""
+        ( \(|\[ )                   # lower bound flag
+        (?:                         # lower bound:
+          " ( (?: [^"] | "")* ) "   #   - a quoted string
+          | ( [^",]+ )              #   - or an unquoted string
+        )?                          #   - or empty (not catched)
+        ,
+        (?:                         # upper bound:
+          " ( (?: [^"] | "")* ) "   #   - a quoted string
+          | ( [^"\)\]]+ )           #   - or an unquoted string
+        )?                          #   - or empty (not catched)
+        ( \)|\] )                   # upper bound flag
+        """, re.VERBOSE)
+
+    _re_undouble = re.compile(r'(["\\])\1')
+
+    def parse(self, s, cur=None):
+        if s is None:
+            return None
+
+        if s == 'empty':
+            return self.range(empty=True)
+
+        m = self._re_range.match(s)
+        if m is None:
+            raise InterfaceError("failed to parse range: '%s'" % s)
+
+        lower = m.group(3)
+        if lower is None:
+            lower = m.group(2)
+            if lower is not None:
+                lower = self._re_undouble.sub(r"\1", lower)
+
+        upper = m.group(5)
+        if upper is None:
+            upper = m.group(4)
+            if upper is not None:
+                upper = self._re_undouble.sub(r"\1", upper)
+
+        if cur is not None:
+            lower = cur.cast(self.subtype_oid, lower)
+            upper = cur.cast(self.subtype_oid, upper)
+
+        bounds = m.group(1) + m.group(6)
+
+        return self.range(lower, upper, bounds)
+
+    def _register(self, scope=None):
+        register_type(self.typecaster, scope)
+        if self.array_typecaster is not None:
+            register_type(self.array_typecaster, scope)
+
+        register_adapter(self.range, self.adapter)
+
+
+class NumericRange(Range):
+    """A `Range` suitable to pass Python numeric types to a PostgreSQL range.
+
+    PostgreSQL types :sql:`int4range`, :sql:`int8range`, :sql:`numrange` are
+    casted into `!NumericRange` instances.
+    """
+    pass
+
+
+class DateRange(Range):
+    """Represents :sql:`daterange` values."""
+    pass
+
+
+class DateTimeRange(Range):
+    """Represents :sql:`tsrange` values."""
+    pass
+
+
+class DateTimeTZRange(Range):
+    """Represents :sql:`tstzrange` values."""
+    pass
+
+
+# Special adaptation for NumericRange. Allows to pass number range regardless
+# of whether they are ints, floats and what size of ints are, which are
+# pointless in Python world. On the way back, no numeric range is casted to
+# NumericRange, but only to their subclasses
+
+class NumberRangeAdapter(RangeAdapter):
+    """Adapt a range if the subtype doesn't need quotes."""
+    def getquoted(self):
+        r = self.adapted
+        if r.isempty:
+            return b"'empty'"
+
+        if not r.lower_inf:
+            # not exactly: we are relying that none of these object is really
+            # quoted (they are numbers). Also, I'm lazy and not preparing the
+            # adapter because I assume encoding doesn't matter for these
+            # objects.
+            lower = adapt(r.lower).getquoted().decode('ascii')
+        else:
+            lower = ''
+
+        if not r.upper_inf:
+            upper = adapt(r.upper).getquoted().decode('ascii')
+        else:
+            upper = ''
+
+        return ("'%s%s,%s%s'" % (
+            r._bounds[0], lower, upper, r._bounds[1])).encode('ascii')
+
+
+# TODO: probably won't work with infs, nans and other tricky cases.
+register_adapter(NumericRange, NumberRangeAdapter)
+
+# Register globally typecasters and adapters for builtin range types.
+
+# note: the adapter is registered more than once, but this is harmless.
+int4range_caster = RangeCaster(NumberRangeAdapter, NumericRange,
+    oid=3904, subtype_oid=23, array_oid=3905)
+int4range_caster._register()
+
+int8range_caster = RangeCaster(NumberRangeAdapter, NumericRange,
+    oid=3926, subtype_oid=20, array_oid=3927)
+int8range_caster._register()
+
+numrange_caster = RangeCaster(NumberRangeAdapter, NumericRange,
+    oid=3906, subtype_oid=1700, array_oid=3907)
+numrange_caster._register()
+
+daterange_caster = RangeCaster('daterange', DateRange,
+    oid=3912, subtype_oid=1082, array_oid=3913)
+daterange_caster._register()
+
+tsrange_caster = RangeCaster('tsrange', DateTimeRange,
+    oid=3908, subtype_oid=1114, array_oid=3909)
+tsrange_caster._register()
+
+tstzrange_caster = RangeCaster('tstzrange', DateTimeTZRange,
+    oid=3910, subtype_oid=1184, array_oid=3911)
+tstzrange_caster._register()
Index: venv/Lib/site-packages/ultimate_sitemap_parser-0.5.dist-info/top_level.txt
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/venv/Lib/site-packages/ultimate_sitemap_parser-0.5.dist-info/top_level.txt b/venv/Lib/site-packages/ultimate_sitemap_parser-0.5.dist-info/top_level.txt
new file mode 100644
--- /dev/null	(date 1616406051481)
+++ b/venv/Lib/site-packages/ultimate_sitemap_parser-0.5.dist-info/top_level.txt	(date 1616406051481)
@@ -0,0 +1,2 @@
+tests
+usp
Index: latest/Lib/site-packages/psycopg2/__init__.py
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/latest/Lib/site-packages/psycopg2/__init__.py b/latest/Lib/site-packages/psycopg2/__init__.py
new file mode 100644
--- /dev/null	(date 1616409347222)
+++ b/latest/Lib/site-packages/psycopg2/__init__.py	(date 1616409347222)
@@ -0,0 +1,131 @@
+"""A Python driver for PostgreSQL
+
+psycopg is a PostgreSQL_ database adapter for the Python_ programming
+language. This is version 2, a complete rewrite of the original code to
+provide new-style classes for connection and cursor objects and other sweet
+candies. Like the original, psycopg 2 was written with the aim of being very
+small and fast, and stable as a rock.
+
+Homepage: https://psycopg.org/
+
+.. _PostgreSQL: https://www.postgresql.org/
+.. _Python: https://www.python.org/
+
+:Groups:
+  * `Connections creation`: connect
+  * `Value objects constructors`: Binary, Date, DateFromTicks, Time,
+    TimeFromTicks, Timestamp, TimestampFromTicks
+"""
+# psycopg/__init__.py - initialization of the psycopg module
+#
+# Copyright (C) 2003-2019 Federico Di Gregorio  <fog@debian.org>
+# Copyright (C) 2020 The Psycopg Team
+#
+# psycopg2 is free software: you can redistribute it and/or modify it
+# under the terms of the GNU Lesser General Public License as published
+# by the Free Software Foundation, either version 3 of the License, or
+# (at your option) any later version.
+#
+# In addition, as a special exception, the copyright holders give
+# permission to link this program with the OpenSSL library (or with
+# modified versions of OpenSSL that use the same license as OpenSSL),
+# and distribute linked combinations including the two.
+#
+# You must obey the GNU Lesser General Public License in all respects for
+# all of the code used other than OpenSSL.
+#
+# psycopg2 is distributed in the hope that it will be useful, but WITHOUT
+# ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or
+# FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public
+# License for more details.
+
+# Import modules needed by _psycopg to allow tools like py2exe to do
+# their work without bothering about the module dependencies.
+
+# Note: the first internal import should be _psycopg, otherwise the real cause
+# of a failed loading of the C module may get hidden, see
+# https://archives.postgresql.org/psycopg/2011-02/msg00044.php
+
+# Import the DBAPI-2.0 stuff into top-level module.
+
+from psycopg2._psycopg import (                     # noqa
+    BINARY, NUMBER, STRING, DATETIME, ROWID,
+
+    Binary, Date, Time, Timestamp,
+    DateFromTicks, TimeFromTicks, TimestampFromTicks,
+
+    Error, Warning, DataError, DatabaseError, ProgrammingError, IntegrityError,
+    InterfaceError, InternalError, NotSupportedError, OperationalError,
+
+    _connect, apilevel, threadsafety, paramstyle,
+    __version__, __libpq_version__,
+)
+
+from psycopg2 import tz                             # noqa
+
+
+# Register default adapters.
+
+from psycopg2 import extensions as _ext
+_ext.register_adapter(tuple, _ext.SQL_IN)
+_ext.register_adapter(type(None), _ext.NoneAdapter)
+
+# Register the Decimal adapter here instead of in the C layer.
+# This way a new class is registered for each sub-interpreter.
+# See ticket #52
+from decimal import Decimal                         # noqa
+from psycopg2._psycopg import Decimal as Adapter    # noqa
+_ext.register_adapter(Decimal, Adapter)
+del Decimal, Adapter
+
+
+def connect(dsn=None, connection_factory=None, cursor_factory=None, **kwargs):
+    """
+    Create a new database connection.
+
+    The connection parameters can be specified as a string:
+
+        conn = psycopg2.connect("dbname=test user=postgres password=secret")
+
+    or using a set of keyword arguments:
+
+        conn = psycopg2.connect(database="test", user="postgres", password="secret")
+
+    Or as a mix of both. The basic connection parameters are:
+
+    - *dbname*: the database name
+    - *database*: the database name (only as keyword argument)
+    - *user*: user name used to authenticate
+    - *password*: password used to authenticate
+    - *host*: database host address (defaults to UNIX socket if not provided)
+    - *port*: connection port number (defaults to 5432 if not provided)
+
+    Using the *connection_factory* parameter a different class or connections
+    factory can be specified. It should be a callable object taking a dsn
+    argument.
+
+    Using the *cursor_factory* parameter, a new default cursor factory will be
+    used by cursor().
+
+    Using *async*=True an asynchronous connection will be created. *async_* is
+    a valid alias (for Python versions where ``async`` is a keyword).
+
+    Any other keyword parameter will be passed to the underlying client
+    library: the list of supported parameters depends on the library version.
+
+    """
+    kwasync = {}
+    if 'async' in kwargs:
+        kwasync['async'] = kwargs.pop('async')
+    if 'async_' in kwargs:
+        kwasync['async_'] = kwargs.pop('async_')
+
+    if dsn is None and not kwargs:
+        raise TypeError('missing dsn and no parameters')
+
+    dsn = _ext.make_dsn(dsn, **kwargs)
+    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
+    if cursor_factory is not None:
+        conn.cursor_factory = cursor_factory
+
+    return conn
Index: venv/Lib/site-packages/ultimate_sitemap_parser-0.5.dist-info/WHEEL
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/venv/Lib/site-packages/ultimate_sitemap_parser-0.5.dist-info/WHEEL b/venv/Lib/site-packages/ultimate_sitemap_parser-0.5.dist-info/WHEEL
new file mode 100644
--- /dev/null	(date 1616406051481)
+++ b/venv/Lib/site-packages/ultimate_sitemap_parser-0.5.dist-info/WHEEL	(date 1616406051481)
@@ -0,0 +1,6 @@
+Wheel-Version: 1.0
+Generator: bdist_wheel (0.33.4)
+Root-Is-Purelib: true
+Tag: py2-none-any
+Tag: py3-none-any
+
Index: venv/Lib/site-packages/ultimate_sitemap_parser-0.5.dist-info/zip-safe
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/venv/Lib/site-packages/ultimate_sitemap_parser-0.5.dist-info/zip-safe b/venv/Lib/site-packages/ultimate_sitemap_parser-0.5.dist-info/zip-safe
new file mode 100644
--- /dev/null	(date 1616406051481)
+++ b/venv/Lib/site-packages/ultimate_sitemap_parser-0.5.dist-info/zip-safe	(date 1616406051481)
@@ -0,0 +1,1 @@
+
Index: venv/Lib/site-packages/dateutil/easter.py
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/venv/Lib/site-packages/dateutil/easter.py b/venv/Lib/site-packages/dateutil/easter.py
new file mode 100644
--- /dev/null	(date 1616406051829)
+++ b/venv/Lib/site-packages/dateutil/easter.py	(date 1616406051829)
@@ -0,0 +1,89 @@
+# -*- coding: utf-8 -*-
+"""
+This module offers a generic easter computing method for any given year, using
+Western, Orthodox or Julian algorithms.
+"""
+
+import datetime
+
+__all__ = ["easter", "EASTER_JULIAN", "EASTER_ORTHODOX", "EASTER_WESTERN"]
+
+EASTER_JULIAN = 1
+EASTER_ORTHODOX = 2
+EASTER_WESTERN = 3
+
+
+def easter(year, method=EASTER_WESTERN):
+    """
+    This method was ported from the work done by GM Arts,
+    on top of the algorithm by Claus Tondering, which was
+    based in part on the algorithm of Ouding (1940), as
+    quoted in "Explanatory Supplement to the Astronomical
+    Almanac", P.  Kenneth Seidelmann, editor.
+
+    This algorithm implements three different easter
+    calculation methods:
+
+    1 - Original calculation in Julian calendar, valid in
+        dates after 326 AD
+    2 - Original method, with date converted to Gregorian
+        calendar, valid in years 1583 to 4099
+    3 - Revised method, in Gregorian calendar, valid in
+        years 1583 to 4099 as well
+
+    These methods are represented by the constants:
+
+    * ``EASTER_JULIAN   = 1``
+    * ``EASTER_ORTHODOX = 2``
+    * ``EASTER_WESTERN  = 3``
+
+    The default method is method 3.
+
+    More about the algorithm may be found at:
+
+    `GM Arts: Easter Algorithms <http://www.gmarts.org/index.php?go=415>`_
+
+    and
+
+    `The Calendar FAQ: Easter <https://www.tondering.dk/claus/cal/easter.php>`_
+
+    """
+
+    if not (1 <= method <= 3):
+        raise ValueError("invalid method")
+
+    # g - Golden year - 1
+    # c - Century
+    # h - (23 - Epact) mod 30
+    # i - Number of days from March 21 to Paschal Full Moon
+    # j - Weekday for PFM (0=Sunday, etc)
+    # p - Number of days from March 21 to Sunday on or before PFM
+    #     (-6 to 28 methods 1 & 3, to 56 for method 2)
+    # e - Extra days to add for method 2 (converting Julian
+    #     date to Gregorian date)
+
+    y = year
+    g = y % 19
+    e = 0
+    if method < 3:
+        # Old method
+        i = (19*g + 15) % 30
+        j = (y + y//4 + i) % 7
+        if method == 2:
+            # Extra dates to convert Julian to Gregorian date
+            e = 10
+            if y > 1600:
+                e = e + y//100 - 16 - (y//100 - 16)//4
+    else:
+        # New method
+        c = y//100
+        h = (c - c//4 - (8*c + 13)//25 + 19*g + 15) % 30
+        i = h - (h//28)*(1 - (h//28)*(29//(h + 1))*((21 - g)//11))
+        j = (y + y//4 + i + 2 - c + c//4) % 7
+
+    # p can be from -6 to 56 corresponding to dates 22 March to 23 May
+    # (later dates apply to method 2, although 23 May never actually occurs)
+    p = i - j + e
+    d = 1 + (p + 27 + (p + 6)//40) % 31
+    m = 3 + (p + 26)//30
+    return datetime.date(int(y), int(m), int(d))
Index: venv/Lib/site-packages/dateutil/relativedelta.py
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/venv/Lib/site-packages/dateutil/relativedelta.py b/venv/Lib/site-packages/dateutil/relativedelta.py
new file mode 100644
--- /dev/null	(date 1616406051829)
+++ b/venv/Lib/site-packages/dateutil/relativedelta.py	(date 1616406051829)
@@ -0,0 +1,599 @@
+# -*- coding: utf-8 -*-
+import datetime
+import calendar
+
+import operator
+from math import copysign
+
+from six import integer_types
+from warnings import warn
+
+from ._common import weekday
+
+MO, TU, WE, TH, FR, SA, SU = weekdays = tuple(weekday(x) for x in range(7))
+
+__all__ = ["relativedelta", "MO", "TU", "WE", "TH", "FR", "SA", "SU"]
+
+
+class relativedelta(object):
+    """
+    The relativedelta type is designed to be applied to an existing datetime and
+    can replace specific components of that datetime, or represents an interval
+    of time.
+
+    It is based on the specification of the excellent work done by M.-A. Lemburg
+    in his
+    `mx.DateTime <https://www.egenix.com/products/python/mxBase/mxDateTime/>`_ extension.
+    However, notice that this type does *NOT* implement the same algorithm as
+    his work. Do *NOT* expect it to behave like mx.DateTime's counterpart.
+
+    There are two different ways to build a relativedelta instance. The
+    first one is passing it two date/datetime classes::
+
+        relativedelta(datetime1, datetime2)
+
+    The second one is passing it any number of the following keyword arguments::
+
+        relativedelta(arg1=x,arg2=y,arg3=z...)
+
+        year, month, day, hour, minute, second, microsecond:
+            Absolute information (argument is singular); adding or subtracting a
+            relativedelta with absolute information does not perform an arithmetic
+            operation, but rather REPLACES the corresponding value in the
+            original datetime with the value(s) in relativedelta.
+
+        years, months, weeks, days, hours, minutes, seconds, microseconds:
+            Relative information, may be negative (argument is plural); adding
+            or subtracting a relativedelta with relative information performs
+            the corresponding arithmetic operation on the original datetime value
+            with the information in the relativedelta.
+
+        weekday: 
+            One of the weekday instances (MO, TU, etc) available in the
+            relativedelta module. These instances may receive a parameter N,
+            specifying the Nth weekday, which could be positive or negative
+            (like MO(+1) or MO(-2)). Not specifying it is the same as specifying
+            +1. You can also use an integer, where 0=MO. This argument is always
+            relative e.g. if the calculated date is already Monday, using MO(1)
+            or MO(-1) won't change the day. To effectively make it absolute, use
+            it in combination with the day argument (e.g. day=1, MO(1) for first
+            Monday of the month).
+
+        leapdays:
+            Will add given days to the date found, if year is a leap
+            year, and the date found is post 28 of february.
+
+        yearday, nlyearday:
+            Set the yearday or the non-leap year day (jump leap days).
+            These are converted to day/month/leapdays information.
+
+    There are relative and absolute forms of the keyword
+    arguments. The plural is relative, and the singular is
+    absolute. For each argument in the order below, the absolute form
+    is applied first (by setting each attribute to that value) and
+    then the relative form (by adding the value to the attribute).
+
+    The order of attributes considered when this relativedelta is
+    added to a datetime is:
+
+    1. Year
+    2. Month
+    3. Day
+    4. Hours
+    5. Minutes
+    6. Seconds
+    7. Microseconds
+
+    Finally, weekday is applied, using the rule described above.
+
+    For example
+
+    >>> from datetime import datetime
+    >>> from dateutil.relativedelta import relativedelta, MO
+    >>> dt = datetime(2018, 4, 9, 13, 37, 0)
+    >>> delta = relativedelta(hours=25, day=1, weekday=MO(1))
+    >>> dt + delta
+    datetime.datetime(2018, 4, 2, 14, 37)
+
+    First, the day is set to 1 (the first of the month), then 25 hours
+    are added, to get to the 2nd day and 14th hour, finally the
+    weekday is applied, but since the 2nd is already a Monday there is
+    no effect.
+
+    """
+
+    def __init__(self, dt1=None, dt2=None,
+                 years=0, months=0, days=0, leapdays=0, weeks=0,
+                 hours=0, minutes=0, seconds=0, microseconds=0,
+                 year=None, month=None, day=None, weekday=None,
+                 yearday=None, nlyearday=None,
+                 hour=None, minute=None, second=None, microsecond=None):
+
+        if dt1 and dt2:
+            # datetime is a subclass of date. So both must be date
+            if not (isinstance(dt1, datetime.date) and
+                    isinstance(dt2, datetime.date)):
+                raise TypeError("relativedelta only diffs datetime/date")
+
+            # We allow two dates, or two datetimes, so we coerce them to be
+            # of the same type
+            if (isinstance(dt1, datetime.datetime) !=
+                    isinstance(dt2, datetime.datetime)):
+                if not isinstance(dt1, datetime.datetime):
+                    dt1 = datetime.datetime.fromordinal(dt1.toordinal())
+                elif not isinstance(dt2, datetime.datetime):
+                    dt2 = datetime.datetime.fromordinal(dt2.toordinal())
+
+            self.years = 0
+            self.months = 0
+            self.days = 0
+            self.leapdays = 0
+            self.hours = 0
+            self.minutes = 0
+            self.seconds = 0
+            self.microseconds = 0
+            self.year = None
+            self.month = None
+            self.day = None
+            self.weekday = None
+            self.hour = None
+            self.minute = None
+            self.second = None
+            self.microsecond = None
+            self._has_time = 0
+
+            # Get year / month delta between the two
+            months = (dt1.year - dt2.year) * 12 + (dt1.month - dt2.month)
+            self._set_months(months)
+
+            # Remove the year/month delta so the timedelta is just well-defined
+            # time units (seconds, days and microseconds)
+            dtm = self.__radd__(dt2)
+
+            # If we've overshot our target, make an adjustment
+            if dt1 < dt2:
+                compare = operator.gt
+                increment = 1
+            else:
+                compare = operator.lt
+                increment = -1
+
+            while compare(dt1, dtm):
+                months += increment
+                self._set_months(months)
+                dtm = self.__radd__(dt2)
+
+            # Get the timedelta between the "months-adjusted" date and dt1
+            delta = dt1 - dtm
+            self.seconds = delta.seconds + delta.days * 86400
+            self.microseconds = delta.microseconds
+        else:
+            # Check for non-integer values in integer-only quantities
+            if any(x is not None and x != int(x) for x in (years, months)):
+                raise ValueError("Non-integer years and months are "
+                                 "ambiguous and not currently supported.")
+
+            # Relative information
+            self.years = int(years)
+            self.months = int(months)
+            self.days = days + weeks * 7
+            self.leapdays = leapdays
+            self.hours = hours
+            self.minutes = minutes
+            self.seconds = seconds
+            self.microseconds = microseconds
+
+            # Absolute information
+            self.year = year
+            self.month = month
+            self.day = day
+            self.hour = hour
+            self.minute = minute
+            self.second = second
+            self.microsecond = microsecond
+
+            if any(x is not None and int(x) != x
+                   for x in (year, month, day, hour,
+                             minute, second, microsecond)):
+                # For now we'll deprecate floats - later it'll be an error.
+                warn("Non-integer value passed as absolute information. " +
+                     "This is not a well-defined condition and will raise " +
+                     "errors in future versions.", DeprecationWarning)
+
+            if isinstance(weekday, integer_types):
+                self.weekday = weekdays[weekday]
+            else:
+                self.weekday = weekday
+
+            yday = 0
+            if nlyearday:
+                yday = nlyearday
+            elif yearday:
+                yday = yearday
+                if yearday > 59:
+                    self.leapdays = -1
+            if yday:
+                ydayidx = [31, 59, 90, 120, 151, 181, 212,
+                           243, 273, 304, 334, 366]
+                for idx, ydays in enumerate(ydayidx):
+                    if yday <= ydays:
+                        self.month = idx+1
+                        if idx == 0:
+                            self.day = yday
+                        else:
+                            self.day = yday-ydayidx[idx-1]
+                        break
+                else:
+                    raise ValueError("invalid year day (%d)" % yday)
+
+        self._fix()
+
+    def _fix(self):
+        if abs(self.microseconds) > 999999:
+            s = _sign(self.microseconds)
+            div, mod = divmod(self.microseconds * s, 1000000)
+            self.microseconds = mod * s
+            self.seconds += div * s
+        if abs(self.seconds) > 59:
+            s = _sign(self.seconds)
+            div, mod = divmod(self.seconds * s, 60)
+            self.seconds = mod * s
+            self.minutes += div * s
+        if abs(self.minutes) > 59:
+            s = _sign(self.minutes)
+            div, mod = divmod(self.minutes * s, 60)
+            self.minutes = mod * s
+            self.hours += div * s
+        if abs(self.hours) > 23:
+            s = _sign(self.hours)
+            div, mod = divmod(self.hours * s, 24)
+            self.hours = mod * s
+            self.days += div * s
+        if abs(self.months) > 11:
+            s = _sign(self.months)
+            div, mod = divmod(self.months * s, 12)
+            self.months = mod * s
+            self.years += div * s
+        if (self.hours or self.minutes or self.seconds or self.microseconds
+                or self.hour is not None or self.minute is not None or
+                self.second is not None or self.microsecond is not None):
+            self._has_time = 1
+        else:
+            self._has_time = 0
+
+    @property
+    def weeks(self):
+        return int(self.days / 7.0)
+
+    @weeks.setter
+    def weeks(self, value):
+        self.days = self.days - (self.weeks * 7) + value * 7
+
+    def _set_months(self, months):
+        self.months = months
+        if abs(self.months) > 11:
+            s = _sign(self.months)
+            div, mod = divmod(self.months * s, 12)
+            self.months = mod * s
+            self.years = div * s
+        else:
+            self.years = 0
+
+    def normalized(self):
+        """
+        Return a version of this object represented entirely using integer
+        values for the relative attributes.
+
+        >>> relativedelta(days=1.5, hours=2).normalized()
+        relativedelta(days=+1, hours=+14)
+
+        :return:
+            Returns a :class:`dateutil.relativedelta.relativedelta` object.
+        """
+        # Cascade remainders down (rounding each to roughly nearest microsecond)
+        days = int(self.days)
+
+        hours_f = round(self.hours + 24 * (self.days - days), 11)
+        hours = int(hours_f)
+
+        minutes_f = round(self.minutes + 60 * (hours_f - hours), 10)
+        minutes = int(minutes_f)
+
+        seconds_f = round(self.seconds + 60 * (minutes_f - minutes), 8)
+        seconds = int(seconds_f)
+
+        microseconds = round(self.microseconds + 1e6 * (seconds_f - seconds))
+
+        # Constructor carries overflow back up with call to _fix()
+        return self.__class__(years=self.years, months=self.months,
+                              days=days, hours=hours, minutes=minutes,
+                              seconds=seconds, microseconds=microseconds,
+                              leapdays=self.leapdays, year=self.year,
+                              month=self.month, day=self.day,
+                              weekday=self.weekday, hour=self.hour,
+                              minute=self.minute, second=self.second,
+                              microsecond=self.microsecond)
+
+    def __add__(self, other):
+        if isinstance(other, relativedelta):
+            return self.__class__(years=other.years + self.years,
+                                 months=other.months + self.months,
+                                 days=other.days + self.days,
+                                 hours=other.hours + self.hours,
+                                 minutes=other.minutes + self.minutes,
+                                 seconds=other.seconds + self.seconds,
+                                 microseconds=(other.microseconds +
+                                               self.microseconds),
+                                 leapdays=other.leapdays or self.leapdays,
+                                 year=(other.year if other.year is not None
+                                       else self.year),
+                                 month=(other.month if other.month is not None
+                                        else self.month),
+                                 day=(other.day if other.day is not None
+                                      else self.day),
+                                 weekday=(other.weekday if other.weekday is not None
+                                          else self.weekday),
+                                 hour=(other.hour if other.hour is not None
+                                       else self.hour),
+                                 minute=(other.minute if other.minute is not None
+                                         else self.minute),
+                                 second=(other.second if other.second is not None
+                                         else self.second),
+                                 microsecond=(other.microsecond if other.microsecond
+                                              is not None else
+                                              self.microsecond))
+        if isinstance(other, datetime.timedelta):
+            return self.__class__(years=self.years,
+                                  months=self.months,
+                                  days=self.days + other.days,
+                                  hours=self.hours,
+                                  minutes=self.minutes,
+                                  seconds=self.seconds + other.seconds,
+                                  microseconds=self.microseconds + other.microseconds,
+                                  leapdays=self.leapdays,
+                                  year=self.year,
+                                  month=self.month,
+                                  day=self.day,
+                                  weekday=self.weekday,
+                                  hour=self.hour,
+                                  minute=self.minute,
+                                  second=self.second,
+                                  microsecond=self.microsecond)
+        if not isinstance(other, datetime.date):
+            return NotImplemented
+        elif self._has_time and not isinstance(other, datetime.datetime):
+            other = datetime.datetime.fromordinal(other.toordinal())
+        year = (self.year or other.year)+self.years
+        month = self.month or other.month
+        if self.months:
+            assert 1 <= abs(self.months) <= 12
+            month += self.months
+            if month > 12:
+                year += 1
+                month -= 12
+            elif month < 1:
+                year -= 1
+                month += 12
+        day = min(calendar.monthrange(year, month)[1],
+                  self.day or other.day)
+        repl = {"year": year, "month": month, "day": day}
+        for attr in ["hour", "minute", "second", "microsecond"]:
+            value = getattr(self, attr)
+            if value is not None:
+                repl[attr] = value
+        days = self.days
+        if self.leapdays and month > 2 and calendar.isleap(year):
+            days += self.leapdays
+        ret = (other.replace(**repl)
+               + datetime.timedelta(days=days,
+                                    hours=self.hours,
+                                    minutes=self.minutes,
+                                    seconds=self.seconds,
+                                    microseconds=self.microseconds))
+        if self.weekday:
+            weekday, nth = self.weekday.weekday, self.weekday.n or 1
+            jumpdays = (abs(nth) - 1) * 7
+            if nth > 0:
+                jumpdays += (7 - ret.weekday() + weekday) % 7
+            else:
+                jumpdays += (ret.weekday() - weekday) % 7
+                jumpdays *= -1
+            ret += datetime.timedelta(days=jumpdays)
+        return ret
+
+    def __radd__(self, other):
+        return self.__add__(other)
+
+    def __rsub__(self, other):
+        return self.__neg__().__radd__(other)
+
+    def __sub__(self, other):
+        if not isinstance(other, relativedelta):
+            return NotImplemented   # In case the other object defines __rsub__
+        return self.__class__(years=self.years - other.years,
+                             months=self.months - other.months,
+                             days=self.days - other.days,
+                             hours=self.hours - other.hours,
+                             minutes=self.minutes - other.minutes,
+                             seconds=self.seconds - other.seconds,
+                             microseconds=self.microseconds - other.microseconds,
+                             leapdays=self.leapdays or other.leapdays,
+                             year=(self.year if self.year is not None
+                                   else other.year),
+                             month=(self.month if self.month is not None else
+                                    other.month),
+                             day=(self.day if self.day is not None else
+                                  other.day),
+                             weekday=(self.weekday if self.weekday is not None else
+                                      other.weekday),
+                             hour=(self.hour if self.hour is not None else
+                                   other.hour),
+                             minute=(self.minute if self.minute is not None else
+                                     other.minute),
+                             second=(self.second if self.second is not None else
+                                     other.second),
+                             microsecond=(self.microsecond if self.microsecond
+                                          is not None else
+                                          other.microsecond))
+
+    def __abs__(self):
+        return self.__class__(years=abs(self.years),
+                              months=abs(self.months),
+                              days=abs(self.days),
+                              hours=abs(self.hours),
+                              minutes=abs(self.minutes),
+                              seconds=abs(self.seconds),
+                              microseconds=abs(self.microseconds),
+                              leapdays=self.leapdays,
+                              year=self.year,
+                              month=self.month,
+                              day=self.day,
+                              weekday=self.weekday,
+                              hour=self.hour,
+                              minute=self.minute,
+                              second=self.second,
+                              microsecond=self.microsecond)
+
+    def __neg__(self):
+        return self.__class__(years=-self.years,
+                             months=-self.months,
+                             days=-self.days,
+                             hours=-self.hours,
+                             minutes=-self.minutes,
+                             seconds=-self.seconds,
+                             microseconds=-self.microseconds,
+                             leapdays=self.leapdays,
+                             year=self.year,
+                             month=self.month,
+                             day=self.day,
+                             weekday=self.weekday,
+                             hour=self.hour,
+                             minute=self.minute,
+                             second=self.second,
+                             microsecond=self.microsecond)
+
+    def __bool__(self):
+        return not (not self.years and
+                    not self.months and
+                    not self.days and
+                    not self.hours and
+                    not self.minutes and
+                    not self.seconds and
+                    not self.microseconds and
+                    not self.leapdays and
+                    self.year is None and
+                    self.month is None and
+                    self.day is None and
+                    self.weekday is None and
+                    self.hour is None and
+                    self.minute is None and
+                    self.second is None and
+                    self.microsecond is None)
+    # Compatibility with Python 2.x
+    __nonzero__ = __bool__
+
+    def __mul__(self, other):
+        try:
+            f = float(other)
+        except TypeError:
+            return NotImplemented
+
+        return self.__class__(years=int(self.years * f),
+                             months=int(self.months * f),
+                             days=int(self.days * f),
+                             hours=int(self.hours * f),
+                             minutes=int(self.minutes * f),
+                             seconds=int(self.seconds * f),
+                             microseconds=int(self.microseconds * f),
+                             leapdays=self.leapdays,
+                             year=self.year,
+                             month=self.month,
+                             day=self.day,
+                             weekday=self.weekday,
+                             hour=self.hour,
+                             minute=self.minute,
+                             second=self.second,
+                             microsecond=self.microsecond)
+
+    __rmul__ = __mul__
+
+    def __eq__(self, other):
+        if not isinstance(other, relativedelta):
+            return NotImplemented
+        if self.weekday or other.weekday:
+            if not self.weekday or not other.weekday:
+                return False
+            if self.weekday.weekday != other.weekday.weekday:
+                return False
+            n1, n2 = self.weekday.n, other.weekday.n
+            if n1 != n2 and not ((not n1 or n1 == 1) and (not n2 or n2 == 1)):
+                return False
+        return (self.years == other.years and
+                self.months == other.months and
+                self.days == other.days and
+                self.hours == other.hours and
+                self.minutes == other.minutes and
+                self.seconds == other.seconds and
+                self.microseconds == other.microseconds and
+                self.leapdays == other.leapdays and
+                self.year == other.year and
+                self.month == other.month and
+                self.day == other.day and
+                self.hour == other.hour and
+                self.minute == other.minute and
+                self.second == other.second and
+                self.microsecond == other.microsecond)
+
+    def __hash__(self):
+        return hash((
+            self.weekday,
+            self.years,
+            self.months,
+            self.days,
+            self.hours,
+            self.minutes,
+            self.seconds,
+            self.microseconds,
+            self.leapdays,
+            self.year,
+            self.month,
+            self.day,
+            self.hour,
+            self.minute,
+            self.second,
+            self.microsecond,
+        ))
+
+    def __ne__(self, other):
+        return not self.__eq__(other)
+
+    def __div__(self, other):
+        try:
+            reciprocal = 1 / float(other)
+        except TypeError:
+            return NotImplemented
+
+        return self.__mul__(reciprocal)
+
+    __truediv__ = __div__
+
+    def __repr__(self):
+        l = []
+        for attr in ["years", "months", "days", "leapdays",
+                     "hours", "minutes", "seconds", "microseconds"]:
+            value = getattr(self, attr)
+            if value:
+                l.append("{attr}={value:+g}".format(attr=attr, value=value))
+        for attr in ["year", "month", "day", "weekday",
+                     "hour", "minute", "second", "microsecond"]:
+            value = getattr(self, attr)
+            if value is not None:
+                l.append("{attr}={value}".format(attr=attr, value=repr(value)))
+        return "{classname}({attrs})".format(classname=self.__class__.__name__,
+                                             attrs=", ".join(l))
+
+
+def _sign(x):
+    return int(copysign(1, x))
+
+# vim:ts=4:sw=4:et
Index: venv/Lib/site-packages/dateutil/rrule.py
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/venv/Lib/site-packages/dateutil/rrule.py b/venv/Lib/site-packages/dateutil/rrule.py
new file mode 100644
--- /dev/null	(date 1616406051829)
+++ b/venv/Lib/site-packages/dateutil/rrule.py	(date 1616406051829)
@@ -0,0 +1,1735 @@
+# -*- coding: utf-8 -*-
+"""
+The rrule module offers a small, complete, and very fast, implementation of
+the recurrence rules documented in the
+`iCalendar RFC <https://tools.ietf.org/html/rfc5545>`_,
+including support for caching of results.
+"""
+import itertools
+import datetime
+import calendar
+import re
+import sys
+
+try:
+    from math import gcd
+except ImportError:
+    from fractions import gcd
+
+from six import advance_iterator, integer_types
+from six.moves import _thread, range
+import heapq
+
+from ._common import weekday as weekdaybase
+
+# For warning about deprecation of until and count
+from warnings import warn
+
+__all__ = ["rrule", "rruleset", "rrulestr",
+           "YEARLY", "MONTHLY", "WEEKLY", "DAILY",
+           "HOURLY", "MINUTELY", "SECONDLY",
+           "MO", "TU", "WE", "TH", "FR", "SA", "SU"]
+
+# Every mask is 7 days longer to handle cross-year weekly periods.
+M366MASK = tuple([1]*31+[2]*29+[3]*31+[4]*30+[5]*31+[6]*30 +
+                 [7]*31+[8]*31+[9]*30+[10]*31+[11]*30+[12]*31+[1]*7)
+M365MASK = list(M366MASK)
+M29, M30, M31 = list(range(1, 30)), list(range(1, 31)), list(range(1, 32))
+MDAY366MASK = tuple(M31+M29+M31+M30+M31+M30+M31+M31+M30+M31+M30+M31+M31[:7])
+MDAY365MASK = list(MDAY366MASK)
+M29, M30, M31 = list(range(-29, 0)), list(range(-30, 0)), list(range(-31, 0))
+NMDAY366MASK = tuple(M31+M29+M31+M30+M31+M30+M31+M31+M30+M31+M30+M31+M31[:7])
+NMDAY365MASK = list(NMDAY366MASK)
+M366RANGE = (0, 31, 60, 91, 121, 152, 182, 213, 244, 274, 305, 335, 366)
+M365RANGE = (0, 31, 59, 90, 120, 151, 181, 212, 243, 273, 304, 334, 365)
+WDAYMASK = [0, 1, 2, 3, 4, 5, 6]*55
+del M29, M30, M31, M365MASK[59], MDAY365MASK[59], NMDAY365MASK[31]
+MDAY365MASK = tuple(MDAY365MASK)
+M365MASK = tuple(M365MASK)
+
+FREQNAMES = ['YEARLY', 'MONTHLY', 'WEEKLY', 'DAILY', 'HOURLY', 'MINUTELY', 'SECONDLY']
+
+(YEARLY,
+ MONTHLY,
+ WEEKLY,
+ DAILY,
+ HOURLY,
+ MINUTELY,
+ SECONDLY) = list(range(7))
+
+# Imported on demand.
+easter = None
+parser = None
+
+
+class weekday(weekdaybase):
+    """
+    This version of weekday does not allow n = 0.
+    """
+    def __init__(self, wkday, n=None):
+        if n == 0:
+            raise ValueError("Can't create weekday with n==0")
+
+        super(weekday, self).__init__(wkday, n)
+
+
+MO, TU, WE, TH, FR, SA, SU = weekdays = tuple(weekday(x) for x in range(7))
+
+
+def _invalidates_cache(f):
+    """
+    Decorator for rruleset methods which may invalidate the
+    cached length.
+    """
+    def inner_func(self, *args, **kwargs):
+        rv = f(self, *args, **kwargs)
+        self._invalidate_cache()
+        return rv
+
+    return inner_func
+
+
+class rrulebase(object):
+    def __init__(self, cache=False):
+        if cache:
+            self._cache = []
+            self._cache_lock = _thread.allocate_lock()
+            self._invalidate_cache()
+        else:
+            self._cache = None
+            self._cache_complete = False
+            self._len = None
+
+    def __iter__(self):
+        if self._cache_complete:
+            return iter(self._cache)
+        elif self._cache is None:
+            return self._iter()
+        else:
+            return self._iter_cached()
+
+    def _invalidate_cache(self):
+        if self._cache is not None:
+            self._cache = []
+            self._cache_complete = False
+            self._cache_gen = self._iter()
+
+            if self._cache_lock.locked():
+                self._cache_lock.release()
+
+        self._len = None
+
+    def _iter_cached(self):
+        i = 0
+        gen = self._cache_gen
+        cache = self._cache
+        acquire = self._cache_lock.acquire
+        release = self._cache_lock.release
+        while gen:
+            if i == len(cache):
+                acquire()
+                if self._cache_complete:
+                    break
+                try:
+                    for j in range(10):
+                        cache.append(advance_iterator(gen))
+                except StopIteration:
+                    self._cache_gen = gen = None
+                    self._cache_complete = True
+                    break
+                release()
+            yield cache[i]
+            i += 1
+        while i < self._len:
+            yield cache[i]
+            i += 1
+
+    def __getitem__(self, item):
+        if self._cache_complete:
+            return self._cache[item]
+        elif isinstance(item, slice):
+            if item.step and item.step < 0:
+                return list(iter(self))[item]
+            else:
+                return list(itertools.islice(self,
+                                             item.start or 0,
+                                             item.stop or sys.maxsize,
+                                             item.step or 1))
+        elif item >= 0:
+            gen = iter(self)
+            try:
+                for i in range(item+1):
+                    res = advance_iterator(gen)
+            except StopIteration:
+                raise IndexError
+            return res
+        else:
+            return list(iter(self))[item]
+
+    def __contains__(self, item):
+        if self._cache_complete:
+            return item in self._cache
+        else:
+            for i in self:
+                if i == item:
+                    return True
+                elif i > item:
+                    return False
+        return False
+
+    # __len__() introduces a large performance penalty.
+    def count(self):
+        """ Returns the number of recurrences in this set. It will have go
+            trough the whole recurrence, if this hasn't been done before. """
+        if self._len is None:
+            for x in self:
+                pass
+        return self._len
+
+    def before(self, dt, inc=False):
+        """ Returns the last recurrence before the given datetime instance. The
+            inc keyword defines what happens if dt is an occurrence. With
+            inc=True, if dt itself is an occurrence, it will be returned. """
+        if self._cache_complete:
+            gen = self._cache
+        else:
+            gen = self
+        last = None
+        if inc:
+            for i in gen:
+                if i > dt:
+                    break
+                last = i
+        else:
+            for i in gen:
+                if i >= dt:
+                    break
+                last = i
+        return last
+
+    def after(self, dt, inc=False):
+        """ Returns the first recurrence after the given datetime instance. The
+            inc keyword defines what happens if dt is an occurrence. With
+            inc=True, if dt itself is an occurrence, it will be returned.  """
+        if self._cache_complete:
+            gen = self._cache
+        else:
+            gen = self
+        if inc:
+            for i in gen:
+                if i >= dt:
+                    return i
+        else:
+            for i in gen:
+                if i > dt:
+                    return i
+        return None
+
+    def xafter(self, dt, count=None, inc=False):
+        """
+        Generator which yields up to `count` recurrences after the given
+        datetime instance, equivalent to `after`.
+
+        :param dt:
+            The datetime at which to start generating recurrences.
+
+        :param count:
+            The maximum number of recurrences to generate. If `None` (default),
+            dates are generated until the recurrence rule is exhausted.
+
+        :param inc:
+            If `dt` is an instance of the rule and `inc` is `True`, it is
+            included in the output.
+
+        :yields: Yields a sequence of `datetime` objects.
+        """
+
+        if self._cache_complete:
+            gen = self._cache
+        else:
+            gen = self
+
+        # Select the comparison function
+        if inc:
+            comp = lambda dc, dtc: dc >= dtc
+        else:
+            comp = lambda dc, dtc: dc > dtc
+
+        # Generate dates
+        n = 0
+        for d in gen:
+            if comp(d, dt):
+                if count is not None:
+                    n += 1
+                    if n > count:
+                        break
+
+                yield d
+
+    def between(self, after, before, inc=False, count=1):
+        """ Returns all the occurrences of the rrule between after and before.
+        The inc keyword defines what happens if after and/or before are
+        themselves occurrences. With inc=True, they will be included in the
+        list, if they are found in the recurrence set. """
+        if self._cache_complete:
+            gen = self._cache
+        else:
+            gen = self
+        started = False
+        l = []
+        if inc:
+            for i in gen:
+                if i > before:
+                    break
+                elif not started:
+                    if i >= after:
+                        started = True
+                        l.append(i)
+                else:
+                    l.append(i)
+        else:
+            for i in gen:
+                if i >= before:
+                    break
+                elif not started:
+                    if i > after:
+                        started = True
+                        l.append(i)
+                else:
+                    l.append(i)
+        return l
+
+
+class rrule(rrulebase):
+    """
+    That's the base of the rrule operation. It accepts all the keywords
+    defined in the RFC as its constructor parameters (except byday,
+    which was renamed to byweekday) and more. The constructor prototype is::
+
+            rrule(freq)
+
+    Where freq must be one of YEARLY, MONTHLY, WEEKLY, DAILY, HOURLY, MINUTELY,
+    or SECONDLY.
+
+    .. note::
+        Per RFC section 3.3.10, recurrence instances falling on invalid dates
+        and times are ignored rather than coerced:
+
+            Recurrence rules may generate recurrence instances with an invalid
+            date (e.g., February 30) or nonexistent local time (e.g., 1:30 AM
+            on a day where the local time is moved forward by an hour at 1:00
+            AM).  Such recurrence instances MUST be ignored and MUST NOT be
+            counted as part of the recurrence set.
+
+        This can lead to possibly surprising behavior when, for example, the
+        start date occurs at the end of the month:
+
+        >>> from dateutil.rrule import rrule, MONTHLY
+        >>> from datetime import datetime
+        >>> start_date = datetime(2014, 12, 31)
+        >>> list(rrule(freq=MONTHLY, count=4, dtstart=start_date))
+        ... # doctest: +NORMALIZE_WHITESPACE
+        [datetime.datetime(2014, 12, 31, 0, 0),
+         datetime.datetime(2015, 1, 31, 0, 0),
+         datetime.datetime(2015, 3, 31, 0, 0),
+         datetime.datetime(2015, 5, 31, 0, 0)]
+
+    Additionally, it supports the following keyword arguments:
+
+    :param dtstart:
+        The recurrence start. Besides being the base for the recurrence,
+        missing parameters in the final recurrence instances will also be
+        extracted from this date. If not given, datetime.now() will be used
+        instead.
+    :param interval:
+        The interval between each freq iteration. For example, when using
+        YEARLY, an interval of 2 means once every two years, but with HOURLY,
+        it means once every two hours. The default interval is 1.
+    :param wkst:
+        The week start day. Must be one of the MO, TU, WE constants, or an
+        integer, specifying the first day of the week. This will affect
+        recurrences based on weekly periods. The default week start is got
+        from calendar.firstweekday(), and may be modified by
+        calendar.setfirstweekday().
+    :param count:
+        If given, this determines how many occurrences will be generated.
+
+        .. note::
+            As of version 2.5.0, the use of the keyword ``until`` in conjunction
+            with ``count`` is deprecated, to make sure ``dateutil`` is fully
+            compliant with `RFC-5545 Sec. 3.3.10 <https://tools.ietf.org/
+            html/rfc5545#section-3.3.10>`_. Therefore, ``until`` and ``count``
+            **must not** occur in the same call to ``rrule``.
+    :param until:
+        If given, this must be a datetime instance specifying the upper-bound
+        limit of the recurrence. The last recurrence in the rule is the greatest
+        datetime that is less than or equal to the value specified in the
+        ``until`` parameter.
+
+        .. note::
+            As of version 2.5.0, the use of the keyword ``until`` in conjunction
+            with ``count`` is deprecated, to make sure ``dateutil`` is fully
+            compliant with `RFC-5545 Sec. 3.3.10 <https://tools.ietf.org/
+            html/rfc5545#section-3.3.10>`_. Therefore, ``until`` and ``count``
+            **must not** occur in the same call to ``rrule``.
+    :param bysetpos:
+        If given, it must be either an integer, or a sequence of integers,
+        positive or negative. Each given integer will specify an occurrence
+        number, corresponding to the nth occurrence of the rule inside the
+        frequency period. For example, a bysetpos of -1 if combined with a
+        MONTHLY frequency, and a byweekday of (MO, TU, WE, TH, FR), will
+        result in the last work day of every month.
+    :param bymonth:
+        If given, it must be either an integer, or a sequence of integers,
+        meaning the months to apply the recurrence to.
+    :param bymonthday:
+        If given, it must be either an integer, or a sequence of integers,
+        meaning the month days to apply the recurrence to.
+    :param byyearday:
+        If given, it must be either an integer, or a sequence of integers,
+        meaning the year days to apply the recurrence to.
+    :param byeaster:
+        If given, it must be either an integer, or a sequence of integers,
+        positive or negative. Each integer will define an offset from the
+        Easter Sunday. Passing the offset 0 to byeaster will yield the Easter
+        Sunday itself. This is an extension to the RFC specification.
+    :param byweekno:
+        If given, it must be either an integer, or a sequence of integers,
+        meaning the week numbers to apply the recurrence to. Week numbers
+        have the meaning described in ISO8601, that is, the first week of
+        the year is that containing at least four days of the new year.
+    :param byweekday:
+        If given, it must be either an integer (0 == MO), a sequence of
+        integers, one of the weekday constants (MO, TU, etc), or a sequence
+        of these constants. When given, these variables will define the
+        weekdays where the recurrence will be applied. It's also possible to
+        use an argument n for the weekday instances, which will mean the nth
+        occurrence of this weekday in the period. For example, with MONTHLY,
+        or with YEARLY and BYMONTH, using FR(+1) in byweekday will specify the
+        first friday of the month where the recurrence happens. Notice that in
+        the RFC documentation, this is specified as BYDAY, but was renamed to
+        avoid the ambiguity of that keyword.
+    :param byhour:
+        If given, it must be either an integer, or a sequence of integers,
+        meaning the hours to apply the recurrence to.
+    :param byminute:
+        If given, it must be either an integer, or a sequence of integers,
+        meaning the minutes to apply the recurrence to.
+    :param bysecond:
+        If given, it must be either an integer, or a sequence of integers,
+        meaning the seconds to apply the recurrence to.
+    :param cache:
+        If given, it must be a boolean value specifying to enable or disable
+        caching of results. If you will use the same rrule instance multiple
+        times, enabling caching will improve the performance considerably.
+     """
+    def __init__(self, freq, dtstart=None,
+                 interval=1, wkst=None, count=None, until=None, bysetpos=None,
+                 bymonth=None, bymonthday=None, byyearday=None, byeaster=None,
+                 byweekno=None, byweekday=None,
+                 byhour=None, byminute=None, bysecond=None,
+                 cache=False):
+        super(rrule, self).__init__(cache)
+        global easter
+        if not dtstart:
+            if until and until.tzinfo:
+                dtstart = datetime.datetime.now(tz=until.tzinfo).replace(microsecond=0)
+            else:
+                dtstart = datetime.datetime.now().replace(microsecond=0)
+        elif not isinstance(dtstart, datetime.datetime):
+            dtstart = datetime.datetime.fromordinal(dtstart.toordinal())
+        else:
+            dtstart = dtstart.replace(microsecond=0)
+        self._dtstart = dtstart
+        self._tzinfo = dtstart.tzinfo
+        self._freq = freq
+        self._interval = interval
+        self._count = count
+
+        # Cache the original byxxx rules, if they are provided, as the _byxxx
+        # attributes do not necessarily map to the inputs, and this can be
+        # a problem in generating the strings. Only store things if they've
+        # been supplied (the string retrieval will just use .get())
+        self._original_rule = {}
+
+        if until and not isinstance(until, datetime.datetime):
+            until = datetime.datetime.fromordinal(until.toordinal())
+        self._until = until
+
+        if self._dtstart and self._until:
+            if (self._dtstart.tzinfo is not None) != (self._until.tzinfo is not None):
+                # According to RFC5545 Section 3.3.10:
+                # https://tools.ietf.org/html/rfc5545#section-3.3.10
+                #
+                # > If the "DTSTART" property is specified as a date with UTC
+                # > time or a date with local time and time zone reference,
+                # > then the UNTIL rule part MUST be specified as a date with
+                # > UTC time.
+                raise ValueError(
+                    'RRULE UNTIL values must be specified in UTC when DTSTART '
+                    'is timezone-aware'
+                )
+
+        if count is not None and until:
+            warn("Using both 'count' and 'until' is inconsistent with RFC 5545"
+                 " and has been deprecated in dateutil. Future versions will "
+                 "raise an error.", DeprecationWarning)
+
+        if wkst is None:
+            self._wkst = calendar.firstweekday()
+        elif isinstance(wkst, integer_types):
+            self._wkst = wkst
+        else:
+            self._wkst = wkst.weekday
+
+        if bysetpos is None:
+            self._bysetpos = None
+        elif isinstance(bysetpos, integer_types):
+            if bysetpos == 0 or not (-366 <= bysetpos <= 366):
+                raise ValueError("bysetpos must be between 1 and 366, "
+                                 "or between -366 and -1")
+            self._bysetpos = (bysetpos,)
+        else:
+            self._bysetpos = tuple(bysetpos)
+            for pos in self._bysetpos:
+                if pos == 0 or not (-366 <= pos <= 366):
+                    raise ValueError("bysetpos must be between 1 and 366, "
+                                     "or between -366 and -1")
+
+        if self._bysetpos:
+            self._original_rule['bysetpos'] = self._bysetpos
+
+        if (byweekno is None and byyearday is None and bymonthday is None and
+                byweekday is None and byeaster is None):
+            if freq == YEARLY:
+                if bymonth is None:
+                    bymonth = dtstart.month
+                    self._original_rule['bymonth'] = None
+                bymonthday = dtstart.day
+                self._original_rule['bymonthday'] = None
+            elif freq == MONTHLY:
+                bymonthday = dtstart.day
+                self._original_rule['bymonthday'] = None
+            elif freq == WEEKLY:
+                byweekday = dtstart.weekday()
+                self._original_rule['byweekday'] = None
+
+        # bymonth
+        if bymonth is None:
+            self._bymonth = None
+        else:
+            if isinstance(bymonth, integer_types):
+                bymonth = (bymonth,)
+
+            self._bymonth = tuple(sorted(set(bymonth)))
+
+            if 'bymonth' not in self._original_rule:
+                self._original_rule['bymonth'] = self._bymonth
+
+        # byyearday
+        if byyearday is None:
+            self._byyearday = None
+        else:
+            if isinstance(byyearday, integer_types):
+                byyearday = (byyearday,)
+
+            self._byyearday = tuple(sorted(set(byyearday)))
+            self._original_rule['byyearday'] = self._byyearday
+
+        # byeaster
+        if byeaster is not None:
+            if not easter:
+                from dateutil import easter
+            if isinstance(byeaster, integer_types):
+                self._byeaster = (byeaster,)
+            else:
+                self._byeaster = tuple(sorted(byeaster))
+
+            self._original_rule['byeaster'] = self._byeaster
+        else:
+            self._byeaster = None
+
+        # bymonthday
+        if bymonthday is None:
+            self._bymonthday = ()
+            self._bynmonthday = ()
+        else:
+            if isinstance(bymonthday, integer_types):
+                bymonthday = (bymonthday,)
+
+            bymonthday = set(bymonthday)            # Ensure it's unique
+
+            self._bymonthday = tuple(sorted(x for x in bymonthday if x > 0))
+            self._bynmonthday = tuple(sorted(x for x in bymonthday if x < 0))
+
+            # Storing positive numbers first, then negative numbers
+            if 'bymonthday' not in self._original_rule:
+                self._original_rule['bymonthday'] = tuple(
+                    itertools.chain(self._bymonthday, self._bynmonthday))
+
+        # byweekno
+        if byweekno is None:
+            self._byweekno = None
+        else:
+            if isinstance(byweekno, integer_types):
+                byweekno = (byweekno,)
+
+            self._byweekno = tuple(sorted(set(byweekno)))
+
+            self._original_rule['byweekno'] = self._byweekno
+
+        # byweekday / bynweekday
+        if byweekday is None:
+            self._byweekday = None
+            self._bynweekday = None
+        else:
+            # If it's one of the valid non-sequence types, convert to a
+            # single-element sequence before the iterator that builds the
+            # byweekday set.
+            if isinstance(byweekday, integer_types) or hasattr(byweekday, "n"):
+                byweekday = (byweekday,)
+
+            self._byweekday = set()
+            self._bynweekday = set()
+            for wday in byweekday:
+                if isinstance(wday, integer_types):
+                    self._byweekday.add(wday)
+                elif not wday.n or freq > MONTHLY:
+                    self._byweekday.add(wday.weekday)
+                else:
+                    self._bynweekday.add((wday.weekday, wday.n))
+
+            if not self._byweekday:
+                self._byweekday = None
+            elif not self._bynweekday:
+                self._bynweekday = None
+
+            if self._byweekday is not None:
+                self._byweekday = tuple(sorted(self._byweekday))
+                orig_byweekday = [weekday(x) for x in self._byweekday]
+            else:
+                orig_byweekday = ()
+
+            if self._bynweekday is not None:
+                self._bynweekday = tuple(sorted(self._bynweekday))
+                orig_bynweekday = [weekday(*x) for x in self._bynweekday]
+            else:
+                orig_bynweekday = ()
+
+            if 'byweekday' not in self._original_rule:
+                self._original_rule['byweekday'] = tuple(itertools.chain(
+                    orig_byweekday, orig_bynweekday))
+
+        # byhour
+        if byhour is None:
+            if freq < HOURLY:
+                self._byhour = {dtstart.hour}
+            else:
+                self._byhour = None
+        else:
+            if isinstance(byhour, integer_types):
+                byhour = (byhour,)
+
+            if freq == HOURLY:
+                self._byhour = self.__construct_byset(start=dtstart.hour,
+                                                      byxxx=byhour,
+                                                      base=24)
+            else:
+                self._byhour = set(byhour)
+
+            self._byhour = tuple(sorted(self._byhour))
+            self._original_rule['byhour'] = self._byhour
+
+        # byminute
+        if byminute is None:
+            if freq < MINUTELY:
+                self._byminute = {dtstart.minute}
+            else:
+                self._byminute = None
+        else:
+            if isinstance(byminute, integer_types):
+                byminute = (byminute,)
+
+            if freq == MINUTELY:
+                self._byminute = self.__construct_byset(start=dtstart.minute,
+                                                        byxxx=byminute,
+                                                        base=60)
+            else:
+                self._byminute = set(byminute)
+
+            self._byminute = tuple(sorted(self._byminute))
+            self._original_rule['byminute'] = self._byminute
+
+        # bysecond
+        if bysecond is None:
+            if freq < SECONDLY:
+                self._bysecond = ((dtstart.second,))
+            else:
+                self._bysecond = None
+        else:
+            if isinstance(bysecond, integer_types):
+                bysecond = (bysecond,)
+
+            self._bysecond = set(bysecond)
+
+            if freq == SECONDLY:
+                self._bysecond = self.__construct_byset(start=dtstart.second,
+                                                        byxxx=bysecond,
+                                                        base=60)
+            else:
+                self._bysecond = set(bysecond)
+
+            self._bysecond = tuple(sorted(self._bysecond))
+            self._original_rule['bysecond'] = self._bysecond
+
+        if self._freq >= HOURLY:
+            self._timeset = None
+        else:
+            self._timeset = []
+            for hour in self._byhour:
+                for minute in self._byminute:
+                    for second in self._bysecond:
+                        self._timeset.append(
+                            datetime.time(hour, minute, second,
+                                          tzinfo=self._tzinfo))
+            self._timeset.sort()
+            self._timeset = tuple(self._timeset)
+
+    def __str__(self):
+        """
+        Output a string that would generate this RRULE if passed to rrulestr.
+        This is mostly compatible with RFC5545, except for the
+        dateutil-specific extension BYEASTER.
+        """
+
+        output = []
+        h, m, s = [None] * 3
+        if self._dtstart:
+            output.append(self._dtstart.strftime('DTSTART:%Y%m%dT%H%M%S'))
+            h, m, s = self._dtstart.timetuple()[3:6]
+
+        parts = ['FREQ=' + FREQNAMES[self._freq]]
+        if self._interval != 1:
+            parts.append('INTERVAL=' + str(self._interval))
+
+        if self._wkst:
+            parts.append('WKST=' + repr(weekday(self._wkst))[0:2])
+
+        if self._count is not None:
+            parts.append('COUNT=' + str(self._count))
+
+        if self._until:
+            parts.append(self._until.strftime('UNTIL=%Y%m%dT%H%M%S'))
+
+        if self._original_rule.get('byweekday') is not None:
+            # The str() method on weekday objects doesn't generate
+            # RFC5545-compliant strings, so we should modify that.
+            original_rule = dict(self._original_rule)
+            wday_strings = []
+            for wday in original_rule['byweekday']:
+                if wday.n:
+                    wday_strings.append('{n:+d}{wday}'.format(
+                        n=wday.n,
+                        wday=repr(wday)[0:2]))
+                else:
+                    wday_strings.append(repr(wday))
+
+            original_rule['byweekday'] = wday_strings
+        else:
+            original_rule = self._original_rule
+
+        partfmt = '{name}={vals}'
+        for name, key in [('BYSETPOS', 'bysetpos'),
+                          ('BYMONTH', 'bymonth'),
+                          ('BYMONTHDAY', 'bymonthday'),
+                          ('BYYEARDAY', 'byyearday'),
+                          ('BYWEEKNO', 'byweekno'),
+                          ('BYDAY', 'byweekday'),
+                          ('BYHOUR', 'byhour'),
+                          ('BYMINUTE', 'byminute'),
+                          ('BYSECOND', 'bysecond'),
+                          ('BYEASTER', 'byeaster')]:
+            value = original_rule.get(key)
+            if value:
+                parts.append(partfmt.format(name=name, vals=(','.join(str(v)
+                                                             for v in value))))
+
+        output.append('RRULE:' + ';'.join(parts))
+        return '\n'.join(output)
+
+    def replace(self, **kwargs):
+        """Return new rrule with same attributes except for those attributes given new
+           values by whichever keyword arguments are specified."""
+        new_kwargs = {"interval": self._interval,
+                      "count": self._count,
+                      "dtstart": self._dtstart,
+                      "freq": self._freq,
+                      "until": self._until,
+                      "wkst": self._wkst,
+                      "cache": False if self._cache is None else True }
+        new_kwargs.update(self._original_rule)
+        new_kwargs.update(kwargs)
+        return rrule(**new_kwargs)
+
+    def _iter(self):
+        year, month, day, hour, minute, second, weekday, yearday, _ = \
+            self._dtstart.timetuple()
+
+        # Some local variables to speed things up a bit
+        freq = self._freq
+        interval = self._interval
+        wkst = self._wkst
+        until = self._until
+        bymonth = self._bymonth
+        byweekno = self._byweekno
+        byyearday = self._byyearday
+        byweekday = self._byweekday
+        byeaster = self._byeaster
+        bymonthday = self._bymonthday
+        bynmonthday = self._bynmonthday
+        bysetpos = self._bysetpos
+        byhour = self._byhour
+        byminute = self._byminute
+        bysecond = self._bysecond
+
+        ii = _iterinfo(self)
+        ii.rebuild(year, month)
+
+        getdayset = {YEARLY: ii.ydayset,
+                     MONTHLY: ii.mdayset,
+                     WEEKLY: ii.wdayset,
+                     DAILY: ii.ddayset,
+                     HOURLY: ii.ddayset,
+                     MINUTELY: ii.ddayset,
+                     SECONDLY: ii.ddayset}[freq]
+
+        if freq < HOURLY:
+            timeset = self._timeset
+        else:
+            gettimeset = {HOURLY: ii.htimeset,
+                          MINUTELY: ii.mtimeset,
+                          SECONDLY: ii.stimeset}[freq]
+            if ((freq >= HOURLY and
+                 self._byhour and hour not in self._byhour) or
+                (freq >= MINUTELY and
+                 self._byminute and minute not in self._byminute) or
+                (freq >= SECONDLY and
+                 self._bysecond and second not in self._bysecond)):
+                timeset = ()
+            else:
+                timeset = gettimeset(hour, minute, second)
+
+        total = 0
+        count = self._count
+        while True:
+            # Get dayset with the right frequency
+            dayset, start, end = getdayset(year, month, day)
+
+            # Do the "hard" work ;-)
+            filtered = False
+            for i in dayset[start:end]:
+                if ((bymonth and ii.mmask[i] not in bymonth) or
+                    (byweekno and not ii.wnomask[i]) or
+                    (byweekday and ii.wdaymask[i] not in byweekday) or
+                    (ii.nwdaymask and not ii.nwdaymask[i]) or
+                    (byeaster and not ii.eastermask[i]) or
+                    ((bymonthday or bynmonthday) and
+                     ii.mdaymask[i] not in bymonthday and
+                     ii.nmdaymask[i] not in bynmonthday) or
+                    (byyearday and
+                     ((i < ii.yearlen and i+1 not in byyearday and
+                       -ii.yearlen+i not in byyearday) or
+                      (i >= ii.yearlen and i+1-ii.yearlen not in byyearday and
+                       -ii.nextyearlen+i-ii.yearlen not in byyearday)))):
+                    dayset[i] = None
+                    filtered = True
+
+            # Output results
+            if bysetpos and timeset:
+                poslist = []
+                for pos in bysetpos:
+                    if pos < 0:
+                        daypos, timepos = divmod(pos, len(timeset))
+                    else:
+                        daypos, timepos = divmod(pos-1, len(timeset))
+                    try:
+                        i = [x for x in dayset[start:end]
+                             if x is not None][daypos]
+                        time = timeset[timepos]
+                    except IndexError:
+                        pass
+                    else:
+                        date = datetime.date.fromordinal(ii.yearordinal+i)
+                        res = datetime.datetime.combine(date, time)
+                        if res not in poslist:
+                            poslist.append(res)
+                poslist.sort()
+                for res in poslist:
+                    if until and res > until:
+                        self._len = total
+                        return
+                    elif res >= self._dtstart:
+                        if count is not None:
+                            count -= 1
+                            if count < 0:
+                                self._len = total
+                                return
+                        total += 1
+                        yield res
+            else:
+                for i in dayset[start:end]:
+                    if i is not None:
+                        date = datetime.date.fromordinal(ii.yearordinal + i)
+                        for time in timeset:
+                            res = datetime.datetime.combine(date, time)
+                            if until and res > until:
+                                self._len = total
+                                return
+                            elif res >= self._dtstart:
+                                if count is not None:
+                                    count -= 1
+                                    if count < 0:
+                                        self._len = total
+                                        return
+
+                                total += 1
+                                yield res
+
+            # Handle frequency and interval
+            fixday = False
+            if freq == YEARLY:
+                year += interval
+                if year > datetime.MAXYEAR:
+                    self._len = total
+                    return
+                ii.rebuild(year, month)
+            elif freq == MONTHLY:
+                month += interval
+                if month > 12:
+                    div, mod = divmod(month, 12)
+                    month = mod
+                    year += div
+                    if month == 0:
+                        month = 12
+                        year -= 1
+                    if year > datetime.MAXYEAR:
+                        self._len = total
+                        return
+                ii.rebuild(year, month)
+            elif freq == WEEKLY:
+                if wkst > weekday:
+                    day += -(weekday+1+(6-wkst))+self._interval*7
+                else:
+                    day += -(weekday-wkst)+self._interval*7
+                weekday = wkst
+                fixday = True
+            elif freq == DAILY:
+                day += interval
+                fixday = True
+            elif freq == HOURLY:
+                if filtered:
+                    # Jump to one iteration before next day
+                    hour += ((23-hour)//interval)*interval
+
+                if byhour:
+                    ndays, hour = self.__mod_distance(value=hour,
+                                                      byxxx=self._byhour,
+                                                      base=24)
+                else:
+                    ndays, hour = divmod(hour+interval, 24)
+
+                if ndays:
+                    day += ndays
+                    fixday = True
+
+                timeset = gettimeset(hour, minute, second)
+            elif freq == MINUTELY:
+                if filtered:
+                    # Jump to one iteration before next day
+                    minute += ((1439-(hour*60+minute))//interval)*interval
+
+                valid = False
+                rep_rate = (24*60)
+                for j in range(rep_rate // gcd(interval, rep_rate)):
+                    if byminute:
+                        nhours, minute = \
+                            self.__mod_distance(value=minute,
+                                                byxxx=self._byminute,
+                                                base=60)
+                    else:
+                        nhours, minute = divmod(minute+interval, 60)
+
+                    div, hour = divmod(hour+nhours, 24)
+                    if div:
+                        day += div
+                        fixday = True
+                        filtered = False
+
+                    if not byhour or hour in byhour:
+                        valid = True
+                        break
+
+                if not valid:
+                    raise ValueError('Invalid combination of interval and ' +
+                                     'byhour resulting in empty rule.')
+
+                timeset = gettimeset(hour, minute, second)
+            elif freq == SECONDLY:
+                if filtered:
+                    # Jump to one iteration before next day
+                    second += (((86399 - (hour * 3600 + minute * 60 + second))
+                                // interval) * interval)
+
+                rep_rate = (24 * 3600)
+                valid = False
+                for j in range(0, rep_rate // gcd(interval, rep_rate)):
+                    if bysecond:
+                        nminutes, second = \
+                            self.__mod_distance(value=second,
+                                                byxxx=self._bysecond,
+                                                base=60)
+                    else:
+                        nminutes, second = divmod(second+interval, 60)
+
+                    div, minute = divmod(minute+nminutes, 60)
+                    if div:
+                        hour += div
+                        div, hour = divmod(hour, 24)
+                        if div:
+                            day += div
+                            fixday = True
+
+                    if ((not byhour or hour in byhour) and
+                            (not byminute or minute in byminute) and
+                            (not bysecond or second in bysecond)):
+                        valid = True
+                        break
+
+                if not valid:
+                    raise ValueError('Invalid combination of interval, ' +
+                                     'byhour and byminute resulting in empty' +
+                                     ' rule.')
+
+                timeset = gettimeset(hour, minute, second)
+
+            if fixday and day > 28:
+                daysinmonth = calendar.monthrange(year, month)[1]
+                if day > daysinmonth:
+                    while day > daysinmonth:
+                        day -= daysinmonth
+                        month += 1
+                        if month == 13:
+                            month = 1
+                            year += 1
+                            if year > datetime.MAXYEAR:
+                                self._len = total
+                                return
+                        daysinmonth = calendar.monthrange(year, month)[1]
+                    ii.rebuild(year, month)
+
+    def __construct_byset(self, start, byxxx, base):
+        """
+        If a `BYXXX` sequence is passed to the constructor at the same level as
+        `FREQ` (e.g. `FREQ=HOURLY,BYHOUR={2,4,7},INTERVAL=3`), there are some
+        specifications which cannot be reached given some starting conditions.
+
+        This occurs whenever the interval is not coprime with the base of a
+        given unit and the difference between the starting position and the
+        ending position is not coprime with the greatest common denominator
+        between the interval and the base. For example, with a FREQ of hourly
+        starting at 17:00 and an interval of 4, the only valid values for
+        BYHOUR would be {21, 1, 5, 9, 13, 17}, because 4 and 24 are not
+        coprime.
+
+        :param start:
+            Specifies the starting position.
+        :param byxxx:
+            An iterable containing the list of allowed values.
+        :param base:
+            The largest allowable value for the specified frequency (e.g.
+            24 hours, 60 minutes).
+
+        This does not preserve the type of the iterable, returning a set, since
+        the values should be unique and the order is irrelevant, this will
+        speed up later lookups.
+
+        In the event of an empty set, raises a :exception:`ValueError`, as this
+        results in an empty rrule.
+        """
+
+        cset = set()
+
+        # Support a single byxxx value.
+        if isinstance(byxxx, integer_types):
+            byxxx = (byxxx, )
+
+        for num in byxxx:
+            i_gcd = gcd(self._interval, base)
+            # Use divmod rather than % because we need to wrap negative nums.
+            if i_gcd == 1 or divmod(num - start, i_gcd)[1] == 0:
+                cset.add(num)
+
+        if len(cset) == 0:
+            raise ValueError("Invalid rrule byxxx generates an empty set.")
+
+        return cset
+
+    def __mod_distance(self, value, byxxx, base):
+        """
+        Calculates the next value in a sequence where the `FREQ` parameter is
+        specified along with a `BYXXX` parameter at the same "level"
+        (e.g. `HOURLY` specified with `BYHOUR`).
+
+        :param value:
+            The old value of the component.
+        :param byxxx:
+            The `BYXXX` set, which should have been generated by
+            `rrule._construct_byset`, or something else which checks that a
+            valid rule is present.
+        :param base:
+            The largest allowable value for the specified frequency (e.g.
+            24 hours, 60 minutes).
+
+        If a valid value is not found after `base` iterations (the maximum
+        number before the sequence would start to repeat), this raises a
+        :exception:`ValueError`, as no valid values were found.
+
+        This returns a tuple of `divmod(n*interval, base)`, where `n` is the
+        smallest number of `interval` repetitions until the next specified
+        value in `byxxx` is found.
+        """
+        accumulator = 0
+        for ii in range(1, base + 1):
+            # Using divmod() over % to account for negative intervals
+            div, value = divmod(value + self._interval, base)
+            accumulator += div
+            if value in byxxx:
+                return (accumulator, value)
+
+
+class _iterinfo(object):
+    __slots__ = ["rrule", "lastyear", "lastmonth",
+                 "yearlen", "nextyearlen", "yearordinal", "yearweekday",
+                 "mmask", "mrange", "mdaymask", "nmdaymask",
+                 "wdaymask", "wnomask", "nwdaymask", "eastermask"]
+
+    def __init__(self, rrule):
+        for attr in self.__slots__:
+            setattr(self, attr, None)
+        self.rrule = rrule
+
+    def rebuild(self, year, month):
+        # Every mask is 7 days longer to handle cross-year weekly periods.
+        rr = self.rrule
+        if year != self.lastyear:
+            self.yearlen = 365 + calendar.isleap(year)
+            self.nextyearlen = 365 + calendar.isleap(year + 1)
+            firstyday = datetime.date(year, 1, 1)
+            self.yearordinal = firstyday.toordinal()
+            self.yearweekday = firstyday.weekday()
+
+            wday = datetime.date(year, 1, 1).weekday()
+            if self.yearlen == 365:
+                self.mmask = M365MASK
+                self.mdaymask = MDAY365MASK
+                self.nmdaymask = NMDAY365MASK
+                self.wdaymask = WDAYMASK[wday:]
+                self.mrange = M365RANGE
+            else:
+                self.mmask = M366MASK
+                self.mdaymask = MDAY366MASK
+                self.nmdaymask = NMDAY366MASK
+                self.wdaymask = WDAYMASK[wday:]
+                self.mrange = M366RANGE
+
+            if not rr._byweekno:
+                self.wnomask = None
+            else:
+                self.wnomask = [0]*(self.yearlen+7)
+                # no1wkst = firstwkst = self.wdaymask.index(rr._wkst)
+                no1wkst = firstwkst = (7-self.yearweekday+rr._wkst) % 7
+                if no1wkst >= 4:
+                    no1wkst = 0
+                    # Number of days in the year, plus the days we got
+                    # from last year.
+                    wyearlen = self.yearlen+(self.yearweekday-rr._wkst) % 7
+                else:
+                    # Number of days in the year, minus the days we
+                    # left in last year.
+                    wyearlen = self.yearlen-no1wkst
+                div, mod = divmod(wyearlen, 7)
+                numweeks = div+mod//4
+                for n in rr._byweekno:
+                    if n < 0:
+                        n += numweeks+1
+                    if not (0 < n <= numweeks):
+                        continue
+                    if n > 1:
+                        i = no1wkst+(n-1)*7
+                        if no1wkst != firstwkst:
+                            i -= 7-firstwkst
+                    else:
+                        i = no1wkst
+                    for j in range(7):
+                        self.wnomask[i] = 1
+                        i += 1
+                        if self.wdaymask[i] == rr._wkst:
+                            break
+                if 1 in rr._byweekno:
+                    # Check week number 1 of next year as well
+                    # TODO: Check -numweeks for next year.
+                    i = no1wkst+numweeks*7
+                    if no1wkst != firstwkst:
+                        i -= 7-firstwkst
+                    if i < self.yearlen:
+                        # If week starts in next year, we
+                        # don't care about it.
+                        for j in range(7):
+                            self.wnomask[i] = 1
+                            i += 1
+                            if self.wdaymask[i] == rr._wkst:
+                                break
+                if no1wkst:
+                    # Check last week number of last year as
+                    # well. If no1wkst is 0, either the year
+                    # started on week start, or week number 1
+                    # got days from last year, so there are no
+                    # days from last year's last week number in
+                    # this year.
+                    if -1 not in rr._byweekno:
+                        lyearweekday = datetime.date(year-1, 1, 1).weekday()
+                        lno1wkst = (7-lyearweekday+rr._wkst) % 7
+                        lyearlen = 365+calendar.isleap(year-1)
+                        if lno1wkst >= 4:
+                            lno1wkst = 0
+                            lnumweeks = 52+(lyearlen +
+                                            (lyearweekday-rr._wkst) % 7) % 7//4
+                        else:
+                            lnumweeks = 52+(self.yearlen-no1wkst) % 7//4
+                    else:
+                        lnumweeks = -1
+                    if lnumweeks in rr._byweekno:
+                        for i in range(no1wkst):
+                            self.wnomask[i] = 1
+
+        if (rr._bynweekday and (month != self.lastmonth or
+                                year != self.lastyear)):
+            ranges = []
+            if rr._freq == YEARLY:
+                if rr._bymonth:
+                    for month in rr._bymonth:
+                        ranges.append(self.mrange[month-1:month+1])
+                else:
+                    ranges = [(0, self.yearlen)]
+            elif rr._freq == MONTHLY:
+                ranges = [self.mrange[month-1:month+1]]
+            if ranges:
+                # Weekly frequency won't get here, so we may not
+                # care about cross-year weekly periods.
+                self.nwdaymask = [0]*self.yearlen
+                for first, last in ranges:
+                    last -= 1
+                    for wday, n in rr._bynweekday:
+                        if n < 0:
+                            i = last+(n+1)*7
+                            i -= (self.wdaymask[i]-wday) % 7
+                        else:
+                            i = first+(n-1)*7
+                            i += (7-self.wdaymask[i]+wday) % 7
+                        if first <= i <= last:
+                            self.nwdaymask[i] = 1
+
+        if rr._byeaster:
+            self.eastermask = [0]*(self.yearlen+7)
+            eyday = easter.easter(year).toordinal()-self.yearordinal
+            for offset in rr._byeaster:
+                self.eastermask[eyday+offset] = 1
+
+        self.lastyear = year
+        self.lastmonth = month
+
+    def ydayset(self, year, month, day):
+        return list(range(self.yearlen)), 0, self.yearlen
+
+    def mdayset(self, year, month, day):
+        dset = [None]*self.yearlen
+        start, end = self.mrange[month-1:month+1]
+        for i in range(start, end):
+            dset[i] = i
+        return dset, start, end
+
+    def wdayset(self, year, month, day):
+        # We need to handle cross-year weeks here.
+        dset = [None]*(self.yearlen+7)
+        i = datetime.date(year, month, day).toordinal()-self.yearordinal
+        start = i
+        for j in range(7):
+            dset[i] = i
+            i += 1
+            # if (not (0 <= i < self.yearlen) or
+            #    self.wdaymask[i] == self.rrule._wkst):
+            # This will cross the year boundary, if necessary.
+            if self.wdaymask[i] == self.rrule._wkst:
+                break
+        return dset, start, i
+
+    def ddayset(self, year, month, day):
+        dset = [None] * self.yearlen
+        i = datetime.date(year, month, day).toordinal() - self.yearordinal
+        dset[i] = i
+        return dset, i, i + 1
+
+    def htimeset(self, hour, minute, second):
+        tset = []
+        rr = self.rrule
+        for minute in rr._byminute:
+            for second in rr._bysecond:
+                tset.append(datetime.time(hour, minute, second,
+                                          tzinfo=rr._tzinfo))
+        tset.sort()
+        return tset
+
+    def mtimeset(self, hour, minute, second):
+        tset = []
+        rr = self.rrule
+        for second in rr._bysecond:
+            tset.append(datetime.time(hour, minute, second, tzinfo=rr._tzinfo))
+        tset.sort()
+        return tset
+
+    def stimeset(self, hour, minute, second):
+        return (datetime.time(hour, minute, second,
+                tzinfo=self.rrule._tzinfo),)
+
+
+class rruleset(rrulebase):
+    """ The rruleset type allows more complex recurrence setups, mixing
+    multiple rules, dates, exclusion rules, and exclusion dates. The type
+    constructor takes the following keyword arguments:
+
+    :param cache: If True, caching of results will be enabled, improving
+                  performance of multiple queries considerably. """
+
+    class _genitem(object):
+        def __init__(self, genlist, gen):
+            try:
+                self.dt = advance_iterator(gen)
+                genlist.append(self)
+            except StopIteration:
+                pass
+            self.genlist = genlist
+            self.gen = gen
+
+        def __next__(self):
+            try:
+                self.dt = advance_iterator(self.gen)
+            except StopIteration:
+                if self.genlist[0] is self:
+                    heapq.heappop(self.genlist)
+                else:
+                    self.genlist.remove(self)
+                    heapq.heapify(self.genlist)
+
+        next = __next__
+
+        def __lt__(self, other):
+            return self.dt < other.dt
+
+        def __gt__(self, other):
+            return self.dt > other.dt
+
+        def __eq__(self, other):
+            return self.dt == other.dt
+
+        def __ne__(self, other):
+            return self.dt != other.dt
+
+    def __init__(self, cache=False):
+        super(rruleset, self).__init__(cache)
+        self._rrule = []
+        self._rdate = []
+        self._exrule = []
+        self._exdate = []
+
+    @_invalidates_cache
+    def rrule(self, rrule):
+        """ Include the given :py:class:`rrule` instance in the recurrence set
+            generation. """
+        self._rrule.append(rrule)
+
+    @_invalidates_cache
+    def rdate(self, rdate):
+        """ Include the given :py:class:`datetime` instance in the recurrence
+            set generation. """
+        self._rdate.append(rdate)
+
+    @_invalidates_cache
+    def exrule(self, exrule):
+        """ Include the given rrule instance in the recurrence set exclusion
+            list. Dates which are part of the given recurrence rules will not
+            be generated, even if some inclusive rrule or rdate matches them.
+        """
+        self._exrule.append(exrule)
+
+    @_invalidates_cache
+    def exdate(self, exdate):
+        """ Include the given datetime instance in the recurrence set
+            exclusion list. Dates included that way will not be generated,
+            even if some inclusive rrule or rdate matches them. """
+        self._exdate.append(exdate)
+
+    def _iter(self):
+        rlist = []
+        self._rdate.sort()
+        self._genitem(rlist, iter(self._rdate))
+        for gen in [iter(x) for x in self._rrule]:
+            self._genitem(rlist, gen)
+        exlist = []
+        self._exdate.sort()
+        self._genitem(exlist, iter(self._exdate))
+        for gen in [iter(x) for x in self._exrule]:
+            self._genitem(exlist, gen)
+        lastdt = None
+        total = 0
+        heapq.heapify(rlist)
+        heapq.heapify(exlist)
+        while rlist:
+            ritem = rlist[0]
+            if not lastdt or lastdt != ritem.dt:
+                while exlist and exlist[0] < ritem:
+                    exitem = exlist[0]
+                    advance_iterator(exitem)
+                    if exlist and exlist[0] is exitem:
+                        heapq.heapreplace(exlist, exitem)
+                if not exlist or ritem != exlist[0]:
+                    total += 1
+                    yield ritem.dt
+                lastdt = ritem.dt
+            advance_iterator(ritem)
+            if rlist and rlist[0] is ritem:
+                heapq.heapreplace(rlist, ritem)
+        self._len = total
+
+
+
+
+class _rrulestr(object):
+    """ Parses a string representation of a recurrence rule or set of
+    recurrence rules.
+
+    :param s:
+        Required, a string defining one or more recurrence rules.
+
+    :param dtstart:
+        If given, used as the default recurrence start if not specified in the
+        rule string.
+
+    :param cache:
+        If set ``True`` caching of results will be enabled, improving
+        performance of multiple queries considerably.
+
+    :param unfold:
+        If set ``True`` indicates that a rule string is split over more
+        than one line and should be joined before processing.
+
+    :param forceset:
+        If set ``True`` forces a :class:`dateutil.rrule.rruleset` to
+        be returned.
+
+    :param compatible:
+        If set ``True`` forces ``unfold`` and ``forceset`` to be ``True``.
+
+    :param ignoretz:
+        If set ``True``, time zones in parsed strings are ignored and a naive
+        :class:`datetime.datetime` object is returned.
+
+    :param tzids:
+        If given, a callable or mapping used to retrieve a
+        :class:`datetime.tzinfo` from a string representation.
+        Defaults to :func:`dateutil.tz.gettz`.
+
+    :param tzinfos:
+        Additional time zone names / aliases which may be present in a string
+        representation.  See :func:`dateutil.parser.parse` for more
+        information.
+
+    :return:
+        Returns a :class:`dateutil.rrule.rruleset` or
+        :class:`dateutil.rrule.rrule`
+    """
+
+    _freq_map = {"YEARLY": YEARLY,
+                 "MONTHLY": MONTHLY,
+                 "WEEKLY": WEEKLY,
+                 "DAILY": DAILY,
+                 "HOURLY": HOURLY,
+                 "MINUTELY": MINUTELY,
+                 "SECONDLY": SECONDLY}
+
+    _weekday_map = {"MO": 0, "TU": 1, "WE": 2, "TH": 3,
+                    "FR": 4, "SA": 5, "SU": 6}
+
+    def _handle_int(self, rrkwargs, name, value, **kwargs):
+        rrkwargs[name.lower()] = int(value)
+
+    def _handle_int_list(self, rrkwargs, name, value, **kwargs):
+        rrkwargs[name.lower()] = [int(x) for x in value.split(',')]
+
+    _handle_INTERVAL = _handle_int
+    _handle_COUNT = _handle_int
+    _handle_BYSETPOS = _handle_int_list
+    _handle_BYMONTH = _handle_int_list
+    _handle_BYMONTHDAY = _handle_int_list
+    _handle_BYYEARDAY = _handle_int_list
+    _handle_BYEASTER = _handle_int_list
+    _handle_BYWEEKNO = _handle_int_list
+    _handle_BYHOUR = _handle_int_list
+    _handle_BYMINUTE = _handle_int_list
+    _handle_BYSECOND = _handle_int_list
+
+    def _handle_FREQ(self, rrkwargs, name, value, **kwargs):
+        rrkwargs["freq"] = self._freq_map[value]
+
+    def _handle_UNTIL(self, rrkwargs, name, value, **kwargs):
+        global parser
+        if not parser:
+            from dateutil import parser
+        try:
+            rrkwargs["until"] = parser.parse(value,
+                                             ignoretz=kwargs.get("ignoretz"),
+                                             tzinfos=kwargs.get("tzinfos"))
+        except ValueError:
+            raise ValueError("invalid until date")
+
+    def _handle_WKST(self, rrkwargs, name, value, **kwargs):
+        rrkwargs["wkst"] = self._weekday_map[value]
+
+    def _handle_BYWEEKDAY(self, rrkwargs, name, value, **kwargs):
+        """
+        Two ways to specify this: +1MO or MO(+1)
+        """
+        l = []
+        for wday in value.split(','):
+            if '(' in wday:
+                # If it's of the form TH(+1), etc.
+                splt = wday.split('(')
+                w = splt[0]
+                n = int(splt[1][:-1])
+            elif len(wday):
+                # If it's of the form +1MO
+                for i in range(len(wday)):
+                    if wday[i] not in '+-0123456789':
+                        break
+                n = wday[:i] or None
+                w = wday[i:]
+                if n:
+                    n = int(n)
+            else:
+                raise ValueError("Invalid (empty) BYDAY specification.")
+
+            l.append(weekdays[self._weekday_map[w]](n))
+        rrkwargs["byweekday"] = l
+
+    _handle_BYDAY = _handle_BYWEEKDAY
+
+    def _parse_rfc_rrule(self, line,
+                         dtstart=None,
+                         cache=False,
+                         ignoretz=False,
+                         tzinfos=None):
+        if line.find(':') != -1:
+            name, value = line.split(':')
+            if name != "RRULE":
+                raise ValueError("unknown parameter name")
+        else:
+            value = line
+        rrkwargs = {}
+        for pair in value.split(';'):
+            name, value = pair.split('=')
+            name = name.upper()
+            value = value.upper()
+            try:
+                getattr(self, "_handle_"+name)(rrkwargs, name, value,
+                                               ignoretz=ignoretz,
+                                               tzinfos=tzinfos)
+            except AttributeError:
+                raise ValueError("unknown parameter '%s'" % name)
+            except (KeyError, ValueError):
+                raise ValueError("invalid '%s': %s" % (name, value))
+        return rrule(dtstart=dtstart, cache=cache, **rrkwargs)
+
+    def _parse_date_value(self, date_value, parms, rule_tzids,
+                          ignoretz, tzids, tzinfos):
+        global parser
+        if not parser:
+            from dateutil import parser
+
+        datevals = []
+        value_found = False
+        TZID = None
+
+        for parm in parms:
+            if parm.startswith("TZID="):
+                try:
+                    tzkey = rule_tzids[parm.split('TZID=')[-1]]
+                except KeyError:
+                    continue
+                if tzids is None:
+                    from . import tz
+                    tzlookup = tz.gettz
+                elif callable(tzids):
+                    tzlookup = tzids
+                else:
+                    tzlookup = getattr(tzids, 'get', None)
+                    if tzlookup is None:
+                        msg = ('tzids must be a callable, mapping, or None, '
+                               'not %s' % tzids)
+                        raise ValueError(msg)
+
+                TZID = tzlookup(tzkey)
+                continue
+
+            # RFC 5445 3.8.2.4: The VALUE parameter is optional, but may be found
+            # only once.
+            if parm not in {"VALUE=DATE-TIME", "VALUE=DATE"}:
+                raise ValueError("unsupported parm: " + parm)
+            else:
+                if value_found:
+                    msg = ("Duplicate value parameter found in: " + parm)
+                    raise ValueError(msg)
+                value_found = True
+
+        for datestr in date_value.split(','):
+            date = parser.parse(datestr, ignoretz=ignoretz, tzinfos=tzinfos)
+            if TZID is not None:
+                if date.tzinfo is None:
+                    date = date.replace(tzinfo=TZID)
+                else:
+                    raise ValueError('DTSTART/EXDATE specifies multiple timezone')
+            datevals.append(date)
+
+        return datevals
+
+    def _parse_rfc(self, s,
+                   dtstart=None,
+                   cache=False,
+                   unfold=False,
+                   forceset=False,
+                   compatible=False,
+                   ignoretz=False,
+                   tzids=None,
+                   tzinfos=None):
+        global parser
+        if compatible:
+            forceset = True
+            unfold = True
+
+        TZID_NAMES = dict(map(
+            lambda x: (x.upper(), x),
+            re.findall('TZID=(?P<name>[^:]+):', s)
+        ))
+        s = s.upper()
+        if not s.strip():
+            raise ValueError("empty string")
+        if unfold:
+            lines = s.splitlines()
+            i = 0
+            while i < len(lines):
+                line = lines[i].rstrip()
+                if not line:
+                    del lines[i]
+                elif i > 0 and line[0] == " ":
+                    lines[i-1] += line[1:]
+                    del lines[i]
+                else:
+                    i += 1
+        else:
+            lines = s.split()
+        if (not forceset and len(lines) == 1 and (s.find(':') == -1 or
+                                                  s.startswith('RRULE:'))):
+            return self._parse_rfc_rrule(lines[0], cache=cache,
+                                         dtstart=dtstart, ignoretz=ignoretz,
+                                         tzinfos=tzinfos)
+        else:
+            rrulevals = []
+            rdatevals = []
+            exrulevals = []
+            exdatevals = []
+            for line in lines:
+                if not line:
+                    continue
+                if line.find(':') == -1:
+                    name = "RRULE"
+                    value = line
+                else:
+                    name, value = line.split(':', 1)
+                parms = name.split(';')
+                if not parms:
+                    raise ValueError("empty property name")
+                name = parms[0]
+                parms = parms[1:]
+                if name == "RRULE":
+                    for parm in parms:
+                        raise ValueError("unsupported RRULE parm: "+parm)
+                    rrulevals.append(value)
+                elif name == "RDATE":
+                    for parm in parms:
+                        if parm != "VALUE=DATE-TIME":
+                            raise ValueError("unsupported RDATE parm: "+parm)
+                    rdatevals.append(value)
+                elif name == "EXRULE":
+                    for parm in parms:
+                        raise ValueError("unsupported EXRULE parm: "+parm)
+                    exrulevals.append(value)
+                elif name == "EXDATE":
+                    exdatevals.extend(
+                        self._parse_date_value(value, parms,
+                                               TZID_NAMES, ignoretz,
+                                               tzids, tzinfos)
+                    )
+                elif name == "DTSTART":
+                    dtvals = self._parse_date_value(value, parms, TZID_NAMES,
+                                                    ignoretz, tzids, tzinfos)
+                    if len(dtvals) != 1:
+                        raise ValueError("Multiple DTSTART values specified:" +
+                                         value)
+                    dtstart = dtvals[0]
+                else:
+                    raise ValueError("unsupported property: "+name)
+            if (forceset or len(rrulevals) > 1 or rdatevals
+                    or exrulevals or exdatevals):
+                if not parser and (rdatevals or exdatevals):
+                    from dateutil import parser
+                rset = rruleset(cache=cache)
+                for value in rrulevals:
+                    rset.rrule(self._parse_rfc_rrule(value, dtstart=dtstart,
+                                                     ignoretz=ignoretz,
+                                                     tzinfos=tzinfos))
+                for value in rdatevals:
+                    for datestr in value.split(','):
+                        rset.rdate(parser.parse(datestr,
+                                                ignoretz=ignoretz,
+                                                tzinfos=tzinfos))
+                for value in exrulevals:
+                    rset.exrule(self._parse_rfc_rrule(value, dtstart=dtstart,
+                                                      ignoretz=ignoretz,
+                                                      tzinfos=tzinfos))
+                for value in exdatevals:
+                    rset.exdate(value)
+                if compatible and dtstart:
+                    rset.rdate(dtstart)
+                return rset
+            else:
+                return self._parse_rfc_rrule(rrulevals[0],
+                                             dtstart=dtstart,
+                                             cache=cache,
+                                             ignoretz=ignoretz,
+                                             tzinfos=tzinfos)
+
+    def __call__(self, s, **kwargs):
+        return self._parse_rfc(s, **kwargs)
+
+
+rrulestr = _rrulestr()
+
+# vim:ts=4:sw=4:et
Index: venv/Lib/site-packages/dateutil/tzwin.py
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/venv/Lib/site-packages/dateutil/tzwin.py b/venv/Lib/site-packages/dateutil/tzwin.py
new file mode 100644
--- /dev/null	(date 1616406051829)
+++ b/venv/Lib/site-packages/dateutil/tzwin.py	(date 1616406051829)
@@ -0,0 +1,2 @@
+# tzwin has moved to dateutil.tz.win
+from .tz.win import *
Index: venv/Lib/site-packages/dateutil/utils.py
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/venv/Lib/site-packages/dateutil/utils.py b/venv/Lib/site-packages/dateutil/utils.py
new file mode 100644
--- /dev/null	(date 1616406051829)
+++ b/venv/Lib/site-packages/dateutil/utils.py	(date 1616406051829)
@@ -0,0 +1,71 @@
+# -*- coding: utf-8 -*-
+"""
+This module offers general convenience and utility functions for dealing with
+datetimes.
+
+.. versionadded:: 2.7.0
+"""
+from __future__ import unicode_literals
+
+from datetime import datetime, time
+
+
+def today(tzinfo=None):
+    """
+    Returns a :py:class:`datetime` representing the current day at midnight
+
+    :param tzinfo:
+        The time zone to attach (also used to determine the current day).
+
+    :return:
+        A :py:class:`datetime.datetime` object representing the current day
+        at midnight.
+    """
+
+    dt = datetime.now(tzinfo)
+    return datetime.combine(dt.date(), time(0, tzinfo=tzinfo))
+
+
+def default_tzinfo(dt, tzinfo):
+    """
+    Sets the ``tzinfo`` parameter on naive datetimes only
+
+    This is useful for example when you are provided a datetime that may have
+    either an implicit or explicit time zone, such as when parsing a time zone
+    string.
+
+    .. doctest::
+
+        >>> from dateutil.tz import tzoffset
+        >>> from dateutil.parser import parse
+        >>> from dateutil.utils import default_tzinfo
+        >>> dflt_tz = tzoffset("EST", -18000)
+        >>> print(default_tzinfo(parse('2014-01-01 12:30 UTC'), dflt_tz))
+        2014-01-01 12:30:00+00:00
+        >>> print(default_tzinfo(parse('2014-01-01 12:30'), dflt_tz))
+        2014-01-01 12:30:00-05:00
+
+    :param dt:
+        The datetime on which to replace the time zone
+
+    :param tzinfo:
+        The :py:class:`datetime.tzinfo` subclass instance to assign to
+        ``dt`` if (and only if) it is naive.
+
+    :return:
+        Returns an aware :py:class:`datetime.datetime`.
+    """
+    if dt.tzinfo is not None:
+        return dt
+    else:
+        return dt.replace(tzinfo=tzinfo)
+
+
+def within_delta(dt1, dt2, delta):
+    """
+    Useful for comparing two datetimes that may a negilible difference
+    to be considered equal.
+    """
+    delta = abs(delta)
+    difference = dt1 - dt2
+    return -delta <= difference <= delta
Index: venv/Lib/site-packages/dateutil/_common.py
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/venv/Lib/site-packages/dateutil/_common.py b/venv/Lib/site-packages/dateutil/_common.py
new file mode 100644
--- /dev/null	(date 1616406051829)
+++ b/venv/Lib/site-packages/dateutil/_common.py	(date 1616406051829)
@@ -0,0 +1,43 @@
+"""
+Common code used in multiple modules.
+"""
+
+
+class weekday(object):
+    __slots__ = ["weekday", "n"]
+
+    def __init__(self, weekday, n=None):
+        self.weekday = weekday
+        self.n = n
+
+    def __call__(self, n):
+        if n == self.n:
+            return self
+        else:
+            return self.__class__(self.weekday, n)
+
+    def __eq__(self, other):
+        try:
+            if self.weekday != other.weekday or self.n != other.n:
+                return False
+        except AttributeError:
+            return False
+        return True
+
+    def __hash__(self):
+        return hash((
+          self.weekday,
+          self.n,
+        ))
+
+    def __ne__(self, other):
+        return not (self == other)
+
+    def __repr__(self):
+        s = ("MO", "TU", "WE", "TH", "FR", "SA", "SU")[self.weekday]
+        if not self.n:
+            return s
+        else:
+            return "%s(%+d)" % (s, self.n)
+
+# vim:ts=4:sw=4:et
Index: venv/Lib/site-packages/dateutil/_version.py
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/venv/Lib/site-packages/dateutil/_version.py b/venv/Lib/site-packages/dateutil/_version.py
new file mode 100644
--- /dev/null	(date 1616406051829)
+++ b/venv/Lib/site-packages/dateutil/_version.py	(date 1616406051829)
@@ -0,0 +1,4 @@
+# coding: utf-8
+# file generated by setuptools_scm
+# don't change, don't track in version control
+version = '2.8.1'
Index: venv/Lib/site-packages/dateutil/__init__.py
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/venv/Lib/site-packages/dateutil/__init__.py b/venv/Lib/site-packages/dateutil/__init__.py
new file mode 100644
--- /dev/null	(date 1616406051829)
+++ b/venv/Lib/site-packages/dateutil/__init__.py	(date 1616406051829)
@@ -0,0 +1,8 @@
+# -*- coding: utf-8 -*-
+try:
+    from ._version import version as __version__
+except ImportError:
+    __version__ = 'unknown'
+
+__all__ = ['easter', 'parser', 'relativedelta', 'rrule', 'tz',
+           'utils', 'zoneinfo']
Index: latest/Lib/site-packages/psycopg2-2.8.6.dist-info/INSTALLER
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/latest/Lib/site-packages/psycopg2-2.8.6.dist-info/INSTALLER b/latest/Lib/site-packages/psycopg2-2.8.6.dist-info/INSTALLER
new file mode 100644
--- /dev/null	(date 1616409347750)
+++ b/latest/Lib/site-packages/psycopg2-2.8.6.dist-info/INSTALLER	(date 1616409347750)
@@ -0,0 +1,1 @@
+pip
Index: venv/Lib/site-packages/dateutil/tz/tz.py
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/venv/Lib/site-packages/dateutil/tz/tz.py b/venv/Lib/site-packages/dateutil/tz/tz.py
new file mode 100644
--- /dev/null	(date 1616406051845)
+++ b/venv/Lib/site-packages/dateutil/tz/tz.py	(date 1616406051845)
@@ -0,0 +1,1849 @@
+# -*- coding: utf-8 -*-
+"""
+This module offers timezone implementations subclassing the abstract
+:py:class:`datetime.tzinfo` type. There are classes to handle tzfile format
+files (usually are in :file:`/etc/localtime`, :file:`/usr/share/zoneinfo`,
+etc), TZ environment string (in all known formats), given ranges (with help
+from relative deltas), local machine timezone, fixed offset timezone, and UTC
+timezone.
+"""
+import datetime
+import struct
+import time
+import sys
+import os
+import bisect
+import weakref
+from collections import OrderedDict
+
+import six
+from six import string_types
+from six.moves import _thread
+from ._common import tzname_in_python2, _tzinfo
+from ._common import tzrangebase, enfold
+from ._common import _validate_fromutc_inputs
+
+from ._factories import _TzSingleton, _TzOffsetFactory
+from ._factories import _TzStrFactory
+try:
+    from .win import tzwin, tzwinlocal
+except ImportError:
+    tzwin = tzwinlocal = None
+
+# For warning about rounding tzinfo
+from warnings import warn
+
+ZERO = datetime.timedelta(0)
+EPOCH = datetime.datetime.utcfromtimestamp(0)
+EPOCHORDINAL = EPOCH.toordinal()
+
+
+@six.add_metaclass(_TzSingleton)
+class tzutc(datetime.tzinfo):
+    """
+    This is a tzinfo object that represents the UTC time zone.
+
+    **Examples:**
+
+    .. doctest::
+
+        >>> from datetime import *
+        >>> from dateutil.tz import *
+
+        >>> datetime.now()
+        datetime.datetime(2003, 9, 27, 9, 40, 1, 521290)
+
+        >>> datetime.now(tzutc())
+        datetime.datetime(2003, 9, 27, 12, 40, 12, 156379, tzinfo=tzutc())
+
+        >>> datetime.now(tzutc()).tzname()
+        'UTC'
+
+    .. versionchanged:: 2.7.0
+        ``tzutc()`` is now a singleton, so the result of ``tzutc()`` will
+        always return the same object.
+
+        .. doctest::
+
+            >>> from dateutil.tz import tzutc, UTC
+            >>> tzutc() is tzutc()
+            True
+            >>> tzutc() is UTC
+            True
+    """
+    def utcoffset(self, dt):
+        return ZERO
+
+    def dst(self, dt):
+        return ZERO
+
+    @tzname_in_python2
+    def tzname(self, dt):
+        return "UTC"
+
+    def is_ambiguous(self, dt):
+        """
+        Whether or not the "wall time" of a given datetime is ambiguous in this
+        zone.
+
+        :param dt:
+            A :py:class:`datetime.datetime`, naive or time zone aware.
+
+
+        :return:
+            Returns ``True`` if ambiguous, ``False`` otherwise.
+
+        .. versionadded:: 2.6.0
+        """
+        return False
+
+    @_validate_fromutc_inputs
+    def fromutc(self, dt):
+        """
+        Fast track version of fromutc() returns the original ``dt`` object for
+        any valid :py:class:`datetime.datetime` object.
+        """
+        return dt
+
+    def __eq__(self, other):
+        if not isinstance(other, (tzutc, tzoffset)):
+            return NotImplemented
+
+        return (isinstance(other, tzutc) or
+                (isinstance(other, tzoffset) and other._offset == ZERO))
+
+    __hash__ = None
+
+    def __ne__(self, other):
+        return not (self == other)
+
+    def __repr__(self):
+        return "%s()" % self.__class__.__name__
+
+    __reduce__ = object.__reduce__
+
+
+#: Convenience constant providing a :class:`tzutc()` instance
+#:
+#: .. versionadded:: 2.7.0
+UTC = tzutc()
+
+
+@six.add_metaclass(_TzOffsetFactory)
+class tzoffset(datetime.tzinfo):
+    """
+    A simple class for representing a fixed offset from UTC.
+
+    :param name:
+        The timezone name, to be returned when ``tzname()`` is called.
+    :param offset:
+        The time zone offset in seconds, or (since version 2.6.0, represented
+        as a :py:class:`datetime.timedelta` object).
+    """
+    def __init__(self, name, offset):
+        self._name = name
+
+        try:
+            # Allow a timedelta
+            offset = offset.total_seconds()
+        except (TypeError, AttributeError):
+            pass
+
+        self._offset = datetime.timedelta(seconds=_get_supported_offset(offset))
+
+    def utcoffset(self, dt):
+        return self._offset
+
+    def dst(self, dt):
+        return ZERO
+
+    @tzname_in_python2
+    def tzname(self, dt):
+        return self._name
+
+    @_validate_fromutc_inputs
+    def fromutc(self, dt):
+        return dt + self._offset
+
+    def is_ambiguous(self, dt):
+        """
+        Whether or not the "wall time" of a given datetime is ambiguous in this
+        zone.
+
+        :param dt:
+            A :py:class:`datetime.datetime`, naive or time zone aware.
+        :return:
+            Returns ``True`` if ambiguous, ``False`` otherwise.
+
+        .. versionadded:: 2.6.0
+        """
+        return False
+
+    def __eq__(self, other):
+        if not isinstance(other, tzoffset):
+            return NotImplemented
+
+        return self._offset == other._offset
+
+    __hash__ = None
+
+    def __ne__(self, other):
+        return not (self == other)
+
+    def __repr__(self):
+        return "%s(%s, %s)" % (self.__class__.__name__,
+                               repr(self._name),
+                               int(self._offset.total_seconds()))
+
+    __reduce__ = object.__reduce__
+
+
+class tzlocal(_tzinfo):
+    """
+    A :class:`tzinfo` subclass built around the ``time`` timezone functions.
+    """
+    def __init__(self):
+        super(tzlocal, self).__init__()
+
+        self._std_offset = datetime.timedelta(seconds=-time.timezone)
+        if time.daylight:
+            self._dst_offset = datetime.timedelta(seconds=-time.altzone)
+        else:
+            self._dst_offset = self._std_offset
+
+        self._dst_saved = self._dst_offset - self._std_offset
+        self._hasdst = bool(self._dst_saved)
+        self._tznames = tuple(time.tzname)
+
+    def utcoffset(self, dt):
+        if dt is None and self._hasdst:
+            return None
+
+        if self._isdst(dt):
+            return self._dst_offset
+        else:
+            return self._std_offset
+
+    def dst(self, dt):
+        if dt is None and self._hasdst:
+            return None
+
+        if self._isdst(dt):
+            return self._dst_offset - self._std_offset
+        else:
+            return ZERO
+
+    @tzname_in_python2
+    def tzname(self, dt):
+        return self._tznames[self._isdst(dt)]
+
+    def is_ambiguous(self, dt):
+        """
+        Whether or not the "wall time" of a given datetime is ambiguous in this
+        zone.
+
+        :param dt:
+            A :py:class:`datetime.datetime`, naive or time zone aware.
+
+
+        :return:
+            Returns ``True`` if ambiguous, ``False`` otherwise.
+
+        .. versionadded:: 2.6.0
+        """
+        naive_dst = self._naive_is_dst(dt)
+        return (not naive_dst and
+                (naive_dst != self._naive_is_dst(dt - self._dst_saved)))
+
+    def _naive_is_dst(self, dt):
+        timestamp = _datetime_to_timestamp(dt)
+        return time.localtime(timestamp + time.timezone).tm_isdst
+
+    def _isdst(self, dt, fold_naive=True):
+        # We can't use mktime here. It is unstable when deciding if
+        # the hour near to a change is DST or not.
+        #
+        # timestamp = time.mktime((dt.year, dt.month, dt.day, dt.hour,
+        #                         dt.minute, dt.second, dt.weekday(), 0, -1))
+        # return time.localtime(timestamp).tm_isdst
+        #
+        # The code above yields the following result:
+        #
+        # >>> import tz, datetime
+        # >>> t = tz.tzlocal()
+        # >>> datetime.datetime(2003,2,15,23,tzinfo=t).tzname()
+        # 'BRDT'
+        # >>> datetime.datetime(2003,2,16,0,tzinfo=t).tzname()
+        # 'BRST'
+        # >>> datetime.datetime(2003,2,15,23,tzinfo=t).tzname()
+        # 'BRST'
+        # >>> datetime.datetime(2003,2,15,22,tzinfo=t).tzname()
+        # 'BRDT'
+        # >>> datetime.datetime(2003,2,15,23,tzinfo=t).tzname()
+        # 'BRDT'
+        #
+        # Here is a more stable implementation:
+        #
+        if not self._hasdst:
+            return False
+
+        # Check for ambiguous times:
+        dstval = self._naive_is_dst(dt)
+        fold = getattr(dt, 'fold', None)
+
+        if self.is_ambiguous(dt):
+            if fold is not None:
+                return not self._fold(dt)
+            else:
+                return True
+
+        return dstval
+
+    def __eq__(self, other):
+        if isinstance(other, tzlocal):
+            return (self._std_offset == other._std_offset and
+                    self._dst_offset == other._dst_offset)
+        elif isinstance(other, tzutc):
+            return (not self._hasdst and
+                    self._tznames[0] in {'UTC', 'GMT'} and
+                    self._std_offset == ZERO)
+        elif isinstance(other, tzoffset):
+            return (not self._hasdst and
+                    self._tznames[0] == other._name and
+                    self._std_offset == other._offset)
+        else:
+            return NotImplemented
+
+    __hash__ = None
+
+    def __ne__(self, other):
+        return not (self == other)
+
+    def __repr__(self):
+        return "%s()" % self.__class__.__name__
+
+    __reduce__ = object.__reduce__
+
+
+class _ttinfo(object):
+    __slots__ = ["offset", "delta", "isdst", "abbr",
+                 "isstd", "isgmt", "dstoffset"]
+
+    def __init__(self):
+        for attr in self.__slots__:
+            setattr(self, attr, None)
+
+    def __repr__(self):
+        l = []
+        for attr in self.__slots__:
+            value = getattr(self, attr)
+            if value is not None:
+                l.append("%s=%s" % (attr, repr(value)))
+        return "%s(%s)" % (self.__class__.__name__, ", ".join(l))
+
+    def __eq__(self, other):
+        if not isinstance(other, _ttinfo):
+            return NotImplemented
+
+        return (self.offset == other.offset and
+                self.delta == other.delta and
+                self.isdst == other.isdst and
+                self.abbr == other.abbr and
+                self.isstd == other.isstd and
+                self.isgmt == other.isgmt and
+                self.dstoffset == other.dstoffset)
+
+    __hash__ = None
+
+    def __ne__(self, other):
+        return not (self == other)
+
+    def __getstate__(self):
+        state = {}
+        for name in self.__slots__:
+            state[name] = getattr(self, name, None)
+        return state
+
+    def __setstate__(self, state):
+        for name in self.__slots__:
+            if name in state:
+                setattr(self, name, state[name])
+
+
+class _tzfile(object):
+    """
+    Lightweight class for holding the relevant transition and time zone
+    information read from binary tzfiles.
+    """
+    attrs = ['trans_list', 'trans_list_utc', 'trans_idx', 'ttinfo_list',
+             'ttinfo_std', 'ttinfo_dst', 'ttinfo_before', 'ttinfo_first']
+
+    def __init__(self, **kwargs):
+        for attr in self.attrs:
+            setattr(self, attr, kwargs.get(attr, None))
+
+
+class tzfile(_tzinfo):
+    """
+    This is a ``tzinfo`` subclass that allows one to use the ``tzfile(5)``
+    format timezone files to extract current and historical zone information.
+
+    :param fileobj:
+        This can be an opened file stream or a file name that the time zone
+        information can be read from.
+
+    :param filename:
+        This is an optional parameter specifying the source of the time zone
+        information in the event that ``fileobj`` is a file object. If omitted
+        and ``fileobj`` is a file stream, this parameter will be set either to
+        ``fileobj``'s ``name`` attribute or to ``repr(fileobj)``.
+
+    See `Sources for Time Zone and Daylight Saving Time Data
+    <https://data.iana.org/time-zones/tz-link.html>`_ for more information.
+    Time zone files can be compiled from the `IANA Time Zone database files
+    <https://www.iana.org/time-zones>`_ with the `zic time zone compiler
+    <https://www.freebsd.org/cgi/man.cgi?query=zic&sektion=8>`_
+
+    .. note::
+
+        Only construct a ``tzfile`` directly if you have a specific timezone
+        file on disk that you want to read into a Python ``tzinfo`` object.
+        If you want to get a ``tzfile`` representing a specific IANA zone,
+        (e.g. ``'America/New_York'``), you should call
+        :func:`dateutil.tz.gettz` with the zone identifier.
+
+
+    **Examples:**
+
+    Using the US Eastern time zone as an example, we can see that a ``tzfile``
+    provides time zone information for the standard Daylight Saving offsets:
+
+    .. testsetup:: tzfile
+
+        from dateutil.tz import gettz
+        from datetime import datetime
+
+    .. doctest:: tzfile
+
+        >>> NYC = gettz('America/New_York')
+        >>> NYC
+        tzfile('/usr/share/zoneinfo/America/New_York')
+
+        >>> print(datetime(2016, 1, 3, tzinfo=NYC))     # EST
+        2016-01-03 00:00:00-05:00
+
+        >>> print(datetime(2016, 7, 7, tzinfo=NYC))     # EDT
+        2016-07-07 00:00:00-04:00
+
+
+    The ``tzfile`` structure contains a fully history of the time zone,
+    so historical dates will also have the right offsets. For example, before
+    the adoption of the UTC standards, New York used local solar  mean time:
+
+    .. doctest:: tzfile
+
+       >>> print(datetime(1901, 4, 12, tzinfo=NYC))    # LMT
+       1901-04-12 00:00:00-04:56
+
+    And during World War II, New York was on "Eastern War Time", which was a
+    state of permanent daylight saving time:
+
+    .. doctest:: tzfile
+
+        >>> print(datetime(1944, 2, 7, tzinfo=NYC))    # EWT
+        1944-02-07 00:00:00-04:00
+
+    """
+
+    def __init__(self, fileobj, filename=None):
+        super(tzfile, self).__init__()
+
+        file_opened_here = False
+        if isinstance(fileobj, string_types):
+            self._filename = fileobj
+            fileobj = open(fileobj, 'rb')
+            file_opened_here = True
+        elif filename is not None:
+            self._filename = filename
+        elif hasattr(fileobj, "name"):
+            self._filename = fileobj.name
+        else:
+            self._filename = repr(fileobj)
+
+        if fileobj is not None:
+            if not file_opened_here:
+                fileobj = _nullcontext(fileobj)
+
+            with fileobj as file_stream:
+                tzobj = self._read_tzfile(file_stream)
+
+            self._set_tzdata(tzobj)
+
+    def _set_tzdata(self, tzobj):
+        """ Set the time zone data of this object from a _tzfile object """
+        # Copy the relevant attributes over as private attributes
+        for attr in _tzfile.attrs:
+            setattr(self, '_' + attr, getattr(tzobj, attr))
+
+    def _read_tzfile(self, fileobj):
+        out = _tzfile()
+
+        # From tzfile(5):
+        #
+        # The time zone information files used by tzset(3)
+        # begin with the magic characters "TZif" to identify
+        # them as time zone information files, followed by
+        # sixteen bytes reserved for future use, followed by
+        # six four-byte values of type long, written in a
+        # ``standard'' byte order (the high-order  byte
+        # of the value is written first).
+        if fileobj.read(4).decode() != "TZif":
+            raise ValueError("magic not found")
+
+        fileobj.read(16)
+
+        (
+            # The number of UTC/local indicators stored in the file.
+            ttisgmtcnt,
+
+            # The number of standard/wall indicators stored in the file.
+            ttisstdcnt,
+
+            # The number of leap seconds for which data is
+            # stored in the file.
+            leapcnt,
+
+            # The number of "transition times" for which data
+            # is stored in the file.
+            timecnt,
+
+            # The number of "local time types" for which data
+            # is stored in the file (must not be zero).
+            typecnt,
+
+            # The  number  of  characters  of "time zone
+            # abbreviation strings" stored in the file.
+            charcnt,
+
+        ) = struct.unpack(">6l", fileobj.read(24))
+
+        # The above header is followed by tzh_timecnt four-byte
+        # values  of  type long,  sorted  in ascending order.
+        # These values are written in ``standard'' byte order.
+        # Each is used as a transition time (as  returned  by
+        # time(2)) at which the rules for computing local time
+        # change.
+
+        if timecnt:
+            out.trans_list_utc = list(struct.unpack(">%dl" % timecnt,
+                                                    fileobj.read(timecnt*4)))
+        else:
+            out.trans_list_utc = []
+
+        # Next come tzh_timecnt one-byte values of type unsigned
+        # char; each one tells which of the different types of
+        # ``local time'' types described in the file is associated
+        # with the same-indexed transition time. These values
+        # serve as indices into an array of ttinfo structures that
+        # appears next in the file.
+
+        if timecnt:
+            out.trans_idx = struct.unpack(">%dB" % timecnt,
+                                          fileobj.read(timecnt))
+        else:
+            out.trans_idx = []
+
+        # Each ttinfo structure is written as a four-byte value
+        # for tt_gmtoff  of  type long,  in  a  standard  byte
+        # order, followed  by a one-byte value for tt_isdst
+        # and a one-byte  value  for  tt_abbrind.   In  each
+        # structure, tt_gmtoff  gives  the  number  of
+        # seconds to be added to UTC, tt_isdst tells whether
+        # tm_isdst should be set by  localtime(3),  and
+        # tt_abbrind serves  as an index into the array of
+        # time zone abbreviation characters that follow the
+        # ttinfo structure(s) in the file.
+
+        ttinfo = []
+
+        for i in range(typecnt):
+            ttinfo.append(struct.unpack(">lbb", fileobj.read(6)))
+
+        abbr = fileobj.read(charcnt).decode()
+
+        # Then there are tzh_leapcnt pairs of four-byte
+        # values, written in  standard byte  order;  the
+        # first  value  of  each pair gives the time (as
+        # returned by time(2)) at which a leap second
+        # occurs;  the  second  gives the  total  number of
+        # leap seconds to be applied after the given time.
+        # The pairs of values are sorted in ascending order
+        # by time.
+
+        # Not used, for now (but seek for correct file position)
+        if leapcnt:
+            fileobj.seek(leapcnt * 8, os.SEEK_CUR)
+
+        # Then there are tzh_ttisstdcnt standard/wall
+        # indicators, each stored as a one-byte value;
+        # they tell whether the transition times associated
+        # with local time types were specified as standard
+        # time or wall clock time, and are used when
+        # a time zone file is used in handling POSIX-style
+        # time zone environment variables.
+
+        if ttisstdcnt:
+            isstd = struct.unpack(">%db" % ttisstdcnt,
+                                  fileobj.read(ttisstdcnt))
+
+        # Finally, there are tzh_ttisgmtcnt UTC/local
+        # indicators, each stored as a one-byte value;
+        # they tell whether the transition times associated
+        # with local time types were specified as UTC or
+        # local time, and are used when a time zone file
+        # is used in handling POSIX-style time zone envi-
+        # ronment variables.
+
+        if ttisgmtcnt:
+            isgmt = struct.unpack(">%db" % ttisgmtcnt,
+                                  fileobj.read(ttisgmtcnt))
+
+        # Build ttinfo list
+        out.ttinfo_list = []
+        for i in range(typecnt):
+            gmtoff, isdst, abbrind = ttinfo[i]
+            gmtoff = _get_supported_offset(gmtoff)
+            tti = _ttinfo()
+            tti.offset = gmtoff
+            tti.dstoffset = datetime.timedelta(0)
+            tti.delta = datetime.timedelta(seconds=gmtoff)
+            tti.isdst = isdst
+            tti.abbr = abbr[abbrind:abbr.find('\x00', abbrind)]
+            tti.isstd = (ttisstdcnt > i and isstd[i] != 0)
+            tti.isgmt = (ttisgmtcnt > i and isgmt[i] != 0)
+            out.ttinfo_list.append(tti)
+
+        # Replace ttinfo indexes for ttinfo objects.
+        out.trans_idx = [out.ttinfo_list[idx] for idx in out.trans_idx]
+
+        # Set standard, dst, and before ttinfos. before will be
+        # used when a given time is before any transitions,
+        # and will be set to the first non-dst ttinfo, or to
+        # the first dst, if all of them are dst.
+        out.ttinfo_std = None
+        out.ttinfo_dst = None
+        out.ttinfo_before = None
+        if out.ttinfo_list:
+            if not out.trans_list_utc:
+                out.ttinfo_std = out.ttinfo_first = out.ttinfo_list[0]
+            else:
+                for i in range(timecnt-1, -1, -1):
+                    tti = out.trans_idx[i]
+                    if not out.ttinfo_std and not tti.isdst:
+                        out.ttinfo_std = tti
+                    elif not out.ttinfo_dst and tti.isdst:
+                        out.ttinfo_dst = tti
+
+                    if out.ttinfo_std and out.ttinfo_dst:
+                        break
+                else:
+                    if out.ttinfo_dst and not out.ttinfo_std:
+                        out.ttinfo_std = out.ttinfo_dst
+
+                for tti in out.ttinfo_list:
+                    if not tti.isdst:
+                        out.ttinfo_before = tti
+                        break
+                else:
+                    out.ttinfo_before = out.ttinfo_list[0]
+
+        # Now fix transition times to become relative to wall time.
+        #
+        # I'm not sure about this. In my tests, the tz source file
+        # is setup to wall time, and in the binary file isstd and
+        # isgmt are off, so it should be in wall time. OTOH, it's
+        # always in gmt time. Let me know if you have comments
+        # about this.
+        lastdst = None
+        lastoffset = None
+        lastdstoffset = None
+        lastbaseoffset = None
+        out.trans_list = []
+
+        for i, tti in enumerate(out.trans_idx):
+            offset = tti.offset
+            dstoffset = 0
+
+            if lastdst is not None:
+                if tti.isdst:
+                    if not lastdst:
+                        dstoffset = offset - lastoffset
+
+                    if not dstoffset and lastdstoffset:
+                        dstoffset = lastdstoffset
+
+                    tti.dstoffset = datetime.timedelta(seconds=dstoffset)
+                    lastdstoffset = dstoffset
+
+            # If a time zone changes its base offset during a DST transition,
+            # then you need to adjust by the previous base offset to get the
+            # transition time in local time. Otherwise you use the current
+            # base offset. Ideally, I would have some mathematical proof of
+            # why this is true, but I haven't really thought about it enough.
+            baseoffset = offset - dstoffset
+            adjustment = baseoffset
+            if (lastbaseoffset is not None and baseoffset != lastbaseoffset
+                    and tti.isdst != lastdst):
+                # The base DST has changed
+                adjustment = lastbaseoffset
+
+            lastdst = tti.isdst
+            lastoffset = offset
+            lastbaseoffset = baseoffset
+
+            out.trans_list.append(out.trans_list_utc[i] + adjustment)
+
+        out.trans_idx = tuple(out.trans_idx)
+        out.trans_list = tuple(out.trans_list)
+        out.trans_list_utc = tuple(out.trans_list_utc)
+
+        return out
+
+    def _find_last_transition(self, dt, in_utc=False):
+        # If there's no list, there are no transitions to find
+        if not self._trans_list:
+            return None
+
+        timestamp = _datetime_to_timestamp(dt)
+
+        # Find where the timestamp fits in the transition list - if the
+        # timestamp is a transition time, it's part of the "after" period.
+        trans_list = self._trans_list_utc if in_utc else self._trans_list
+        idx = bisect.bisect_right(trans_list, timestamp)
+
+        # We want to know when the previous transition was, so subtract off 1
+        return idx - 1
+
+    def _get_ttinfo(self, idx):
+        # For no list or after the last transition, default to _ttinfo_std
+        if idx is None or (idx + 1) >= len(self._trans_list):
+            return self._ttinfo_std
+
+        # If there is a list and the time is before it, return _ttinfo_before
+        if idx < 0:
+            return self._ttinfo_before
+
+        return self._trans_idx[idx]
+
+    def _find_ttinfo(self, dt):
+        idx = self._resolve_ambiguous_time(dt)
+
+        return self._get_ttinfo(idx)
+
+    def fromutc(self, dt):
+        """
+        The ``tzfile`` implementation of :py:func:`datetime.tzinfo.fromutc`.
+
+        :param dt:
+            A :py:class:`datetime.datetime` object.
+
+        :raises TypeError:
+            Raised if ``dt`` is not a :py:class:`datetime.datetime` object.
+
+        :raises ValueError:
+            Raised if this is called with a ``dt`` which does not have this
+            ``tzinfo`` attached.
+
+        :return:
+            Returns a :py:class:`datetime.datetime` object representing the
+            wall time in ``self``'s time zone.
+        """
+        # These isinstance checks are in datetime.tzinfo, so we'll preserve
+        # them, even if we don't care about duck typing.
+        if not isinstance(dt, datetime.datetime):
+            raise TypeError("fromutc() requires a datetime argument")
+
+        if dt.tzinfo is not self:
+            raise ValueError("dt.tzinfo is not self")
+
+        # First treat UTC as wall time and get the transition we're in.
+        idx = self._find_last_transition(dt, in_utc=True)
+        tti = self._get_ttinfo(idx)
+
+        dt_out = dt + datetime.timedelta(seconds=tti.offset)
+
+        fold = self.is_ambiguous(dt_out, idx=idx)
+
+        return enfold(dt_out, fold=int(fold))
+
+    def is_ambiguous(self, dt, idx=None):
+        """
+        Whether or not the "wall time" of a given datetime is ambiguous in this
+        zone.
+
+        :param dt:
+            A :py:class:`datetime.datetime`, naive or time zone aware.
+
+
+        :return:
+            Returns ``True`` if ambiguous, ``False`` otherwise.
+
+        .. versionadded:: 2.6.0
+        """
+        if idx is None:
+            idx = self._find_last_transition(dt)
+
+        # Calculate the difference in offsets from current to previous
+        timestamp = _datetime_to_timestamp(dt)
+        tti = self._get_ttinfo(idx)
+
+        if idx is None or idx <= 0:
+            return False
+
+        od = self._get_ttinfo(idx - 1).offset - tti.offset
+        tt = self._trans_list[idx]          # Transition time
+
+        return timestamp < tt + od
+
+    def _resolve_ambiguous_time(self, dt):
+        idx = self._find_last_transition(dt)
+
+        # If we have no transitions, return the index
+        _fold = self._fold(dt)
+        if idx is None or idx == 0:
+            return idx
+
+        # If it's ambiguous and we're in a fold, shift to a different index.
+        idx_offset = int(not _fold and self.is_ambiguous(dt, idx))
+
+        return idx - idx_offset
+
+    def utcoffset(self, dt):
+        if dt is None:
+            return None
+
+        if not self._ttinfo_std:
+            return ZERO
+
+        return self._find_ttinfo(dt).delta
+
+    def dst(self, dt):
+        if dt is None:
+            return None
+
+        if not self._ttinfo_dst:
+            return ZERO
+
+        tti = self._find_ttinfo(dt)
+
+        if not tti.isdst:
+            return ZERO
+
+        # The documentation says that utcoffset()-dst() must
+        # be constant for every dt.
+        return tti.dstoffset
+
+    @tzname_in_python2
+    def tzname(self, dt):
+        if not self._ttinfo_std or dt is None:
+            return None
+        return self._find_ttinfo(dt).abbr
+
+    def __eq__(self, other):
+        if not isinstance(other, tzfile):
+            return NotImplemented
+        return (self._trans_list == other._trans_list and
+                self._trans_idx == other._trans_idx and
+                self._ttinfo_list == other._ttinfo_list)
+
+    __hash__ = None
+
+    def __ne__(self, other):
+        return not (self == other)
+
+    def __repr__(self):
+        return "%s(%s)" % (self.__class__.__name__, repr(self._filename))
+
+    def __reduce__(self):
+        return self.__reduce_ex__(None)
+
+    def __reduce_ex__(self, protocol):
+        return (self.__class__, (None, self._filename), self.__dict__)
+
+
+class tzrange(tzrangebase):
+    """
+    The ``tzrange`` object is a time zone specified by a set of offsets and
+    abbreviations, equivalent to the way the ``TZ`` variable can be specified
+    in POSIX-like systems, but using Python delta objects to specify DST
+    start, end and offsets.
+
+    :param stdabbr:
+        The abbreviation for standard time (e.g. ``'EST'``).
+
+    :param stdoffset:
+        An integer or :class:`datetime.timedelta` object or equivalent
+        specifying the base offset from UTC.
+
+        If unspecified, +00:00 is used.
+
+    :param dstabbr:
+        The abbreviation for DST / "Summer" time (e.g. ``'EDT'``).
+
+        If specified, with no other DST information, DST is assumed to occur
+        and the default behavior or ``dstoffset``, ``start`` and ``end`` is
+        used. If unspecified and no other DST information is specified, it
+        is assumed that this zone has no DST.
+
+        If this is unspecified and other DST information is *is* specified,
+        DST occurs in the zone but the time zone abbreviation is left
+        unchanged.
+
+    :param dstoffset:
+        A an integer or :class:`datetime.timedelta` object or equivalent
+        specifying the UTC offset during DST. If unspecified and any other DST
+        information is specified, it is assumed to be the STD offset +1 hour.
+
+    :param start:
+        A :class:`relativedelta.relativedelta` object or equivalent specifying
+        the time and time of year that daylight savings time starts. To
+        specify, for example, that DST starts at 2AM on the 2nd Sunday in
+        March, pass:
+
+            ``relativedelta(hours=2, month=3, day=1, weekday=SU(+2))``
+
+        If unspecified and any other DST information is specified, the default
+        value is 2 AM on the first Sunday in April.
+
+    :param end:
+        A :class:`relativedelta.relativedelta` object or equivalent
+        representing the time and time of year that daylight savings time
+        ends, with the same specification method as in ``start``. One note is
+        that this should point to the first time in the *standard* zone, so if
+        a transition occurs at 2AM in the DST zone and the clocks are set back
+        1 hour to 1AM, set the ``hours`` parameter to +1.
+
+
+    **Examples:**
+
+    .. testsetup:: tzrange
+
+        from dateutil.tz import tzrange, tzstr
+
+    .. doctest:: tzrange
+
+        >>> tzstr('EST5EDT') == tzrange("EST", -18000, "EDT")
+        True
+
+        >>> from dateutil.relativedelta import *
+        >>> range1 = tzrange("EST", -18000, "EDT")
+        >>> range2 = tzrange("EST", -18000, "EDT", -14400,
+        ...                  relativedelta(hours=+2, month=4, day=1,
+        ...                                weekday=SU(+1)),
+        ...                  relativedelta(hours=+1, month=10, day=31,
+        ...                                weekday=SU(-1)))
+        >>> tzstr('EST5EDT') == range1 == range2
+        True
+
+    """
+    def __init__(self, stdabbr, stdoffset=None,
+                 dstabbr=None, dstoffset=None,
+                 start=None, end=None):
+
+        global relativedelta
+        from dateutil import relativedelta
+
+        self._std_abbr = stdabbr
+        self._dst_abbr = dstabbr
+
+        try:
+            stdoffset = stdoffset.total_seconds()
+        except (TypeError, AttributeError):
+            pass
+
+        try:
+            dstoffset = dstoffset.total_seconds()
+        except (TypeError, AttributeError):
+            pass
+
+        if stdoffset is not None:
+            self._std_offset = datetime.timedelta(seconds=stdoffset)
+        else:
+            self._std_offset = ZERO
+
+        if dstoffset is not None:
+            self._dst_offset = datetime.timedelta(seconds=dstoffset)
+        elif dstabbr and stdoffset is not None:
+            self._dst_offset = self._std_offset + datetime.timedelta(hours=+1)
+        else:
+            self._dst_offset = ZERO
+
+        if dstabbr and start is None:
+            self._start_delta = relativedelta.relativedelta(
+                hours=+2, month=4, day=1, weekday=relativedelta.SU(+1))
+        else:
+            self._start_delta = start
+
+        if dstabbr and end is None:
+            self._end_delta = relativedelta.relativedelta(
+                hours=+1, month=10, day=31, weekday=relativedelta.SU(-1))
+        else:
+            self._end_delta = end
+
+        self._dst_base_offset_ = self._dst_offset - self._std_offset
+        self.hasdst = bool(self._start_delta)
+
+    def transitions(self, year):
+        """
+        For a given year, get the DST on and off transition times, expressed
+        always on the standard time side. For zones with no transitions, this
+        function returns ``None``.
+
+        :param year:
+            The year whose transitions you would like to query.
+
+        :return:
+            Returns a :class:`tuple` of :class:`datetime.datetime` objects,
+            ``(dston, dstoff)`` for zones with an annual DST transition, or
+            ``None`` for fixed offset zones.
+        """
+        if not self.hasdst:
+            return None
+
+        base_year = datetime.datetime(year, 1, 1)
+
+        start = base_year + self._start_delta
+        end = base_year + self._end_delta
+
+        return (start, end)
+
+    def __eq__(self, other):
+        if not isinstance(other, tzrange):
+            return NotImplemented
+
+        return (self._std_abbr == other._std_abbr and
+                self._dst_abbr == other._dst_abbr and
+                self._std_offset == other._std_offset and
+                self._dst_offset == other._dst_offset and
+                self._start_delta == other._start_delta and
+                self._end_delta == other._end_delta)
+
+    @property
+    def _dst_base_offset(self):
+        return self._dst_base_offset_
+
+
+@six.add_metaclass(_TzStrFactory)
+class tzstr(tzrange):
+    """
+    ``tzstr`` objects are time zone objects specified by a time-zone string as
+    it would be passed to a ``TZ`` variable on POSIX-style systems (see
+    the `GNU C Library: TZ Variable`_ for more details).
+
+    There is one notable exception, which is that POSIX-style time zones use an
+    inverted offset format, so normally ``GMT+3`` would be parsed as an offset
+    3 hours *behind* GMT. The ``tzstr`` time zone object will parse this as an
+    offset 3 hours *ahead* of GMT. If you would like to maintain the POSIX
+    behavior, pass a ``True`` value to ``posix_offset``.
+
+    The :class:`tzrange` object provides the same functionality, but is
+    specified using :class:`relativedelta.relativedelta` objects. rather than
+    strings.
+
+    :param s:
+        A time zone string in ``TZ`` variable format. This can be a
+        :class:`bytes` (2.x: :class:`str`), :class:`str` (2.x:
+        :class:`unicode`) or a stream emitting unicode characters
+        (e.g. :class:`StringIO`).
+
+    :param posix_offset:
+        Optional. If set to ``True``, interpret strings such as ``GMT+3`` or
+        ``UTC+3`` as being 3 hours *behind* UTC rather than ahead, per the
+        POSIX standard.
+
+    .. caution::
+
+        Prior to version 2.7.0, this function also supported time zones
+        in the format:
+
+            * ``EST5EDT,4,0,6,7200,10,0,26,7200,3600``
+            * ``EST5EDT,4,1,0,7200,10,-1,0,7200,3600``
+
+        This format is non-standard and has been deprecated; this function
+        will raise a :class:`DeprecatedTZFormatWarning` until
+        support is removed in a future version.
+
+    .. _`GNU C Library: TZ Variable`:
+        https://www.gnu.org/software/libc/manual/html_node/TZ-Variable.html
+    """
+    def __init__(self, s, posix_offset=False):
+        global parser
+        from dateutil.parser import _parser as parser
+
+        self._s = s
+
+        res = parser._parsetz(s)
+        if res is None or res.any_unused_tokens:
+            raise ValueError("unknown string format")
+
+        # Here we break the compatibility with the TZ variable handling.
+        # GMT-3 actually *means* the timezone -3.
+        if res.stdabbr in ("GMT", "UTC") and not posix_offset:
+            res.stdoffset *= -1
+
+        # We must initialize it first, since _delta() needs
+        # _std_offset and _dst_offset set. Use False in start/end
+        # to avoid building it two times.
+        tzrange.__init__(self, res.stdabbr, res.stdoffset,
+                         res.dstabbr, res.dstoffset,
+                         start=False, end=False)
+
+        if not res.dstabbr:
+            self._start_delta = None
+            self._end_delta = None
+        else:
+            self._start_delta = self._delta(res.start)
+            if self._start_delta:
+                self._end_delta = self._delta(res.end, isend=1)
+
+        self.hasdst = bool(self._start_delta)
+
+    def _delta(self, x, isend=0):
+        from dateutil import relativedelta
+        kwargs = {}
+        if x.month is not None:
+            kwargs["month"] = x.month
+            if x.weekday is not None:
+                kwargs["weekday"] = relativedelta.weekday(x.weekday, x.week)
+                if x.week > 0:
+                    kwargs["day"] = 1
+                else:
+                    kwargs["day"] = 31
+            elif x.day:
+                kwargs["day"] = x.day
+        elif x.yday is not None:
+            kwargs["yearday"] = x.yday
+        elif x.jyday is not None:
+            kwargs["nlyearday"] = x.jyday
+        if not kwargs:
+            # Default is to start on first sunday of april, and end
+            # on last sunday of october.
+            if not isend:
+                kwargs["month"] = 4
+                kwargs["day"] = 1
+                kwargs["weekday"] = relativedelta.SU(+1)
+            else:
+                kwargs["month"] = 10
+                kwargs["day"] = 31
+                kwargs["weekday"] = relativedelta.SU(-1)
+        if x.time is not None:
+            kwargs["seconds"] = x.time
+        else:
+            # Default is 2AM.
+            kwargs["seconds"] = 7200
+        if isend:
+            # Convert to standard time, to follow the documented way
+            # of working with the extra hour. See the documentation
+            # of the tzinfo class.
+            delta = self._dst_offset - self._std_offset
+            kwargs["seconds"] -= delta.seconds + delta.days * 86400
+        return relativedelta.relativedelta(**kwargs)
+
+    def __repr__(self):
+        return "%s(%s)" % (self.__class__.__name__, repr(self._s))
+
+
+class _tzicalvtzcomp(object):
+    def __init__(self, tzoffsetfrom, tzoffsetto, isdst,
+                 tzname=None, rrule=None):
+        self.tzoffsetfrom = datetime.timedelta(seconds=tzoffsetfrom)
+        self.tzoffsetto = datetime.timedelta(seconds=tzoffsetto)
+        self.tzoffsetdiff = self.tzoffsetto - self.tzoffsetfrom
+        self.isdst = isdst
+        self.tzname = tzname
+        self.rrule = rrule
+
+
+class _tzicalvtz(_tzinfo):
+    def __init__(self, tzid, comps=[]):
+        super(_tzicalvtz, self).__init__()
+
+        self._tzid = tzid
+        self._comps = comps
+        self._cachedate = []
+        self._cachecomp = []
+        self._cache_lock = _thread.allocate_lock()
+
+    def _find_comp(self, dt):
+        if len(self._comps) == 1:
+            return self._comps[0]
+
+        dt = dt.replace(tzinfo=None)
+
+        try:
+            with self._cache_lock:
+                return self._cachecomp[self._cachedate.index(
+                    (dt, self._fold(dt)))]
+        except ValueError:
+            pass
+
+        lastcompdt = None
+        lastcomp = None
+
+        for comp in self._comps:
+            compdt = self._find_compdt(comp, dt)
+
+            if compdt and (not lastcompdt or lastcompdt < compdt):
+                lastcompdt = compdt
+                lastcomp = comp
+
+        if not lastcomp:
+            # RFC says nothing about what to do when a given
+            # time is before the first onset date. We'll look for the
+            # first standard component, or the first component, if
+            # none is found.
+            for comp in self._comps:
+                if not comp.isdst:
+                    lastcomp = comp
+                    break
+            else:
+                lastcomp = comp[0]
+
+        with self._cache_lock:
+            self._cachedate.insert(0, (dt, self._fold(dt)))
+            self._cachecomp.insert(0, lastcomp)
+
+            if len(self._cachedate) > 10:
+                self._cachedate.pop()
+                self._cachecomp.pop()
+
+        return lastcomp
+
+    def _find_compdt(self, comp, dt):
+        if comp.tzoffsetdiff < ZERO and self._fold(dt):
+            dt -= comp.tzoffsetdiff
+
+        compdt = comp.rrule.before(dt, inc=True)
+
+        return compdt
+
+    def utcoffset(self, dt):
+        if dt is None:
+            return None
+
+        return self._find_comp(dt).tzoffsetto
+
+    def dst(self, dt):
+        comp = self._find_comp(dt)
+        if comp.isdst:
+            return comp.tzoffsetdiff
+        else:
+            return ZERO
+
+    @tzname_in_python2
+    def tzname(self, dt):
+        return self._find_comp(dt).tzname
+
+    def __repr__(self):
+        return "<tzicalvtz %s>" % repr(self._tzid)
+
+    __reduce__ = object.__reduce__
+
+
+class tzical(object):
+    """
+    This object is designed to parse an iCalendar-style ``VTIMEZONE`` structure
+    as set out in `RFC 5545`_ Section 4.6.5 into one or more `tzinfo` objects.
+
+    :param `fileobj`:
+        A file or stream in iCalendar format, which should be UTF-8 encoded
+        with CRLF endings.
+
+    .. _`RFC 5545`: https://tools.ietf.org/html/rfc5545
+    """
+    def __init__(self, fileobj):
+        global rrule
+        from dateutil import rrule
+
+        if isinstance(fileobj, string_types):
+            self._s = fileobj
+            # ical should be encoded in UTF-8 with CRLF
+            fileobj = open(fileobj, 'r')
+        else:
+            self._s = getattr(fileobj, 'name', repr(fileobj))
+            fileobj = _nullcontext(fileobj)
+
+        self._vtz = {}
+
+        with fileobj as fobj:
+            self._parse_rfc(fobj.read())
+
+    def keys(self):
+        """
+        Retrieves the available time zones as a list.
+        """
+        return list(self._vtz.keys())
+
+    def get(self, tzid=None):
+        """
+        Retrieve a :py:class:`datetime.tzinfo` object by its ``tzid``.
+
+        :param tzid:
+            If there is exactly one time zone available, omitting ``tzid``
+            or passing :py:const:`None` value returns it. Otherwise a valid
+            key (which can be retrieved from :func:`keys`) is required.
+
+        :raises ValueError:
+            Raised if ``tzid`` is not specified but there are either more
+            or fewer than 1 zone defined.
+
+        :returns:
+            Returns either a :py:class:`datetime.tzinfo` object representing
+            the relevant time zone or :py:const:`None` if the ``tzid`` was
+            not found.
+        """
+        if tzid is None:
+            if len(self._vtz) == 0:
+                raise ValueError("no timezones defined")
+            elif len(self._vtz) > 1:
+                raise ValueError("more than one timezone available")
+            tzid = next(iter(self._vtz))
+
+        return self._vtz.get(tzid)
+
+    def _parse_offset(self, s):
+        s = s.strip()
+        if not s:
+            raise ValueError("empty offset")
+        if s[0] in ('+', '-'):
+            signal = (-1, +1)[s[0] == '+']
+            s = s[1:]
+        else:
+            signal = +1
+        if len(s) == 4:
+            return (int(s[:2]) * 3600 + int(s[2:]) * 60) * signal
+        elif len(s) == 6:
+            return (int(s[:2]) * 3600 + int(s[2:4]) * 60 + int(s[4:])) * signal
+        else:
+            raise ValueError("invalid offset: " + s)
+
+    def _parse_rfc(self, s):
+        lines = s.splitlines()
+        if not lines:
+            raise ValueError("empty string")
+
+        # Unfold
+        i = 0
+        while i < len(lines):
+            line = lines[i].rstrip()
+            if not line:
+                del lines[i]
+            elif i > 0 and line[0] == " ":
+                lines[i-1] += line[1:]
+                del lines[i]
+            else:
+                i += 1
+
+        tzid = None
+        comps = []
+        invtz = False
+        comptype = None
+        for line in lines:
+            if not line:
+                continue
+            name, value = line.split(':', 1)
+            parms = name.split(';')
+            if not parms:
+                raise ValueError("empty property name")
+            name = parms[0].upper()
+            parms = parms[1:]
+            if invtz:
+                if name == "BEGIN":
+                    if value in ("STANDARD", "DAYLIGHT"):
+                        # Process component
+                        pass
+                    else:
+                        raise ValueError("unknown component: "+value)
+                    comptype = value
+                    founddtstart = False
+                    tzoffsetfrom = None
+                    tzoffsetto = None
+                    rrulelines = []
+                    tzname = None
+                elif name == "END":
+                    if value == "VTIMEZONE":
+                        if comptype:
+                            raise ValueError("component not closed: "+comptype)
+                        if not tzid:
+                            raise ValueError("mandatory TZID not found")
+                        if not comps:
+                            raise ValueError(
+                                "at least one component is needed")
+                        # Process vtimezone
+                        self._vtz[tzid] = _tzicalvtz(tzid, comps)
+                        invtz = False
+                    elif value == comptype:
+                        if not founddtstart:
+                            raise ValueError("mandatory DTSTART not found")
+                        if tzoffsetfrom is None:
+                            raise ValueError(
+                                "mandatory TZOFFSETFROM not found")
+                        if tzoffsetto is None:
+                            raise ValueError(
+                                "mandatory TZOFFSETFROM not found")
+                        # Process component
+                        rr = None
+                        if rrulelines:
+                            rr = rrule.rrulestr("\n".join(rrulelines),
+                                                compatible=True,
+                                                ignoretz=True,
+                                                cache=True)
+                        comp = _tzicalvtzcomp(tzoffsetfrom, tzoffsetto,
+                                              (comptype == "DAYLIGHT"),
+                                              tzname, rr)
+                        comps.append(comp)
+                        comptype = None
+                    else:
+                        raise ValueError("invalid component end: "+value)
+                elif comptype:
+                    if name == "DTSTART":
+                        # DTSTART in VTIMEZONE takes a subset of valid RRULE
+                        # values under RFC 5545.
+                        for parm in parms:
+                            if parm != 'VALUE=DATE-TIME':
+                                msg = ('Unsupported DTSTART param in ' +
+                                       'VTIMEZONE: ' + parm)
+                                raise ValueError(msg)
+                        rrulelines.append(line)
+                        founddtstart = True
+                    elif name in ("RRULE", "RDATE", "EXRULE", "EXDATE"):
+                        rrulelines.append(line)
+                    elif name == "TZOFFSETFROM":
+                        if parms:
+                            raise ValueError(
+                                "unsupported %s parm: %s " % (name, parms[0]))
+                        tzoffsetfrom = self._parse_offset(value)
+                    elif name == "TZOFFSETTO":
+                        if parms:
+                            raise ValueError(
+                                "unsupported TZOFFSETTO parm: "+parms[0])
+                        tzoffsetto = self._parse_offset(value)
+                    elif name == "TZNAME":
+                        if parms:
+                            raise ValueError(
+                                "unsupported TZNAME parm: "+parms[0])
+                        tzname = value
+                    elif name == "COMMENT":
+                        pass
+                    else:
+                        raise ValueError("unsupported property: "+name)
+                else:
+                    if name == "TZID":
+                        if parms:
+                            raise ValueError(
+                                "unsupported TZID parm: "+parms[0])
+                        tzid = value
+                    elif name in ("TZURL", "LAST-MODIFIED", "COMMENT"):
+                        pass
+                    else:
+                        raise ValueError("unsupported property: "+name)
+            elif name == "BEGIN" and value == "VTIMEZONE":
+                tzid = None
+                comps = []
+                invtz = True
+
+    def __repr__(self):
+        return "%s(%s)" % (self.__class__.__name__, repr(self._s))
+
+
+if sys.platform != "win32":
+    TZFILES = ["/etc/localtime", "localtime"]
+    TZPATHS = ["/usr/share/zoneinfo",
+               "/usr/lib/zoneinfo",
+               "/usr/share/lib/zoneinfo",
+               "/etc/zoneinfo"]
+else:
+    TZFILES = []
+    TZPATHS = []
+
+
+def __get_gettz():
+    tzlocal_classes = (tzlocal,)
+    if tzwinlocal is not None:
+        tzlocal_classes += (tzwinlocal,)
+
+    class GettzFunc(object):
+        """
+        Retrieve a time zone object from a string representation
+
+        This function is intended to retrieve the :py:class:`tzinfo` subclass
+        that best represents the time zone that would be used if a POSIX
+        `TZ variable`_ were set to the same value.
+
+        If no argument or an empty string is passed to ``gettz``, local time
+        is returned:
+
+        .. code-block:: python3
+
+            >>> gettz()
+            tzfile('/etc/localtime')
+
+        This function is also the preferred way to map IANA tz database keys
+        to :class:`tzfile` objects:
+
+        .. code-block:: python3
+
+            >>> gettz('Pacific/Kiritimati')
+            tzfile('/usr/share/zoneinfo/Pacific/Kiritimati')
+
+        On Windows, the standard is extended to include the Windows-specific
+        zone names provided by the operating system:
+
+        .. code-block:: python3
+
+            >>> gettz('Egypt Standard Time')
+            tzwin('Egypt Standard Time')
+
+        Passing a GNU ``TZ`` style string time zone specification returns a
+        :class:`tzstr` object:
+
+        .. code-block:: python3
+
+            >>> gettz('AEST-10AEDT-11,M10.1.0/2,M4.1.0/3')
+            tzstr('AEST-10AEDT-11,M10.1.0/2,M4.1.0/3')
+
+        :param name:
+            A time zone name (IANA, or, on Windows, Windows keys), location of
+            a ``tzfile(5)`` zoneinfo file or ``TZ`` variable style time zone
+            specifier. An empty string, no argument or ``None`` is interpreted
+            as local time.
+
+        :return:
+            Returns an instance of one of ``dateutil``'s :py:class:`tzinfo`
+            subclasses.
+
+        .. versionchanged:: 2.7.0
+
+            After version 2.7.0, any two calls to ``gettz`` using the same
+            input strings will return the same object:
+
+            .. code-block:: python3
+
+                >>> tz.gettz('America/Chicago') is tz.gettz('America/Chicago')
+                True
+
+            In addition to improving performance, this ensures that
+            `"same zone" semantics`_ are used for datetimes in the same zone.
+
+
+        .. _`TZ variable`:
+            https://www.gnu.org/software/libc/manual/html_node/TZ-Variable.html
+
+        .. _`"same zone" semantics`:
+            https://blog.ganssle.io/articles/2018/02/aware-datetime-arithmetic.html
+        """
+        def __init__(self):
+
+            self.__instances = weakref.WeakValueDictionary()
+            self.__strong_cache_size = 8
+            self.__strong_cache = OrderedDict()
+            self._cache_lock = _thread.allocate_lock()
+
+        def __call__(self, name=None):
+            with self._cache_lock:
+                rv = self.__instances.get(name, None)
+
+                if rv is None:
+                    rv = self.nocache(name=name)
+                    if not (name is None
+                            or isinstance(rv, tzlocal_classes)
+                            or rv is None):
+                        # tzlocal is slightly more complicated than the other
+                        # time zone providers because it depends on environment
+                        # at construction time, so don't cache that.
+                        #
+                        # We also cannot store weak references to None, so we
+                        # will also not store that.
+                        self.__instances[name] = rv
+                    else:
+                        # No need for strong caching, return immediately
+                        return rv
+
+                self.__strong_cache[name] = self.__strong_cache.pop(name, rv)
+
+                if len(self.__strong_cache) > self.__strong_cache_size:
+                    self.__strong_cache.popitem(last=False)
+
+            return rv
+
+        def set_cache_size(self, size):
+            with self._cache_lock:
+                self.__strong_cache_size = size
+                while len(self.__strong_cache) > size:
+                    self.__strong_cache.popitem(last=False)
+
+        def cache_clear(self):
+            with self._cache_lock:
+                self.__instances = weakref.WeakValueDictionary()
+                self.__strong_cache.clear()
+
+        @staticmethod
+        def nocache(name=None):
+            """A non-cached version of gettz"""
+            tz = None
+            if not name:
+                try:
+                    name = os.environ["TZ"]
+                except KeyError:
+                    pass
+            if name is None or name == ":":
+                for filepath in TZFILES:
+                    if not os.path.isabs(filepath):
+                        filename = filepath
+                        for path in TZPATHS:
+                            filepath = os.path.join(path, filename)
+                            if os.path.isfile(filepath):
+                                break
+                        else:
+                            continue
+                    if os.path.isfile(filepath):
+                        try:
+                            tz = tzfile(filepath)
+                            break
+                        except (IOError, OSError, ValueError):
+                            pass
+                else:
+                    tz = tzlocal()
+            else:
+                try:
+                    if name.startswith(":"):
+                        name = name[1:]
+                except TypeError as e:
+                    if isinstance(name, bytes):
+                        new_msg = "gettz argument should be str, not bytes"
+                        six.raise_from(TypeError(new_msg), e)
+                    else:
+                        raise
+                if os.path.isabs(name):
+                    if os.path.isfile(name):
+                        tz = tzfile(name)
+                    else:
+                        tz = None
+                else:
+                    for path in TZPATHS:
+                        filepath = os.path.join(path, name)
+                        if not os.path.isfile(filepath):
+                            filepath = filepath.replace(' ', '_')
+                            if not os.path.isfile(filepath):
+                                continue
+                        try:
+                            tz = tzfile(filepath)
+                            break
+                        except (IOError, OSError, ValueError):
+                            pass
+                    else:
+                        tz = None
+                        if tzwin is not None:
+                            try:
+                                tz = tzwin(name)
+                            except (WindowsError, UnicodeEncodeError):
+                                # UnicodeEncodeError is for Python 2.7 compat
+                                tz = None
+
+                        if not tz:
+                            from dateutil.zoneinfo import get_zonefile_instance
+                            tz = get_zonefile_instance().get(name)
+
+                        if not tz:
+                            for c in name:
+                                # name is not a tzstr unless it has at least
+                                # one offset. For short values of "name", an
+                                # explicit for loop seems to be the fastest way
+                                # To determine if a string contains a digit
+                                if c in "0123456789":
+                                    try:
+                                        tz = tzstr(name)
+                                    except ValueError:
+                                        pass
+                                    break
+                            else:
+                                if name in ("GMT", "UTC"):
+                                    tz = UTC
+                                elif name in time.tzname:
+                                    tz = tzlocal()
+            return tz
+
+    return GettzFunc()
+
+
+gettz = __get_gettz()
+del __get_gettz
+
+
+def datetime_exists(dt, tz=None):
+    """
+    Given a datetime and a time zone, determine whether or not a given datetime
+    would fall in a gap.
+
+    :param dt:
+        A :class:`datetime.datetime` (whose time zone will be ignored if ``tz``
+        is provided.)
+
+    :param tz:
+        A :class:`datetime.tzinfo` with support for the ``fold`` attribute. If
+        ``None`` or not provided, the datetime's own time zone will be used.
+
+    :return:
+        Returns a boolean value whether or not the "wall time" exists in
+        ``tz``.
+
+    .. versionadded:: 2.7.0
+    """
+    if tz is None:
+        if dt.tzinfo is None:
+            raise ValueError('Datetime is naive and no time zone provided.')
+        tz = dt.tzinfo
+
+    dt = dt.replace(tzinfo=None)
+
+    # This is essentially a test of whether or not the datetime can survive
+    # a round trip to UTC.
+    dt_rt = dt.replace(tzinfo=tz).astimezone(UTC).astimezone(tz)
+    dt_rt = dt_rt.replace(tzinfo=None)
+
+    return dt == dt_rt
+
+
+def datetime_ambiguous(dt, tz=None):
+    """
+    Given a datetime and a time zone, determine whether or not a given datetime
+    is ambiguous (i.e if there are two times differentiated only by their DST
+    status).
+
+    :param dt:
+        A :class:`datetime.datetime` (whose time zone will be ignored if ``tz``
+        is provided.)
+
+    :param tz:
+        A :class:`datetime.tzinfo` with support for the ``fold`` attribute. If
+        ``None`` or not provided, the datetime's own time zone will be used.
+
+    :return:
+        Returns a boolean value whether or not the "wall time" is ambiguous in
+        ``tz``.
+
+    .. versionadded:: 2.6.0
+    """
+    if tz is None:
+        if dt.tzinfo is None:
+            raise ValueError('Datetime is naive and no time zone provided.')
+
+        tz = dt.tzinfo
+
+    # If a time zone defines its own "is_ambiguous" function, we'll use that.
+    is_ambiguous_fn = getattr(tz, 'is_ambiguous', None)
+    if is_ambiguous_fn is not None:
+        try:
+            return tz.is_ambiguous(dt)
+        except Exception:
+            pass
+
+    # If it doesn't come out and tell us it's ambiguous, we'll just check if
+    # the fold attribute has any effect on this particular date and time.
+    dt = dt.replace(tzinfo=tz)
+    wall_0 = enfold(dt, fold=0)
+    wall_1 = enfold(dt, fold=1)
+
+    same_offset = wall_0.utcoffset() == wall_1.utcoffset()
+    same_dst = wall_0.dst() == wall_1.dst()
+
+    return not (same_offset and same_dst)
+
+
+def resolve_imaginary(dt):
+    """
+    Given a datetime that may be imaginary, return an existing datetime.
+
+    This function assumes that an imaginary datetime represents what the
+    wall time would be in a zone had the offset transition not occurred, so
+    it will always fall forward by the transition's change in offset.
+
+    .. doctest::
+
+        >>> from dateutil import tz
+        >>> from datetime import datetime
+        >>> NYC = tz.gettz('America/New_York')
+        >>> print(tz.resolve_imaginary(datetime(2017, 3, 12, 2, 30, tzinfo=NYC)))
+        2017-03-12 03:30:00-04:00
+
+        >>> KIR = tz.gettz('Pacific/Kiritimati')
+        >>> print(tz.resolve_imaginary(datetime(1995, 1, 1, 12, 30, tzinfo=KIR)))
+        1995-01-02 12:30:00+14:00
+
+    As a note, :func:`datetime.astimezone` is guaranteed to produce a valid,
+    existing datetime, so a round-trip to and from UTC is sufficient to get
+    an extant datetime, however, this generally "falls back" to an earlier time
+    rather than falling forward to the STD side (though no guarantees are made
+    about this behavior).
+
+    :param dt:
+        A :class:`datetime.datetime` which may or may not exist.
+
+    :return:
+        Returns an existing :class:`datetime.datetime`. If ``dt`` was not
+        imaginary, the datetime returned is guaranteed to be the same object
+        passed to the function.
+
+    .. versionadded:: 2.7.0
+    """
+    if dt.tzinfo is not None and not datetime_exists(dt):
+
+        curr_offset = (dt + datetime.timedelta(hours=24)).utcoffset()
+        old_offset = (dt - datetime.timedelta(hours=24)).utcoffset()
+
+        dt += curr_offset - old_offset
+
+    return dt
+
+
+def _datetime_to_timestamp(dt):
+    """
+    Convert a :class:`datetime.datetime` object to an epoch timestamp in
+    seconds since January 1, 1970, ignoring the time zone.
+    """
+    return (dt.replace(tzinfo=None) - EPOCH).total_seconds()
+
+
+if sys.version_info >= (3, 6):
+    def _get_supported_offset(second_offset):
+        return second_offset
+else:
+    def _get_supported_offset(second_offset):
+        # For python pre-3.6, round to full-minutes if that's not the case.
+        # Python's datetime doesn't accept sub-minute timezones. Check
+        # http://python.org/sf/1447945 or https://bugs.python.org/issue5288
+        # for some information.
+        old_offset = second_offset
+        calculated_offset = 60 * ((second_offset + 30) // 60)
+        return calculated_offset
+
+
+try:
+    # Python 3.7 feature
+    from contextlib import nullcontext as _nullcontext
+except ImportError:
+    class _nullcontext(object):
+        """
+        Class for wrapping contexts so that they are passed through in a
+        with statement.
+        """
+        def __init__(self, context):
+            self.context = context
+
+        def __enter__(self):
+            return self.context
+
+        def __exit__(*args, **kwargs):
+            pass
+
+# vim:ts=4:sw=4:et
Index: latest/Lib/site-packages/psycopg2-2.8.6.dist-info/LICENSE
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/latest/Lib/site-packages/psycopg2-2.8.6.dist-info/LICENSE b/latest/Lib/site-packages/psycopg2-2.8.6.dist-info/LICENSE
new file mode 100644
--- /dev/null	(date 1616409347268)
+++ b/latest/Lib/site-packages/psycopg2-2.8.6.dist-info/LICENSE	(date 1616409347268)
@@ -0,0 +1,49 @@
+psycopg2 and the LGPL
+---------------------
+
+psycopg2 is free software: you can redistribute it and/or modify it
+under the terms of the GNU Lesser General Public License as published
+by the Free Software Foundation, either version 3 of the License, or
+(at your option) any later version.
+
+psycopg2 is distributed in the hope that it will be useful, but WITHOUT
+ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or
+FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public
+License for more details.
+
+In addition, as a special exception, the copyright holders give
+permission to link this program with the OpenSSL library (or with
+modified versions of OpenSSL that use the same license as OpenSSL),
+and distribute linked combinations including the two.
+
+You must obey the GNU Lesser General Public License in all respects for
+all of the code used other than OpenSSL. If you modify file(s) with this
+exception, you may extend this exception to your version of the file(s),
+but you are not obligated to do so. If you do not wish to do so, delete
+this exception statement from your version. If you delete this exception
+statement from all source files in the program, then also delete it here.
+
+You should have received a copy of the GNU Lesser General Public License
+along with psycopg2 (see the doc/ directory.)
+If not, see <https://www.gnu.org/licenses/>.
+
+
+Alternative licenses
+--------------------
+
+The following BSD-like license applies (at your option) to the files following
+the pattern ``psycopg/adapter*.{h,c}`` and ``psycopg/microprotocol*.{h,c}``:
+
+ Permission is granted to anyone to use this software for any purpose,
+ including commercial applications, and to alter it and redistribute it
+ freely, subject to the following restrictions:
+
+ 1. The origin of this software must not be misrepresented; you must not
+    claim that you wrote the original software. If you use this
+    software in a product, an acknowledgment in the product documentation
+    would be appreciated but is not required.
+
+ 2. Altered source versions must be plainly marked as such, and must not
+    be misrepresented as being the original software.
+
+ 3. This notice may not be removed or altered from any source distribution.
Index: venv/Lib/site-packages/dateutil/tz/win.py
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/venv/Lib/site-packages/dateutil/tz/win.py b/venv/Lib/site-packages/dateutil/tz/win.py
new file mode 100644
--- /dev/null	(date 1616406051845)
+++ b/venv/Lib/site-packages/dateutil/tz/win.py	(date 1616406051845)
@@ -0,0 +1,370 @@
+# -*- coding: utf-8 -*-
+"""
+This module provides an interface to the native time zone data on Windows,
+including :py:class:`datetime.tzinfo` implementations.
+
+Attempting to import this module on a non-Windows platform will raise an
+:py:obj:`ImportError`.
+"""
+# This code was originally contributed by Jeffrey Harris.
+import datetime
+import struct
+
+from six.moves import winreg
+from six import text_type
+
+try:
+    import ctypes
+    from ctypes import wintypes
+except ValueError:
+    # ValueError is raised on non-Windows systems for some horrible reason.
+    raise ImportError("Running tzwin on non-Windows system")
+
+from ._common import tzrangebase
+
+__all__ = ["tzwin", "tzwinlocal", "tzres"]
+
+ONEWEEK = datetime.timedelta(7)
+
+TZKEYNAMENT = r"SOFTWARE\Microsoft\Windows NT\CurrentVersion\Time Zones"
+TZKEYNAME9X = r"SOFTWARE\Microsoft\Windows\CurrentVersion\Time Zones"
+TZLOCALKEYNAME = r"SYSTEM\CurrentControlSet\Control\TimeZoneInformation"
+
+
+def _settzkeyname():
+    handle = winreg.ConnectRegistry(None, winreg.HKEY_LOCAL_MACHINE)
+    try:
+        winreg.OpenKey(handle, TZKEYNAMENT).Close()
+        TZKEYNAME = TZKEYNAMENT
+    except WindowsError:
+        TZKEYNAME = TZKEYNAME9X
+    handle.Close()
+    return TZKEYNAME
+
+
+TZKEYNAME = _settzkeyname()
+
+
+class tzres(object):
+    """
+    Class for accessing ``tzres.dll``, which contains timezone name related
+    resources.
+
+    .. versionadded:: 2.5.0
+    """
+    p_wchar = ctypes.POINTER(wintypes.WCHAR)        # Pointer to a wide char
+
+    def __init__(self, tzres_loc='tzres.dll'):
+        # Load the user32 DLL so we can load strings from tzres
+        user32 = ctypes.WinDLL('user32')
+
+        # Specify the LoadStringW function
+        user32.LoadStringW.argtypes = (wintypes.HINSTANCE,
+                                       wintypes.UINT,
+                                       wintypes.LPWSTR,
+                                       ctypes.c_int)
+
+        self.LoadStringW = user32.LoadStringW
+        self._tzres = ctypes.WinDLL(tzres_loc)
+        self.tzres_loc = tzres_loc
+
+    def load_name(self, offset):
+        """
+        Load a timezone name from a DLL offset (integer).
+
+        >>> from dateutil.tzwin import tzres
+        >>> tzr = tzres()
+        >>> print(tzr.load_name(112))
+        'Eastern Standard Time'
+
+        :param offset:
+            A positive integer value referring to a string from the tzres dll.
+
+        .. note::
+
+            Offsets found in the registry are generally of the form
+            ``@tzres.dll,-114``. The offset in this case is 114, not -114.
+
+        """
+        resource = self.p_wchar()
+        lpBuffer = ctypes.cast(ctypes.byref(resource), wintypes.LPWSTR)
+        nchar = self.LoadStringW(self._tzres._handle, offset, lpBuffer, 0)
+        return resource[:nchar]
+
+    def name_from_string(self, tzname_str):
+        """
+        Parse strings as returned from the Windows registry into the time zone
+        name as defined in the registry.
+
+        >>> from dateutil.tzwin import tzres
+        >>> tzr = tzres()
+        >>> print(tzr.name_from_string('@tzres.dll,-251'))
+        'Dateline Daylight Time'
+        >>> print(tzr.name_from_string('Eastern Standard Time'))
+        'Eastern Standard Time'
+
+        :param tzname_str:
+            A timezone name string as returned from a Windows registry key.
+
+        :return:
+            Returns the localized timezone string from tzres.dll if the string
+            is of the form `@tzres.dll,-offset`, else returns the input string.
+        """
+        if not tzname_str.startswith('@'):
+            return tzname_str
+
+        name_splt = tzname_str.split(',-')
+        try:
+            offset = int(name_splt[1])
+        except:
+            raise ValueError("Malformed timezone string.")
+
+        return self.load_name(offset)
+
+
+class tzwinbase(tzrangebase):
+    """tzinfo class based on win32's timezones available in the registry."""
+    def __init__(self):
+        raise NotImplementedError('tzwinbase is an abstract base class')
+
+    def __eq__(self, other):
+        # Compare on all relevant dimensions, including name.
+        if not isinstance(other, tzwinbase):
+            return NotImplemented
+
+        return  (self._std_offset == other._std_offset and
+                 self._dst_offset == other._dst_offset and
+                 self._stddayofweek == other._stddayofweek and
+                 self._dstdayofweek == other._dstdayofweek and
+                 self._stdweeknumber == other._stdweeknumber and
+                 self._dstweeknumber == other._dstweeknumber and
+                 self._stdhour == other._stdhour and
+                 self._dsthour == other._dsthour and
+                 self._stdminute == other._stdminute and
+                 self._dstminute == other._dstminute and
+                 self._std_abbr == other._std_abbr and
+                 self._dst_abbr == other._dst_abbr)
+
+    @staticmethod
+    def list():
+        """Return a list of all time zones known to the system."""
+        with winreg.ConnectRegistry(None, winreg.HKEY_LOCAL_MACHINE) as handle:
+            with winreg.OpenKey(handle, TZKEYNAME) as tzkey:
+                result = [winreg.EnumKey(tzkey, i)
+                          for i in range(winreg.QueryInfoKey(tzkey)[0])]
+        return result
+
+    def display(self):
+        """
+        Return the display name of the time zone.
+        """
+        return self._display
+
+    def transitions(self, year):
+        """
+        For a given year, get the DST on and off transition times, expressed
+        always on the standard time side. For zones with no transitions, this
+        function returns ``None``.
+
+        :param year:
+            The year whose transitions you would like to query.
+
+        :return:
+            Returns a :class:`tuple` of :class:`datetime.datetime` objects,
+            ``(dston, dstoff)`` for zones with an annual DST transition, or
+            ``None`` for fixed offset zones.
+        """
+
+        if not self.hasdst:
+            return None
+
+        dston = picknthweekday(year, self._dstmonth, self._dstdayofweek,
+                               self._dsthour, self._dstminute,
+                               self._dstweeknumber)
+
+        dstoff = picknthweekday(year, self._stdmonth, self._stddayofweek,
+                                self._stdhour, self._stdminute,
+                                self._stdweeknumber)
+
+        # Ambiguous dates default to the STD side
+        dstoff -= self._dst_base_offset
+
+        return dston, dstoff
+
+    def _get_hasdst(self):
+        return self._dstmonth != 0
+
+    @property
+    def _dst_base_offset(self):
+        return self._dst_base_offset_
+
+
+class tzwin(tzwinbase):
+    """
+    Time zone object created from the zone info in the Windows registry
+
+    These are similar to :py:class:`dateutil.tz.tzrange` objects in that
+    the time zone data is provided in the format of a single offset rule
+    for either 0 or 2 time zone transitions per year.
+
+    :param: name
+        The name of a Windows time zone key, e.g. "Eastern Standard Time".
+        The full list of keys can be retrieved with :func:`tzwin.list`.
+    """
+
+    def __init__(self, name):
+        self._name = name
+
+        with winreg.ConnectRegistry(None, winreg.HKEY_LOCAL_MACHINE) as handle:
+            tzkeyname = text_type("{kn}\\{name}").format(kn=TZKEYNAME, name=name)
+            with winreg.OpenKey(handle, tzkeyname) as tzkey:
+                keydict = valuestodict(tzkey)
+
+        self._std_abbr = keydict["Std"]
+        self._dst_abbr = keydict["Dlt"]
+
+        self._display = keydict["Display"]
+
+        # See http://ww_winreg.jsiinc.com/SUBA/tip0300/rh0398.htm
+        tup = struct.unpack("=3l16h", keydict["TZI"])
+        stdoffset = -tup[0]-tup[1]          # Bias + StandardBias * -1
+        dstoffset = stdoffset-tup[2]        # + DaylightBias * -1
+        self._std_offset = datetime.timedelta(minutes=stdoffset)
+        self._dst_offset = datetime.timedelta(minutes=dstoffset)
+
+        # for the meaning see the win32 TIME_ZONE_INFORMATION structure docs
+        # http://msdn.microsoft.com/en-us/library/windows/desktop/ms725481(v=vs.85).aspx
+        (self._stdmonth,
+         self._stddayofweek,   # Sunday = 0
+         self._stdweeknumber,  # Last = 5
+         self._stdhour,
+         self._stdminute) = tup[4:9]
+
+        (self._dstmonth,
+         self._dstdayofweek,   # Sunday = 0
+         self._dstweeknumber,  # Last = 5
+         self._dsthour,
+         self._dstminute) = tup[12:17]
+
+        self._dst_base_offset_ = self._dst_offset - self._std_offset
+        self.hasdst = self._get_hasdst()
+
+    def __repr__(self):
+        return "tzwin(%s)" % repr(self._name)
+
+    def __reduce__(self):
+        return (self.__class__, (self._name,))
+
+
+class tzwinlocal(tzwinbase):
+    """
+    Class representing the local time zone information in the Windows registry
+
+    While :class:`dateutil.tz.tzlocal` makes system calls (via the :mod:`time`
+    module) to retrieve time zone information, ``tzwinlocal`` retrieves the
+    rules directly from the Windows registry and creates an object like
+    :class:`dateutil.tz.tzwin`.
+
+    Because Windows does not have an equivalent of :func:`time.tzset`, on
+    Windows, :class:`dateutil.tz.tzlocal` instances will always reflect the
+    time zone settings *at the time that the process was started*, meaning
+    changes to the machine's time zone settings during the run of a program
+    on Windows will **not** be reflected by :class:`dateutil.tz.tzlocal`.
+    Because ``tzwinlocal`` reads the registry directly, it is unaffected by
+    this issue.
+    """
+    def __init__(self):
+        with winreg.ConnectRegistry(None, winreg.HKEY_LOCAL_MACHINE) as handle:
+            with winreg.OpenKey(handle, TZLOCALKEYNAME) as tzlocalkey:
+                keydict = valuestodict(tzlocalkey)
+
+            self._std_abbr = keydict["StandardName"]
+            self._dst_abbr = keydict["DaylightName"]
+
+            try:
+                tzkeyname = text_type('{kn}\\{sn}').format(kn=TZKEYNAME,
+                                                          sn=self._std_abbr)
+                with winreg.OpenKey(handle, tzkeyname) as tzkey:
+                    _keydict = valuestodict(tzkey)
+                    self._display = _keydict["Display"]
+            except OSError:
+                self._display = None
+
+        stdoffset = -keydict["Bias"]-keydict["StandardBias"]
+        dstoffset = stdoffset-keydict["DaylightBias"]
+
+        self._std_offset = datetime.timedelta(minutes=stdoffset)
+        self._dst_offset = datetime.timedelta(minutes=dstoffset)
+
+        # For reasons unclear, in this particular key, the day of week has been
+        # moved to the END of the SYSTEMTIME structure.
+        tup = struct.unpack("=8h", keydict["StandardStart"])
+
+        (self._stdmonth,
+         self._stdweeknumber,  # Last = 5
+         self._stdhour,
+         self._stdminute) = tup[1:5]
+
+        self._stddayofweek = tup[7]
+
+        tup = struct.unpack("=8h", keydict["DaylightStart"])
+
+        (self._dstmonth,
+         self._dstweeknumber,  # Last = 5
+         self._dsthour,
+         self._dstminute) = tup[1:5]
+
+        self._dstdayofweek = tup[7]
+
+        self._dst_base_offset_ = self._dst_offset - self._std_offset
+        self.hasdst = self._get_hasdst()
+
+    def __repr__(self):
+        return "tzwinlocal()"
+
+    def __str__(self):
+        # str will return the standard name, not the daylight name.
+        return "tzwinlocal(%s)" % repr(self._std_abbr)
+
+    def __reduce__(self):
+        return (self.__class__, ())
+
+
+def picknthweekday(year, month, dayofweek, hour, minute, whichweek):
+    """ dayofweek == 0 means Sunday, whichweek 5 means last instance """
+    first = datetime.datetime(year, month, 1, hour, minute)
+
+    # This will work if dayofweek is ISO weekday (1-7) or Microsoft-style (0-6),
+    # Because 7 % 7 = 0
+    weekdayone = first.replace(day=((dayofweek - first.isoweekday()) % 7) + 1)
+    wd = weekdayone + ((whichweek - 1) * ONEWEEK)
+    if (wd.month != month):
+        wd -= ONEWEEK
+
+    return wd
+
+
+def valuestodict(key):
+    """Convert a registry key's values to a dictionary."""
+    dout = {}
+    size = winreg.QueryInfoKey(key)[1]
+    tz_res = None
+
+    for i in range(size):
+        key_name, value, dtype = winreg.EnumValue(key, i)
+        if dtype == winreg.REG_DWORD or dtype == winreg.REG_DWORD_LITTLE_ENDIAN:
+            # If it's a DWORD (32-bit integer), it's stored as unsigned - convert
+            # that to a proper signed integer
+            if value & (1 << 31):
+                value = value - (1 << 32)
+        elif dtype == winreg.REG_SZ:
+            # If it's a reference to the tzres DLL, load the actual string
+            if value.startswith('@tzres'):
+                tz_res = tz_res or tzres()
+                value = tz_res.name_from_string(value)
+
+            value = value.rstrip('\x00')    # Remove trailing nulls
+
+        dout[key_name] = value
+
+    return dout
Index: latest/Lib/site-packages/psycopg2-2.8.6.dist-info/METADATA
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/latest/Lib/site-packages/psycopg2-2.8.6.dist-info/METADATA b/latest/Lib/site-packages/psycopg2-2.8.6.dist-info/METADATA
new file mode 100644
--- /dev/null	(date 1616409347270)
+++ b/latest/Lib/site-packages/psycopg2-2.8.6.dist-info/METADATA	(date 1616409347270)
@@ -0,0 +1,111 @@
+Metadata-Version: 2.1
+Name: psycopg2
+Version: 2.8.6
+Summary: psycopg2 - Python-PostgreSQL Database Adapter
+Home-page: https://psycopg.org/
+Author: Federico Di Gregorio
+Author-email: fog@initd.org
+Maintainer: Daniele Varrazzo
+Maintainer-email: daniele.varrazzo@gmail.org
+License: LGPL with exceptions
+Project-URL: Homepage, https://psycopg.org/
+Project-URL: Documentation, https://www.psycopg.org/docs/
+Project-URL: Code, https://github.com/psycopg/psycopg2
+Project-URL: Issue Tracker, https://github.com/psycopg/psycopg2/issues
+Project-URL: Download, https://pypi.org/project/psycopg2/
+Platform: any
+Classifier: Development Status :: 5 - Production/Stable
+Classifier: Intended Audience :: Developers
+Classifier: License :: OSI Approved :: GNU Library or Lesser General Public License (LGPL)
+Classifier: Programming Language :: Python
+Classifier: Programming Language :: Python :: 2
+Classifier: Programming Language :: Python :: 2.7
+Classifier: Programming Language :: Python :: 3
+Classifier: Programming Language :: Python :: 3.4
+Classifier: Programming Language :: Python :: 3.5
+Classifier: Programming Language :: Python :: 3.6
+Classifier: Programming Language :: Python :: 3.7
+Classifier: Programming Language :: Python :: 3.8
+Classifier: Programming Language :: Python :: Implementation :: CPython
+Classifier: Programming Language :: C
+Classifier: Programming Language :: SQL
+Classifier: Topic :: Database
+Classifier: Topic :: Database :: Front-Ends
+Classifier: Topic :: Software Development
+Classifier: Topic :: Software Development :: Libraries :: Python Modules
+Classifier: Operating System :: Microsoft :: Windows
+Classifier: Operating System :: Unix
+Requires-Python: >=2.7,!=3.0.*,!=3.1.*,!=3.2.*,!=3.3.*
+
+Psycopg is the most popular PostgreSQL database adapter for the Python
+programming language.  Its main features are the complete implementation of
+the Python DB API 2.0 specification and the thread safety (several threads can
+share the same connection).  It was designed for heavily multi-threaded
+applications that create and destroy lots of cursors and make a large number
+of concurrent "INSERT"s or "UPDATE"s.
+
+Psycopg 2 is mostly implemented in C as a libpq wrapper, resulting in being
+both efficient and secure.  It features client-side and server-side cursors,
+asynchronous communication and notifications, "COPY TO/COPY FROM" support.
+Many Python types are supported out-of-the-box and adapted to matching
+PostgreSQL data types; adaptation can be extended and customized thanks to a
+flexible objects adaptation system.
+
+Psycopg 2 is both Unicode and Python 3 friendly.
+
+
+Documentation
+-------------
+
+Documentation is included in the ``doc`` directory and is `available online`__.
+
+.. __: https://www.psycopg.org/docs/
+
+For any other resource (source code repository, bug tracker, mailing list)
+please check the `project homepage`__.
+
+.. __: https://psycopg.org/
+
+
+Installation
+------------
+
+Building Psycopg requires a few prerequisites (a C compiler, some development
+packages): please check the install_ and the faq_ documents in the ``doc`` dir
+or online for the details.
+
+If prerequisites are met, you can install psycopg like any other Python
+package, using ``pip`` to download it from PyPI_::
+
+    $ pip install psycopg2
+
+or using ``setup.py`` if you have downloaded the source package locally::
+
+    $ python setup.py build
+    $ sudo python setup.py install
+
+You can also obtain a stand-alone package, not requiring a compiler or
+external libraries, by installing the `psycopg2-binary`_ package from PyPI::
+
+    $ pip install psycopg2-binary
+
+The binary package is a practical choice for development and testing but in
+production it is advised to use the package built from sources.
+
+.. _PyPI: https://pypi.org/project/psycopg2/
+.. _psycopg2-binary: https://pypi.org/project/psycopg2-binary/
+.. _install: https://www.psycopg.org/docs/install.html#install-from-source
+.. _faq: https://www.psycopg.org/docs/faq.html#faq-compile
+
+:Linux/OSX: |travis|
+:Windows: |appveyor|
+
+.. |travis| image:: https://travis-ci.org/psycopg/psycopg2.svg?branch=master
+    :target: https://travis-ci.org/psycopg/psycopg2
+    :alt: Linux and OSX build status
+
+.. |appveyor| image:: https://ci.appveyor.com/api/projects/status/github/psycopg/psycopg2?branch=master&svg=true
+    :target: https://ci.appveyor.com/project/psycopg/psycopg2/branch/master
+    :alt: Windows build status
+
+
Index: venv/Lib/site-packages/dateutil/tz/_common.py
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/venv/Lib/site-packages/dateutil/tz/_common.py b/venv/Lib/site-packages/dateutil/tz/_common.py
new file mode 100644
--- /dev/null	(date 1616406051845)
+++ b/venv/Lib/site-packages/dateutil/tz/_common.py	(date 1616406051845)
@@ -0,0 +1,419 @@
+from six import PY2
+
+from functools import wraps
+
+from datetime import datetime, timedelta, tzinfo
+
+
+ZERO = timedelta(0)
+
+__all__ = ['tzname_in_python2', 'enfold']
+
+
+def tzname_in_python2(namefunc):
+    """Change unicode output into bytestrings in Python 2
+
+    tzname() API changed in Python 3. It used to return bytes, but was changed
+    to unicode strings
+    """
+    if PY2:
+        @wraps(namefunc)
+        def adjust_encoding(*args, **kwargs):
+            name = namefunc(*args, **kwargs)
+            if name is not None:
+                name = name.encode()
+
+            return name
+
+        return adjust_encoding
+    else:
+        return namefunc
+
+
+# The following is adapted from Alexander Belopolsky's tz library
+# https://github.com/abalkin/tz
+if hasattr(datetime, 'fold'):
+    # This is the pre-python 3.6 fold situation
+    def enfold(dt, fold=1):
+        """
+        Provides a unified interface for assigning the ``fold`` attribute to
+        datetimes both before and after the implementation of PEP-495.
+
+        :param fold:
+            The value for the ``fold`` attribute in the returned datetime. This
+            should be either 0 or 1.
+
+        :return:
+            Returns an object for which ``getattr(dt, 'fold', 0)`` returns
+            ``fold`` for all versions of Python. In versions prior to
+            Python 3.6, this is a ``_DatetimeWithFold`` object, which is a
+            subclass of :py:class:`datetime.datetime` with the ``fold``
+            attribute added, if ``fold`` is 1.
+
+        .. versionadded:: 2.6.0
+        """
+        return dt.replace(fold=fold)
+
+else:
+    class _DatetimeWithFold(datetime):
+        """
+        This is a class designed to provide a PEP 495-compliant interface for
+        Python versions before 3.6. It is used only for dates in a fold, so
+        the ``fold`` attribute is fixed at ``1``.
+
+        .. versionadded:: 2.6.0
+        """
+        __slots__ = ()
+
+        def replace(self, *args, **kwargs):
+            """
+            Return a datetime with the same attributes, except for those
+            attributes given new values by whichever keyword arguments are
+            specified. Note that tzinfo=None can be specified to create a naive
+            datetime from an aware datetime with no conversion of date and time
+            data.
+
+            This is reimplemented in ``_DatetimeWithFold`` because pypy3 will
+            return a ``datetime.datetime`` even if ``fold`` is unchanged.
+            """
+            argnames = (
+                'year', 'month', 'day', 'hour', 'minute', 'second',
+                'microsecond', 'tzinfo'
+            )
+
+            for arg, argname in zip(args, argnames):
+                if argname in kwargs:
+                    raise TypeError('Duplicate argument: {}'.format(argname))
+
+                kwargs[argname] = arg
+
+            for argname in argnames:
+                if argname not in kwargs:
+                    kwargs[argname] = getattr(self, argname)
+
+            dt_class = self.__class__ if kwargs.get('fold', 1) else datetime
+
+            return dt_class(**kwargs)
+
+        @property
+        def fold(self):
+            return 1
+
+    def enfold(dt, fold=1):
+        """
+        Provides a unified interface for assigning the ``fold`` attribute to
+        datetimes both before and after the implementation of PEP-495.
+
+        :param fold:
+            The value for the ``fold`` attribute in the returned datetime. This
+            should be either 0 or 1.
+
+        :return:
+            Returns an object for which ``getattr(dt, 'fold', 0)`` returns
+            ``fold`` for all versions of Python. In versions prior to
+            Python 3.6, this is a ``_DatetimeWithFold`` object, which is a
+            subclass of :py:class:`datetime.datetime` with the ``fold``
+            attribute added, if ``fold`` is 1.
+
+        .. versionadded:: 2.6.0
+        """
+        if getattr(dt, 'fold', 0) == fold:
+            return dt
+
+        args = dt.timetuple()[:6]
+        args += (dt.microsecond, dt.tzinfo)
+
+        if fold:
+            return _DatetimeWithFold(*args)
+        else:
+            return datetime(*args)
+
+
+def _validate_fromutc_inputs(f):
+    """
+    The CPython version of ``fromutc`` checks that the input is a ``datetime``
+    object and that ``self`` is attached as its ``tzinfo``.
+    """
+    @wraps(f)
+    def fromutc(self, dt):
+        if not isinstance(dt, datetime):
+            raise TypeError("fromutc() requires a datetime argument")
+        if dt.tzinfo is not self:
+            raise ValueError("dt.tzinfo is not self")
+
+        return f(self, dt)
+
+    return fromutc
+
+
+class _tzinfo(tzinfo):
+    """
+    Base class for all ``dateutil`` ``tzinfo`` objects.
+    """
+
+    def is_ambiguous(self, dt):
+        """
+        Whether or not the "wall time" of a given datetime is ambiguous in this
+        zone.
+
+        :param dt:
+            A :py:class:`datetime.datetime`, naive or time zone aware.
+
+
+        :return:
+            Returns ``True`` if ambiguous, ``False`` otherwise.
+
+        .. versionadded:: 2.6.0
+        """
+
+        dt = dt.replace(tzinfo=self)
+
+        wall_0 = enfold(dt, fold=0)
+        wall_1 = enfold(dt, fold=1)
+
+        same_offset = wall_0.utcoffset() == wall_1.utcoffset()
+        same_dt = wall_0.replace(tzinfo=None) == wall_1.replace(tzinfo=None)
+
+        return same_dt and not same_offset
+
+    def _fold_status(self, dt_utc, dt_wall):
+        """
+        Determine the fold status of a "wall" datetime, given a representation
+        of the same datetime as a (naive) UTC datetime. This is calculated based
+        on the assumption that ``dt.utcoffset() - dt.dst()`` is constant for all
+        datetimes, and that this offset is the actual number of hours separating
+        ``dt_utc`` and ``dt_wall``.
+
+        :param dt_utc:
+            Representation of the datetime as UTC
+
+        :param dt_wall:
+            Representation of the datetime as "wall time". This parameter must
+            either have a `fold` attribute or have a fold-naive
+            :class:`datetime.tzinfo` attached, otherwise the calculation may
+            fail.
+        """
+        if self.is_ambiguous(dt_wall):
+            delta_wall = dt_wall - dt_utc
+            _fold = int(delta_wall == (dt_utc.utcoffset() - dt_utc.dst()))
+        else:
+            _fold = 0
+
+        return _fold
+
+    def _fold(self, dt):
+        return getattr(dt, 'fold', 0)
+
+    def _fromutc(self, dt):
+        """
+        Given a timezone-aware datetime in a given timezone, calculates a
+        timezone-aware datetime in a new timezone.
+
+        Since this is the one time that we *know* we have an unambiguous
+        datetime object, we take this opportunity to determine whether the
+        datetime is ambiguous and in a "fold" state (e.g. if it's the first
+        occurrence, chronologically, of the ambiguous datetime).
+
+        :param dt:
+            A timezone-aware :class:`datetime.datetime` object.
+        """
+
+        # Re-implement the algorithm from Python's datetime.py
+        dtoff = dt.utcoffset()
+        if dtoff is None:
+            raise ValueError("fromutc() requires a non-None utcoffset() "
+                             "result")
+
+        # The original datetime.py code assumes that `dst()` defaults to
+        # zero during ambiguous times. PEP 495 inverts this presumption, so
+        # for pre-PEP 495 versions of python, we need to tweak the algorithm.
+        dtdst = dt.dst()
+        if dtdst is None:
+            raise ValueError("fromutc() requires a non-None dst() result")
+        delta = dtoff - dtdst
+
+        dt += delta
+        # Set fold=1 so we can default to being in the fold for
+        # ambiguous dates.
+        dtdst = enfold(dt, fold=1).dst()
+        if dtdst is None:
+            raise ValueError("fromutc(): dt.dst gave inconsistent "
+                             "results; cannot convert")
+        return dt + dtdst
+
+    @_validate_fromutc_inputs
+    def fromutc(self, dt):
+        """
+        Given a timezone-aware datetime in a given timezone, calculates a
+        timezone-aware datetime in a new timezone.
+
+        Since this is the one time that we *know* we have an unambiguous
+        datetime object, we take this opportunity to determine whether the
+        datetime is ambiguous and in a "fold" state (e.g. if it's the first
+        occurrence, chronologically, of the ambiguous datetime).
+
+        :param dt:
+            A timezone-aware :class:`datetime.datetime` object.
+        """
+        dt_wall = self._fromutc(dt)
+
+        # Calculate the fold status given the two datetimes.
+        _fold = self._fold_status(dt, dt_wall)
+
+        # Set the default fold value for ambiguous dates
+        return enfold(dt_wall, fold=_fold)
+
+
+class tzrangebase(_tzinfo):
+    """
+    This is an abstract base class for time zones represented by an annual
+    transition into and out of DST. Child classes should implement the following
+    methods:
+
+        * ``__init__(self, *args, **kwargs)``
+        * ``transitions(self, year)`` - this is expected to return a tuple of
+          datetimes representing the DST on and off transitions in standard
+          time.
+
+    A fully initialized ``tzrangebase`` subclass should also provide the
+    following attributes:
+        * ``hasdst``: Boolean whether or not the zone uses DST.
+        * ``_dst_offset`` / ``_std_offset``: :class:`datetime.timedelta` objects
+          representing the respective UTC offsets.
+        * ``_dst_abbr`` / ``_std_abbr``: Strings representing the timezone short
+          abbreviations in DST and STD, respectively.
+        * ``_hasdst``: Whether or not the zone has DST.
+
+    .. versionadded:: 2.6.0
+    """
+    def __init__(self):
+        raise NotImplementedError('tzrangebase is an abstract base class')
+
+    def utcoffset(self, dt):
+        isdst = self._isdst(dt)
+
+        if isdst is None:
+            return None
+        elif isdst:
+            return self._dst_offset
+        else:
+            return self._std_offset
+
+    def dst(self, dt):
+        isdst = self._isdst(dt)
+
+        if isdst is None:
+            return None
+        elif isdst:
+            return self._dst_base_offset
+        else:
+            return ZERO
+
+    @tzname_in_python2
+    def tzname(self, dt):
+        if self._isdst(dt):
+            return self._dst_abbr
+        else:
+            return self._std_abbr
+
+    def fromutc(self, dt):
+        """ Given a datetime in UTC, return local time """
+        if not isinstance(dt, datetime):
+            raise TypeError("fromutc() requires a datetime argument")
+
+        if dt.tzinfo is not self:
+            raise ValueError("dt.tzinfo is not self")
+
+        # Get transitions - if there are none, fixed offset
+        transitions = self.transitions(dt.year)
+        if transitions is None:
+            return dt + self.utcoffset(dt)
+
+        # Get the transition times in UTC
+        dston, dstoff = transitions
+
+        dston -= self._std_offset
+        dstoff -= self._std_offset
+
+        utc_transitions = (dston, dstoff)
+        dt_utc = dt.replace(tzinfo=None)
+
+        isdst = self._naive_isdst(dt_utc, utc_transitions)
+
+        if isdst:
+            dt_wall = dt + self._dst_offset
+        else:
+            dt_wall = dt + self._std_offset
+
+        _fold = int(not isdst and self.is_ambiguous(dt_wall))
+
+        return enfold(dt_wall, fold=_fold)
+
+    def is_ambiguous(self, dt):
+        """
+        Whether or not the "wall time" of a given datetime is ambiguous in this
+        zone.
+
+        :param dt:
+            A :py:class:`datetime.datetime`, naive or time zone aware.
+
+
+        :return:
+            Returns ``True`` if ambiguous, ``False`` otherwise.
+
+        .. versionadded:: 2.6.0
+        """
+        if not self.hasdst:
+            return False
+
+        start, end = self.transitions(dt.year)
+
+        dt = dt.replace(tzinfo=None)
+        return (end <= dt < end + self._dst_base_offset)
+
+    def _isdst(self, dt):
+        if not self.hasdst:
+            return False
+        elif dt is None:
+            return None
+
+        transitions = self.transitions(dt.year)
+
+        if transitions is None:
+            return False
+
+        dt = dt.replace(tzinfo=None)
+
+        isdst = self._naive_isdst(dt, transitions)
+
+        # Handle ambiguous dates
+        if not isdst and self.is_ambiguous(dt):
+            return not self._fold(dt)
+        else:
+            return isdst
+
+    def _naive_isdst(self, dt, transitions):
+        dston, dstoff = transitions
+
+        dt = dt.replace(tzinfo=None)
+
+        if dston < dstoff:
+            isdst = dston <= dt < dstoff
+        else:
+            isdst = not dstoff <= dt < dston
+
+        return isdst
+
+    @property
+    def _dst_base_offset(self):
+        return self._dst_offset - self._std_offset
+
+    __hash__ = None
+
+    def __ne__(self, other):
+        return not (self == other)
+
+    def __repr__(self):
+        return "%s(...)" % self.__class__.__name__
+
+    __reduce__ = object.__reduce__
Index: latest/Lib/site-packages/psycopg2-2.8.6.dist-info/RECORD
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/latest/Lib/site-packages/psycopg2-2.8.6.dist-info/RECORD b/latest/Lib/site-packages/psycopg2-2.8.6.dist-info/RECORD
new file mode 100644
--- /dev/null	(date 1616409347916)
+++ b/latest/Lib/site-packages/psycopg2-2.8.6.dist-info/RECORD	(date 1616409347916)
@@ -0,0 +1,34 @@
+psycopg2-2.8.6.dist-info/INSTALLER,sha256=zuuue4knoyJ-UwPPXg8fezS7VCrXJQrAP7zeNuwvFQg,4
+psycopg2-2.8.6.dist-info/LICENSE,sha256=lhS4XfyacsWyyjMUTB1-HtOxwpdFnZ-yimpXYsLo1xs,2238
+psycopg2-2.8.6.dist-info/METADATA,sha256=htTa9QsaWzb-w-SRFJ9QVhgvA_61CejAgm6mNwAzTLA,4389
+psycopg2-2.8.6.dist-info/RECORD,,
+psycopg2-2.8.6.dist-info/REQUESTED,sha256=47DEQpj8HBSa-_TImW-5JCeuQeRkm5NMpJWZG3hSuFU,0
+psycopg2-2.8.6.dist-info/WHEEL,sha256=2Kg4PzfJLrLEnxRV1e1jZf0TVEjxVcXZXjp8WtjE4tI,105
+psycopg2-2.8.6.dist-info/top_level.txt,sha256=7dHGpLqQ3w-vGmGEVn-7uK90qU9fyrGdWWi7S-gTcnM,9
+psycopg2/__init__.py,sha256=f1RIT_o7T7LU9OYn1RAbbGvOZFv1S0y3250h6nuKoSQ,4916
+psycopg2/__pycache__/__init__.cpython-39.pyc,,
+psycopg2/__pycache__/_ipaddress.cpython-39.pyc,,
+psycopg2/__pycache__/_json.cpython-39.pyc,,
+psycopg2/__pycache__/_lru_cache.cpython-39.pyc,,
+psycopg2/__pycache__/_range.cpython-39.pyc,,
+psycopg2/__pycache__/compat.cpython-39.pyc,,
+psycopg2/__pycache__/errorcodes.cpython-39.pyc,,
+psycopg2/__pycache__/errors.cpython-39.pyc,,
+psycopg2/__pycache__/extensions.cpython-39.pyc,,
+psycopg2/__pycache__/extras.cpython-39.pyc,,
+psycopg2/__pycache__/pool.cpython-39.pyc,,
+psycopg2/__pycache__/sql.cpython-39.pyc,,
+psycopg2/__pycache__/tz.cpython-39.pyc,,
+psycopg2/_ipaddress.py,sha256=VTb0XXYHHhwdAgFwGt8mGQvPzcVCah2XVSNYlpW5AzI,2967
+psycopg2/_json.py,sha256=IRUpp3zIdrhw7cv5PdoXHsjEGHBeW9-vArKpxY9R7IU,7296
+psycopg2/_lru_cache.py,sha256=DhDTMD9aQsMcLYHyg8bAunlh62TKljZ6bLAlWd5tTrc,4261
+psycopg2/_psycopg.cp39-win_amd64.pyd,sha256=w81tneSq1KkgboGjXJAKqGhNU2gWgNl5dlxuZ7-YNEc,2399744
+psycopg2/_range.py,sha256=XsuiPZ-6mf9W8vxlBsp7zqwKOQPCac_vLVvEyPhthA4,17705
+psycopg2/compat.py,sha256=YAozNHFrE--nrjvV-g4kHPLbcmhOKVGVN84zo58VOqA,367
+psycopg2/errorcodes.py,sha256=MRcquTgL_7iTmk8x47MA6KM5Z1-MK0trPZc5KZCnxTQ,14273
+psycopg2/errors.py,sha256=iaaJeyL2pU9oMt9MsLaNlOPZipR0BXL0kOKABV2Tu_g,1420
+psycopg2/extensions.py,sha256=T99Lv2oAYC_pjSuYDNVj2xVmWz9gO_S4KmnUEbZcCHs,7122
+psycopg2/extras.py,sha256=pGt1UJdZkVaXDWjXz21kP7JEqEH0ER5FhemiOTmkXNw,44182
+psycopg2/pool.py,sha256=NdulUZrkF2h-Nv_hOX5RXUz6WeiL0WCnbIkxIgAMjPM,6319
+psycopg2/sql.py,sha256=RL1AGbpT5xzzVRNYxpeGbgMUojpkyqzwTZK1PNZUwWY,14903
+psycopg2/tz.py,sha256=_DahbM5JJtkiFzVyyhNWX2RbjDUTASd4xDWVGQAGP-c,4446
Index: venv/Lib/site-packages/dateutil/tz/_factories.py
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/venv/Lib/site-packages/dateutil/tz/_factories.py b/venv/Lib/site-packages/dateutil/tz/_factories.py
new file mode 100644
--- /dev/null	(date 1616406051845)
+++ b/venv/Lib/site-packages/dateutil/tz/_factories.py	(date 1616406051845)
@@ -0,0 +1,80 @@
+from datetime import timedelta
+import weakref
+from collections import OrderedDict
+
+from six.moves import _thread
+
+
+class _TzSingleton(type):
+    def __init__(cls, *args, **kwargs):
+        cls.__instance = None
+        super(_TzSingleton, cls).__init__(*args, **kwargs)
+
+    def __call__(cls):
+        if cls.__instance is None:
+            cls.__instance = super(_TzSingleton, cls).__call__()
+        return cls.__instance
+
+
+class _TzFactory(type):
+    def instance(cls, *args, **kwargs):
+        """Alternate constructor that returns a fresh instance"""
+        return type.__call__(cls, *args, **kwargs)
+
+
+class _TzOffsetFactory(_TzFactory):
+    def __init__(cls, *args, **kwargs):
+        cls.__instances = weakref.WeakValueDictionary()
+        cls.__strong_cache = OrderedDict()
+        cls.__strong_cache_size = 8
+
+        cls._cache_lock = _thread.allocate_lock()
+
+    def __call__(cls, name, offset):
+        if isinstance(offset, timedelta):
+            key = (name, offset.total_seconds())
+        else:
+            key = (name, offset)
+
+        instance = cls.__instances.get(key, None)
+        if instance is None:
+            instance = cls.__instances.setdefault(key,
+                                                  cls.instance(name, offset))
+
+        # This lock may not be necessary in Python 3. See GH issue #901
+        with cls._cache_lock:
+            cls.__strong_cache[key] = cls.__strong_cache.pop(key, instance)
+
+            # Remove an item if the strong cache is overpopulated
+            if len(cls.__strong_cache) > cls.__strong_cache_size:
+                cls.__strong_cache.popitem(last=False)
+
+        return instance
+
+
+class _TzStrFactory(_TzFactory):
+    def __init__(cls, *args, **kwargs):
+        cls.__instances = weakref.WeakValueDictionary()
+        cls.__strong_cache = OrderedDict()
+        cls.__strong_cache_size = 8
+
+        cls.__cache_lock = _thread.allocate_lock()
+
+    def __call__(cls, s, posix_offset=False):
+        key = (s, posix_offset)
+        instance = cls.__instances.get(key, None)
+
+        if instance is None:
+            instance = cls.__instances.setdefault(key,
+                cls.instance(s, posix_offset))
+
+        # This lock may not be necessary in Python 3. See GH issue #901
+        with cls.__cache_lock:
+            cls.__strong_cache[key] = cls.__strong_cache.pop(key, instance)
+
+            # Remove an item if the strong cache is overpopulated
+            if len(cls.__strong_cache) > cls.__strong_cache_size:
+                cls.__strong_cache.popitem(last=False)
+
+        return instance
+
Index: venv/Lib/site-packages/dateutil/tz/__init__.py
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/venv/Lib/site-packages/dateutil/tz/__init__.py b/venv/Lib/site-packages/dateutil/tz/__init__.py
new file mode 100644
--- /dev/null	(date 1616406051845)
+++ b/venv/Lib/site-packages/dateutil/tz/__init__.py	(date 1616406051845)
@@ -0,0 +1,12 @@
+# -*- coding: utf-8 -*-
+from .tz import *
+from .tz import __doc__
+
+__all__ = ["tzutc", "tzoffset", "tzlocal", "tzfile", "tzrange",
+           "tzstr", "tzical", "tzwin", "tzwinlocal", "gettz",
+           "enfold", "datetime_ambiguous", "datetime_exists",
+           "resolve_imaginary", "UTC", "DeprecatedTzFormatWarning"]
+
+
+class DeprecatedTzFormatWarning(Warning):
+    """Warning raised when time zones are parsed from deprecated formats."""
Index: latest/Lib/site-packages/psycopg2-2.8.6.dist-info/top_level.txt
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/latest/Lib/site-packages/psycopg2-2.8.6.dist-info/top_level.txt b/latest/Lib/site-packages/psycopg2-2.8.6.dist-info/top_level.txt
new file mode 100644
--- /dev/null	(date 1616409347274)
+++ b/latest/Lib/site-packages/psycopg2-2.8.6.dist-info/top_level.txt	(date 1616409347274)
@@ -0,0 +1,1 @@
+psycopg2
Index: latest/Lib/site-packages/psycopg2-2.8.6.dist-info/WHEEL
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/latest/Lib/site-packages/psycopg2-2.8.6.dist-info/WHEEL b/latest/Lib/site-packages/psycopg2-2.8.6.dist-info/WHEEL
new file mode 100644
--- /dev/null	(date 1616409347272)
+++ b/latest/Lib/site-packages/psycopg2-2.8.6.dist-info/WHEEL	(date 1616409347272)
@@ -0,0 +1,5 @@
+Wheel-Version: 1.0
+Generator: bdist_wheel (0.35.1)
+Root-Is-Purelib: false
+Tag: cp39-cp39-win_amd64
+
Index: venv/Lib/site-packages/dateutil/parser/isoparser.py
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/venv/Lib/site-packages/dateutil/parser/isoparser.py b/venv/Lib/site-packages/dateutil/parser/isoparser.py
new file mode 100644
--- /dev/null	(date 1616406051845)
+++ b/venv/Lib/site-packages/dateutil/parser/isoparser.py	(date 1616406051845)
@@ -0,0 +1,411 @@
+# -*- coding: utf-8 -*-
+"""
+This module offers a parser for ISO-8601 strings
+
+It is intended to support all valid date, time and datetime formats per the
+ISO-8601 specification.
+
+..versionadded:: 2.7.0
+"""
+from datetime import datetime, timedelta, time, date
+import calendar
+from dateutil import tz
+
+from functools import wraps
+
+import re
+import six
+
+__all__ = ["isoparse", "isoparser"]
+
+
+def _takes_ascii(f):
+    @wraps(f)
+    def func(self, str_in, *args, **kwargs):
+        # If it's a stream, read the whole thing
+        str_in = getattr(str_in, 'read', lambda: str_in)()
+
+        # If it's unicode, turn it into bytes, since ISO-8601 only covers ASCII
+        if isinstance(str_in, six.text_type):
+            # ASCII is the same in UTF-8
+            try:
+                str_in = str_in.encode('ascii')
+            except UnicodeEncodeError as e:
+                msg = 'ISO-8601 strings should contain only ASCII characters'
+                six.raise_from(ValueError(msg), e)
+
+        return f(self, str_in, *args, **kwargs)
+
+    return func
+
+
+class isoparser(object):
+    def __init__(self, sep=None):
+        """
+        :param sep:
+            A single character that separates date and time portions. If
+            ``None``, the parser will accept any single character.
+            For strict ISO-8601 adherence, pass ``'T'``.
+        """
+        if sep is not None:
+            if (len(sep) != 1 or ord(sep) >= 128 or sep in '0123456789'):
+                raise ValueError('Separator must be a single, non-numeric ' +
+                                 'ASCII character')
+
+            sep = sep.encode('ascii')
+
+        self._sep = sep
+
+    @_takes_ascii
+    def isoparse(self, dt_str):
+        """
+        Parse an ISO-8601 datetime string into a :class:`datetime.datetime`.
+
+        An ISO-8601 datetime string consists of a date portion, followed
+        optionally by a time portion - the date and time portions are separated
+        by a single character separator, which is ``T`` in the official
+        standard. Incomplete date formats (such as ``YYYY-MM``) may *not* be
+        combined with a time portion.
+
+        Supported date formats are:
+
+        Common:
+
+        - ``YYYY``
+        - ``YYYY-MM`` or ``YYYYMM``
+        - ``YYYY-MM-DD`` or ``YYYYMMDD``
+
+        Uncommon:
+
+        - ``YYYY-Www`` or ``YYYYWww`` - ISO week (day defaults to 0)
+        - ``YYYY-Www-D`` or ``YYYYWwwD`` - ISO week and day
+
+        The ISO week and day numbering follows the same logic as
+        :func:`datetime.date.isocalendar`.
+
+        Supported time formats are:
+
+        - ``hh``
+        - ``hh:mm`` or ``hhmm``
+        - ``hh:mm:ss`` or ``hhmmss``
+        - ``hh:mm:ss.ssssss`` (Up to 6 sub-second digits)
+
+        Midnight is a special case for `hh`, as the standard supports both
+        00:00 and 24:00 as a representation. The decimal separator can be
+        either a dot or a comma.
+
+
+        .. caution::
+
+            Support for fractional components other than seconds is part of the
+            ISO-8601 standard, but is not currently implemented in this parser.
+
+        Supported time zone offset formats are:
+
+        - `Z` (UTC)
+        - `HH:MM`
+        - `HHMM`
+        - `HH`
+
+        Offsets will be represented as :class:`dateutil.tz.tzoffset` objects,
+        with the exception of UTC, which will be represented as
+        :class:`dateutil.tz.tzutc`. Time zone offsets equivalent to UTC (such
+        as `+00:00`) will also be represented as :class:`dateutil.tz.tzutc`.
+
+        :param dt_str:
+            A string or stream containing only an ISO-8601 datetime string
+
+        :return:
+            Returns a :class:`datetime.datetime` representing the string.
+            Unspecified components default to their lowest value.
+
+        .. warning::
+
+            As of version 2.7.0, the strictness of the parser should not be
+            considered a stable part of the contract. Any valid ISO-8601 string
+            that parses correctly with the default settings will continue to
+            parse correctly in future versions, but invalid strings that
+            currently fail (e.g. ``2017-01-01T00:00+00:00:00``) are not
+            guaranteed to continue failing in future versions if they encode
+            a valid date.
+
+        .. versionadded:: 2.7.0
+        """
+        components, pos = self._parse_isodate(dt_str)
+
+        if len(dt_str) > pos:
+            if self._sep is None or dt_str[pos:pos + 1] == self._sep:
+                components += self._parse_isotime(dt_str[pos + 1:])
+            else:
+                raise ValueError('String contains unknown ISO components')
+
+        if len(components) > 3 and components[3] == 24:
+            components[3] = 0
+            return datetime(*components) + timedelta(days=1)
+
+        return datetime(*components)
+
+    @_takes_ascii
+    def parse_isodate(self, datestr):
+        """
+        Parse the date portion of an ISO string.
+
+        :param datestr:
+            The string portion of an ISO string, without a separator
+
+        :return:
+            Returns a :class:`datetime.date` object
+        """
+        components, pos = self._parse_isodate(datestr)
+        if pos < len(datestr):
+            raise ValueError('String contains unknown ISO ' +
+                             'components: {}'.format(datestr))
+        return date(*components)
+
+    @_takes_ascii
+    def parse_isotime(self, timestr):
+        """
+        Parse the time portion of an ISO string.
+
+        :param timestr:
+            The time portion of an ISO string, without a separator
+
+        :return:
+            Returns a :class:`datetime.time` object
+        """
+        components = self._parse_isotime(timestr)
+        if components[0] == 24:
+            components[0] = 0
+        return time(*components)
+
+    @_takes_ascii
+    def parse_tzstr(self, tzstr, zero_as_utc=True):
+        """
+        Parse a valid ISO time zone string.
+
+        See :func:`isoparser.isoparse` for details on supported formats.
+
+        :param tzstr:
+            A string representing an ISO time zone offset
+
+        :param zero_as_utc:
+            Whether to return :class:`dateutil.tz.tzutc` for zero-offset zones
+
+        :return:
+            Returns :class:`dateutil.tz.tzoffset` for offsets and
+            :class:`dateutil.tz.tzutc` for ``Z`` and (if ``zero_as_utc`` is
+            specified) offsets equivalent to UTC.
+        """
+        return self._parse_tzstr(tzstr, zero_as_utc=zero_as_utc)
+
+    # Constants
+    _DATE_SEP = b'-'
+    _TIME_SEP = b':'
+    _FRACTION_REGEX = re.compile(b'[\\.,]([0-9]+)')
+
+    def _parse_isodate(self, dt_str):
+        try:
+            return self._parse_isodate_common(dt_str)
+        except ValueError:
+            return self._parse_isodate_uncommon(dt_str)
+
+    def _parse_isodate_common(self, dt_str):
+        len_str = len(dt_str)
+        components = [1, 1, 1]
+
+        if len_str < 4:
+            raise ValueError('ISO string too short')
+
+        # Year
+        components[0] = int(dt_str[0:4])
+        pos = 4
+        if pos >= len_str:
+            return components, pos
+
+        has_sep = dt_str[pos:pos + 1] == self._DATE_SEP
+        if has_sep:
+            pos += 1
+
+        # Month
+        if len_str - pos < 2:
+            raise ValueError('Invalid common month')
+
+        components[1] = int(dt_str[pos:pos + 2])
+        pos += 2
+
+        if pos >= len_str:
+            if has_sep:
+                return components, pos
+            else:
+                raise ValueError('Invalid ISO format')
+
+        if has_sep:
+            if dt_str[pos:pos + 1] != self._DATE_SEP:
+                raise ValueError('Invalid separator in ISO string')
+            pos += 1
+
+        # Day
+        if len_str - pos < 2:
+            raise ValueError('Invalid common day')
+        components[2] = int(dt_str[pos:pos + 2])
+        return components, pos + 2
+
+    def _parse_isodate_uncommon(self, dt_str):
+        if len(dt_str) < 4:
+            raise ValueError('ISO string too short')
+
+        # All ISO formats start with the year
+        year = int(dt_str[0:4])
+
+        has_sep = dt_str[4:5] == self._DATE_SEP
+
+        pos = 4 + has_sep       # Skip '-' if it's there
+        if dt_str[pos:pos + 1] == b'W':
+            # YYYY-?Www-?D?
+            pos += 1
+            weekno = int(dt_str[pos:pos + 2])
+            pos += 2
+
+            dayno = 1
+            if len(dt_str) > pos:
+                if (dt_str[pos:pos + 1] == self._DATE_SEP) != has_sep:
+                    raise ValueError('Inconsistent use of dash separator')
+
+                pos += has_sep
+
+                dayno = int(dt_str[pos:pos + 1])
+                pos += 1
+
+            base_date = self._calculate_weekdate(year, weekno, dayno)
+        else:
+            # YYYYDDD or YYYY-DDD
+            if len(dt_str) - pos < 3:
+                raise ValueError('Invalid ordinal day')
+
+            ordinal_day = int(dt_str[pos:pos + 3])
+            pos += 3
+
+            if ordinal_day < 1 or ordinal_day > (365 + calendar.isleap(year)):
+                raise ValueError('Invalid ordinal day' +
+                                 ' {} for year {}'.format(ordinal_day, year))
+
+            base_date = date(year, 1, 1) + timedelta(days=ordinal_day - 1)
+
+        components = [base_date.year, base_date.month, base_date.day]
+        return components, pos
+
+    def _calculate_weekdate(self, year, week, day):
+        """
+        Calculate the day of corresponding to the ISO year-week-day calendar.
+
+        This function is effectively the inverse of
+        :func:`datetime.date.isocalendar`.
+
+        :param year:
+            The year in the ISO calendar
+
+        :param week:
+            The week in the ISO calendar - range is [1, 53]
+
+        :param day:
+            The day in the ISO calendar - range is [1 (MON), 7 (SUN)]
+
+        :return:
+            Returns a :class:`datetime.date`
+        """
+        if not 0 < week < 54:
+            raise ValueError('Invalid week: {}'.format(week))
+
+        if not 0 < day < 8:     # Range is 1-7
+            raise ValueError('Invalid weekday: {}'.format(day))
+
+        # Get week 1 for the specific year:
+        jan_4 = date(year, 1, 4)   # Week 1 always has January 4th in it
+        week_1 = jan_4 - timedelta(days=jan_4.isocalendar()[2] - 1)
+
+        # Now add the specific number of weeks and days to get what we want
+        week_offset = (week - 1) * 7 + (day - 1)
+        return week_1 + timedelta(days=week_offset)
+
+    def _parse_isotime(self, timestr):
+        len_str = len(timestr)
+        components = [0, 0, 0, 0, None]
+        pos = 0
+        comp = -1
+
+        if len(timestr) < 2:
+            raise ValueError('ISO time too short')
+
+        has_sep = len_str >= 3 and timestr[2:3] == self._TIME_SEP
+
+        while pos < len_str and comp < 5:
+            comp += 1
+
+            if timestr[pos:pos + 1] in b'-+Zz':
+                # Detect time zone boundary
+                components[-1] = self._parse_tzstr(timestr[pos:])
+                pos = len_str
+                break
+
+            if comp < 3:
+                # Hour, minute, second
+                components[comp] = int(timestr[pos:pos + 2])
+                pos += 2
+                if (has_sep and pos < len_str and
+                        timestr[pos:pos + 1] == self._TIME_SEP):
+                    pos += 1
+
+            if comp == 3:
+                # Fraction of a second
+                frac = self._FRACTION_REGEX.match(timestr[pos:])
+                if not frac:
+                    continue
+
+                us_str = frac.group(1)[:6]  # Truncate to microseconds
+                components[comp] = int(us_str) * 10**(6 - len(us_str))
+                pos += len(frac.group())
+
+        if pos < len_str:
+            raise ValueError('Unused components in ISO string')
+
+        if components[0] == 24:
+            # Standard supports 00:00 and 24:00 as representations of midnight
+            if any(component != 0 for component in components[1:4]):
+                raise ValueError('Hour may only be 24 at 24:00:00.000')
+
+        return components
+
+    def _parse_tzstr(self, tzstr, zero_as_utc=True):
+        if tzstr == b'Z' or tzstr == b'z':
+            return tz.UTC
+
+        if len(tzstr) not in {3, 5, 6}:
+            raise ValueError('Time zone offset must be 1, 3, 5 or 6 characters')
+
+        if tzstr[0:1] == b'-':
+            mult = -1
+        elif tzstr[0:1] == b'+':
+            mult = 1
+        else:
+            raise ValueError('Time zone offset requires sign')
+
+        hours = int(tzstr[1:3])
+        if len(tzstr) == 3:
+            minutes = 0
+        else:
+            minutes = int(tzstr[(4 if tzstr[3:4] == self._TIME_SEP else 3):])
+
+        if zero_as_utc and hours == 0 and minutes == 0:
+            return tz.UTC
+        else:
+            if minutes > 59:
+                raise ValueError('Invalid minutes in time zone offset')
+
+            if hours > 23:
+                raise ValueError('Invalid hours in time zone offset')
+
+            return tz.tzoffset(None, mult * (hours * 60 + minutes) * 60)
+
+
+DEFAULT_ISOPARSER = isoparser()
+isoparse = DEFAULT_ISOPARSER.isoparse
Index: venv/Lib/site-packages/dateutil/parser/_parser.py
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/venv/Lib/site-packages/dateutil/parser/_parser.py b/venv/Lib/site-packages/dateutil/parser/_parser.py
new file mode 100644
--- /dev/null	(date 1616406051845)
+++ b/venv/Lib/site-packages/dateutil/parser/_parser.py	(date 1616406051845)
@@ -0,0 +1,1609 @@
+# -*- coding: utf-8 -*-
+"""
+This module offers a generic date/time string parser which is able to parse
+most known formats to represent a date and/or time.
+
+This module attempts to be forgiving with regards to unlikely input formats,
+returning a datetime object even for dates which are ambiguous. If an element
+of a date/time stamp is omitted, the following rules are applied:
+
+- If AM or PM is left unspecified, a 24-hour clock is assumed, however, an hour
+  on a 12-hour clock (``0 <= hour <= 12``) *must* be specified if AM or PM is
+  specified.
+- If a time zone is omitted, a timezone-naive datetime is returned.
+
+If any other elements are missing, they are taken from the
+:class:`datetime.datetime` object passed to the parameter ``default``. If this
+results in a day number exceeding the valid number of days per month, the
+value falls back to the end of the month.
+
+Additional resources about date/time string formats can be found below:
+
+- `A summary of the international standard date and time notation
+  <http://www.cl.cam.ac.uk/~mgk25/iso-time.html>`_
+- `W3C Date and Time Formats <http://www.w3.org/TR/NOTE-datetime>`_
+- `Time Formats (Planetary Rings Node) <https://pds-rings.seti.org:443/tools/time_formats.html>`_
+- `CPAN ParseDate module
+  <http://search.cpan.org/~muir/Time-modules-2013.0912/lib/Time/ParseDate.pm>`_
+- `Java SimpleDateFormat Class
+  <https://docs.oracle.com/javase/6/docs/api/java/text/SimpleDateFormat.html>`_
+"""
+from __future__ import unicode_literals
+
+import datetime
+import re
+import string
+import time
+import warnings
+
+from calendar import monthrange
+from io import StringIO
+
+import six
+from six import integer_types, text_type
+
+from decimal import Decimal
+
+from warnings import warn
+
+from .. import relativedelta
+from .. import tz
+
+__all__ = ["parse", "parserinfo", "ParserError"]
+
+
+# TODO: pandas.core.tools.datetimes imports this explicitly.  Might be worth
+# making public and/or figuring out if there is something we can
+# take off their plate.
+class _timelex(object):
+    # Fractional seconds are sometimes split by a comma
+    _split_decimal = re.compile("([.,])")
+
+    def __init__(self, instream):
+        if six.PY2:
+            # In Python 2, we can't duck type properly because unicode has
+            # a 'decode' function, and we'd be double-decoding
+            if isinstance(instream, (bytes, bytearray)):
+                instream = instream.decode()
+        else:
+            if getattr(instream, 'decode', None) is not None:
+                instream = instream.decode()
+
+        if isinstance(instream, text_type):
+            instream = StringIO(instream)
+        elif getattr(instream, 'read', None) is None:
+            raise TypeError('Parser must be a string or character stream, not '
+                            '{itype}'.format(itype=instream.__class__.__name__))
+
+        self.instream = instream
+        self.charstack = []
+        self.tokenstack = []
+        self.eof = False
+
+    def get_token(self):
+        """
+        This function breaks the time string into lexical units (tokens), which
+        can be parsed by the parser. Lexical units are demarcated by changes in
+        the character set, so any continuous string of letters is considered
+        one unit, any continuous string of numbers is considered one unit.
+
+        The main complication arises from the fact that dots ('.') can be used
+        both as separators (e.g. "Sep.20.2009") or decimal points (e.g.
+        "4:30:21.447"). As such, it is necessary to read the full context of
+        any dot-separated strings before breaking it into tokens; as such, this
+        function maintains a "token stack", for when the ambiguous context
+        demands that multiple tokens be parsed at once.
+        """
+        if self.tokenstack:
+            return self.tokenstack.pop(0)
+
+        seenletters = False
+        token = None
+        state = None
+
+        while not self.eof:
+            # We only realize that we've reached the end of a token when we
+            # find a character that's not part of the current token - since
+            # that character may be part of the next token, it's stored in the
+            # charstack.
+            if self.charstack:
+                nextchar = self.charstack.pop(0)
+            else:
+                nextchar = self.instream.read(1)
+                while nextchar == '\x00':
+                    nextchar = self.instream.read(1)
+
+            if not nextchar:
+                self.eof = True
+                break
+            elif not state:
+                # First character of the token - determines if we're starting
+                # to parse a word, a number or something else.
+                token = nextchar
+                if self.isword(nextchar):
+                    state = 'a'
+                elif self.isnum(nextchar):
+                    state = '0'
+                elif self.isspace(nextchar):
+                    token = ' '
+                    break  # emit token
+                else:
+                    break  # emit token
+            elif state == 'a':
+                # If we've already started reading a word, we keep reading
+                # letters until we find something that's not part of a word.
+                seenletters = True
+                if self.isword(nextchar):
+                    token += nextchar
+                elif nextchar == '.':
+                    token += nextchar
+                    state = 'a.'
+                else:
+                    self.charstack.append(nextchar)
+                    break  # emit token
+            elif state == '0':
+                # If we've already started reading a number, we keep reading
+                # numbers until we find something that doesn't fit.
+                if self.isnum(nextchar):
+                    token += nextchar
+                elif nextchar == '.' or (nextchar == ',' and len(token) >= 2):
+                    token += nextchar
+                    state = '0.'
+                else:
+                    self.charstack.append(nextchar)
+                    break  # emit token
+            elif state == 'a.':
+                # If we've seen some letters and a dot separator, continue
+                # parsing, and the tokens will be broken up later.
+                seenletters = True
+                if nextchar == '.' or self.isword(nextchar):
+                    token += nextchar
+                elif self.isnum(nextchar) and token[-1] == '.':
+                    token += nextchar
+                    state = '0.'
+                else:
+                    self.charstack.append(nextchar)
+                    break  # emit token
+            elif state == '0.':
+                # If we've seen at least one dot separator, keep going, we'll
+                # break up the tokens later.
+                if nextchar == '.' or self.isnum(nextchar):
+                    token += nextchar
+                elif self.isword(nextchar) and token[-1] == '.':
+                    token += nextchar
+                    state = 'a.'
+                else:
+                    self.charstack.append(nextchar)
+                    break  # emit token
+
+        if (state in ('a.', '0.') and (seenletters or token.count('.') > 1 or
+                                       token[-1] in '.,')):
+            l = self._split_decimal.split(token)
+            token = l[0]
+            for tok in l[1:]:
+                if tok:
+                    self.tokenstack.append(tok)
+
+        if state == '0.' and token.count('.') == 0:
+            token = token.replace(',', '.')
+
+        return token
+
+    def __iter__(self):
+        return self
+
+    def __next__(self):
+        token = self.get_token()
+        if token is None:
+            raise StopIteration
+
+        return token
+
+    def next(self):
+        return self.__next__()  # Python 2.x support
+
+    @classmethod
+    def split(cls, s):
+        return list(cls(s))
+
+    @classmethod
+    def isword(cls, nextchar):
+        """ Whether or not the next character is part of a word """
+        return nextchar.isalpha()
+
+    @classmethod
+    def isnum(cls, nextchar):
+        """ Whether the next character is part of a number """
+        return nextchar.isdigit()
+
+    @classmethod
+    def isspace(cls, nextchar):
+        """ Whether the next character is whitespace """
+        return nextchar.isspace()
+
+
+class _resultbase(object):
+
+    def __init__(self):
+        for attr in self.__slots__:
+            setattr(self, attr, None)
+
+    def _repr(self, classname):
+        l = []
+        for attr in self.__slots__:
+            value = getattr(self, attr)
+            if value is not None:
+                l.append("%s=%s" % (attr, repr(value)))
+        return "%s(%s)" % (classname, ", ".join(l))
+
+    def __len__(self):
+        return (sum(getattr(self, attr) is not None
+                    for attr in self.__slots__))
+
+    def __repr__(self):
+        return self._repr(self.__class__.__name__)
+
+
+class parserinfo(object):
+    """
+    Class which handles what inputs are accepted. Subclass this to customize
+    the language and acceptable values for each parameter.
+
+    :param dayfirst:
+        Whether to interpret the first value in an ambiguous 3-integer date
+        (e.g. 01/05/09) as the day (``True``) or month (``False``). If
+        ``yearfirst`` is set to ``True``, this distinguishes between YDM
+        and YMD. Default is ``False``.
+
+    :param yearfirst:
+        Whether to interpret the first value in an ambiguous 3-integer date
+        (e.g. 01/05/09) as the year. If ``True``, the first number is taken
+        to be the year, otherwise the last number is taken to be the year.
+        Default is ``False``.
+    """
+
+    # m from a.m/p.m, t from ISO T separator
+    JUMP = [" ", ".", ",", ";", "-", "/", "'",
+            "at", "on", "and", "ad", "m", "t", "of",
+            "st", "nd", "rd", "th"]
+
+    WEEKDAYS = [("Mon", "Monday"),
+                ("Tue", "Tuesday"),     # TODO: "Tues"
+                ("Wed", "Wednesday"),
+                ("Thu", "Thursday"),    # TODO: "Thurs"
+                ("Fri", "Friday"),
+                ("Sat", "Saturday"),
+                ("Sun", "Sunday")]
+    MONTHS = [("Jan", "January"),
+              ("Feb", "February"),      # TODO: "Febr"
+              ("Mar", "March"),
+              ("Apr", "April"),
+              ("May", "May"),
+              ("Jun", "June"),
+              ("Jul", "July"),
+              ("Aug", "August"),
+              ("Sep", "Sept", "September"),
+              ("Oct", "October"),
+              ("Nov", "November"),
+              ("Dec", "December")]
+    HMS = [("h", "hour", "hours"),
+           ("m", "minute", "minutes"),
+           ("s", "second", "seconds")]
+    AMPM = [("am", "a"),
+            ("pm", "p")]
+    UTCZONE = ["UTC", "GMT", "Z", "z"]
+    PERTAIN = ["of"]
+    TZOFFSET = {}
+    # TODO: ERA = ["AD", "BC", "CE", "BCE", "Stardate",
+    #              "Anno Domini", "Year of Our Lord"]
+
+    def __init__(self, dayfirst=False, yearfirst=False):
+        self._jump = self._convert(self.JUMP)
+        self._weekdays = self._convert(self.WEEKDAYS)
+        self._months = self._convert(self.MONTHS)
+        self._hms = self._convert(self.HMS)
+        self._ampm = self._convert(self.AMPM)
+        self._utczone = self._convert(self.UTCZONE)
+        self._pertain = self._convert(self.PERTAIN)
+
+        self.dayfirst = dayfirst
+        self.yearfirst = yearfirst
+
+        self._year = time.localtime().tm_year
+        self._century = self._year // 100 * 100
+
+    def _convert(self, lst):
+        dct = {}
+        for i, v in enumerate(lst):
+            if isinstance(v, tuple):
+                for v in v:
+                    dct[v.lower()] = i
+            else:
+                dct[v.lower()] = i
+        return dct
+
+    def jump(self, name):
+        return name.lower() in self._jump
+
+    def weekday(self, name):
+        try:
+            return self._weekdays[name.lower()]
+        except KeyError:
+            pass
+        return None
+
+    def month(self, name):
+        try:
+            return self._months[name.lower()] + 1
+        except KeyError:
+            pass
+        return None
+
+    def hms(self, name):
+        try:
+            return self._hms[name.lower()]
+        except KeyError:
+            return None
+
+    def ampm(self, name):
+        try:
+            return self._ampm[name.lower()]
+        except KeyError:
+            return None
+
+    def pertain(self, name):
+        return name.lower() in self._pertain
+
+    def utczone(self, name):
+        return name.lower() in self._utczone
+
+    def tzoffset(self, name):
+        if name in self._utczone:
+            return 0
+
+        return self.TZOFFSET.get(name)
+
+    def convertyear(self, year, century_specified=False):
+        """
+        Converts two-digit years to year within [-50, 49]
+        range of self._year (current local time)
+        """
+
+        # Function contract is that the year is always positive
+        assert year >= 0
+
+        if year < 100 and not century_specified:
+            # assume current century to start
+            year += self._century
+
+            if year >= self._year + 50:  # if too far in future
+                year -= 100
+            elif year < self._year - 50:  # if too far in past
+                year += 100
+
+        return year
+
+    def validate(self, res):
+        # move to info
+        if res.year is not None:
+            res.year = self.convertyear(res.year, res.century_specified)
+
+        if ((res.tzoffset == 0 and not res.tzname) or
+             (res.tzname == 'Z' or res.tzname == 'z')):
+            res.tzname = "UTC"
+            res.tzoffset = 0
+        elif res.tzoffset != 0 and res.tzname and self.utczone(res.tzname):
+            res.tzoffset = 0
+        return True
+
+
+class _ymd(list):
+    def __init__(self, *args, **kwargs):
+        super(self.__class__, self).__init__(*args, **kwargs)
+        self.century_specified = False
+        self.dstridx = None
+        self.mstridx = None
+        self.ystridx = None
+
+    @property
+    def has_year(self):
+        return self.ystridx is not None
+
+    @property
+    def has_month(self):
+        return self.mstridx is not None
+
+    @property
+    def has_day(self):
+        return self.dstridx is not None
+
+    def could_be_day(self, value):
+        if self.has_day:
+            return False
+        elif not self.has_month:
+            return 1 <= value <= 31
+        elif not self.has_year:
+            # Be permissive, assume leap year
+            month = self[self.mstridx]
+            return 1 <= value <= monthrange(2000, month)[1]
+        else:
+            month = self[self.mstridx]
+            year = self[self.ystridx]
+            return 1 <= value <= monthrange(year, month)[1]
+
+    def append(self, val, label=None):
+        if hasattr(val, '__len__'):
+            if val.isdigit() and len(val) > 2:
+                self.century_specified = True
+                if label not in [None, 'Y']:  # pragma: no cover
+                    raise ValueError(label)
+                label = 'Y'
+        elif val > 100:
+            self.century_specified = True
+            if label not in [None, 'Y']:  # pragma: no cover
+                raise ValueError(label)
+            label = 'Y'
+
+        super(self.__class__, self).append(int(val))
+
+        if label == 'M':
+            if self.has_month:
+                raise ValueError('Month is already set')
+            self.mstridx = len(self) - 1
+        elif label == 'D':
+            if self.has_day:
+                raise ValueError('Day is already set')
+            self.dstridx = len(self) - 1
+        elif label == 'Y':
+            if self.has_year:
+                raise ValueError('Year is already set')
+            self.ystridx = len(self) - 1
+
+    def _resolve_from_stridxs(self, strids):
+        """
+        Try to resolve the identities of year/month/day elements using
+        ystridx, mstridx, and dstridx, if enough of these are specified.
+        """
+        if len(self) == 3 and len(strids) == 2:
+            # we can back out the remaining stridx value
+            missing = [x for x in range(3) if x not in strids.values()]
+            key = [x for x in ['y', 'm', 'd'] if x not in strids]
+            assert len(missing) == len(key) == 1
+            key = key[0]
+            val = missing[0]
+            strids[key] = val
+
+        assert len(self) == len(strids)  # otherwise this should not be called
+        out = {key: self[strids[key]] for key in strids}
+        return (out.get('y'), out.get('m'), out.get('d'))
+
+    def resolve_ymd(self, yearfirst, dayfirst):
+        len_ymd = len(self)
+        year, month, day = (None, None, None)
+
+        strids = (('y', self.ystridx),
+                  ('m', self.mstridx),
+                  ('d', self.dstridx))
+
+        strids = {key: val for key, val in strids if val is not None}
+        if (len(self) == len(strids) > 0 or
+                (len(self) == 3 and len(strids) == 2)):
+            return self._resolve_from_stridxs(strids)
+
+        mstridx = self.mstridx
+
+        if len_ymd > 3:
+            raise ValueError("More than three YMD values")
+        elif len_ymd == 1 or (mstridx is not None and len_ymd == 2):
+            # One member, or two members with a month string
+            if mstridx is not None:
+                month = self[mstridx]
+                # since mstridx is 0 or 1, self[mstridx-1] always
+                # looks up the other element
+                other = self[mstridx - 1]
+            else:
+                other = self[0]
+
+            if len_ymd > 1 or mstridx is None:
+                if other > 31:
+                    year = other
+                else:
+                    day = other
+
+        elif len_ymd == 2:
+            # Two members with numbers
+            if self[0] > 31:
+                # 99-01
+                year, month = self
+            elif self[1] > 31:
+                # 01-99
+                month, year = self
+            elif dayfirst and self[1] <= 12:
+                # 13-01
+                day, month = self
+            else:
+                # 01-13
+                month, day = self
+
+        elif len_ymd == 3:
+            # Three members
+            if mstridx == 0:
+                if self[1] > 31:
+                    # Apr-2003-25
+                    month, year, day = self
+                else:
+                    month, day, year = self
+            elif mstridx == 1:
+                if self[0] > 31 or (yearfirst and self[2] <= 31):
+                    # 99-Jan-01
+                    year, month, day = self
+                else:
+                    # 01-Jan-01
+                    # Give precedence to day-first, since
+                    # two-digit years is usually hand-written.
+                    day, month, year = self
+
+            elif mstridx == 2:
+                # WTF!?
+                if self[1] > 31:
+                    # 01-99-Jan
+                    day, year, month = self
+                else:
+                    # 99-01-Jan
+                    year, day, month = self
+
+            else:
+                if (self[0] > 31 or
+                    self.ystridx == 0 or
+                        (yearfirst and self[1] <= 12 and self[2] <= 31)):
+                    # 99-01-01
+                    if dayfirst and self[2] <= 12:
+                        year, day, month = self
+                    else:
+                        year, month, day = self
+                elif self[0] > 12 or (dayfirst and self[1] <= 12):
+                    # 13-01-01
+                    day, month, year = self
+                else:
+                    # 01-13-01
+                    month, day, year = self
+
+        return year, month, day
+
+
+class parser(object):
+    def __init__(self, info=None):
+        self.info = info or parserinfo()
+
+    def parse(self, timestr, default=None,
+              ignoretz=False, tzinfos=None, **kwargs):
+        """
+        Parse the date/time string into a :class:`datetime.datetime` object.
+
+        :param timestr:
+            Any date/time string using the supported formats.
+
+        :param default:
+            The default datetime object, if this is a datetime object and not
+            ``None``, elements specified in ``timestr`` replace elements in the
+            default object.
+
+        :param ignoretz:
+            If set ``True``, time zones in parsed strings are ignored and a
+            naive :class:`datetime.datetime` object is returned.
+
+        :param tzinfos:
+            Additional time zone names / aliases which may be present in the
+            string. This argument maps time zone names (and optionally offsets
+            from those time zones) to time zones. This parameter can be a
+            dictionary with timezone aliases mapping time zone names to time
+            zones or a function taking two parameters (``tzname`` and
+            ``tzoffset``) and returning a time zone.
+
+            The timezones to which the names are mapped can be an integer
+            offset from UTC in seconds or a :class:`tzinfo` object.
+
+            .. doctest::
+               :options: +NORMALIZE_WHITESPACE
+
+                >>> from dateutil.parser import parse
+                >>> from dateutil.tz import gettz
+                >>> tzinfos = {"BRST": -7200, "CST": gettz("America/Chicago")}
+                >>> parse("2012-01-19 17:21:00 BRST", tzinfos=tzinfos)
+                datetime.datetime(2012, 1, 19, 17, 21, tzinfo=tzoffset(u'BRST', -7200))
+                >>> parse("2012-01-19 17:21:00 CST", tzinfos=tzinfos)
+                datetime.datetime(2012, 1, 19, 17, 21,
+                                  tzinfo=tzfile('/usr/share/zoneinfo/America/Chicago'))
+
+            This parameter is ignored if ``ignoretz`` is set.
+
+        :param \\*\\*kwargs:
+            Keyword arguments as passed to ``_parse()``.
+
+        :return:
+            Returns a :class:`datetime.datetime` object or, if the
+            ``fuzzy_with_tokens`` option is ``True``, returns a tuple, the
+            first element being a :class:`datetime.datetime` object, the second
+            a tuple containing the fuzzy tokens.
+
+        :raises ParserError:
+            Raised for invalid or unknown string format, if the provided
+            :class:`tzinfo` is not in a valid format, or if an invalid date
+            would be created.
+
+        :raises TypeError:
+            Raised for non-string or character stream input.
+
+        :raises OverflowError:
+            Raised if the parsed date exceeds the largest valid C integer on
+            your system.
+        """
+
+        if default is None:
+            default = datetime.datetime.now().replace(hour=0, minute=0,
+                                                      second=0, microsecond=0)
+
+        res, skipped_tokens = self._parse(timestr, **kwargs)
+
+        if res is None:
+            raise ParserError("Unknown string format: %s", timestr)
+
+        if len(res) == 0:
+            raise ParserError("String does not contain a date: %s", timestr)
+
+        try:
+            ret = self._build_naive(res, default)
+        except ValueError as e:
+            six.raise_from(ParserError(e.args[0] + ": %s", timestr), e)
+
+        if not ignoretz:
+            ret = self._build_tzaware(ret, res, tzinfos)
+
+        if kwargs.get('fuzzy_with_tokens', False):
+            return ret, skipped_tokens
+        else:
+            return ret
+
+    class _result(_resultbase):
+        __slots__ = ["year", "month", "day", "weekday",
+                     "hour", "minute", "second", "microsecond",
+                     "tzname", "tzoffset", "ampm","any_unused_tokens"]
+
+    def _parse(self, timestr, dayfirst=None, yearfirst=None, fuzzy=False,
+               fuzzy_with_tokens=False):
+        """
+        Private method which performs the heavy lifting of parsing, called from
+        ``parse()``, which passes on its ``kwargs`` to this function.
+
+        :param timestr:
+            The string to parse.
+
+        :param dayfirst:
+            Whether to interpret the first value in an ambiguous 3-integer date
+            (e.g. 01/05/09) as the day (``True``) or month (``False``). If
+            ``yearfirst`` is set to ``True``, this distinguishes between YDM
+            and YMD. If set to ``None``, this value is retrieved from the
+            current :class:`parserinfo` object (which itself defaults to
+            ``False``).
+
+        :param yearfirst:
+            Whether to interpret the first value in an ambiguous 3-integer date
+            (e.g. 01/05/09) as the year. If ``True``, the first number is taken
+            to be the year, otherwise the last number is taken to be the year.
+            If this is set to ``None``, the value is retrieved from the current
+            :class:`parserinfo` object (which itself defaults to ``False``).
+
+        :param fuzzy:
+            Whether to allow fuzzy parsing, allowing for string like "Today is
+            January 1, 2047 at 8:21:00AM".
+
+        :param fuzzy_with_tokens:
+            If ``True``, ``fuzzy`` is automatically set to True, and the parser
+            will return a tuple where the first element is the parsed
+            :class:`datetime.datetime` datetimestamp and the second element is
+            a tuple containing the portions of the string which were ignored:
+
+            .. doctest::
+
+                >>> from dateutil.parser import parse
+                >>> parse("Today is January 1, 2047 at 8:21:00AM", fuzzy_with_tokens=True)
+                (datetime.datetime(2047, 1, 1, 8, 21), (u'Today is ', u' ', u'at '))
+
+        """
+        if fuzzy_with_tokens:
+            fuzzy = True
+
+        info = self.info
+
+        if dayfirst is None:
+            dayfirst = info.dayfirst
+
+        if yearfirst is None:
+            yearfirst = info.yearfirst
+
+        res = self._result()
+        l = _timelex.split(timestr)         # Splits the timestr into tokens
+
+        skipped_idxs = []
+
+        # year/month/day list
+        ymd = _ymd()
+
+        len_l = len(l)
+        i = 0
+        try:
+            while i < len_l:
+
+                # Check if it's a number
+                value_repr = l[i]
+                try:
+                    value = float(value_repr)
+                except ValueError:
+                    value = None
+
+                if value is not None:
+                    # Numeric token
+                    i = self._parse_numeric_token(l, i, info, ymd, res, fuzzy)
+
+                # Check weekday
+                elif info.weekday(l[i]) is not None:
+                    value = info.weekday(l[i])
+                    res.weekday = value
+
+                # Check month name
+                elif info.month(l[i]) is not None:
+                    value = info.month(l[i])
+                    ymd.append(value, 'M')
+
+                    if i + 1 < len_l:
+                        if l[i + 1] in ('-', '/'):
+                            # Jan-01[-99]
+                            sep = l[i + 1]
+                            ymd.append(l[i + 2])
+
+                            if i + 3 < len_l and l[i + 3] == sep:
+                                # Jan-01-99
+                                ymd.append(l[i + 4])
+                                i += 2
+
+                            i += 2
+
+                        elif (i + 4 < len_l and l[i + 1] == l[i + 3] == ' ' and
+                              info.pertain(l[i + 2])):
+                            # Jan of 01
+                            # In this case, 01 is clearly year
+                            if l[i + 4].isdigit():
+                                # Convert it here to become unambiguous
+                                value = int(l[i + 4])
+                                year = str(info.convertyear(value))
+                                ymd.append(year, 'Y')
+                            else:
+                                # Wrong guess
+                                pass
+                                # TODO: not hit in tests
+                            i += 4
+
+                # Check am/pm
+                elif info.ampm(l[i]) is not None:
+                    value = info.ampm(l[i])
+                    val_is_ampm = self._ampm_valid(res.hour, res.ampm, fuzzy)
+
+                    if val_is_ampm:
+                        res.hour = self._adjust_ampm(res.hour, value)
+                        res.ampm = value
+
+                    elif fuzzy:
+                        skipped_idxs.append(i)
+
+                # Check for a timezone name
+                elif self._could_be_tzname(res.hour, res.tzname, res.tzoffset, l[i]):
+                    res.tzname = l[i]
+                    res.tzoffset = info.tzoffset(res.tzname)
+
+                    # Check for something like GMT+3, or BRST+3. Notice
+                    # that it doesn't mean "I am 3 hours after GMT", but
+                    # "my time +3 is GMT". If found, we reverse the
+                    # logic so that timezone parsing code will get it
+                    # right.
+                    if i + 1 < len_l and l[i + 1] in ('+', '-'):
+                        l[i + 1] = ('+', '-')[l[i + 1] == '+']
+                        res.tzoffset = None
+                        if info.utczone(res.tzname):
+                            # With something like GMT+3, the timezone
+                            # is *not* GMT.
+                            res.tzname = None
+
+                # Check for a numbered timezone
+                elif res.hour is not None and l[i] in ('+', '-'):
+                    signal = (-1, 1)[l[i] == '+']
+                    len_li = len(l[i + 1])
+
+                    # TODO: check that l[i + 1] is integer?
+                    if len_li == 4:
+                        # -0300
+                        hour_offset = int(l[i + 1][:2])
+                        min_offset = int(l[i + 1][2:])
+                    elif i + 2 < len_l and l[i + 2] == ':':
+                        # -03:00
+                        hour_offset = int(l[i + 1])
+                        min_offset = int(l[i + 3])  # TODO: Check that l[i+3] is minute-like?
+                        i += 2
+                    elif len_li <= 2:
+                        # -[0]3
+                        hour_offset = int(l[i + 1][:2])
+                        min_offset = 0
+                    else:
+                        raise ValueError(timestr)
+
+                    res.tzoffset = signal * (hour_offset * 3600 + min_offset * 60)
+
+                    # Look for a timezone name between parenthesis
+                    if (i + 5 < len_l and
+                            info.jump(l[i + 2]) and l[i + 3] == '(' and
+                            l[i + 5] == ')' and
+                            3 <= len(l[i + 4]) and
+                            self._could_be_tzname(res.hour, res.tzname,
+                                                  None, l[i + 4])):
+                        # -0300 (BRST)
+                        res.tzname = l[i + 4]
+                        i += 4
+
+                    i += 1
+
+                # Check jumps
+                elif not (info.jump(l[i]) or fuzzy):
+                    raise ValueError(timestr)
+
+                else:
+                    skipped_idxs.append(i)
+                i += 1
+
+            # Process year/month/day
+            year, month, day = ymd.resolve_ymd(yearfirst, dayfirst)
+
+            res.century_specified = ymd.century_specified
+            res.year = year
+            res.month = month
+            res.day = day
+
+        except (IndexError, ValueError):
+            return None, None
+
+        if not info.validate(res):
+            return None, None
+
+        if fuzzy_with_tokens:
+            skipped_tokens = self._recombine_skipped(l, skipped_idxs)
+            return res, tuple(skipped_tokens)
+        else:
+            return res, None
+
+    def _parse_numeric_token(self, tokens, idx, info, ymd, res, fuzzy):
+        # Token is a number
+        value_repr = tokens[idx]
+        try:
+            value = self._to_decimal(value_repr)
+        except Exception as e:
+            six.raise_from(ValueError('Unknown numeric token'), e)
+
+        len_li = len(value_repr)
+
+        len_l = len(tokens)
+
+        if (len(ymd) == 3 and len_li in (2, 4) and
+            res.hour is None and
+            (idx + 1 >= len_l or
+             (tokens[idx + 1] != ':' and
+              info.hms(tokens[idx + 1]) is None))):
+            # 19990101T23[59]
+            s = tokens[idx]
+            res.hour = int(s[:2])
+
+            if len_li == 4:
+                res.minute = int(s[2:])
+
+        elif len_li == 6 or (len_li > 6 and tokens[idx].find('.') == 6):
+            # YYMMDD or HHMMSS[.ss]
+            s = tokens[idx]
+
+            if not ymd and '.' not in tokens[idx]:
+                ymd.append(s[:2])
+                ymd.append(s[2:4])
+                ymd.append(s[4:])
+            else:
+                # 19990101T235959[.59]
+
+                # TODO: Check if res attributes already set.
+                res.hour = int(s[:2])
+                res.minute = int(s[2:4])
+                res.second, res.microsecond = self._parsems(s[4:])
+
+        elif len_li in (8, 12, 14):
+            # YYYYMMDD
+            s = tokens[idx]
+            ymd.append(s[:4], 'Y')
+            ymd.append(s[4:6])
+            ymd.append(s[6:8])
+
+            if len_li > 8:
+                res.hour = int(s[8:10])
+                res.minute = int(s[10:12])
+
+                if len_li > 12:
+                    res.second = int(s[12:])
+
+        elif self._find_hms_idx(idx, tokens, info, allow_jump=True) is not None:
+            # HH[ ]h or MM[ ]m or SS[.ss][ ]s
+            hms_idx = self._find_hms_idx(idx, tokens, info, allow_jump=True)
+            (idx, hms) = self._parse_hms(idx, tokens, info, hms_idx)
+            if hms is not None:
+                # TODO: checking that hour/minute/second are not
+                # already set?
+                self._assign_hms(res, value_repr, hms)
+
+        elif idx + 2 < len_l and tokens[idx + 1] == ':':
+            # HH:MM[:SS[.ss]]
+            res.hour = int(value)
+            value = self._to_decimal(tokens[idx + 2])  # TODO: try/except for this?
+            (res.minute, res.second) = self._parse_min_sec(value)
+
+            if idx + 4 < len_l and tokens[idx + 3] == ':':
+                res.second, res.microsecond = self._parsems(tokens[idx + 4])
+
+                idx += 2
+
+            idx += 2
+
+        elif idx + 1 < len_l and tokens[idx + 1] in ('-', '/', '.'):
+            sep = tokens[idx + 1]
+            ymd.append(value_repr)
+
+            if idx + 2 < len_l and not info.jump(tokens[idx + 2]):
+                if tokens[idx + 2].isdigit():
+                    # 01-01[-01]
+                    ymd.append(tokens[idx + 2])
+                else:
+                    # 01-Jan[-01]
+                    value = info.month(tokens[idx + 2])
+
+                    if value is not None:
+                        ymd.append(value, 'M')
+                    else:
+                        raise ValueError()
+
+                if idx + 3 < len_l and tokens[idx + 3] == sep:
+                    # We have three members
+                    value = info.month(tokens[idx + 4])
+
+                    if value is not None:
+                        ymd.append(value, 'M')
+                    else:
+                        ymd.append(tokens[idx + 4])
+                    idx += 2
+
+                idx += 1
+            idx += 1
+
+        elif idx + 1 >= len_l or info.jump(tokens[idx + 1]):
+            if idx + 2 < len_l and info.ampm(tokens[idx + 2]) is not None:
+                # 12 am
+                hour = int(value)
+                res.hour = self._adjust_ampm(hour, info.ampm(tokens[idx + 2]))
+                idx += 1
+            else:
+                # Year, month or day
+                ymd.append(value)
+            idx += 1
+
+        elif info.ampm(tokens[idx + 1]) is not None and (0 <= value < 24):
+            # 12am
+            hour = int(value)
+            res.hour = self._adjust_ampm(hour, info.ampm(tokens[idx + 1]))
+            idx += 1
+
+        elif ymd.could_be_day(value):
+            ymd.append(value)
+
+        elif not fuzzy:
+            raise ValueError()
+
+        return idx
+
+    def _find_hms_idx(self, idx, tokens, info, allow_jump):
+        len_l = len(tokens)
+
+        if idx+1 < len_l and info.hms(tokens[idx+1]) is not None:
+            # There is an "h", "m", or "s" label following this token.  We take
+            # assign the upcoming label to the current token.
+            # e.g. the "12" in 12h"
+            hms_idx = idx + 1
+
+        elif (allow_jump and idx+2 < len_l and tokens[idx+1] == ' ' and
+              info.hms(tokens[idx+2]) is not None):
+            # There is a space and then an "h", "m", or "s" label.
+            # e.g. the "12" in "12 h"
+            hms_idx = idx + 2
+
+        elif idx > 0 and info.hms(tokens[idx-1]) is not None:
+            # There is a "h", "m", or "s" preceding this token.  Since neither
+            # of the previous cases was hit, there is no label following this
+            # token, so we use the previous label.
+            # e.g. the "04" in "12h04"
+            hms_idx = idx-1
+
+        elif (1 < idx == len_l-1 and tokens[idx-1] == ' ' and
+              info.hms(tokens[idx-2]) is not None):
+            # If we are looking at the final token, we allow for a
+            # backward-looking check to skip over a space.
+            # TODO: Are we sure this is the right condition here?
+            hms_idx = idx - 2
+
+        else:
+            hms_idx = None
+
+        return hms_idx
+
+    def _assign_hms(self, res, value_repr, hms):
+        # See GH issue #427, fixing float rounding
+        value = self._to_decimal(value_repr)
+
+        if hms == 0:
+            # Hour
+            res.hour = int(value)
+            if value % 1:
+                res.minute = int(60*(value % 1))
+
+        elif hms == 1:
+            (res.minute, res.second) = self._parse_min_sec(value)
+
+        elif hms == 2:
+            (res.second, res.microsecond) = self._parsems(value_repr)
+
+    def _could_be_tzname(self, hour, tzname, tzoffset, token):
+        return (hour is not None and
+                tzname is None and
+                tzoffset is None and
+                len(token) <= 5 and
+                (all(x in string.ascii_uppercase for x in token)
+                 or token in self.info.UTCZONE))
+
+    def _ampm_valid(self, hour, ampm, fuzzy):
+        """
+        For fuzzy parsing, 'a' or 'am' (both valid English words)
+        may erroneously trigger the AM/PM flag. Deal with that
+        here.
+        """
+        val_is_ampm = True
+
+        # If there's already an AM/PM flag, this one isn't one.
+        if fuzzy and ampm is not None:
+            val_is_ampm = False
+
+        # If AM/PM is found and hour is not, raise a ValueError
+        if hour is None:
+            if fuzzy:
+                val_is_ampm = False
+            else:
+                raise ValueError('No hour specified with AM or PM flag.')
+        elif not 0 <= hour <= 12:
+            # If AM/PM is found, it's a 12 hour clock, so raise
+            # an error for invalid range
+            if fuzzy:
+                val_is_ampm = False
+            else:
+                raise ValueError('Invalid hour specified for 12-hour clock.')
+
+        return val_is_ampm
+
+    def _adjust_ampm(self, hour, ampm):
+        if hour < 12 and ampm == 1:
+            hour += 12
+        elif hour == 12 and ampm == 0:
+            hour = 0
+        return hour
+
+    def _parse_min_sec(self, value):
+        # TODO: Every usage of this function sets res.second to the return
+        # value. Are there any cases where second will be returned as None and
+        # we *don't* want to set res.second = None?
+        minute = int(value)
+        second = None
+
+        sec_remainder = value % 1
+        if sec_remainder:
+            second = int(60 * sec_remainder)
+        return (minute, second)
+
+    def _parse_hms(self, idx, tokens, info, hms_idx):
+        # TODO: Is this going to admit a lot of false-positives for when we
+        # just happen to have digits and "h", "m" or "s" characters in non-date
+        # text?  I guess hex hashes won't have that problem, but there's plenty
+        # of random junk out there.
+        if hms_idx is None:
+            hms = None
+            new_idx = idx
+        elif hms_idx > idx:
+            hms = info.hms(tokens[hms_idx])
+            new_idx = hms_idx
+        else:
+            # Looking backwards, increment one.
+            hms = info.hms(tokens[hms_idx]) + 1
+            new_idx = idx
+
+        return (new_idx, hms)
+
+    # ------------------------------------------------------------------
+    # Handling for individual tokens.  These are kept as methods instead
+    #  of functions for the sake of customizability via subclassing.
+
+    def _parsems(self, value):
+        """Parse a I[.F] seconds value into (seconds, microseconds)."""
+        if "." not in value:
+            return int(value), 0
+        else:
+            i, f = value.split(".")
+            return int(i), int(f.ljust(6, "0")[:6])
+
+    def _to_decimal(self, val):
+        try:
+            decimal_value = Decimal(val)
+            # See GH 662, edge case, infinite value should not be converted
+            #  via `_to_decimal`
+            if not decimal_value.is_finite():
+                raise ValueError("Converted decimal value is infinite or NaN")
+        except Exception as e:
+            msg = "Could not convert %s to decimal" % val
+            six.raise_from(ValueError(msg), e)
+        else:
+            return decimal_value
+
+    # ------------------------------------------------------------------
+    # Post-Parsing construction of datetime output.  These are kept as
+    #  methods instead of functions for the sake of customizability via
+    #  subclassing.
+
+    def _build_tzinfo(self, tzinfos, tzname, tzoffset):
+        if callable(tzinfos):
+            tzdata = tzinfos(tzname, tzoffset)
+        else:
+            tzdata = tzinfos.get(tzname)
+        # handle case where tzinfo is paased an options that returns None
+        # eg tzinfos = {'BRST' : None}
+        if isinstance(tzdata, datetime.tzinfo) or tzdata is None:
+            tzinfo = tzdata
+        elif isinstance(tzdata, text_type):
+            tzinfo = tz.tzstr(tzdata)
+        elif isinstance(tzdata, integer_types):
+            tzinfo = tz.tzoffset(tzname, tzdata)
+        else:
+            raise TypeError("Offset must be tzinfo subclass, tz string, "
+                            "or int offset.")
+        return tzinfo
+
+    def _build_tzaware(self, naive, res, tzinfos):
+        if (callable(tzinfos) or (tzinfos and res.tzname in tzinfos)):
+            tzinfo = self._build_tzinfo(tzinfos, res.tzname, res.tzoffset)
+            aware = naive.replace(tzinfo=tzinfo)
+            aware = self._assign_tzname(aware, res.tzname)
+
+        elif res.tzname and res.tzname in time.tzname:
+            aware = naive.replace(tzinfo=tz.tzlocal())
+
+            # Handle ambiguous local datetime
+            aware = self._assign_tzname(aware, res.tzname)
+
+            # This is mostly relevant for winter GMT zones parsed in the UK
+            if (aware.tzname() != res.tzname and
+                    res.tzname in self.info.UTCZONE):
+                aware = aware.replace(tzinfo=tz.UTC)
+
+        elif res.tzoffset == 0:
+            aware = naive.replace(tzinfo=tz.UTC)
+
+        elif res.tzoffset:
+            aware = naive.replace(tzinfo=tz.tzoffset(res.tzname, res.tzoffset))
+
+        elif not res.tzname and not res.tzoffset:
+            # i.e. no timezone information was found.
+            aware = naive
+
+        elif res.tzname:
+            # tz-like string was parsed but we don't know what to do
+            # with it
+            warnings.warn("tzname {tzname} identified but not understood.  "
+                          "Pass `tzinfos` argument in order to correctly "
+                          "return a timezone-aware datetime.  In a future "
+                          "version, this will raise an "
+                          "exception.".format(tzname=res.tzname),
+                          category=UnknownTimezoneWarning)
+            aware = naive
+
+        return aware
+
+    def _build_naive(self, res, default):
+        repl = {}
+        for attr in ("year", "month", "day", "hour",
+                     "minute", "second", "microsecond"):
+            value = getattr(res, attr)
+            if value is not None:
+                repl[attr] = value
+
+        if 'day' not in repl:
+            # If the default day exceeds the last day of the month, fall back
+            # to the end of the month.
+            cyear = default.year if res.year is None else res.year
+            cmonth = default.month if res.month is None else res.month
+            cday = default.day if res.day is None else res.day
+
+            if cday > monthrange(cyear, cmonth)[1]:
+                repl['day'] = monthrange(cyear, cmonth)[1]
+
+        naive = default.replace(**repl)
+
+        if res.weekday is not None and not res.day:
+            naive = naive + relativedelta.relativedelta(weekday=res.weekday)
+
+        return naive
+
+    def _assign_tzname(self, dt, tzname):
+        if dt.tzname() != tzname:
+            new_dt = tz.enfold(dt, fold=1)
+            if new_dt.tzname() == tzname:
+                return new_dt
+
+        return dt
+
+    def _recombine_skipped(self, tokens, skipped_idxs):
+        """
+        >>> tokens = ["foo", " ", "bar", " ", "19June2000", "baz"]
+        >>> skipped_idxs = [0, 1, 2, 5]
+        >>> _recombine_skipped(tokens, skipped_idxs)
+        ["foo bar", "baz"]
+        """
+        skipped_tokens = []
+        for i, idx in enumerate(sorted(skipped_idxs)):
+            if i > 0 and idx - 1 == skipped_idxs[i - 1]:
+                skipped_tokens[-1] = skipped_tokens[-1] + tokens[idx]
+            else:
+                skipped_tokens.append(tokens[idx])
+
+        return skipped_tokens
+
+
+DEFAULTPARSER = parser()
+
+
+def parse(timestr, parserinfo=None, **kwargs):
+    """
+
+    Parse a string in one of the supported formats, using the
+    ``parserinfo`` parameters.
+
+    :param timestr:
+        A string containing a date/time stamp.
+
+    :param parserinfo:
+        A :class:`parserinfo` object containing parameters for the parser.
+        If ``None``, the default arguments to the :class:`parserinfo`
+        constructor are used.
+
+    The ``**kwargs`` parameter takes the following keyword arguments:
+
+    :param default:
+        The default datetime object, if this is a datetime object and not
+        ``None``, elements specified in ``timestr`` replace elements in the
+        default object.
+
+    :param ignoretz:
+        If set ``True``, time zones in parsed strings are ignored and a naive
+        :class:`datetime` object is returned.
+
+    :param tzinfos:
+        Additional time zone names / aliases which may be present in the
+        string. This argument maps time zone names (and optionally offsets
+        from those time zones) to time zones. This parameter can be a
+        dictionary with timezone aliases mapping time zone names to time
+        zones or a function taking two parameters (``tzname`` and
+        ``tzoffset``) and returning a time zone.
+
+        The timezones to which the names are mapped can be an integer
+        offset from UTC in seconds or a :class:`tzinfo` object.
+
+        .. doctest::
+           :options: +NORMALIZE_WHITESPACE
+
+            >>> from dateutil.parser import parse
+            >>> from dateutil.tz import gettz
+            >>> tzinfos = {"BRST": -7200, "CST": gettz("America/Chicago")}
+            >>> parse("2012-01-19 17:21:00 BRST", tzinfos=tzinfos)
+            datetime.datetime(2012, 1, 19, 17, 21, tzinfo=tzoffset(u'BRST', -7200))
+            >>> parse("2012-01-19 17:21:00 CST", tzinfos=tzinfos)
+            datetime.datetime(2012, 1, 19, 17, 21,
+                              tzinfo=tzfile('/usr/share/zoneinfo/America/Chicago'))
+
+        This parameter is ignored if ``ignoretz`` is set.
+
+    :param dayfirst:
+        Whether to interpret the first value in an ambiguous 3-integer date
+        (e.g. 01/05/09) as the day (``True``) or month (``False``). If
+        ``yearfirst`` is set to ``True``, this distinguishes between YDM and
+        YMD. If set to ``None``, this value is retrieved from the current
+        :class:`parserinfo` object (which itself defaults to ``False``).
+
+    :param yearfirst:
+        Whether to interpret the first value in an ambiguous 3-integer date
+        (e.g. 01/05/09) as the year. If ``True``, the first number is taken to
+        be the year, otherwise the last number is taken to be the year. If
+        this is set to ``None``, the value is retrieved from the current
+        :class:`parserinfo` object (which itself defaults to ``False``).
+
+    :param fuzzy:
+        Whether to allow fuzzy parsing, allowing for string like "Today is
+        January 1, 2047 at 8:21:00AM".
+
+    :param fuzzy_with_tokens:
+        If ``True``, ``fuzzy`` is automatically set to True, and the parser
+        will return a tuple where the first element is the parsed
+        :class:`datetime.datetime` datetimestamp and the second element is
+        a tuple containing the portions of the string which were ignored:
+
+        .. doctest::
+
+            >>> from dateutil.parser import parse
+            >>> parse("Today is January 1, 2047 at 8:21:00AM", fuzzy_with_tokens=True)
+            (datetime.datetime(2047, 1, 1, 8, 21), (u'Today is ', u' ', u'at '))
+
+    :return:
+        Returns a :class:`datetime.datetime` object or, if the
+        ``fuzzy_with_tokens`` option is ``True``, returns a tuple, the
+        first element being a :class:`datetime.datetime` object, the second
+        a tuple containing the fuzzy tokens.
+
+    :raises ValueError:
+        Raised for invalid or unknown string format, if the provided
+        :class:`tzinfo` is not in a valid format, or if an invalid date
+        would be created.
+
+    :raises OverflowError:
+        Raised if the parsed date exceeds the largest valid C integer on
+        your system.
+    """
+    if parserinfo:
+        return parser(parserinfo).parse(timestr, **kwargs)
+    else:
+        return DEFAULTPARSER.parse(timestr, **kwargs)
+
+
+class _tzparser(object):
+
+    class _result(_resultbase):
+
+        __slots__ = ["stdabbr", "stdoffset", "dstabbr", "dstoffset",
+                     "start", "end"]
+
+        class _attr(_resultbase):
+            __slots__ = ["month", "week", "weekday",
+                         "yday", "jyday", "day", "time"]
+
+        def __repr__(self):
+            return self._repr("")
+
+        def __init__(self):
+            _resultbase.__init__(self)
+            self.start = self._attr()
+            self.end = self._attr()
+
+    def parse(self, tzstr):
+        res = self._result()
+        l = [x for x in re.split(r'([,:.]|[a-zA-Z]+|[0-9]+)',tzstr) if x]
+        used_idxs = list()
+        try:
+
+            len_l = len(l)
+
+            i = 0
+            while i < len_l:
+                # BRST+3[BRDT[+2]]
+                j = i
+                while j < len_l and not [x for x in l[j]
+                                         if x in "0123456789:,-+"]:
+                    j += 1
+                if j != i:
+                    if not res.stdabbr:
+                        offattr = "stdoffset"
+                        res.stdabbr = "".join(l[i:j])
+                    else:
+                        offattr = "dstoffset"
+                        res.dstabbr = "".join(l[i:j])
+
+                    for ii in range(j):
+                        used_idxs.append(ii)
+                    i = j
+                    if (i < len_l and (l[i] in ('+', '-') or l[i][0] in
+                                       "0123456789")):
+                        if l[i] in ('+', '-'):
+                            # Yes, that's right.  See the TZ variable
+                            # documentation.
+                            signal = (1, -1)[l[i] == '+']
+                            used_idxs.append(i)
+                            i += 1
+                        else:
+                            signal = -1
+                        len_li = len(l[i])
+                        if len_li == 4:
+                            # -0300
+                            setattr(res, offattr, (int(l[i][:2]) * 3600 +
+                                                   int(l[i][2:]) * 60) * signal)
+                        elif i + 1 < len_l and l[i + 1] == ':':
+                            # -03:00
+                            setattr(res, offattr,
+                                    (int(l[i]) * 3600 +
+                                     int(l[i + 2]) * 60) * signal)
+                            used_idxs.append(i)
+                            i += 2
+                        elif len_li <= 2:
+                            # -[0]3
+                            setattr(res, offattr,
+                                    int(l[i][:2]) * 3600 * signal)
+                        else:
+                            return None
+                        used_idxs.append(i)
+                        i += 1
+                    if res.dstabbr:
+                        break
+                else:
+                    break
+
+
+            if i < len_l:
+                for j in range(i, len_l):
+                    if l[j] == ';':
+                        l[j] = ','
+
+                assert l[i] == ','
+
+                i += 1
+
+            if i >= len_l:
+                pass
+            elif (8 <= l.count(',') <= 9 and
+                  not [y for x in l[i:] if x != ','
+                       for y in x if y not in "0123456789+-"]):
+                # GMT0BST,3,0,30,3600,10,0,26,7200[,3600]
+                for x in (res.start, res.end):
+                    x.month = int(l[i])
+                    used_idxs.append(i)
+                    i += 2
+                    if l[i] == '-':
+                        value = int(l[i + 1]) * -1
+                        used_idxs.append(i)
+                        i += 1
+                    else:
+                        value = int(l[i])
+                    used_idxs.append(i)
+                    i += 2
+                    if value:
+                        x.week = value
+                        x.weekday = (int(l[i]) - 1) % 7
+                    else:
+                        x.day = int(l[i])
+                    used_idxs.append(i)
+                    i += 2
+                    x.time = int(l[i])
+                    used_idxs.append(i)
+                    i += 2
+                if i < len_l:
+                    if l[i] in ('-', '+'):
+                        signal = (-1, 1)[l[i] == "+"]
+                        used_idxs.append(i)
+                        i += 1
+                    else:
+                        signal = 1
+                    used_idxs.append(i)
+                    res.dstoffset = (res.stdoffset + int(l[i]) * signal)
+
+                # This was a made-up format that is not in normal use
+                warn(('Parsed time zone "%s"' % tzstr) +
+                     'is in a non-standard dateutil-specific format, which ' +
+                     'is now deprecated; support for parsing this format ' +
+                     'will be removed in future versions. It is recommended ' +
+                     'that you switch to a standard format like the GNU ' +
+                     'TZ variable format.', tz.DeprecatedTzFormatWarning)
+            elif (l.count(',') == 2 and l[i:].count('/') <= 2 and
+                  not [y for x in l[i:] if x not in (',', '/', 'J', 'M',
+                                                     '.', '-', ':')
+                       for y in x if y not in "0123456789"]):
+                for x in (res.start, res.end):
+                    if l[i] == 'J':
+                        # non-leap year day (1 based)
+                        used_idxs.append(i)
+                        i += 1
+                        x.jyday = int(l[i])
+                    elif l[i] == 'M':
+                        # month[-.]week[-.]weekday
+                        used_idxs.append(i)
+                        i += 1
+                        x.month = int(l[i])
+                        used_idxs.append(i)
+                        i += 1
+                        assert l[i] in ('-', '.')
+                        used_idxs.append(i)
+                        i += 1
+                        x.week = int(l[i])
+                        if x.week == 5:
+                            x.week = -1
+                        used_idxs.append(i)
+                        i += 1
+                        assert l[i] in ('-', '.')
+                        used_idxs.append(i)
+                        i += 1
+                        x.weekday = (int(l[i]) - 1) % 7
+                    else:
+                        # year day (zero based)
+                        x.yday = int(l[i]) + 1
+
+                    used_idxs.append(i)
+                    i += 1
+
+                    if i < len_l and l[i] == '/':
+                        used_idxs.append(i)
+                        i += 1
+                        # start time
+                        len_li = len(l[i])
+                        if len_li == 4:
+                            # -0300
+                            x.time = (int(l[i][:2]) * 3600 +
+                                      int(l[i][2:]) * 60)
+                        elif i + 1 < len_l and l[i + 1] == ':':
+                            # -03:00
+                            x.time = int(l[i]) * 3600 + int(l[i + 2]) * 60
+                            used_idxs.append(i)
+                            i += 2
+                            if i + 1 < len_l and l[i + 1] == ':':
+                                used_idxs.append(i)
+                                i += 2
+                                x.time += int(l[i])
+                        elif len_li <= 2:
+                            # -[0]3
+                            x.time = (int(l[i][:2]) * 3600)
+                        else:
+                            return None
+                        used_idxs.append(i)
+                        i += 1
+
+                    assert i == len_l or l[i] == ','
+
+                    i += 1
+
+                assert i >= len_l
+
+        except (IndexError, ValueError, AssertionError):
+            return None
+
+        unused_idxs = set(range(len_l)).difference(used_idxs)
+        res.any_unused_tokens = not {l[n] for n in unused_idxs}.issubset({",",":"})
+        return res
+
+
+DEFAULTTZPARSER = _tzparser()
+
+
+def _parsetz(tzstr):
+    return DEFAULTTZPARSER.parse(tzstr)
+
+
+class ParserError(ValueError):
+    """Error class for representing failure to parse a datetime string."""
+    def __str__(self):
+        try:
+            return self.args[0] % self.args[1:]
+        except (TypeError, IndexError):
+            return super(ParserError, self).__str__()
+
+        def __repr__(self):
+            return "%s(%s)" % (self.__class__.__name__, str(self))
+
+
+class UnknownTimezoneWarning(RuntimeWarning):
+    """Raised when the parser finds a timezone it cannot parse into a tzinfo"""
+# vim:ts=4:sw=4:et
Index: venv/Lib/site-packages/dateutil/parser/__init__.py
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/venv/Lib/site-packages/dateutil/parser/__init__.py b/venv/Lib/site-packages/dateutil/parser/__init__.py
new file mode 100644
--- /dev/null	(date 1616406051829)
+++ b/venv/Lib/site-packages/dateutil/parser/__init__.py	(date 1616406051829)
@@ -0,0 +1,61 @@
+# -*- coding: utf-8 -*-
+from ._parser import parse, parser, parserinfo, ParserError
+from ._parser import DEFAULTPARSER, DEFAULTTZPARSER
+from ._parser import UnknownTimezoneWarning
+
+from ._parser import __doc__
+
+from .isoparser import isoparser, isoparse
+
+__all__ = ['parse', 'parser', 'parserinfo',
+           'isoparse', 'isoparser',
+           'ParserError',
+           'UnknownTimezoneWarning']
+
+
+###
+# Deprecate portions of the private interface so that downstream code that
+# is improperly relying on it is given *some* notice.
+
+
+def __deprecated_private_func(f):
+    from functools import wraps
+    import warnings
+
+    msg = ('{name} is a private function and may break without warning, '
+           'it will be moved and or renamed in future versions.')
+    msg = msg.format(name=f.__name__)
+
+    @wraps(f)
+    def deprecated_func(*args, **kwargs):
+        warnings.warn(msg, DeprecationWarning)
+        return f(*args, **kwargs)
+
+    return deprecated_func
+
+def __deprecate_private_class(c):
+    import warnings
+
+    msg = ('{name} is a private class and may break without warning, '
+           'it will be moved and or renamed in future versions.')
+    msg = msg.format(name=c.__name__)
+
+    class private_class(c):
+        __doc__ = c.__doc__
+
+        def __init__(self, *args, **kwargs):
+            warnings.warn(msg, DeprecationWarning)
+            super(private_class, self).__init__(*args, **kwargs)
+
+    private_class.__name__ = c.__name__
+
+    return private_class
+
+
+from ._parser import _timelex, _resultbase
+from ._parser import _tzparser, _parsetz
+
+_timelex = __deprecate_private_class(_timelex)
+_tzparser = __deprecate_private_class(_tzparser)
+_resultbase = __deprecate_private_class(_resultbase)
+_parsetz = __deprecated_private_func(_parsetz)
Index: venv/Lib/site-packages/dateutil/zoneinfo/dateutil-zoneinfo.tar.gz
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/venv/Lib/site-packages/dateutil/zoneinfo/dateutil-zoneinfo.tar.gz b/venv/Lib/site-packages/dateutil/zoneinfo/dateutil-zoneinfo.tar.gz
new file mode 100644
--- /dev/null	(date 1616406051845)
+++ b/venv/Lib/site-packages/dateutil/zoneinfo/dateutil-zoneinfo.tar.gz	(date 1616406051845)
@@ -0,0 +1,1042 @@
+\]dateutil-zoneinfo.tar ]@m]'V,}"UE#"b3D1l}lh,|h{gggvs737V_z7||=}
+=><}}~~^^^))o
+(RlD%?
+uSVod|xn	-cx0T+"Dm`\Z	bMxu@M1}jDFL?!=~x~kMxK<]~nQ1}"W-z<"j~=6g+3{w>>~QQ^=|"<Gz=|}#"##
+~##zt#@a6DGz|OzK?mhul~q^Qq1oX}w@q}~v~j7f@97>"2>2a	/~q{xDo}oPx\p.e^>_7xyV
+>w:Dy\Yl=28&Uo&[GthiJoQUy7 fvm\-Xg^`'4Pu\_2WREOd?i. <b'Mw(\:I/5}^z VFzzzj
+%9TR+)_(bj~T9VGGM5zv{M}Z
+}KYu?NDj<PxQ^dm@jz$M? DoXaeYFCu]7>7Voj,.\3g%kMr>w}CY.w=zsNzS]rIB{A*u#K1I*H^|gM/j,LjhOT+E%q :vF3F5F7 ###bHdd?cH1q1q1qH1qxggR3r32F#srE`dn02?#F
+#Had ;F#|bdN12[/F#|cd12=F8<dd.228/g{Imbc2
+WR<w3dee;rpo?oOF_^ciX;ty^se~5*94%;~iNysKw,;Zv-|pNP`&G*uzy,GLS-/sqSoS;=Z~.ctdH@)Gaj.~W5'\Mjymy,S\l|ZTE^r
+4OK^~QuZ"7>7Wn|tWZOkZ	ZZaM6Ekm5h0+3g${/3.';crts-_;fiFoU7=|]J.
+c(D)(0)QX(0L I`dr02ADF&
+#	ad02y@L"F&#	HbdR12\L0F&#cd	Q`LHF&%#	$&"+
+l",
+l"-s&o;4QX/,
+z,
+( C"Bb$
+`,@1HI&b[mZ_k:&6:\3)9uzw~\\}kRB'fr%kl$)4=o_D+V$zIKM**IU*,i/?{s =rz.#G3J<+}Wh Eo^aV7`hM/m/.G;XI?z{{;O}O?,	7g[T^B=/vwMijzWJHo$^"}?QknkdvwH puLK-M1-5aB6Mfu_jA n66\7mm$pYimM7#o.Fdyi1&fdM7)#oVFpyi%fK~}dLx3oZ{w;CL,,mj=zC
+JG~t,kz-K'VNQO9;XO/3_Cu{GaTldAuJzL5z~8aS=j+exzN.\\]#X4szW/67M
+m>toh"fDM<BH6+	mZy3ffM79
+mvF;wh n@]|CHw=;wh7!bC"m|]N"B5J7Zxq3ZH<};|;3siMlN~Mc:sd:k:-LuN~r-P4Q_}j,UjYuusfuWS59otbuSz}sB}nW?],VAVsRu.lw}VsMO|eo_-v:Zq:VOurxgzw(GVrXUclg}?9C\l VUl]ec9W)WN\S~yF>br(("Vn~
+d=szkI)Rs.[(F9V PNiE\hEnol+vvVbfr4eOVl0\ |5?BJr\EJYJw|4kUfUwY	]G&cFQi5E-5CJ%>	Zriu6VR3E	4(!7pI
+|,	~Vc`5u.w\Oum{eKr+Zz.e>#,KiZtT8-&et{a'rwhZzr" r|}y`>IN(%g<wDw!I{7j>F|6b<mQ7?uGZ;-_ndx.}gz<[Y?b:W?v1]*% jX$,J$J$J"DJ%Xb,c$3$x2222222222IhYlYpYtYxY|;%fdfd!%1fdAfdQfdafdq@N7dF/H
+<%8DHb$Qgda3IIwNwN/VrcR"ccX8%qJp )ISd7N	np<) )S"d7N	n
+8%qJ.p`)`
+#'FN8_J<	Cc@}rrQ,E#'+FNXSb	c9al)uGIMk#~[cq#q,d1F'1J@N|b8Pc># D1bJb&/911]#1e#>.15#(1)#!1D@#q&e1F^c41F\Sc51F\Rc41F1bJb&1%W#c#dI;#'wFN93rgaJ93`dF #F6l 0I`df
+
+Y2
+l<02IH0 `dS$c
+#F6l6p`+t>F5Tk]Z3OrKOxltzz4*9?uq-?O/f[iLlfGnfII8#DwNo6ZvjRN;u|hS_NSH7X/0zeS_-']>dtsMmVKK?%^sRfrmf-UkrqZvb'[;Zb
+6B"0C
+mqWfs'|a9^nn7)dG>*>"Zfi%0df
+Wf{2_zS--Q^9GeK,X n%@GR I*5Th$
+HPD"#@EFRBTdk,""_k"K2	*&TJ$+bZ-i AD2#*A@TL$9HvP1b"ATl?,O"jiZEE$d/ahVH"$e"%H25Q dTDQFEQFTFkAd}[27et]"CW7Kf@l)#
+M+<Z\RRVW=[~$grwGwaTS<i<p0&A_xP8Y@pe<1hF
+'FN6XeXxC
+Fl1[^U}<}^e5=?Ko3^d6kc6mlIms"hsd9y.K;P'@xQGvc~	{GSjJOKJ%dqOL[3Yjg>rvke+e7}5sWRnh-RE6Ylo(9H@L``Ph#p@eHewh knrLoUJa-y VW^cUJoZS\Ry
+K}+WI|Uv*Zr%LeVj>VV#gk@awpRul,qW2^%<<.v]urT;MqTZi#%SZ1
+Z$i=[zLv*W&BU
+]=^n|$5>_kzqZuu-:h)e&ZL%kam[nPMn_~kRyR1.[K]{-Y9q"c=rE7F^K+UFidkYVSuvrGoBB-!>^o1EPK0&9%+m[
+Oi5RiI/5lut%6Zu.<8_S59P2Yh~#6F?23K@b(f
+$b}b-#3$32fF0oj}*&n1t|ab;#3@b>@R L&@?)&hEU6RHn#@m86RBEUmm6[6aQFv
+LJ6au#######A
+(lB@R"bEBT	6R&Hn!aB
+6R+HDYDYD.~+h2+hm2+h2+h2+hM'mvm6RA )!l@RDHn#eD6RHRIH)QO+&mhr"KzIAf#Fj
+$EET6RVH]n#ETjv).mhFv[nd^mNVcdU.mNVgHn#F-A9Ynk+v+7mDUDxFUE9Yn)*vWV{T%]E[mZ2/<kxca
+^/OgdTk'lQ3N-9g>r:33<sy8,Pz`Pg'QF[b)=R?WR~R::aQ]e]e)k,Y>
+5\,35pV}RlyduVrj[R^,,wX8,5q}`+\w{No:kUKZ8-ux:8`1unnuAm%K-A-A4z|g[J[u6IB>r;QO--U,9M,aq)s6<gKc_eW[:xyaNvvjwjs%^NgMK1YzgJg_%vG~Wd342 `3^,6 $9i$p9lNwE#F5"dL<ugMyY}?{JlPco8BH#J%`D0D	Q(QF#J%UDQh#J}`@B@(Q	F#J%Z`D^0D1Q(Q
+F#J%D?t0DCQ"(F(	#J%j=DQQ)(QF
+#J%uD_R0(F#Jt%JaD0DoQ8(F#Jt%a@@?I`DR #zTWb4N%FdFF"+KIW%TW~eI%Y%i](#J2#JR#Jr#J#J#J#JJq_! I(}I`Dl4<DLT\dlt|!;IY`DI`DI`DI`DI`DI`DI`DI`DIe6V[VkaZ~Z3:Ow|}<3zli8=uIkVl9=W^ir-zw]dI.~[/\sS|cK_~oOO.Bun1"u[,XRSM?g}W]crHq|B;^p9E3[^5|6'q'q{q'q{S1'qm%#s?q'qH<U"[J_JcJ\gJkJoJ9.MEVFQduw
+_j,E&Dx/)
+{7||~{o_'i_u[uQ=%d)VKhIk#hB[iV.T.7/o)V&d#_9PH._]yW|}q9s-=rn$[
+++g|5%r8`6r0p\RlkXJLZ[>gh%Vz=['5%ms+zP*4$W,_Te\5[e7\>[+[VUj1bQ3z5Vjyjdx\s#r:u?|`7EZ[l=zlA
+jofB4>_@k2}^Zak<fRCkYU.Y!J7[K*;{t:V<t2U[OAZslkclji{l1Ji1Bl.>zOT8J}O~m++N_N%7B9l	FpG[b9Z=hCf
+=
+16<9DumU4g%[/>ghRO?Ysi3=_z_N]r?D0F&CDC%CF4."{^BDyf8!R<3DLg)R5I$Qq$Hyf8j&8jr8zI,eI61-k,e-WI)bZ YLS6iYiY51-"eb,bZVML*lkbZ=uR'q6$bZ	q$I'fY$bZU&eGAiYl,.bZ83U^#eUTML2bHL*iYd1-"e61-k,e=iYbZ)H51-fb	D		&eGAiYMQ$rbZV
+q$% I[bzuHL"nY$bZAq$VI(eMGAHiYQ$bZ'(HM1-k8
+SL g]riYQ61-E*e=GANriYXZ1-"e9Q$bZ7(H_1-kE",e,c1-kE,eGA|e_Y61-\hfq2_?}YujkYxx,|<>N~Fy&YC
+bmFnSRbyEeO~-br_k[mN:/Yp=kG,>6]6v?Sj#IC]=uIQ-ZtRZ^KWel;h;)U]NM;%9.ju@r|N	R7jKCl)WZ66|Ig._%6MIg&	kSlShsR )oy_'#p 
+_NWU"w9/~(Y]hr`QpQ" 5<CL2? vvd/"B-~_4^]&|QLPw0ED!"-ige&D$L*""|C2AD/x)"A/I;;. EDH""%|hU@R74GwN4#c#^Yq7%w@W$>mn:w\9misrLN z'VI[V9U7^|BSy'o+Yl4U7[@mb5G?kPjQj$cRsw&$fV/HIyTo^u6=>W;WX;vOv:Uh9II:^#+ZbHCHGe?LzTVR[>1
+[{^^ygV_oc;':=H&zp/Izv_~S1uza1\zjn$Y~^ipvaG%3N$F1R(p?a$a:u
+PSa*8xQq*Cf`cVXF_a:#9uc*C:#9uC5:#9uG0r <A|AAA<A|aUXq_!a:b$W:1uG02uG02uyRXB2uda*KaOa%d
+ ,!UXpIX:_a%d ,g>_s[_yto{C7Oo\))CKv;lM/<HjUETf){^byK5CR8KS-3EQopmO-Y'^ii2UgGt0.$)Wg(<7',N-h^K
+q]m \!Q{xm m57dW0~E
+VqEha6hajV!1nEVA1n#'oX[	
+D&64ml0Fw^	5+OdLl3gSXq%.9w$lRjg85OzWc^Og+$JA724\'j5&#'qe1[8:$RSMsl%(8dri.G0#'9?W]&]}?
+OWx:oH/F=\kdCgcMk|Gu|3=Za3Y3H=g``*BE*l)^<SNY%g=g>]r1/g%s|&r#S7bo!#KFm3fo #oQ%P@1XVM[e: .<3d\)?Q.iz7*_,}"cQNc,PF&Yv:v,h9}1'T'H6(3kZ~C--|..y)kjRjjGa;?Nrm@bgA%xgJ:Kn,52B:v,t1hT+xvWsCW-UqT6Q}ZFEf)NfoO>\`E5pZky'K6mQja~j}<KJ!-KAj-5_B.QCwo7Yr_j:!B-Z]	U[l5)8ZnO#U
+vS&5e>RW.{uJ]%S:=UcX{6/}g5v/2-o@PtJPpSJsRM[@|}:diYHm91BuyN2H%-WqbbTF,)G(khkg9$.$N=J\8$p$
+ejcHL\$il-
+'=bl1qcC q(._`y6'q%~2OqXq_qXqO-+ 87
+sH|F%N#98n9(-G:wGh#h%
+@{t cGshYYYY#Y'Y+` `d`d`d@j 4i#hJz1h 
+I[/Y!`c7&M1a] Aa-4I0M1h& :@Z
+D,)nacah3f&=4ie61qbZ8(:1-k	1h?Abtc&=tqT"I1M1hH1eJ1beN1*Z*b5c&m4+,i,Ig{&btc&4i~bKUuP1_q5xv?},OoJ#^>SgMDAVMtJ^(]IHq?9#)UMRmV[c)5=7=R^7R|*L-X./")N%C67O?oRgBJr	!>2:/J#A)k	9yHMl
+i>EsMs;u!ae*>VFv?L4AH
+;t(G?t;u`n-7JntDT2(^ %2gC1FiJ$yWu<Dm	oPUJ|c
+ 1!uCwM!KBg#bft:kS`FaO#wGF_^_g)17'l(cK^Ez-uP)sD""HQ	'G	'G	'G
+'GQ
+'G
+'G
+'G@Q'G'G'G'GQG(Hh#	pj<1NXFS#vC%pj85b1NXFz{Aph" 1FS#V]pj085b1
+NFS#}(b HLc#6#pjL85b'1NX
+FLS#cpj\85b/1NXdALj85b6NF,S#pjzFkX~;<GyMGW()4wwby|J|%	zaCb3.3ayR]>?->?Sm#
+w:>|~~vX?cis
+:wI^|~vO9~nX?/~X^pm,_Z|~Xx^*/h
+/[-~EXN
+=Qb\~XZ?_w:-
+++_:'wMog&bUX7?OXm!X]6wrzyN|>es>ciA9sA0[ay_K	w{yc`h?sS|h|X|q?X?9!c'aLz--Y56[6[O^~U?#=?//3S4L{-om>4cY]e[wy+Ym5+.mSI~HVTve`m=	m{7PjsLoj;2;m"?	o;ZlrBk('Nm3sT;Sv{B9BM.,\.G~yFzdbr}v9>f1mWx\r@2Y{?<8n{j{)Hy~:kERy,;XqR
+Rp31URy2^(I\K&%G{iqgwqa24A1A{(EF7(0Av)Bp]rP`H
+ EF9(z(G,sa"	M(EF9(0AQ0rPa"
+mcRI}N'QI8yE##G$#G%#G&#G'#G(#G)#G*#G+GkQ)rq-?^\"X\F/3:s3:g J{]mg3Ov5xvF;G7H2P3hjx%|"OK$sK>3uwl%=/tbK-t/4r^>V5L|M|=Ao[|]mSwUr[a^pY,w\h`|xG{&?R3-&Mvea].-brY]*^t61G?o7]\"cmM0g!_%StN{	JRoj0GQ?>hH~vLOe!}})+26[d`i?#F-~8 Yd))))D.bbbbHKB8BXBxBBBBBC8CXCxCCCCCR"S,"S<"SL*.&'nKq1qGN
+c1b;91Rs\Nnn1(A1=/<2zsA>C1g?@.IsoO!Npnxo7r{ge7xye/s=[i1yxZeiG(l3}k9}m6;_*DNWMkl_E6eajKmR\(vP\YalKgPVNvVMmVkvTdz[r[
+68dl<vSt9eWUJ(_'NUX`l[m5V?b~"mg]Kk>+,%yl;T~vcNH'c5&*OxUO+b|Blg{+ZUlr.Y\*QYI-fK}Sr5_S~`J6}pfx
+SO[OI7sSCo+Y9j*).Tr})O7sUq[.A=-OR~%o36|-e[9o
+Q+lq-P+znV{Zo'i%~B.t\r	\fvoY'v3l0\\\qbr*Jw|nykU.UqP	G&0~FQi5E-5CJ%>	Zriu6VR3E	4(!7pI
+|,7C.|7En|ndbf'Z	ZZkm4Vkj$?_p]'a7-eUrnW]vk=|&GYEe_EZqZL`0NZmb,c}-kqQE|QHKyjkCCn}6|my#WorK'3g}Mt;_,6C	\rEP
+Z^m{O...|b]^.9v1lA9OG2AXRb$e$8&I,#,#K-#-$eH2RrR$(2.5JK<R$(4NIRx\$(6%	dFIqQs\j$%Y^HqQw\j$%iBI1HMri|1H$GR )
+`pR)`pR)-`pRZ""49
+)]Vc
+)u WN!;hMAkJ+hSj]yqZj2t9)eN-sJ?hS
+5! ")eN)	-sJKhSjBZ249*)]0hMiAkJ_/ZS{a^98)NpJwhW,"ipJhS:d#Z-`8M2rdt)&#NFN@JF92r:eiS+#WFNf92reiS/#_ `FN@J9%3rZfS4/iFN9e3rfH)8R9#sFN93rzgiS=#{FN1#R?(3@D6 HV ,#Fl"0M`dv-#FdB0 `d;<?Ed-^0`dV#[Fl=~0adV0uj0=ad6
+#F,!#[F1Iig/$\Dm
+
+#F8ls0ada{+=*}k<<3_7x^<Q];SkxKf/=9|;4H|y\d2xx8=_}5p<A^61L2^x-elg6yfkai],-/q~SzhKfomkZFs-\{k^"8g'~[P`5>}o?GOissgn8wnOu=Kp|.eTKOWrn\9lqx~um_IU}pI[;HW5z,wwIfUSzp?@c[GYl>NfV]/[32QT#e
+gu|z-K5z_[sTL#]CTT ZP^XAkGz!R1u^Pkj%HU,zkUzT}+|TvHg\CE*ZBkkK_ZEWYZj%kLX`pzrxj|[om>s@dK[j\;eGuvl4Y G8Sq6r2Yw6`	K;{`n=ltM>x'tgi(#d3s,A8y8U=@mN(@q?89z q $N ^ n ~          K' q
+5 
+5 q5 5 q1pQub+s;
+=llj j!j"Ff^&s2_vjd/j0j1jbhcJg(Q+Q+Q+Q+Q+gV V V Vh:Z j. I@
+$zZ4ij
+!HGP+V =A@$mA@$A@:Z
+j
+;H{P+V 
+B@:Zij% i#4
+j*
+WH[@._@0 #-;8^?{viq<yU|SJ(GB;7.i=}w9j{|Q]KM4t?d-/m]x<Ix94eV{A9\Y|5g+b7g;&3L91\slijY>G}f/ip"z8fb/Vz%u6<(2*&~Le[:5?o*_Q6SB9*9kg])3kLMtx0utxF7qx1u0:lJ2=^o60^<xQsZG:u?\c7-ajk=\9"s}sj&hxG;Zr:lnYc%|i{xw;sGyst=:49,>5b^}9"G+(12{]n=s	#vVG6g_8~71G|'7'eN2<^S1jhb,Gtn9?xeKU)XeklRgfovMy~a^;C=1X$&H8Vb%	gJ3%b*tb*"U8@b."NH,S$&)21|A
+H]&8Eb9"1HC$p~Upppp
+p|BtwcNN}&r!z IAIEIIIMIQIUIYI]IaIeIi_)) I}IU& %S$5S$ES$US$eS$uB"S$S$S$S$]fUNH%br *k@V5U2*9DWHjn1)+OtO
+'H*(w>!*kL1#p@RKtI1rI=5&ET]cRRtIM5&EET]cRVtI]5'B*q
+	-@R]t+[L
+$F]cRctI5&UFx
+	3
+>RkLj1)6#+7#+8p#+93Y5!1;Yw^5{'_W/)obcb#c?ow]=7[k4>47yfKI]m[9iU}j_S6`ikc}wow5sqC%v$nc?0xmcN%43B\x3+Uma*Ns)7?)`$wL9^7|]!
+=WB>6tO079]Iop1	5IGIGP<4,vP(+P={
+wWfsRUJ]{Qo'="`gle1y9j151lhlz8(5we7\j6Yx^rCwMw&{iR`'&&y2V}l
+r3&RR5Me347<0-UM;%<fjnU{")w_.]&ujTM
+1N(XFR22D~}fWS~+Wn;cClE~CwWIYo4Bo{c''
+aa;3a1ads9..f{YF
+=d@]5+ag
+UZ,y9jUE#bqs&&9`c#.c.s*y9am#~$.3{T}TQ5`j$=@HtU#i(sc5H:
+EZHI3P5nj$@H4U#FT'/T+/T/W3W7/T;/T?/TC/TG/TK/TOISIP5^;,nqYD.YDgHsiIP5HG
+jle9TuW CH$CHU#i FATIQ5&j$]i#HgH#1@:jRT*Y3_ DUI4U%(
+C*ISQU$mEUI4U%,+i-#-4#.U$/H`T"IQE*2F?k3P"EVc54UM"g
+GR?k9I"YQE$mGQ?k<"YagG@?k?"9<*rH")'%sj>]Z 2B|^)> >2.t/_bBk
+Mf{$4igLkx^bs1?xO w3<o/=k~^'=_ 0mx*c"cJ/eI{|Kl?cvaf;Y_6Q40oH[eZJZX{i)%giX]\Ow?ql"IFBuC_H?$0N[G,3mYXs]!98.%~o{?y6TNs9o_5j7~F!u`O?+YJ7raDf/cN&MO^m:uK=-r{cVpmDaow3
+;'H];K~!/p-t=%fq _l.}V<1;e>-L2Jo)s5m%G5KNk_>K.7U7_og>bxp~bItKk/-_fk_S_z>P*>kZa-jMy'-`pO$tE;57iwOsi	=2fEbmlbZ[
+>4Z>/u^y( z:{-_&v,x9LC4s4GkIW~4<ks
+
+'5C.~bI^3|OZ0Ms)va_sg#?-?#yVdgi<?r4GJD"#'?H^DdG
+5G#h\?rlEGN-?Hg?{WT)<_uPI^wK)L>!|}zl2)a}'~XXF@0@p@@@0
+H@0
+Y'G~H~I~JdLdNdPeYRNSHp@_
+:K)wP<fHp1ghJpYHeYHp@@@0H@@0@p@@@0@p@@@0=Ep\Hj {L-Rnlh]
+1X!:k uz:pI`#X%RC[_C'|t:qI
+:qu3:qlIJwNT3:q}'":qS1G_"5K.1&/%RDHb^1_,+|jx//%RDjH=ci_"uK17/%RDj:qcZ}?ZN4vLk!:qcZNhiD'n7vLk%H|';XwXW/%RgFE3;uc^6|%'t0:%R&3e/%R+w+uz]SXSh;ugk;uW;u_+w+w+wv+wbNZNZN]:u1_]U|SN]:u1_|Scn\|{~uq~_4Wc93gdv#"CjtuLDCaa]g8;7\/,Z(_HEiI9L>)J!h!tv?_p.h_"%s+wwrW~L\!\Z;+-^pe0^^W<W9TN5IrrMs\X,;>ouL)rMK	yp	I&%(YB	_	wx"7]V]oN]-{d_'7
+
+c(_=_$|b@2aNn,ZW(<pTF	'8BF[FI=3{E,{({g!>A-x=,R}7d{#"Q9RYwR]o8Ej"}xNR{G"5w.ocfIVIN3R\srG)~o9<ii0R;+	)H<'F9ZCpd6RJ>9eNN+yNz>s4-}bNG)}yo``+
+ZyK=.~O&E=c}fl$(Tz9L-++= Laj 	!joCAeeHoHPi2_7LzP[ `wj_tg
+t8j;V V 5}`P{}dAjAqP{]9ldGAsP{H=zP{e2^W$Cl2:P{_pP{Sd	ArP{liL1ET6Tej +^wY+-^w+>P{I^CjOP{ehj_Ka"7+rP{G1Es;Rdcb!<+Ez=\WP{p]iHP{qP{tw9jjG[(Cd=7C%AcZMr$=wj y@mNqP{t:*jo]KVP{$2^	j9j
+Q;-AqP{:^j$;joJ+~joJ++pP{AaJ+v\U9=M/?4 O|$/0?JIyEuV3.{|+<P+C}$}[\[b5K[xi|1{>aY;RN-]	}[]>?5+_Ibmw/;"R#]mw4]<Wu	]`vhs8O?b<ZTDXX4[:%(wtbveK'O{KgF4z:B.x4/6]u]tv\~Fxdx}ziwJ%j?4.JK,2{W^^s<MBfOrxOiZaX[&WrQ)^Y92k^wh
+g'BF50OqzZK+Oibz]d|>}RD!['|Jo=6K{2`\*d|8X,Z)Y;KX)ze&HEa&~aB1+vvp]\{X=c=5'_zQ1SgtW;R1;E
+	-\zB^zja>gKi[%)An
+ybRTb}fy]._
+]Q+zMA6w6"v>2&bfGy-FNR\W<Th(.%)&u;$[U6!MU%.9IP]OHOH)AmRK\J+*>8-=^z1]L&M__ox/mxA!)l95RC6`0t5
+<	R2(*	`!	 `"	0@#@2F@(%aapG'	x` (DvLLY0L TY0L\Y0L dY0LlH /[/	 `0	`1	 3O@R?Spf0hf0j%K`X
+ `	|K`
+^);-xI%0N%+`	<#`	a	4`	8tXm'uX@(PE?I`~7K`ORH bORP  O`)t`)Dk,XX
+]')8ti!"{X%X
+iq)X
+iLE?I2$BKRa)`)xbOR`)a)xuX
+uEX
+b,I
+,o%X
+DX
+KaKrKaKaKaKa2r,J%,,,YXNX
+	,@B_	K!^G\*Ra):rEX
+N:,IKaK!SpU k%X
+4X
+J`)R`%
+Ka5Ra)+lX
+uX
+5X
+%X
+F8	B+BKK[pNV)oJ BX	RhZPRxMA0^P_^0N@.RH@,aV!%X
+DX
+]uX
+5X
+n:,
+2+%0_)V!0_)J,WJ@`)`R"KX
+a,*b#r@8S&&$L|?_#~[-3'KYAVU^,2`jyj=)]COBFLSy]yqy
+
+*%yk,yk;uym o om#oPnS.W oWf[[M<<[^YjuT^Q~ o*[VBG!7w^HsAlOJi#'(<{_e`Juy9Y@
+-G[Os]]lH:?;q<+1f>UF'N(q}%KkQ	k*c]-OL~b%F59HY'%'JJrJq%95%$E~>s"OKYy1>"NMs
+UTW)RBqf	'8s,,	L2$d1Ifd1Ifd<[3@&,,d#LXX9ku NRJlR9<TcO vl)M?e*_9|
+AS6
+M?emJ A vl)lW+Ir6
+P*grr6R9W*g|lp_94|l Pl*_)$T9TU*gVr66v"";|k@E3
+pD~""2<vXh"(!k@;b/ 	)"N_AEI|D~"" c5 a(<vXh
+"(a?+<vX(l;QkuAE_yW A1_)*cRt|(
+";|sw+1D. 
+csO^UGM),7V+Ic.
+l~3H;|elQU#~lk\
+?{[?>3K
+?7Y[gZ~nUO|}a9|mA-_'/73||Zb	vmEOzvu^;aM3|}vp <Wj`Lkk?y^KK#5t;+(r|SQnd9c:j9e7uao]UhPs+>+~k/QM,f#F[n?wxXJk6~/v^yKyj>u1xRTT[Rcr8Lu5RyNhpx_	Fya5iw)9-n\oivnr&u,-.6	Sj9cTln+|2`6}3mhGO,JNnQZze%wlx|O|-bB]n(6m@7c;*ls}Ln&53OY>g3{f1:w!6;$9$Sozu:Z}+?V+7]lIwAl7:"Ytw4Y%rp)n%*`)L.]>/o\)y3TCFd%O_be52:>4j+-3$*2%c{f}	)Yy/9j=&;'G%mI	aJ)2%$|dya>bNSM>'}Ug_;.{E+\Q
+	(y_ctZ#)		MOhBB
+uTY{AH4H`*S|W1W2Gp)>L#\%eQ"^6e"`)f"b)<f"d)\f"f)|f"h)f"j)f"l%f{fQ"o6g"q),g"s6Lg"u-lg"w-g"y-g"{-g"}-ggFR\T9"GRR&)eR#XHI`#l$5uFR;9&[9N0!r r0!r r1!rt r|"GRc996d<z3c]9LgyU;"\"D	"LgX99 r|1qT"G"<D!rlcGX;#i,rhGM"=vDM/XT1b	N8sLp*dS!YTbNEbv8Tp*TT8hd3wm;F&Dv;Ym3[9MlSb	bT,uTHTB<b-8x;NgT$'uNET2p*TSiSxWp*\n
+X<ZxN3sox
+	g9nMSqNd8>gTHS?Nd8X8!p*S1NgTDSSSN A,p*Lp*,xf	N~vLyl""89TSkS1%NjS1$NKv8]T,2aSdS1"S.Nca
+;<D|NZ;<8|N+6p*0_)SJ
+Y<iH_W?CM1N;-*OV."m4|]8,\(7
+h~Mk>Vr'fhS	r*=Z=6P93z_9j?>Up&\:_>W.\Yw/	We-9E6OPK-h0F-,0/	L|yNP=-ZZWxlR;FZsRgpE-\V*^Q*u,mZS`'\lEx<m2DB(z0)4o(4"VP\oN5Q4VoAq_WXzLR:-glUZE9	&9y>(/V=eh(C:cA9O-*ST^O'dP-%#JtvjA].w]w	}w=|?5T}7ycb3c+"W!Bk|h!i<PS8[wx>mc?%bT2{:0WuS#P"Q]uM./(mghi^*Nh%8C&84W*qnPabV9)Hs4~R`]!)q;?XHX'WQSlJJe5eWM+PR_QU_1)#&WYhJ[[T{3)fRc>crQzYAV"S=C_C_[ 
+<	RtV?VPo)PSUkIV*h_Px4vg|1E'ru	xu]?E-"zumS+PTWzu=F_Pq0b|B" S> y1EDkSF^Lz/u=W?P u=NP :)p_E@} U>VvL(u}M/@]g 4C]SGPTtz
+u-*PSTRu) J SG u}.B]C]PoP*:W~]VU	 5Ju= b?uB]UP* :)P* x} T  H~ Rqxrzu	Pyuu]B]Wm*Tz
+u~ R
+ b9HPPu9> WZ|
+X^~
+WZ1_i|VAkWZ
+'_A|_
+<.&ysqSc&/#veyn?n7Lg!>z^c-
+{NMuI1.}l^rFtOF~vvB48Th%hr|M\;K91[d(Tz_tX|fr|.mtx_Y&3[^?j9??^&J/a!(,#s}\JB8rXF.cx,\#k"p\H5rAH.*gmBc_As@URAg)A*2V>o<+@
+Vp?z_~~U<Jp_dKkUg]gv;+p_Pez*c V#;bF,92H3us
+,	@F6}pdpC
+/|m1J+Jqkyw@kg\89)N3UGQxjo5~[T]~?_P=Jp?JN1\MEhW/4xRZdf|x&j+`2|yXx5tM#+ekkf|7V$N7^F:MT^Qa~wu??ka930CN3`#9#"g0cfL3)r1E}b/9c,%grZ gE63T9,};4X?9a;3MGztgP'|?1)qs1~_oGBq9
+U6]o+l.
+RMM}w6k(N}^).|_S-]}I{D({=Qi,~P=Tor0UJkKuQ|g67oA9S.'	].VS]W'r"ON.u]uZ|CXn
+
+jC[8L-/ 6
+o
+m1=
+f!
+N9
+jg"g,@4jC" g+}ajfvLOW0'\rHs`bZ+FSU[O~T7
+$?'OZ LgT7]7l.J}b8zPpSp"Zpkh5Gm;
+%_JXKWw2- Om9#n[[6oXRh]7x8_mkN* |C_Pd(0{N|{5(s:*=v5<_W[n0v:Yb{vC;AX
+m8|Tph<Oy5\d{[0g tQ5=
+u
+Q_
+2!>WaEus6!_y'zEEC?"/{50i=j`hTQ
+}nA
+,5F"5=j;wj50XrwPXQKTZ5;"C
+DAB<>r7JHE]%Rrw,
+!w)T}zT,!w.KERr3P!w1KERr7T,!w5Rrw"GM&G*B~R2X*BfKEl`U	R!:+xl
+YF2S$"dTHaT"!"dF1JfKEbhFf/"_!
+YR2w=!qVg9
+9[7]e\hWj^n7XZdOENk7%h-XeQe{ZltO=km	~-gL5{57D2M~z)j`!h#k4Ni#g5
+5-v 6dDMhEMjDM+0i6x~ii[QQZQzP[QQ[QvQ~#G?W~~~N	M85asU{
+\}}?Oxt?U#cN&@Z3X(Xv&[kZgOm#muK:kou=zG.lkm714Xw1<Q$sdle@KDk:F7zYjx|i-kU!=jfc/O3G][gqkK!k7TNUyf'^5NUB_2jx}o1=!ogr{n[Z{l$<>1ggjocU?<iZ$09=/e4).]p>mjWSAna(N,`
+8F5,eW{CtIazaE;W
+FFf+YQ^ZG:Yqj\x05~o56::ndzBbTg40)!)1_|\R5>=YbN>bu Zkv9ng	eE5U>c_kghZD>30F}'<Qiw9osfk=~k<	<xyIG:7H'#tstYd]KG:H1\#tst^m:MG:H9\#tst}:Fl$8@Gtx.0%D)!PB{1	##
+`#ac<a`
+SVWG{_X =3W
+ss0WbR,b#Lbbs\_QKX<\_Yt\=]l$06c26<c4\c6|c8c:c<c`	1W` 	2W`!	2w`"s.)>b$)Nb%)^b&)nb')~b(	b)	b*	b+)b,)b-)b.)b/)b0	b1	b2	.b3)>b4)Nb5)^3' ]W6yvS|;hvH;UMIN?\d%p>Xz`<gbu[4\@c cj9V_Oc%:k/zGl[o:blnbl8{HXln=nn%S4zN/k6f[S~V6Xz*[8bmil=6}F
+ul
+Em/:u,xe=>f7wx$jX;;DZ=fV[-_R~Xb+w`m!!7CVB^5eg5]LkuFg3/c}m`JG !. u6hid
+2F_3]jV0<lnaDlqd|^j:6:~5):W=XdKpbMXk{uA	)40)Xd19fHhcK	*pZSs/JT{l/_NK_k{1'>bmg>)ZDLi!u#VP\XAi^7efP&)"^)$-+#@+3d42A m h/1  % dco7o1o6?n1fm  $tm ~V_
+b} G F)P
+ 	p/F_6j
+" {m YAl  sm # A	'c
+: |@q})A@q})(Rp K
+sl \   
+@
+&b}l !' 
+?
+?_ @ ~ AFk	 7A
+ EFR:+
+?? (  ]  70@GA]
+ lA!)2OPNAAs!  Vv
+ A@X?zLCR|1 /QUOQ2Z)\tSwQKkrmpu+-`?[jmy_-6ZK-_WcK0_FX4s
+`~m{_x3r;oWv(///}lO2;GUp8/VmVg>7G7sNpdFY9kz7}){ZOy}hWiF75ZfM4iKf;/t6kwi{}gDn}wk
+Lzx9$N=Tj^0&wxY?4wXg#rG
+1dh||"'f'IZ0dBt*|:,P:3|vHw\hw|gw;w	_"gSs+wwrW8)]d}++[#gIGo? ~N.iC>rix${!L/q:9N:6^}5"I5b5WZb/9!?]N;R]m\UwMoz[om"4H",Hw"RUoJ$Xgi2"J7\f'JnKK
+KDR-Z
+NV"m74C(/{:=B$r`;=Z6k+)T[p/I]@on\Pzr5"q>g=?5H~}I7&oJ"c`9$xr3"Y&e@$wBR4F1|l^4{y[ rRdY59* G:Y]Tbl8E"}xN")G"Rb.ocfIVIN3R\srG)~o9<ii0n
+}BJnbI=1Hk';'\^,R.3urZs}iSs:J#~ScR/ZojJ&+$_F:v^MjxosN=.22X
+2Q~n?H #ec%`&-DQG8P[8)	t!Z[\]^$_$`$aJu<f#d$e6lfKI|fKIfffffKMfKMfKMfKMgKMgKM,gKM<g#t$u6lgd{ewR!KMgXr,5ARu,5PR&d,5$aa2dKMJXj;uKMvg?,5iJ;KONKOI	+k2q!a2V_)a2V%a2VO>s2'{EJ}d44s a:V|d&,R%9KK,IR%Ijp\N,y2,IKrKm,d$wudK2H%taIr$;Gk",HF8ZIj$"IdV$"`E6`E.evD9CG~VhVd+2D9_9J9U,aE`Ep"kK"6Z	V;u6kvLk41"bftX6Ve2D	Vd+r+3VVVHVBVd	Vd+ &|\S +;| Vd5Vd+CAV$	$\V"VNV:U:24	V
+V0	VLVd	Vs2>2j
+XaQ+;V$+!||=9X1&"WHA')\'|NJyHW_`EaEV{&o	1	+sW,nH=/htty^A-,:{H!PZhkzSO-,{wla>mc+1bxd^PC[8898O{S
+P:@,;+
+aEi36F.GfRq(p1)UJ
+Z7sq]&
+4g6)@jiZr	)%hRMJuISsKi%C3_^wK/#8-+^WrNC_BQnP#QH
+T{ad
+2|v3XEn{P
+hCAT z
+4L	:Pk
+th:dAICDp	t:-A)F2@>Ai:Z*A^@6C5:P
+th:4NZ CAd*
+
+"St;hC!t:t]rA
+1C4!MZm
+"SthC@Z.
+A^@C:&e#r@H_?>U=JW].-|YTgrNI_2qg>W>|-YG7%mm@ZVnM- }G'(n,m/~SK75;"m:w@R{}gfk;7_Tx_=E}GD3v&}5B+"~dwKw)gwu;T;~D{Y;ZtyI,'+jgSv
+C:iByGbZKjWowo~Q ^: K6nL_(L\ &~*~zx{TnCRihM+w5~OrxOiZafSBQ)^Y92k^wh
+g'BF50OqzZK+Oibz]d|>}RD!['|Jo=6K{2`\*d|8X,Z)Y;KX)ze&HEa&~aB1+vvp]\{X=c=5'_zQ1SgtW;RJ#<_z?\2G	c&<.@](q J.%QSlDsE1e='|#-"XGRC2z$YOg_G! !#"t8KzcztYd>YC0YzYw:|
+Y&Yb3z>#yF3F3MBF3DDc#8KDt3:Dq
+"oZ[AG0"	"/N-A$B bEp	""[k'B5txzx
+YOvLkn 9!)llzHz6zKzzHzDd=a"ds zizzkERXCMDDkd*v!yGG3SDDk%Z#!4d=:OYO=
+YO]YXGSWD(!)\|+!Y'"td=Dd=td=Y:UxHDCB3XCRBYC3KB)"IzJz\Dd=Z'LGS("# 5Y2<ZdjzzZUFQY~M1ScG
+>>\Qu-5{d3GCoN6jVTNox3z3s&rc+%:5)H2Cw@X_UmL2G^D@BssGM[[-*z|j=ywC+]_WzyNgckUk'_??xOXJY_w=Sx0y-2O~s#*=lN:tRo	
+?8?'N?7|M7N0?|_M-:;*vyr|rE+k>Vrg)'fh	I9W96P93K9| #>3_Yw/}:-O_MrkrwONQJ-h`QJkg%/w/q<_*Tns<jNYGu0\QUBpJ]-Kwd/d7X;o8[O?$4;E
+tx
+.)MjSM~P-SB[VQNBG'	m|u/x=UOG,4NXxeS;ew0;I/4YTK	}/( |yW|eBc_.j-O)U~MXXU{{jH%fZAse/.VOO>U5/LAn7jTA%lW~r+aElB~Dvadf/1+lJ25.4Z+P=){	&u
+e8a|?!%TU'Fy
+XWHJOv.#Vu RtYMuYUJ23cissLJEn_QEwM.:a	2e~.kET, j"
+UEeQ`b 
+&GRAi-YSIR5U5
+T5y">RA#AdM1A"lH*5+Sr](}EAme<n-
+n3xdU/cx8#
+UUy
+BdcYA7dUdU*y@Ao
+/VA
+`/`
+ y `.@`La$	00"yAQy<g?")3<AyP<8< <)<8<qa`c01E`"1u*t0 {Sy=)R<HfaD	0.(01Ep6a`c< #A
+MA
+` Wy@UaLP`0^al`a,`ad0*00)00:)0100n(0*0
+0<r&<X<.<Ha0+0l*
+e*hA
+`,<P`G+PA9,V,fbXy*<<X<<P``
+ V:U|9.M DJ{n7@UU+zm[:H;hPC}?J^'c}_GOL07T^~bFM]?Eg%?N81p}k(.{
+?1`9KP/_}-?-7O<7uw-~@y"<oW84~Pi^\t@U\wU}w%
+b^>o/o=c o[[_iwy~a}qEJ=w!v7i=c?po|o*xo:%xnuko1}HS3{*OVzft{=SSns^	}WJh|s|co>}+l);e{((K j)PH@!@R
+}Vx8W8DbPQE+58pE(s
+R)INs+C~HeSaYY[cn7Fd#c2!q+;pMUu1}w7V2a7e(<Lm#}JZg)u6#9F}I5Tfz|=-RfLR
+k
+Qwmj9
+0#l6
+{ys59Gk<l&:*8P7?'yWrdp>L H]
+A@&&>`O]$q~XIb'm$q~X F@O9?ILb'kkwL;9GwTFb+#r;b/71wb9Gl1wj9G1wr9oGlg$z9G) H8GJ;R"*pAcBHrF(bH2~?Cw
+"d~
+%]wF(,H%p#)H}I8G*;R"qwJ#eH8G*;R*QHxdIy;R-FR.z1qTwd#5)H8G;R7qTwt#)HP>1#%!H9G;RF:rw#%H19oGv#e$%)HQ9G;RVrwB5^)sVy
+yJ+'=60?"D[qIUPrfgLj%'XLEPwa??eeXz[x~GU?_5C0GEs0?5Osa|Oe HkLaH-|xxo|GG-&GV]dH~(&GU]T(~h?`rtG7[!$Sw1c,!c~%:[wc-!_?fg?WU#?/u:?+'=?U#Oka g{
+Go ?C|N*~kLU3[?~|`rdG
+pk|-7[??GQw-7[??LCGZUwQC~hC'`rtG!co~ISw1C~X_
+j- Cw3X0[wj- ?WjVp|"cX?eI3VF>R2sX/scF&TiI
+5;n?WV>^^pl3['>NtTlnTS^}fFJ@VFwU1>=|k?4nig}w)*g4MH_-F2$Hyf_G[yw%(WE}ez5Mw\qJH&)sw5]ejt7XK{gY
+mk
+(_/M(wyo3{'~8`1]]	
+2+U?=iFb=vw1#zF}m$rzYw{rJ ]GKoP/B}XNYt1)>Hm;-nvd;=c;v+#xei eF~=km=:-)3s_Qr
+{T+_4{e{
++o=(wxc\{; [ -yR<:X_~$t*EC2P@
+bA. h@
+A: dF$oHD@R%bAN H$DV i .@"Af 
+ 6@Av H@ B  A B  B$
+F D B< D!BL ABT Bd a$Bx B# 	QB' 
+bHBHb`1h!\$^@"!f@f
+qB9HI<F= q[ !@!b !@#@!@%b	`2h!$@(#(B
+!@*
+!@,B!eW/#/H"!@20!KNn.]u3G82)&wc{ao-oof;~lrd[1m5Ad=Z*JmfTlHint'bW:%|X[me
+7&Vn!idR&c"\\-AYzJjz1Zcz!=zQeJioS_z3w4K	|Puwiz[.G]zX%<
+="n9DcjwTb[@]q}Rfz^.c]oz>lSB+}BIh0#N:3|8^O,Xd[6>p-{6FWGI'42FGS*cKQg*?A]N-{Nr:uqEFEgzjeFZ`=HH62j73nL;xT|YnJZdmfI%'9>Q-0cs-ly{,_ajz[
+&
+{yKc}=dHK
+uAgf66cm)S
+[sb'r/QS?_m&Cj"(lSq6*Cl;(kuuu_w[)km+U|G3,sl#xtG
++tS5F"._u2R&_u"2 qI POB%~,O'X?^[aCo$Og$|*'lw*?n_d__&S~NI@w7Q77mXQWO2
+_!'!?_/| B/1,?u?2)k~X{R]]t	;lek{6+)/Z#zmGVoz]YX-1xg
+7m6zn
+yfydFg&k6M%{2y_7[?w\ouz^5{~#WkFn%]2ifHzf-wMBWu7Vw,FKnL!-*;uok1;=XJ?}DNb}M7aj6}ot>F	o3
+}Cmt={#f}j'PK*	GGj?kMf6tqn^s8usM5=e\mR^Zzzp-} =vtg}Ol3;Q7WQ_Q=yGGw9jsr~AZYMymi\X!$3|JC];5'l;;7CA$)+z/5GAQ?bLT1m&?g??&?/Q@p-lc@v5@|D~4{u/k&)~
+'O_O?n&_u2?!B4$_u&2@_ JI'K6a&:]e^'~:IO'_&^Sk67oE?W.:MB$'?H|?	O5	yTlXWBx+X:]TM,_
+a?F	t`IQ[V^hVC}6Sc?ldwwV 2mEhlY]+Uk'.ZVZojBVGx=y7xqyxqf}MB+]Rl.Dm^Z=ZGk^f:o3Tm7~ZUQWwMWQb|,:JRCWfh]G]
+Kafxq5".W
+dFoQcj70c[vE_3{|sZ"|g-kW~u/a}9H{kC>t'j5=j#fTG5FmWN|:Ffr}5{ty]6oMH]aN\9&>,N
+]MNOTSiGi=ZO@Q 3k._RS[73gd6}6W\/i6Gmq
++onS-TZ7!AMe^<:X_~$
+e5_mS;'{w7L@5H)D|?TlU2SBU}5|o1OO3;35GT5SLKULk}_3~
+jG?_ORghU5T!,L{UL[T2qG{>2qI Le\/J$XoO%?'&oOPwT7OBHb'F['O.S>L>+LC}OW/''?N|?	I@n?d!7_!_O+_
+U|?	G4TW+Y&rkSI?g?,*W$\U"b
+?pk!C"bwKYC}[[i9SV6ccwxd(L*]fH?k4hS;=xx9EYU{1ON#[m5$&6;x`ZC`S5HU9B{@7brr?,*p^|'MG#/>q={7;Q@};|IoWy97Cc;;~<pck9Jzw:Z;cxGzO=WuJt{"jMG&9"mG8uOln|2O^=tnIswsnZyT++Y^S_@luw:q^W!(W,W+Uf+
+f+Uqh Z 5h ZZLuZM@kb@-D@"#$H-Veh] Z/ZPhu Z" "h ""
+ "X9{?zY'2aJ7#'-sU/o{{c#xSz}7y_guGnyys3wrU}pn+xo
+Z9/zI,s9y^u]L<.=.v9jOp>(#YA:We/JYf`6r%ClG!]Nox'nv]O{^L'V7qOu~YVf$Wb	CPDD}"~e7<f-D+R-[P1Rz@ DK@(
+D@0H-
+Dk3R@<#>HQ D$ 
+e(")*dkD#E{4#ZPaOCOD4"2]@D#EHDugy> "H"OyH/BSRfLp
+ko9wn>p~P{TLmV}%k;[?e."OgNrs?QgT9?Nj9t/*5~=\
+5m>?s?##c>tWDe){{%=)z}?))WUY}2qDF9~3aswlpwWrjrZY@}k jl($p~ 4t!Br
+f}CUWB<UOOosH\pq~?eSI.v03p"?
+'dfgWkW3?{|rESr""L@T`?"[UX;0E/?f]7+2onW<};t.-;p	S(LS8VBr
+n?dVFE#}I'i?%]#<G	#=KvVpU"Md7}rU(~zy
+FF
+H "8GIP\:f\7~?+/gtj] 	<juNP4;:+%~6
+.N^dcVogMcGDFY}8]j CA
+(`x _fM:%;+krFvV?"&?)w
+5;q.1=y
+:.
+u6QToF-s^~vO%+^YxsG-gZzZt^2F_kMl7dU=Wi'v^?{Q:K#2gXTG.Fz"cowW|'[wx}}ZOw9{5^r}g~"{9/xyp[{8<QM\1t~0Jf:F|]:8G5t8F+:G03\LWq+6-_x'87N<H;.nm68}M+[HV\G/_]5=9g6uRgmZVAwys<ys9GyRC19E>6yqhg9O4C=O/XE<#@D? @0e( X3`%@0 Fb
+=@0$ `]@05d2L
+xXH;k&`$,N 
+K`*le$ZFb`0,@Fj4y,b8r `<g$x,Y@( 2 @(*R @(+5z0 "@(	j *@( 2@(
+j :@(H
+
+1~"g9BP$ T	eBP( T
+BP, TBc&BMEBP6 
+BP:g9)#y91%sbDH<	<eLRuodXuOUZw7[YZ_ccn+wVRk,+;/-p#Ly}~Thkt\1tw%skq_IF@|U .?'OO_F73mV^F_*a_w{S[W{C
+<;{78Bf^z{%mIg	?=:1Y6f(&x4JqQ
+ze[F-o@x QGebDYfm\[uowTwO5=,}{7EqL
+W1;*-G]f'![%>91.x@7cOIncqRjv*]S\8Jr33gs/sxJ>"s9o]=i(7cl;k
+q>m=45#29)!6yL
+fNlf;[cN_wL|}6=zOh3_>Lvl6Q![~3|F9{Rls
+5oxwLoz9;wtPVx?2	h"t$d@t> !Dq
+P8qwF!%BmZ@	/N,f,j,n,r@333 #!4"4#4$4%4$
+k$
+UNRrB,"|9YH!HaB
+eF
+gNRHs4nB	
+sNRs4gzSsDN
+8YHT`$:p(IC'
+4$zpcE8i9LN]8iHaAN}8YHF,$*18iHNiWP]A1N%
+qA8iWPD?NY[H]AI=259iH!QH4E@@E4= '8?I)<50>+ug
+m_.
+O*jwYejGoW-Vc:<S0[AzN|	mx#}+so&sY\[+}SsN?-3mF~!a]AwZ_3~uj/9!j?_/ru	yVs{Vd%?2hCWc2<Rw$?Y>+?V\7Uv3O,TpgTu]tgW9smB7}/>yG!$eb=zTO:]mvN}NmKmtmxc7?Z[Gvh'Z{SYL?b\3=H>x 
+E*"R22e/4J@\t .</D a` AQ:S0R @@4
+Dc`Fh< F!19G
+H*5,#5.wR#24jh^Fy5:/CehQ24
+^F( )(x#HA(P8HD 4h$#x1s7)YCGLk ~uu?:U5*Wza\)B(g?[UH3}uFT|qBnVUzVvzN8:#72j~usNgxU/OFcC=sP{qmwtv|o
+d7Cc;"x{Z8KWO7tv>5:K>9VTAlGl4k,9bY.9	sJN/kHCr_y%'@{;$')9Y+INhkwv\CFh_e]S	|@
+tyr9B\t+owWIpS3/&:VuurLu@)\B,H:c`$.>PQ3r+)k8whk;n+xM
+`v
+Yv,cJ)ekH8Z*JmfTlHint'bmW:%|X[me[-FMmt+}/r4Jq	*Wt]AinnZkA;~^whznoynT~+WzvMW-#$0Rx(.M]yet49q7['l	+8m|x=`1tco}9_Mj$T>JrOm*cK=j*?a`r	)WNEFEgzjeFZ`=HH62j73nL;xT|Y6#enhKvfFTr6DWz}V/giLec|w'n1n*f7HgXzli#)]#mwr[4CWP^j5.)BTP{-z qF(a!T$nl<L j0(o|E4@UCA-@
+sM4
+Q!DgF4f$jAo (q;n<
+A @n, !
+@#I2TiJB2xZj%!2lZIH29
+0 !/$1jI@j $BzY*
+BB7F8 d8H!{@H!@H!r$rGH<2D!$@%nL d7H'$
+R
+!@*
+2!$@-#I.!Aa @1nd d7H3X*|L3T!$@6
+|!@8R%DFt	z0}3rr/?woxxTs7_ZI9i?_k+?z;3z?tpcdriv_5m5^UvGa.@2:ro\,S}mOPB)*|'95h 2yB/B^Xq9 "1~3;v]>ycm3>k}Zz;Mwz:{_uN~}3uGd$'kuFV]Q%==l*g>ww:<}r@	O\eq+nuj-Kp;\:<#&rx8{ctovp$W;L~21>;+wU:o*NGTHgB42RDkddLHn_ PD,fZv)z5SPkHf|j\hvpvOE"2E=e|v	[-#-fK&v0C%7==r1OKa[&[&&[&6[&F[&V[&fa`db#1221OrxXx1j~&]72_w,/j=?PjD\9bzFw5_1{-{mXf:z
+{X
+@8`vm)zUZ[l	5j	l>A\g-<%g+__#~=F[gpw}i~2K6<r~?y'S{Uty[<Lb3+:]kV2)k.L
+$!h,	JNmxL&FebE/{)UsEK[wS[ss[&4<$9gI-rJTNb
+ 8#)9`/EyM
+_]?L]v2pj,
+^#IHX 7TcY_k)U3w/kIm8sVnhV)g5N/.<-:NtO*/M'ios#Eshq;[1ki8henJ#im?;acHnFOdv}wq'_T0Tx2fJDI	]m!mS.SVgL=-cU}?[|}>73ihW3G2WwuP28=znxarm0nZM<`ig_OuOYw|p9gv||x>Ddy-&_*I6<_#z%\lAdYWJ5 E5nl 3`@D9#E:CD@D? @06F 
+ K)@70  `lQ@
+f.gb,c$6Fb
+}@70~~lrYSr&eN <3WZTfO
+`*Q_j0qDFeL kwN^hHl6~>uW\+|jE!_QC^EG~z8T|:&uk@|U}k?'-7/r:spkj>`m=~'*^6v^cxQpE?+#eR}nOS|,?.u]>Zq2kZq8W??*XRfL?(Gu{UZw+	\M"Ma\q^;+b4t|h]F_RzFi*f?Yi7$IisrUh`"]m|pq[ms]-k#iee_U5:?p-.D>p qJ@\) #]1 W*c+&;Xc+_.;@\ev*tT3U]yv,tPcV`B-Z;j~j:kWsJS~g{\-+.YN<\+3rMR&$\monn3{jQF#-\ijFumVl;nt{i{_=E;TKCu%]wCN[;g\^5v,gmGeDGnTb{|k?K<7wFa[Sjv0.{\J
+JAG*\4#Cag]{uWA=I6JZGGo=Q%y[}l.e7(oYLH}>q\EM,v,uONm6x7H;H1Qt{2c4{fQ2#?Tb9(M=uz/s=l=k7b}Sa1oB{
+)QfZ!2D!L#J4ps~
+tI1twu~pe<i	do1	x7d_p0;
+;R1&C;;;jR1^8 C;R1X-C<bcAcAc1H*Cvb|d(C<bdAeA<e^*WR1r#W*_u!sR1>s8H	9T,C;/9Bi :R1=i#>HI8B9	Vps !i@H?8B9mF}0ps 1!~
+Bs B! =BI&F' 4t
+B, tB0 t-B4F5 
+c$B; 4B?&@?b{q?1Ot/LK|[[_|0C!_Qmo+5`=^C[-?Y|[9?C34a	=Dlypw_G(jl|q~x}/HjmY97^1>?t]:n|R;~r{RZg/[QbRmN={)!*_dM/@cg,"YvoWHD^:"tvh1 Z
+hAFjE5yZgUyZguyZVhm ZVh} " H`h ""
+ " "B "h"bxfg)rxfG)wD$"Es]Q:iv9J'^trS@q&q\BQD#J?aS9q11chJ~l(/GM<5#v&tgLXYY223S:#;
++^?%+%5kb,9*hsyC3
+On:rPl8O4DOmt9ew5op~]?4=6<u_vm]|m^d[]+tw_jn.F!sjSRz.5SlR:+5.RJEj^pI"y0wJFsJk"y)5Kj^{5%5Re6Jk;<C:]k;9u@\6|nd*#S2SRs.;""h_5|~^_M.fzYS*hP[y#xM'}K}K}K}$7~F?+7
+f_
+KL19ki)Cs,WZ_Kw(sOUg4-uw]#hzzPxr7Vi3v
+essyV,+4Q{>2Q&jr
+MHt0$BJ $YBZUj<^J1)s+xSrBR3RR,_vC?GFY??uezF	N{bqcoh(~+<`akf?s|1%;Gn{s]~u[>A<=cjd?G/3E%lg2%dFHeF
+X5uP]fwP	vJuPkteeFh]fvWYfj9dF&|teF_bX4mh	Fj
+|"*lebQbVbE-Z7 N29mb_#a?<*f;7\Yx}n;rO=R[G~ttrv<c_UmW=lGx
+75zrO/1v/<	-}W]Yu>8jqDmW{j[]y6qg}zQO[]tUFn)iEjC!EU;:z[=ZeovQsO9W>$9U.7l?uk@Q^ (a#M?x:pWbM\Q]|:bnj\I'>SGG=Y/uaQk_4m/xw	ER&t)wM
+M`vd\Q3W:;2hF~C_mELQ;}9r>6(=5?6W~zuNi9[Qal]\7*yzW|gY?;iG>/7/7kG'O9 _8G9+G$\Up<	8D|$s.I2W%%I{TI2qIi*IeEdJ)HL|dJ.$$IOLAEdjIN2/%?qxI&*'d*5([I2=_q5(cI2.$F$n)$>I2Ii*I8x.I"I2U%t%%I^$]dZ I IV>I2y5i#$)$>I2!I"I2fI2=JiKLUI2tIi*I($IIjz3d($$IFUL.I2]JKL}5HLm54ILUI2O@h#ZHzf[@hc@hzk@h1uw@h#@ Z@">Wh%cE
+B?P t-BO1_BHk575eR|s?Goo_*-^V)s})JF+=>N6z>>{a_AsJ{nJkkS[*1Ioq?Q<$T$]#gye#;O6ee);n1f4jba$7VIe:(6~k\A2X(?PRn:dL26)i1`2WSO%\gd>Sq[/#J60J93J%77GeVcoP4S2<+7(g2}|*zw3+- U}G,G;G$vG.q,GlG`!;Yb"ld'Kd$V%f2;CKS[cks{Y
+@,1XNW %`GKJ,)N`GK*-;ZRvhI9z%aGK*-	;YRHU\,.dIaIe%aGKT-);ZRv@r*7cxo.aGU;gh*]|ywz-+3a[~{/}u{k^]njvXm3>}mv?zSag{w7?
+>>q}oq^'goa3ki$k?55w~j}qp~u/_UKV%=/dMN?t|LOQxE
+<dwgJ8Zd[a*6{fVa7gdUX~WE_r4-(	p8NCo,xN[/cf>]:m/3{eF)lfTp@ItZ=w^G>vfVw~OuH3~3$.4p.$+tX0+2\jkSY/OS)+{c<w(zwxNQO5^4H~tHc
+(~t@Im$>IX `!Z@!b@b!j@H?B+{I+{I+zII7/Y*{gKed/
+2/-r~
+^Om[*{2rE/	*#Tn-o^7JeK!R*Y*{/7'KeojTNNkw`TNA
+.T$RZ$}RH*|klVH2
+x!K=2eD&_fKd%LKa|@&_:da|@&_:fK|)/m5: |U"CL|iS"Cg3e%D2ez}X&_(ja|y@2T=,/PuTLL+jLL)22D&_Z"/W~LL,+2eo5|:[3?~9IJ4+g_9+2_l
+WaiJ/N3/<#l2iByE+C1[T:Pkaw^mfF0O[*5Awi1\8RPEZ]Ijhci35,=9F%#Q-jLfl=_N{fWzRY^Ry`w|eZu@|moq}qn7%4ibmN5`6tc;uD:gWmZjoQW=vd&0'SRMW'.&'
+hiq]#jZFo[k~N_|oF~v/{T-3sWrb
++D]o468j7Kn*l\Dj,+{naP/`d`yr>q*jg4SlvOlv)6OlvFX>bbkbUf^bbbff'6qSlv:'f~LHfGbkRLn>{?q!4XL.KA]D2ruUjm]U}sNontw?g'={C4;Z'hv{h<L>BN[D?fffflD4{F4{D4{h"hL4;S"NNDGS&n0J9N-5$&3f1x%'>e&]W"64FF?~O'^ h&X"c&%#:|DO +iF0FFDFk:%OtSN3_B4z1iSFgfh0303Dhht4?h~#^zZlt,aOHJ*OOOdI*P ?E
+w;3zgQ,s`l[!9j]Z\a_QAoS4OA~&N4,YunTZ(c`goE?dSV+l|GW'2a#
+k8 ?f/^k_F"
+e_}9 gqwoPa_Sr!{VC}Q?va$?TozF^}P%OKu%`'Yc/YnCKxKi_ :)%R?@(p]mqqsjswl>$?qP
+${GB]
+>
+\"\Rsa*0C?P0&"X?HdQI~>kb@EX
+faCiSN,&<oX{~C!\YB+$YmNN*
+s'$0/cIMHNL)r?c<k=xJy/}+~*_>5rGR3;'G5NEq?>N_la3{/?:}~nvsO`u-]*MRTUL$WI5uRwn>k6d}hZEkWZdL3\)3]<n\R^xoX"9>I0,Z|sO:Z")EQe,Qf2<hgTG;tyQ:<8uIQ'8uDQ9yN;4v&y3K2D"R0^($,2h` Ua= `A,3S`gU,'&33&#51+>V\MU)=_<VK\hhz~N{Mw[&_JS~*O%Ujs\-G|Mrnkoz^'_}6	N5!L/I	,"`"Um]%:?OVi|N[9"h	 \=/$cHDQ=CEGjDT'N$OzPX/6!)it5$5pk1[FQ2bel.G K>J1SXgy@A+.r1G!;o~9924uylp)}YJ87^Nn&%%[]]$;	NJG3[Ol|q=%md/e>uN}]J'emyWzi4mCQYKkK#C+{y<_ew,P0%-%#A,_'D&W"4U&$H%u%W"L&tCbKU&n* X	XRXvX4X:OdbIS%bIK:[b$C'#PbIdbI'%bIXR{Xq<KK"VH&C4$blbI_[b('4^"DO,X1 X`XpM3W_\Bfnc?XHs<w	,WT%P+Z_WD+QV
+6[&$''x(3~6k+z\BwZ(GWr	%1`pbm6@>pc9El.b8q$=pUQ`kedZPap
+{ossoi	n*[*a0b}:
+5_;X0vgap,lHe,mP,==7OlQ
+B>_GwFwt[g7> elU+CnC=k<_h O[EbJ=4[G6d6^+Txok
+6yS|R9vgb[^S:dsf&*AYk&.Z|\nJ,<t]>3|t\OUg~+_wQG1Ru*rL|.rVE\lVdVz*cQ;:CNrCv`dDf$d?rF>6WLdXS&ZxEJBTo9\+'X]w:)N]'.'9j3O^s)qMxi>F)I8[AN=dy,lU^XL?4D2#<sT2k}9<ia=*XVqe`:@-m6toC0P0m0-`a!=X`a(8 `XZ *`. b0[F`b`fh@, A Cx q:bp$<5g$faP%2#3Y!"*C2 t/5gF N:dL:5gpG O:CVsCQxHl+h@:dL:dB:*Y-]B 3A:d0~!y!\
+} !A<s3C1<s7CRcxvHlUHdCV*CCI[]1&[2BP-OVB~nEJ?Z\>>7
+,]5h:M.uaPi_y-AQ"]Br?#{sc<(e(R,
+D%Y!isF_/$5P4|3&dL-(~W/-51!9\?yr%\PPmr7^X
+Dfv/hl|6|~Nv<T-RVMCm*o[nJn5lY_JwtU:w?gi-_5~s<ckhkh1'bq%}}jmZM?qy6[Qh>{E\VB^48&x{=k=;#ovwJ6O?&m!=Pz
+~3tMxoajM.JuSm}/EQ##"=.D.5D&DO3D_%:7>l1}71W%2l=8{g<a00dG;ahqU#FnYeFo0U-_R8	Qs=N:GwiBaR !YeH
+	)CZ<!:Czjf?,[umV|N?n:#'6sluP#^o}V%[k>9ntce(oZ]8CDFDDF[o{`M4^R
+H\v@wsRw pEOQ4 	@			 iUE~ X:E`````7 IH5454IHTh@ |UZmimVx %2s$D(DH"6D*D@@mI<$GU$V$36+U6O$EId@-6O18Im${18Zmi+D
+	D@-mTIgTH"D^f#F%<F@y$6$4IUI$l$_SI"DDDNTiF9jK{$	IIH"cp$H"H"2Dv$H"UI"f#Jy$DND~^%m#jK{I8<J9Mv,$18[Idj}-s$DS%H"D~F#$r$+*I8I*IdtU*UYYgMA?C>V{31vTRR.OJ5-Po1oA!NWDux=nU}Ehph'h7R+:Ww5wDMmT=QiV'u~8=1CY1wKn)?Jw]a5g
+xlXhw-8(-5neK
+x0svC>JTV>XU#NbH?XXOI%M3;%5?9wxIV	%	pV%[3v]XI^H :>UXG#E<seG%w*20VRj1cxEo=f{eOzHH+fH\@Zu)0jcg$w'6!zY5-,@MyPq<AsU"T.kR:)w 'Iyr<<s<B$RW8RHy\IyHy|'*X)H'#N=lR X/Iy(#"HyIyHydr<X]"1#qF"#D#qZwf:Gx}?E[\)YVO`X.t/jIJ`zpCO7f),pK2ZL[1[G$5k9|=	F*=ael$|jjL^+{@X7}'rb~[{	
+InOU-e-3}Kycg3_u:8>-c.z-ij[8h ebro   `_6#y,X?,xphI`Zv2(`'vR`'Fl<DNoebt+VBqN/!A7LNt?%!u
+_!A!F+c`M)w?sDk9WMMr
+GBG~,|y
+cG_@Ue/Qv;d;[M3lM?{VfT
+_
+-j-OH!_j[;N
+/2<@
+KmuAJsp 
+,*Fhu
+,\/ld-nZv0]Cpd3Gv=%]Wpm
+X]c:k]o89'.Hw=@X`~{m{G`>{Xgh},"\Ru`@O$fOo!!jUG=OWO7xX%)b=#Z
+Esv>E>wrd;mAZnXuz7Ds;\e=;7p~`ys${e.3rOT4kt'KZS+oL[45:9? cSUh].Lj+^L~PC|
+\
+,lsXI];XB-?2)%54(]`'+8Vm<b.\oD[{EY\rI7ns%u"EX:VR'*
+C	\H_^"9W*(HFH:2+
+l&:(^q9R^!; s>9[Fc>-Jc|_&	QsDfR^EAp4qq4U>)=Ip){~srfRfWr<)kKi+^%egtf,ZZ[rT*WMTF.[K<a
+mV<`a AXLBA
+26P20phX`a#X`aP	'
+Pl
+VxEKM#p`a2X
+5X`ap9Xh`-`ae,  ,   x  (  ,   , -X X X X X X X4Kz%b`#IMn`K'$L cHt2P?(0(6o3n%_W{7|O^?u_'+w/GQsr(k0%e=$ph/.u]++bJC	_>2
+&=f.l%GsWLj/oSHoy}ze,/&'>-HVC\dY0C4xI-
+?'?0Jn{&iblM,3cczO0>rbA;uo$'!Mzj)e4o4ya.uD)f.G\U<[:bO U=5Ovg=_gr)<rc)~bpz 
+du}(A_.0 -.00,
+PdAb0Pu.0`E.]dF]a #bY.0-.0Y)x
+YP4M0A
+|00 H]Qp wK8 Ys% ,Y<*`A4
+ h/ d?@h/Sp #4S1P!
+ / 2dAhJpUUIPm?Bs ?`
+a{z`]V+lwMQfK.{`d_/
+?{Jhp6S(xYp6-Z"Wx>5C`+Pw?,O-NAAR-I4?~'GG`poKXLm}^X!{GSL-tMG^6
+vxl_-u.iboeawE&~boG@j)04n2zqj
+vd=~G<=l>x{{M)ns#M~oS8|QEGs/Ole'Xo(x?8 s&6}#5}cCp>s#,s"GOw^`7,-N&G	QL	m~3%1jT'dL}{i2dvGjt{Z7FL,-L3{3r*fg-TXLBlmpu[	8 CF+|SLA+|/iMeii
+
+j$-iV&jVhaRl7aRlA-b[uza0Slkb[i==a>b[vmm)N"(%Rl+Da"MVvZjI"2
+_?Vh8WO@D+|o1x":> gph2`N4xhphRhp?i"`"z&I4 PDZd"vVc /evZ <N4
+vZ&
+f"J$<D4xH4h0m*
++ h/@[@.|>W!_Jw?!U+|#_(k~P
+-My6v|iKMosfc[3m_cGvJ1yZ
+G9>?f)9g6}80(G;hx%pl8}o[F-]'lTT3G<]~8SvO|qnj/kWVa8kkS(o1~}Zy|zoK+:hWwq
+V~4eVY*_U}buzs
+~hvs2ueCuQQ? 04hG&b.W?&z57c]DCEbA_k-'t2nZzR];=['wG-#;okck%l-<>?TGR`T+A%],J
+vJhlW:=W6l7CR6gPR~C"dGF4J%-#j^?Ju}1#}7j_]< 89vbl8b.'/9C1g6r(&9
+eHqS]x	b>Dbj?wxSw:Y[K^2H~{OY-/^#N[1<cb98sYK..wAT\|lg	,qs)(^'!d'1$-a2\XpS`Uw\Ven+2CaP+C6d.
+-sky|S08<QWx,<-sscvPsfj.Rsfj'Rsfj*RsfjX\&5lc1Pl(5;4jc9cn?XfK[1Vbi+~s]{1c,m\2Q:Z|QMRcq '5qA$5H}R_iai!A
+-6qb`:9hF
+ZlhqZlh .6 - 05,L/jHUt~RTuk6r^b&U U=2Tu$R]IUJ"U<T$Rv$nvT$R.WHU/J"U}
+j,WHU?T+M:,7IU%UT6AI'dI"U'Tu$R/if@RlZ#UAzTuHzTu}TuW3ER1L? uAR/f!RlZ$UTTuTjT(jTfR#EROIUwIUO0nNMDaZ%Uk6T$UA#UMa%UA	S/j'L7h'f1H]^aj&UMx)T5jRWIU?n&UbOOHMMZ
+q?_+ONup}X'X5>!cWEay&WoMo]/\x{39T7~-,Qnc5UxOFW
+czU=LWg=^;=/k{\EcsssqJ~ur3 COUvv.n;WWm#?]{.Ujk-Vheh{W0w:cvO[>{{=Yo1f{vw~ynq$N%j 6+8
+6T}]g1;UIdb]b\erigNsQbjN(-'(>g aO&6@l`6
+,,0 .d`aad
+6]60Fv.e#l bd
+FaPbD
+L08]6H@E+F>E-F@E/F0 F1F(@%fxd-`ae#lcD
+vlc
+zlc
+~@2 ` #/ #01p`D"T#,h`("9 #<d 	9r4&hPQ~ Ex [w<Qm4? (
+|ak BUc #H*a|w~pP:IS+[-HKZzBjs/e0^]%-Q:q_B@/t~Y]&]j;ENtP!z+:Ww5s<$_w\4E+K*RUQ3S]O
+K5nk>\S+:nOjoyI_6N AdjO5J? GoOMQszJ5/IM3{=+5+_JVk6drz/[:Vkew4;6H]%;2_?*=>7$aOLR/-Ww=-/zN;B[{^Y,tH]L)nsf[$[~RdD97(ZhnZ$ZH}1[U=Jvc~1PGS>4MmOk#_^W3l,'.&(?saRw]s0ZW/i;I_]&ezkk)ui{d,|2C3s?<Y[^^fb4P9{f4#<sT4k)gRg52` i(arI0E0rj0D5iSNCSr<ui((!_4h:4)D9
+_
+r>`D90WW5qH(aF9O0N#eSCOrtqhQ1Ar|ph)rJr(]<SQ:Ej]'EF9oPM0(aDfF9$q(aD9fqJlxn:8\6S<Z(wf)JLQrw7vDZ(JF9{uqXQDQrY(9|CQrT
+E3&sG(nT'R`I:8HQ)0"F^p_$q8eT3R`RM0(((aN9OkN9I8,)F9$qh8)!j1H9&sF5/r
+LqQN95q +Sqp@xJ9Wp@xwK9Wp@xK9xa7ftO2zhJ
+ ]dM,AoNWnj?c9/H|yhqSD64s\Tt3e>Df/.M AtsYNYlIz(_[?:(|C)(.L5qK.O*eX;Wpohw$G
+;?n{M?LuHm6]Y_ej=Slbz,zaoTh{MNyk6lO6CfGqMNZ
+{}nhmw~'dhea36+'f>
+/6D`zBXf~B=Bl+tS7o1m7(L)gnsuFn>~C?Vd8o\U\f
+Vc8[/Zu2|rdDI3N(^Xy0;e3c_63e3cw;-Uin/x<wcQ]u5EBZ,R}XL\D3TrC&.1tr.Jq9m]e%r	$SIvLD2eda&B[$Sh"dLdD2,L'2\	g	P0ory++\Fr@re7 r@r@rsc<<JpcQd U%JJ*Fr4$Wc8$W+Hc@h"7"
+W"	;\Yn rF%*e6+kT+m$W$WHlHL3\Y%\a Jr%Fr50*0J0Gr%B	]_YWuU
+ke,rKq_*P)+HO!03wOL&E$s#,S-~pCb NW>{BFe|s<~7:)lvm</$^PKxwRwzw`N\~NGMOD.JS'7X)U+r5S*2*5x\wy7URux+SO*7dJd
+		L9F1o)GHQ
+7q%o6J5d},{{Firll7Vn1o9{aNaJ3t/+* LTd9|@ZC90j4lC\M`10iyo73toJR6g#W"#F|^GbLz1UJ#BoRxVz_C}>z^c}a2F:R<a*TjI%F<jPd
+Rn
+xpBS
+RHBAGb!?u>mRL1F1`<6)f@3
+ll(fB1l<hC> bS6mO@1Hbn#D3P6Mb!<
+hC>x|Q8Ob!<
+
+hC>x CIX\b!<
+hC>x|@IQ6G?8PNyXmOEb!<
++^+(VBbX==
+Fq+XSBV(V0BX,-m>Xen/0u#ObPN_ECwh=a{};4a|Cuh%5+;ec$Sd26.F~(dG#?Rg#R#_"+9??`^l%)aRg'N_9lNe^a&X-r	q(OcG
+xZZ{1Y8.~>sN`syw|G7|uVKUZ^WWn"aUXoe@f%y;{9J%S?$;wy
+7w(1V9}[N8$z{(V:NSI+w7l`o1yJf:93HUz)Sb29{NQ	2?hSdIz7d~
+zyC;k[kEF
+,0jAF5kHC^qo5D>
+E>F)Z6Rz
+.2B 0*k'~F6o'^s
+k'^#^'^#^'^C 	kk)k2E
+oBaH!^S
+C2}5y58IkqkH ,&~O:PFBf852!>5C k5n!1%?lT:
+1P72uY4ABjY~y ^	KmWTs=Do+lZNEZNR2UYYk{<l5Ja8k6Ye ,Y+#"eQY~7~.,43@jS a;L"2)V@fg32KFMD5&s<TRc 
+	r
+-*sU}c:lh?ZcU|=o}/ qTK5c7@~z!wdkVawKNKI8_?%5+Z&?8W+qBhW5hb{M{b]'6[")&@n@n@n@n@n@n@P:k #M~o.Jrk;UT~
+0~A%]j8p3
+^QgP|lKh D
+	c
+E+xa QbhEQEhEQEhEQEhEQEhEQEhEQEhEQE[Ck7F+``R Da
+PNu_r|qJkI g)M-*[*%$O)
+rilf?O3XWt'#n/6%
+GZr}v[$w{K;.}_/UM;[tOm&fp!AB;&\`9tQC1^
+i<)C/-;wph5 ,\p=5kMABvp]'ZNvk;:u!fO]C:"4E!B,KsEae$0:|[}rrU
+_7~! {QR.R'%{a	rpJKS/n
+&V?:n-5!V4g/<qcWO\M|wJgncE^M+':o9WG7}jL6}@ MW|~dJh {C{j~jZC_L5UfyGrTg:w^"qXfoPyaUj#{F6jj]L^B0<E<eMZrn\d>Rhv'yW?e}b	v1cUAoA&c!=R1.tn{LX#t}j4so=_G{V_gUR.2ERIy!akSNn'SNWkTa{lEwjlC!kSiKJEOfUVOWc\&dE9!@$F$@Bglq2^,jb6nf,p0@,x0q
+~ $$F1 ,-X Z[ /AB@Sf`@1 <wc Z$0L`P`T`X`\```d`h`l`p`t`x`|``h/P{ #@kVk(pHQ0a`E NGj`\+` Fk
+ ,
+> n\+xc q	j`xVkV 0' Xp`!9 N,8
+, N,8	@pm9\`&3A
+Xp*hc,8d,8tpej:p9"x3	-sJS@}hS3),Le`{wJv]lTLj
+_5u/jj/=Cy[sttqz=kWh :kOcEqFRryrJ^~'7[U2d^)tk9#q?+zqf{eOzHYjT.*>R2S$_(O
+\ i@N{ :|20'd`RYAX2/7d^1iaA5$,SQ5)[c+$)Rlek|S~5^)[=5fSpYSz5"upD,PyT'ZGG''%y7(YQpg?/9C9JJ%0W/u/1<"E,
+c6b1F),;,Wh@_	cJ)nw(-w-31'Nsdt!H 7p$tpwmj8@]k8v%A
+4wI[Qlw.}pmzK+7gollFl.[!dhrQmw9s
+:T5,7e6]'5*Pp]MhzM6
+(c4@k(s]-=RPe6(c4@/	1p%)ct2FQh2Fw(ctp)c@3lPG:2vO2v' 3`w;:BFV_1.
+SnI[Z&ZOR
+E ?
+ZJRFzB9;?*\@lq*]gqOg2{%yl9 )iTkJ|}0BR>OIOcq-+:2&! e2I/ZR_[q
+qLYz')\`J1KA\;U
+OO(v1jIL)
+oMJ`#$/2:"e5_EQ@`cv\^Te~Y=+KXhU}bz
+DWjyj|c*U+W-(S9.uqyXFP93(/]'ov8sA8'@N
+-;?physE,3Zv`)>!FK/5M?ehHJ?
+_DZ/e?6%5!m2_]_//xI6jeoO[z)V<Z~xsJ?=^7}o=7$G[[E:=6<xoAJZ+>*v*7\R:_?0767_6Y2N;D	{cys'nJi\K|U&|D|)Q-QO?:{>_lUb}J_r2/>e`H'Jh_%i#6W~ap5W~/yeeL#P-:QUOIl((*]S	GcoWvN'=YI~c 2"3?@OYP+7_nV}XoeYR
+[gTS)R}*w}-.z?RX\qc60h#,j0
+F8X`aF<o6Q~~(
+P~3$4DTdte(HhBGPP!,-C1(HhD"LNPR`hbjrzC2teHhG
+  X` X`;X`[e,x
+9 ,xI7,xYw,xAp1oyu2X@`OXHb^(`{&wc	`UXOnJ)c'V1Z2-R,5}biuY[ oo,s^F59Q7RSJY5
+'UXmU)
+gj_*5jpUV|eu(GC
+c
+
+;<ZT04dT7]mrs_+'6uf+2;
+gk"pxUhsCvoTg
+>Gvg$C-[X>>7IUxA' [`B6w-Yc[coN	!LmvEv]`J9v{/e5jdt[(hi^Fz`-&5a~#0[Du@mgbW'lq?xh'?n0<wa-
+ek1_cU5!*py5;']YS'n8MHr3L$$)q!arp#!5aHk'[gH/xT|Nmm3_QgfZjc3K{V->iuj0[)w&fKPgb5zWD,7KQTV<-@t^3.Ah7WjA <K 1@JH J
+Tc '*c )X *X +X ,X -X .X /X 0F[Qf10bF@27+pW(2eG@r?- Pn1'r9ZPn1r9[9besh@\Z=r9[ybs"(#y9[bNs,(sA
+,l2Cr7<Cr<Drk#"!zHn-cpP(B,229-qbs`(C-Pn1r95[b
+'1'
+1g9<Yes~(D 9T!xc
+Ns(sD$-$Qn1Gr9K)8M{)8OPSp(#E)-PQn1r9V[bs(PSphE.ZxQf19`[	ZAuLIuL)EuLsJUYk>l\7{G7-&M-oUW6_7a$KM9^Q>crBIq_?:'Wol%?Cm'Y<-1b9kW6Rh=0;0$qn?|J?n};\K# nqP6>&ca?FmKNpT})STrsTJ% 
+K.X$`K]pe
+,\.pe,\>%]i'6!DKT]lt+O2}zG ?dDqGP5aa)SMIqO}#  <P4W`Yhi:*RYiZnV=[_o=30('=g~od{yvvI{k?~zw-&_Cv'E
+xF.+g5UdE7(zOtrq?:}5Rww;9}8+=k4FdtaGRn1%)&=[kb^{\n1w4c=3coH'-
+2Af+g8>3-?CVuoS.|40Gf}/1-~GlsIwMOH[(M\gM'u/S3m?&uGz_&e>uz)g;$<>pB.5*_<O)2N0dp?Vq19n[7=f}T5j+ocG' bAN;"v DD31
+;"v.D`!bgC:"v<D|"bGD;%#M9:)"vTY2N!t^D##bgF;6"vnDQCGg;<CBGD@D#@DC@Dc@D@D`
+F
+!"C0"D4$D4&D4(D4*D4,D4.D40D42D44D46D48`thx "!"1"A"Q"a"q"z@Y`Yvs-f+_#JzP,-(,L!uox-
+|4Oh'Ch}eF3JMr1]f:c!:-U?_~[Ah1KG[Vksr\n?etaRf]oGH?yN]uJ(>"#CYaxCxW9JcH1_,zmIc(~.Y>I}Y;>'4t!<z9D)CW;l/
+^PHz?O%y?dW	)#)~F6#j(n_yO<~W4!m<qO*d?%f$iBzbO>BFx#>H/\70|S~No%l>)(*M3H%wl?tSazSO
+C
+]kg'a/~mm9	-Cjt s6e[	0t1:ah]9]-?=0&CA!`B:ASBDsbs{`RhVhZh^hbeR#hjhnhrhvhzh~hhhhhhlLM!*"+","-"."/wf{0e9#I#Y#i3u	LK0s`Le\ LIeRQ<TfL*oT T9TfWT.)TR@2)@2WJ2HeL@*sD*E:!I"NP^HeR@32R@72eR%RRq<,Tf;Tf2{tD*@*kTf#*
+D*7*
+4E*!BmC`HeHeIe>$|U&-\*"*Ie>%LIeR)T9Rc*^T
+hTfTiTm2_$RdR'%RdH2>IeR@2?R@2^6Ie"}${E%ItJ*s{|j '?S
+m qZ{I(C4[rjPc%V$.nFjlNU&l0^GEiO{EG\LAVnNM}JSsrBzdTi[jc*7LJhF*\q
+ZiFj.n>F-j|[jL[
+bKo[#wm>g6Pe/%=4;Wi-\m<~Mm:&Ul$mM!L:jC}mJO]Z<9,\D- vfMO[&f7#W\R1{]i{tyj~R06<Q 4:bTHE#dKT}v #C0HZA:a
+. Q 4RZAhSK+H4RK+HkhI
+RV&ii)AC+HdbM+HTD$$yo-Wd"F[9G?=;;wFVy 7?ZYpy+in:&axi 
+Ch
+6/}geQ3v#.O9gwnamux+Z;Z`~~Z+Y{2L9'}<R5
+Q3bt@uL0c/|'gwhc\~Y~G}.
+bOWs5D1wg0N=(xwsg/y8nF`V)#Sihi/zt/`jsnl:NZVY0<I_f'[3GF[
+ESEzj: Xuf0	n_%w+'>_`8!Ov[g9]rG<hwm	RIoB>pUg"WmXYPOeJn;dRijR)\*.F3 KEHv`lU1S/Qh4Rx8S`2lsl?`>l]aDxHXEVI`fl3x8)T<dG?ERl8
+r=F$e#e(,{J>QG")-lPp0cRPp0gRh85)T<sVRwlXIIl5")T<mw*4@!
+: e-m&eKG#E]=A.HRv
+Rv+)")l")[*tB#H/lh;)QjR
+8RTi-mGa@EHRv#@Il_I~LEHRv)RT-mG"eKEo
+D'XMHHqQ/Qe#ZeO??9PuTkC
+&XQFi)!&M[	s	y!Ah@
+T8m&t]6	`Bf3&te6	;LAf6w009'7)t}_%Dzc__RsHgm>[uvuY3X}kDtP4WgUt}x	2O4JCL24ed  
+Uc` (08@HPX#X(I^G#Kkr+97?2:JW0\E+bbGuJo8qP(F)VvKGSD{N(
+=k\EG3(T,fo0%R{R;nxlu\nyP~mzxwuV-md]zAk<Tl_\;[.E'|^ilo-z1d,M-|E[t]Km,ze.A[6(A=pA;B-v\.uEmY*\hC})lT+?mX3
+	Tcg O<b?vr4y@V<&V}\ d3>}Xu?:w: ZG	  " " " "=hlptX D$@@HBHD!"12CDBCDRc@lHnHpHrHt >xGx@?zIXjw?rFk/Oc0u#N=)uSuVO`ET FzRNGTQz	DTt@J|RM|)+E3pG
+zCHB<H\}|iy
+=<oO%RZ,Jn=Rd'Jm%u
+nV_*PX."t>eBnGOz,	BTR6S6(89IrLXq9X7;%z>^cGB79@;/zQ/7
+?+S,:/7="'^+$?+$GTd3qbR8yox/&}Uw>LH'1T7"9?SclMA[i8hO6mMAi8h_6
+mLpK$_J$%_DWDD+T"U_"*a .
+=
+s']hSO3$l'];zHvIvM=B"EKb"EKb?#EKb#EKb#	$zJ%?%_%*&~JkLdm.dTkdSSDp`/x{2|{nLLo^Wn?q!u([glT=zZK$]"{,|d%z?Ld*.x`xhQ=u{6M<75*7-8 :
+68j]^8u0'lf^p%\}Qr@e>ep'6
+mmiC1F;"[{hh|{m
+oFivQYUi;/	w]~My5Um4'-=Uu0
+|
+RigN}6?-$!j*	*{|"(UaFiB/y /W+k(>s7G,?K9^h]IWe1uc65 wb.aS[Ozz}~?#/T+v7re~?9.I4z=.Z`}DK+PL1YdFj8@2CEDcEDEDEDexiEL_^70+US9/4_.72B*)W'VSNO=Us9v>Rk&x\k}r\<.?$5Vu3m-a?w*{drl!%`>(^]RA~JBY?1L_6r})X-hP\ _T9W{RwnYABE>jms9;5=kg%&`/w_W~Ha7|`_<W:yfPaYBWU^Mmkm/l>e{5;>E7Z{=4o.,=zf_wbim3xrqCz7KrJT$Jz:9/a^9]1~Ti{< 
+k0OFABO:+
+4 ,@au A"QA{	 D
+eD3D12LXTCd.*f dTCd4*Cd6*x!2|=FK"Q!8dL<J`*ye2R PF)C.bjue`}O0O]SJ&Ud
+FI|tN 5dIt_[\^rBoWo|~7=#Z{liOT	}#wbI;5I6M|[-mj%ba;7HnQ|1#w#` u4`n	#t 1@x)1uQ[n[s7_k
+7I:=vF
+/cwB
+B,,x~Tk
+u$`,L_
+I|0/H$aD6C4($C%qHc=`pLjo'mIj,>*MHR{HR{HRAf## GR
+ v4GRGR%GRH4f}Q3]RcQnFKxF$Hm7**SfjHW
+F)?yRN.\lZ3'4Bq`OJ'4>NM_-s8cO?_^_/<'| }MoSNp$9S^n00dh1,N_^)N1\IKle^iU0=A2vjH-V+Fl}U1Y0 -#=#M#]#m#}###3ec SVmogHW
+Zp\SS>#;w8Fz\:nl(s\[XSu?B?Ft2gEW*R^VLBmNbsS?3  M-W.A5#YEXnxo<\\Yc	vV/.[x@n(Oev!{.)Zn|ksIt;}BcF	yx0{S`|10eiNww&,o Mn&cGbB0fC^1
+iK/qqhPxQ	bJR8E8[8vf10c~kq`L'0|CqN7vi<MZ'f~@voh>%Nx>Y
+cAO1ps_)b5C-7*1q&|uY3D/(?0ER)DaT f[:c|l98eAK`uecP)zK	 fJ`Ln3
+&d6=C0}&
+`4@r&^,~@&'NInInInG$;$[$BpBa!G3Gd(n
+dB E id]"n"nHHH+HY$Y%.?s$w$s$?HvBFId
+dK"9E`tG{H{H{H;V$'#*$J42J$M0HLv=#Gu3F$$_HvIv?$$ J%&IvIv'$S9=E	na!
+H$'ETL;@$}|_eq$$q$7$$Iv?%Vh
+].v4pe?5?,e??Jl[3OmQ}SIAvUznr\eg]4\Yk| oc[r,J,5vBBX b`E,,!X bVEJ2b{,gM}9mm.!Jm$$h/XQ)IS6|hC!|-~5qmg\mPmI_Y{A[m\<Yf6p'mN7y@f'4
+lmYnRGS}:;>t]>cqK(?Z}YdjgAt~/}Q=9@Z:x_O~gtSsag5_b2jJdo:kmbS| vZgU;~D_7'o))QR!dVfqb]=l%~a<k(m9,x= V
+8UbXE(#k"~
+UF*AG1b"T*BQUiPZ9V
+"p[E(+V.tXP+Y% d3lFh VT!
+l V#f4[p 2ey&sY~	.C^g<\F>FDNFD^fy),/ Gi\RY>
+p2(3*7Q
+N8tKN^L/
+:P5`zv9'h'\kRv]=_UPK_]ndj/cvRQEeJ#uQrBftc@W`)^W7(/;}bZAZm|Sl#S
+,Y5*wo*"6)cjur?h@e\g?9?F1I&#J/ngO{}SI#gy)I]
+u:wJ(~P k2o6,9	u;)x
+]I(]g&LWU\~S
+k
+mO2nH%6EU.{]N$Ha|7E7?<G{x!W1SYPVu'`8W[awY/\
+h+kPjf:uWzYv	(Yr%rfySOk=_dNonW\W$4.<X
+wi24G(
+zMN{7Q-5 T6*5=q^76zO#q-Y6=a;H^|Pj"_j(]eHI(;FjYj+T[}C]?K1w3&hw:RYJ9rLZt'1aBc(~xm;}sB VrB|ECBB$($+'<N<;/txhsQ-~ X`pF\R#6{3lN~Wn@[#ZH=$<jIx!
+mJC%9o	%	%	tHgD3F"Y"*/U$<OW.<HxHxHxHxnHx;eKe+e3eLs!)	2		2	^	xgg''Hxi<{!$(+|W&YL}|#2		\dkyc
+?]?7){
+:s-leR0){)ccsl\NW?7'?2JjO[`7DW#
+AslI+['=[X%ls9_h,eV|.|B3~6|5wMf/ZKPQ
+m?L5 ~N5 V-tYD5 ,W`?\J_8$zrqTkC
+&XQFi)!V
+My+B	\q{@CkV1`j$Q9Y$H$%?@*PQ+ D&4lX VHe @>T S
+|a!< %V
+>9*N:
+>CS	
+>hE*P$T[ 6@pnX`U
+> )V)
+d%&dJ'@,HuK TDBzqe{e:dSVCQ*T?7<8+xG^el0y/Wp =z<o`y0|@q	iGmckvu
+I>j3@8Y|DRwPR|VRXCvcj~p`
+Pty?uEJH51%C*%`2j9Q2
+V`f7]}}Y\Pc|*=FR`>
+IAj
+@7`	M0o|  y0'_I&@$H&/
+C J@.l}@2H4U$Q|~}e@`@QDX^R/l7>JYZu?K+9$?:\xQXek%F~P`Av[_s~"|wT~{a_ht	?l})Wv;/>|W!.w}\oT-3B?Z?k>67j+b+>)6IneN
+o+ud',^QvbZYV#ya57hUSJr_p~VQ6-]v2	sl@Og
+70C`VY!0"C`Dd
+DdDx ,A`DdDdDdDdDd0'X!0
+S`6YHCa"0s}|b"slE`$,+1gIqgQqYFI?9=4FB"<-N7eyaoO{gEbX	\l/j`tcyuT8vpgZ" %W,US^@%OD%O6<^Q B)'SVf=O9Rs=4UN
+zmw\&7]X(/bb=eZ"5 1H$\^?B2LQ~@_b;/SO;bW_.Iva7w|]~szye{
+Go{J>0Eb)fY#2%WN#T#86r71nF0kW)vV&<<V KEv[ qOIS?"Q{D9Rnep7='POOs/JI( !pl()gL?^<#QOL?uC(R2^Yb<peT 
+T eDY!%*cdHo^C)RsgxNi"Fu>BjSs&>ZW>ZIqc~nFm,%IA)3{a`Q|IrK~YM-[6<Lc|v9N"Vd;Za?;Q
+o=_k
+7IvV){")~X:]@&@Q5XA{Y|F,2/|ggvec`2-%eRM	eil|Fedk'_Yws|gve%eq/	v|-e.(e/SKxe
+lb|+{vIER|XYev[cj?j#AS8ateE7,<?6]umk7p$e&^
+
+ao5\#6>y.7Y%:Kb*;v,>,zR Rc.%@e	Pqo%@e_JYtisCQPS-T]b7ef/4tf_+/jmE=pq7|rpstc:h_ Al;U
+K]n~Dl#,*+\5[)P}LQ
+P>&v:}/5apK^@n/?QP	M+m\*9`s5v-9rIhg_8|d7/ns6{FE(#5Y1q!~JMV}?J1J<+58mTh<AYqT+Uz~m.U+5Pu
+Fm~#u ^ZX#0
+ma`<lm	Kd `#Z
+eDxw^.oF:$:~;qOP4gJww JQnj
+Pet(=VbW?yQml	AzxK$(oD9}1J,U9?\((cvygY(aY%KQH1aSImoHzh{oyW>./R||,&BOlUJi4SJw~Q(
+ttxhjV&V{yw%? eHd|';B =cH->I6jX&q%a#Q--hpZ8AK\"t&K$5Ij#%I3I-T"HRsBR3\ YTt%j$9jyd<INg<INGt2d5l$9jHrNIrFI$9x!I<INOSl;'AIr6`;*YIr<!\*!|:2IB$}II\^WEL_?g"V-)k&j"J_-~t}9yRs25]?[	%Yoi;eec9llh-QqrB!rmovo?K|p6B>9!nrwn+_y!>!!!^ozWTXt?_ozDv!Hn3>*N1UW*@	r;	rQAQ,*EiH/	w	7m2222{Q&}Oc#}_(/p{	mRRHIH_IHRvP{e	/DHc'fSKvfEo:9r=0Ge]W;<#8*FVt|\Q{{3Q1f?%~bT{|g*XO6JWND;H+s$M<OEk\
+T`UkFGe4JFi4se}{47=HV0"uOmfOxi>RRn?7#:fo1bKvn!bza74nGP; hb;q9j^?\O'(sLiZGaJ<]>hKY D:nxq\z=z+/BMMZ0jlaT-S`FL)qjsjHohjj9R8RK`U;+u%Ynt8RG/q]RKAt,CJr8~njVfnT!.Zw?qMmO5.m^lG&%"Qc*~5zK998{D$}$,+J"NYBLmN==>f)QrSv9'f^Y?ec^j]5wu5U(M:UK?$yXaqPA?:>up.3\B+rlkibl3XMFNqMlu,Vbo;>(P7-RfWV O Cb4]\$>b#G#w%RE^ UQv-DjCews
+.:VUXYso>PO*m<oA7~"4D#4};lvyZrO-NCoy6tg-N#s\eegK7\aGt9Z'`,,!X"Z"Z	"Z
+{`-&X{Fzl@!hEL%l1ZC*&HOIojeZqjuJI^Li3
+_c?"{)'wz^_G(7&lMk[no1pPLW=ye86h8VZ6-:}CT.8(U#^L^]_)qVfF%73je2{_nLz4k8+_+_]>O\
+J82S	Z',yO8@I/-\
+fBk`uTh(%T)H~E{>xk
+8JMSg'c8%:C9*#Mij5^{A9'#f_j|s)[m+k99%REA-X6Y-~Y#gp~j>~_djoUAP5$9\nJ>
+gE	>i]qviYfbOc5f;l6v*J	A;b;j-Ukv{c;j5hG;j@;DD[dJ.2{^xJsAgD\Ao9W?pzq;E+\|.jwxQW4ep>%SAe
+]N=xLrw+w5u)\kEw|p4
+nWvW83 ,V1?XS`Q,	J,%	J]QUfFeNQQGpfq+*\dOp[lT6T}25}X?d3hm0fr)>k?*R^/ZrgeLFV<76Q6\m;7Yk^Rbwjh `Gz@T4;6	djf;A^9yNXZh)WGJRz/%FnTol=ASj0R=k56H}(R<<zqb3bVoI^Ur
+,'_H >^i-?#K#/Q_F2?f4vo?O(Z"MihW~Rj`>Sg~r?KD(~Lr^413q)W~%n	Zs#/bR{BY{^f0D@%Z'qiK90t)	t)z5;}Osh#"Z[5Bj
+z9w!b!b;1y ^6c<h;~1#D1'DnJ/Q/D>Jf7D'<"ZKgH&%b?`@ZK<Ny"7I0O	D0OD0O
+D0OD1O'DhkS~@1>y"'y"'y"'y"'t}1\-9DP(Rjj*C*-9g9;;?2^?/G'f)+?i\SdlsGyFHjc#bu/uBXLI7Q:@z'e|'~O#|?2o
+G"n!iLSl~Uz(__PUCQ9CPKk5Z+b.?#&NKz.; PWp AHM?8'VD|uD|. u |;&Up   '-2t[W3MO+x
+7[d%glof{nC&kG\qo
+~6+v/Ccxcqm|]q]w5+0e~ N%G|$D9 A?"~>D9"E>7"~vD sjIKL*
+?EyG\4q*Yt#
+wC0=
+z.
+[2oLP_Ls=2#(8Q!>}&	1S9ju\h0xV_+yk5* /kz kW8>=Q>5y?Q7i|dK_i}MaYI|1E.?$itzHc= }tw	-OI_IOK{_Ik=H
+$s{HYgHv#l]5[K.IN[[~?~/
+$~4k^IiwiN=}1}.~_kvT8&>-Z[!"Ch%Dl)Dl-FbjB!b2Vd=Z!&"(ChUDlYB/@z"+g0=!D)[ bA{CEBoBz",1^=!6Dq!bc+z'QUFn=t8#gl2AirA~h.2o%qc,(RZtKxH!DSI0ey?G)%	z8IlEu`\"N-8}pEUD<  e/\BU}^p;J+IZ |,7	@?/]66_++hwVfN5AG)?{/r'?zfSGTuZSQiO9GoP~RX(9Or'|%6eni7g@;W(!@X>.sAt }p[s"ES	$<FfH6p
+Ga(4=	?+?"~<DcxG?6c9xG!|
+U0DZWw~7V
+\?07'7 _Q#F94d6+_gnfN^~n!Zilf9<T+ W1g)2;(x\O8l)ec}tI^j%DAjPWd9#$+nTC	 A]VGE*[C<7Es\I;f_4?pF3'KU[S;2"15%5u+V"5EhT1M7B+~u|1WabN7x+ &bnlR`GFa_cB?vGT@6y_.U!{\{7b<J[<3)-\	|4Z{o^2KVkj-ZNXbl
+X{^o5h5W1
+7M5)_?T`)<r?ekx7][<.7j[_+foRLD5p(Z/6de//*
+\PS?*JsV
+:Yx~+6rTUViKFTh -ku]##"z+D\,O!\?^8
+Yo2G6:s"<pg> F1#NhyrT!'E%A,J0"dTO-L~/\ 9/[bw-7<(~4M$y=/'^#.1	s&gW|VDy,%~OCLP=bLXpmuQjQXY!~FoiDGoyD%5EB b b b!b+!bK!bk!b!b!b!b!b"b+"bK2CDe----F/Ya*mT&Tr+_U_f=h|{WE
+!:8"ciU-boJ' ap?bo
+-N72r'w"mltQpHP;
+/]^VG LTs,oO7-@|s~lH>\e76@7*A8VTolwmNiciKp#+QX!f-*tsGV*N)TUQl0XMa{72%wDJ
+\j9&CAN-s-yfvuSf?rJr/6wrn"t7]nzj,951Vo6\b^c8ay55MnYtL!c4}rYH;-ec}ed^v6Mem?dk*o5/t=MY
+	&7Y2'),Z8{3#}\ y3#F>?"~{@!|0 w"~W}!w"~w!wGD.Y;xmoon2(W_h[g_q'e?i7{u+_^=awh?:#
+1j-&OoRJt[+E%S~MBP.'@]w\_F_H~xe[_|g5?D`	yo[B]>
+\&:6!b\ PG [Eo!mD|#0QBNx^%o)|fA;c_(S?+zZ/MPG?;5eP_j=wJS_m}[LfSOF?`FcPo|g?R/|;5WCF	_)Y+q	uX/o/F~XbW~K%'\\m{>pzY5=kzAy@EB1mr~1g.UjA@-K_4cmb~[utw\x\\z7q]q]'v;EK:AKB4n#FE%F1as'~;6\\s\%,SW{sy15o}0@7\Q\]80B 3F:)M8qQ?,8nq-m/M(M,q|b4n<.5&K4KMn4M$f2\h>nQzZ%N%YQM'gt=w>MJnDnY'q8{%x>]buGa~f#gx7<fc"(lM!gL!
+i&ESBDsb/&
+M!"C03D456A
+hvx hx)$C0K<4@DDefMMM4cD4eD4g<@M!7hyf@M) i1:P""R""R""RC	6T)=mg6RH#x tjD<Z^bf@a+RH;x RHCx t\$D%D&D'6 E!"M!"U1BDbsR"u!"}!"4RHgx RHox 4RHwHyvECDCD
+DDDD*DD:DDJDDZDDjH<&@d%+R&]:@)Q<JNRV|Sk ^v_+F<\ZzV 
+*_To,^3C)oPxEGR[W^olW}~E-z)
+`QUU_U5v@p*TzW5.|XzUSUM/>j3TBf(*
+I.
+]7(E$~QQknY]3x]5_U0dUxTN:[|(Yu;TQ;xg~JdlQxSHG|Q6Et\QE1aU1}IuCELoUwT}yNoKxT
+E	S%(JoQ
+af>Un*yPq3"TFaEzh5E#4F}F^h_tc~h/Tw?Te*IgRcTiV$&7*,1e2(E(6EM]?{WU/*:h. 
+l,\RB@ t\yQl2-3_Tj>TVf7YJ
+S;8X|9=w
+-?5S?8$|4mTL9sS7+7O1e3^]e>SP<*J't
+?H/R
+B)83c(0)8 ct*8 %($37vQRPp%)(88E*(xLAqI28`0IfdJq@&If,8 e,/8
+fQi/((88`()H;I28`(x
+% f ]Fq2(h_Fq@W 4*8 DAqQ|Aq2*(^Aq
+>PPRAq:oQ0_Aq }n 3pCq@N =Q@
+PDq +@c(u8 ZW,NQp ZW0^/8 ZW4h](u81
+2Q@
+Hq +@! <A
+Hq7e4SP@
+PIq +@& R0WAqYAq@eR@
+[1oBtmZ>!PD$'}&7|68]z<ot:ytlH&;SA/.7 &:WO]O\=E#~?k[],+c y 0+_1Z/yz@wm/<|s- fUYMzqNYp|vq_1=D_{K<)u2{Se4%?sB8C;h	/D.EsgIG`
+^+?u`M-q#Qg~!6z?:+)_cOiDCR$
+$'{Yz`]c'3_Z9|cOODx={1c &3(x =WU2x?*(L'\B(s2(x =W'\b(s2xI_V_g)y^Ss^oWc*rTOWO_ 4*QnU^R92	9 j?%WeAKhg}z=476kodK[w2?~a1S;L=>eZa-vnY1zUz ] g> ;!&5!v! y
+Ar[7TOk$8e/m	YHbw%8F%	fKkjuM[ wQponW/?/?`e0h'|z;g @_`Yy0Es}yF_g
+|4U.Z]'/+iAmrXcy
+8^An[Dsrv4
+ybFbG{N9;*5';CW~<~4<b2s91=GZDfl-2D9:D)4's'f_{{F=q+87/OrcS3_3K1;&,2'G-S9S;2sw}^G83V.|s\M)N^dSjPc[q68g_;Qm2qc9v{lqBNid9')
+L(1o91`9P7;_i,,3O(ZE1B:OYvyiKWO>s9iD">T<\}MlTBM~#4Z)e|8'-qS
+K2LrP.qf\15q!E8{f!,t|\A;6`!) drHf!i dL8d>S!dC*1Jf>	+Lr#>"L8z|&F)|FC.G2IQfO:C>VNIrb9qNCrvd&+TCC`!OC~%L!d&Hro9q9Cn,'is\\Na'qi!!$PNrHr8dH2L2T$LHLG8!3q1@qNCt|8KN+C>$98Ny!:C1${ !9D$9qBu8oNsyO%u%/>w{8u7rOp+z{O0Ixc>bEYM_?F3T\pw}Jo_?u~s,.[P?y7\\t`r7)6S=]q=z\NRb4E%udc4sS|loL_wTtKrT;dzwY~xcx[UTsTgR;vfhPy`#jQ50+Y0fom,^IG*
+&Y)0+Q`v<Q`3${`J*$=Q	8P! F94;pR0U/:s-*;_VN[O*Z7]aIMyu:{nso]	%Eub\m=W#=3q^u=2N(WXhk.Mk,*_vU48.k.-Wmdp.!WL4LkbjNmwu_6hP
+}:Ue+6gXRg2n]#dHGyi3z;Tc9:eG[
+CO7>{%co#jb1rBc%fxC_0h5XGl c^g[9oa[d|01qgFcc'6T]5?I~
+
+\SO3~Mk
+WmVV$#HX2(	V
+$HX1j a@	V$&HXQ aeAd+V$4JlA	4 $h
+ A#@V4$hHLK@d4$h
+H= A@M	(4iH4\'zd5NSx5R6.LjX<UnK8Qw'J,4[txOK:<,;
+yS%k5!u)B 5$}3??{7 E>*G7H=ge	+eMVA-A&;9B'^c!d{>-/)$,}eIq=M
+rjrOrZ@wyJ!_2W\_=P!ZC}J~_fyQ'jG+Ij{#c!]	w_5{^is!r;)/\8\|\T8Og*'x$^Vc0iwFSSawwf< -Ih >8w[=1Gb'Uv*pOx -ZSR_AQIPV AiQ2E%S` AA2	J
+&SntLm2%G&SvtLm2GNn Mf.!dKf1@w%3tH]2CAwKf4.dKfD&!cB
+%3*t]2Bw%32t]2cCw%3:t:@	F!3F`(QD$(H0R` XA	A0H0b`(1F$6H0n` Ac	$>H0~   @0 	H @@ 	@$ H 
+  <@	@F$ 
+hXP2p	 @$ 
+H  8 t&*Ej(}O{j
+y	Zmuh_}][
+Ya<G`u6A6gPmnBB~:LVP.tC_sBgnMBCO?#^7{=V#&Qr: h]JyV'4Bl3r
+~/Fory9a*9q?dcvwsB	!k4^%vNRi	i#B^]?v6_ce6q@]0nAF	;z}5<z-oQQf))DVSaDxBMI+Dhe$B'#@6Ol%
+DxS
+J"<@l%!6TFLe(P Sa,">DH$VeJ" VTAj!+bEIzdlJrQa
+>CVTDX%S2%dJ"<TYSOdELE15EVTSWLe
+1ETYS_dEL15FVTj3Mh}KL^hb1+_W_(oX~:prlGOb2KjT
+Yz~qLwSF9%5R>9>Y!\}G|zc+|YO=KfYoCb
+	rBrQBh!
+0`>#LFcW.{F5o u=1kHsUl$- aoRVJjuSeZ?e#o}N)Py)v(wrX!Qr	p.Q?%,"yy`^-*ys<yk[v_[~'oM9P /[[eJ) A))Pr
+(RNRxr
+<) JetBdt@h|J	\V[:T7YfMOtK!c,MKcaR	|R*>nU(F=>aNc>qa#w'KuN~F/i~mU_zjV0OO('$	%	KJ$	$OO'$$	*|B(O>O>1O>0O>G|'U	uJ.'Jo]>&WmW_Jaj@o~V
+mzL2nS
+x{S?sRLe +?5	>L ^5ia_AOV4o~ZbD<P*/UrtU ?xK9Prr<%c\qs8:oAmw=)oal{|l U8&V.wk+wD|N$jl	<DKf'qfqQVYzxkg83-r1^bNz}E>^/>bI(8-3/q.)cKr[\fr\e$1
+_sE!VSWaz
+n@g-b=[$#ay0lqKdz"O	cep-JX<s2a1&`1SjaQ"E7Y,2b<[hxhGTXtxNGSPva1e@yNk@NO@N%Ag1~J 9Nk/P D A	@T1bS^_SW}we'n;W{|eT2\?OTU^CLljN_*gW(}MV8(~8Ghu][k	4.vJmz.%pqY7{`(r-Fm%n7zX,6me;+%)6.YRNpvK=V5.mfnE\K]X2?
+ZepJ-waR024^-{[>o@^k1R5sxM?+xYy"nSuGFb~V3e2_he~)@3A(K^IY:T@(K@Q`(1Hj%  , xR.jHYbLCg*+'2H(*J*_@A2HPg A2h7HPU'D}O:)cPrWP{0f?@8{;HxjJ/?i/VqNRKve>pnVE+!\lssKA08%n({;aW;if~%k{&oCPa65u+#QGY^F/e1i^Gre3;R?H?8_59?1,z?EW5hA8k|5ut?jlJj?nvfU1VYc"W
+[?e'?N;Q;Qf(A33A;Q=vomF*,%BTX\"58EM\LX7Mi+:ltP0Hb;(tFi2c:LpP0HC
+>iB k(W\Zy5?|?{|AaeziUPyuCS_>[t$C
+?|*H??2#H
+_<W/>O(9RO!J|K:;w't=!u |/.u&w7".T1em1$h!/#_=Fz`	1~)	H]
+)IWIIi%<tCr||<h]?0Iw!~tG0mF>!a1+]tC;qIW	cY
+|hwcewJE9sw6&O%)T<9 ?ln7KS/wg<XxlW?&@(/|-P&YM 	$H`+(A$Jf? @[	l
+$m	6`1yc&1D)T (?f"c,?f"c0>f-dln:lX.xK==Rf\[Jso)uordCv2!w;m Dlo@loDl<!LlL"GVc gU7(c w(Q,(cQvtl*%UO @N	xY @v	p$`H3i P2l	0$H:w @	0$ HBH
+&\D$#J.	X	$`&HMo1,uO,vG0?u0.\co#u+U{\uV5+Os:+]wZc?~!_;3
+k@_:3_4 nUg$QL\r`13wdTWnU]|f
+t-5\**ocbz-0VuBQacXx"jZ#_PZn"j_PZ.v/5Z/ "jAED#@DHJADm/>eJ(})/.-VG]Ko9'4yfJr1:5&kkV&\cO2L(-)1y_:cYse?p"=%-64?vH-sWeXaV{
+[ t2 @uvv-(t]!\4^ZS4%\FF-BV<?w=Z8gSIe6,Cs696gnJdX,a*v})s.Xovkeo?X_b2r}Y=K2xflU[dtF]_:6Tg'?P&Xd~)IZNQ$L\hM=^jM[v<k2s~uX_wsOI?Ffa<PM_M"B\PC lm)|rH\B9N
+-(NeHeBx+QV
+-;X)TZ)C	z%
+-Z)|JF+Z~r;J-dC!J))Z}J
+1G+3^I\|1
+1Z)jBF$Q?
+1!L1dH!(A/)\5%;b.RR-`jSTgZ(%
+T(R-'jZ+zY0XI`||W	e/o*!`W=>_G[|i
+<RaCG=/#"{xOy/41=v~Tf=;iCf=tQSGBtR44=%>gs/Xf=dM,o1f}%[%'Y,]ZSBkwZbo26Hrd#07^te#ULY\Tc\}kji7OO{CGk[#u#G0(u`xL$I^Q#NNN=m2DJFcXmJ|<zSM7eZizS
+MF 1@oL^i%=mAo4%9=t0jJIM9QAEDj|[(ARwkw(YiT?U\/1<\&5kf3Ww8B'+.2BI@Rr8pH=#`TJ~S'2iZMW+p<k?Y<vezVqWt~Ef#TtiSklzAph}(g[o5ND	czpVk6K\ajnYxI\b??>;9zxjRt_zka.g|N_Y"\=rOkl`ak=QeEqwg\.(M&~Y(k'qO~>zRlWgGDU4#ANq%\],]Z%[BC_GaYo#^z,G{.'G-t	zM.~`hSos#>Hg>W[=G_PYHz\2'
+}Lp|j>9r<'/z|6By?.Gw*{5~Ds'#['GI4^)H;*Og
+<X9I4~DsH4~DsH4~$Os{M8?xC/8~9%>wUXro3bV;%!fMcYbV;eN!f] @K	,$XH<`}(+D,$X#HH` 2AubB`Xa
+$X,HZ` z,7bA5`
+$X8Cc^4U-1/1RP 	0G_0P0(J`!AZ0<(C
+2<(C2<(CtI0ahC2T<yt<(C2(O6XudyR:'eyR>'eyRB'Jw!C; 0O	#N'eU	
+/zX(j!v<za}($H@4jtCo5v<a^VK; @<@; @	($!H@D 1_$ $H@I -Ab<B; 9Q2	
+P$ )H@S Ul$+H@X i0	.H@^'@` AD	E"EWEEsM^/_<GWyouzu8w1
+j'_-]em^8&fnyrHnKVmk<V_b\e'Y"Xgc_X5|;\S&_uom-A\qJ=8N-;"W7L{gZn=WO47M4 zu15^FoL7_9}#X 5=KnwV=zP}V,,5p^h1T[[u~Sh}
+MBSsCOro4/fPBaVY!M%BaVHg>IY8OkV?
+^h=`R:;{kUo&kM|xogkY[]$WkeoiTxh2])[f\X9QlT]mYMm!=$%Ly(+IyCV
+>U:>uYQflWb|5|5oT}Y{rbYpPeQn8'Zyq{('i+KR(Ks=[Y';Qf5KSu}r73y>8uYkhkfqoD'=]v0@DmTqLIPy,N1|S},N`XbfYTs 	&$H0dDQ03A&L%3ddQ|B 0b)9+)9+)T|Z1g==g5=gTLoq{\Q2-Jfb.fXbf.fXb.fXbf.fyc8c:#9b&E.f(c?JX:Dd`$`4`D`T 43b,r1@$``	`
+```
+`d \\kPp$,rP&,rP(,r1"*,r1",9 ](|aqAJ e iXbEi2<OWq(RM<Xaj^ch4^wypwOK=~,8Ux y}leo,}o T?wO&r>zy	ksjWO|<y(>,k{]H6L/~bc]jB*tkr3%r?W.<~zc=Uc.w\"NgJ?~$9|F?"sz/h%}Bt 7Gimb&{_|OWO)r
+%Cr1ugEW_$(x9|fJ,|~Bd|w#-;>F~9:
+s?/`k=_K5P1=_qZ{{!2|Cs{fWgJ~@gdm=_a=_/uj {V@gVbv%@8-\Hm	8[b2,3	L$H05`nH0;`zx43+);6~Ic0M:R5`pRY[Yy|K
+g{06138j8&7f(i#f8rAL9)&=r`f#f r` fr`
+U90@r`TT2A9ArJP28A. 0Z3xA.7HnP2A.`0~3B.`0"3HB`	0&_
+%+?Q [_3C.`02oUob\
+raud`%>
+ 9'pU9k)5\U4~1pUG
+W_u*SUE
+jhb`9-wW$1]u1]`91rbwe&<_+SL^#`*,b?ZY+^VeXaGIp~}Cyhm/glkfcc
+{t3`b=B.8dGAEkLrBO>F?{|q_V<wc]<
+i"/t
+5l&2AAL/tg]2J  7|!_f37Dh\Rn\t15J'2dTc=sUM`r%T&(z&(RL\2K(3g.
+0g\zQ91Zk0p*
+\W.g?9q?155>#Mf0G9soo-gMF[$XhB>YhaxB>Xh;XG8Lf}Ytn>/\jK=A1{a_8{-K_{J8]Y};-\>1~Lak 	#CAO-HxAG.#*|\9Z>qWxWXc=Z=R|\9R&V#5zl)Gj%=R--Fly1reK+[f\Rc#WeG(cK+[~\
+` #W
+))>A5*8nqIj?M]2u%X-na'V&KE6E\34LKmBu*qgsol]">u
+nd-AU=S{pT8xYsKVm;m6-:me3og
+blKU-_Uq+7J*qf1MU,W%MdK:[?Gy-L[Z{limm/2vUe
+K\YUn^LobFMWtQupq& LZE RU%NCRWK$,=J)9oeZom#n#g#i#F~v&~F~6[loQTz/aV\SzrMfjF5u/rF#% Je#ffJcj&7cj*7Le1Ec/$Zj43LQ2,Sm2,Sq25Gh`^2[{|`:a+-^|S&^54u%;_	;,3y}q7goqYHO)pzw3 k3	GUI7
+p8J])%AU+G>9`O59;Zw%Zlnbi7f~.`AHV!}s1#2;?t {b5&|O7y_k5u	?FJ8
+#q z],	]y	um-d'JsV1w[E\<}%Rpc616gPmHpc4sAWy
+4A?#^7{4zL3e	Q	8HgzAs@0;,=#~r-k>q+fC6f}g>'KON`f)IQrjd!xV;RxH!|KJG)V{x5a%v	8 I?@~Gc(Bc|gm'5FJSRO)o5RRwOQhij8M}r4VNUJI6Z9yX+'OSkA%U(A(_%J_QR]|FI5%.SRydJS{5!%(LI}@IJGO(.PRIW]>[T3&Dj>-_lW}	mCy
+k5[{a}m&3\f~xn2>t1V
+O^*pX
+^So	`?Y.c*`cs{ZvZVH.o/h**VzXOT$\@U@6F<0H"2W{!?	!c4)?>\NR_3m%][.
+Z[(8yC<Yw\n+Qa@QV~VJ6Zi?'J*=AO+iOT%	=AJTd=ACZqOp562K[X^2~+S&<,Wr}gnK%MXjI$=hv,s,iYvYbI9/96z/h\1j20g
+?_@B
+zc~.S{I,qu"i4i6?-9io,=.S@
+(]Ytq"3.v]BYwIrI+{Z)]Jb%Q$+0=t{T%{F+)]tkS=J01tkSEL1MTN|I=VJt	%?PRc%djKiL})mLA)mLY<PgJs6,6A6NPJ*uE&^?I	%:c_lTX4T=Wzmy5q~egn;aAU"k/W9~\{u!Kc0]Ub8S{>N{{mmpBzZVnkW{X\8G5kgIZ5J;-gkk`7h;
+cMvRrgu&fS'.6f;_+	>NIZc_N=
+|=cW:s~}X7PW_Ww]n6K-+q*xEVx+8x48h'N8^JP	xvxm'G8A]}m$7$SxP[&7GMo8^8(5qYvxT8U#$S9xFz:}L
+1U$815qjv{EM];q'h:,q;K$SavW;nNwsUqrbi_:1e|s #kGOS0_`cp#7ilvX}
+p - 7S
+[sCUm.*qO	hp qk{$z=F*kz3ug'y%j}QoMK6nI-6=T0u7?o'?Qaygq#=Tvq&}eg)~#90K 3&fdjq
+xtfuV
+vx+
+1J@[CHx(	o%{ -doOqfo$}D Pg$Wu<\)_bAsfei`*Zh_=;uw:w@uv3'Rc&~b.{iJ2'u~3E>}'e_oyw<ygqO6;.5m:5Gk~t'6Qvbk<M'aRa^5to]-o54{=5veu^A5
+l?5
+2 aLF
+k43>qa}/6aM>{1?+EQoKF~
+q_t?u$%sEZSpBdl0]85:-8j9`	,0 	z%	 A7OH' AW@NLoP_; A@=Bt	$JS8
+B`~Lp3t
+G!0}QLp;t3QLqCt$#@`:%B`~	z
+u@_,.9[ AA=	J%i^d
+LA]Y==;ORKhCE#1e
+Z_o%Ek
+Bc66g7}vWg>xZl~^}*qgb}6]"^/5yLmzz6>}3b}1Y	%=,S36C(Q?
+Eblp#g{^uQo3ng	;<4f?;s/L0_Lz3%I9S;S}Z/#B	 <^gVR)f]RRS0AE$*>o"sTSP-RHE"}" 	,2"{"7T|Q"T"j']T3"#N*NsR0IE1N*f:"`O'UN*fT%RHE@%J9L?Rp#>]" G*"z'wR)'T4;8_"N*"TBcRPO1[TX}_06HUaMBF~&Ma$?.a?,IP"O;7ndAa}k+h,Kcz08/d^9W;c1*-KO[jw^*~S(,]A_M#d=t7pB(wHDL	F)8ed
+.$\~<Od&R/Z]/t)g\Ay;oPG</\_:03C~>m_*1s~v'&?==wj
+y@}]uO:u
+]u?A#.4FmY21j.ph':t%V0u2huVmUA	|f4f0y/e1i^Gre3;R?H?8_psa#uU.h[j~M_mVyWfI,4;m$v0H H`Db4$;d$vA@m$vpAAi#Fb0;8 vH`2#b3;< v0$dbt3hh7V_[x
+'zn/w=_u_skP
+}:Ue+6gXRg2n]#dHGyi3z;Tc9:eG[
+CO7>{%co#jFmN qwaq@p:PL]>[frG)Ovq  A?AJPr8p?v?o$HOI:4so_l*gEz_zkr&|*lGOb2KjT
+Yz~qLwSF9%519?H%@;|V7/~w~@X[b.DZ&,Y f
+/Gd]UCe6S6&'0f}G	q7B6B1wV3<s%n0\XU}?k<navM+AO~nnI;P)vr$r{%r#$r$r$r%r(aEmmmC	+2mMn+6M'M mm/m/mm,~D&mmer$O mmgcrQhE&>)>).=q-,8.+
+@L9E>
+KL|u^Sh/]mn5s
+;+@_z
+9^79@FtUpN;+NQ^m;4O\0mS
+s<uUk]wg]}.$xOW}:7nm kx!eb /;S/kwJ<75:}%-6_>BTo5JQslX~xc?nMB?|_f=,JyX-.CJ!YA(b^g[>U|P>z||1G,NtNzns\li7L5^]rm.CqR@_K,S@rz<)4P)O) D)(4VPD)DLY(4PD)R@T<ByJP&J)#O) N|
+u	iSL^-{Xk}96y
+f*` aP;;	KiV..5 hUJ5,b*)*_j_w]w/;9'~$B6@{bN' 9BM<ym^\|L'Lv3"@l/9NXqo:kySMYRc|j_}Ew@qyN?~c9kk6I-8?Gbs\Xz^g>.nA.~.a,R{3ovkm;b5r"l6bq*|~R}gMgAk|}:0>0
+Blmp;xw:F uR}g}zO4
+5{g+\LiChNxzR^}vWmq4}gzpX_3dpo
+sr=vu$f^aI,*+uYES=rU1^5X;wsI[s/?'f{|FGo?E<Js.wTm0on|^A$wk})*G6m~9G@nnDn?/[0c*H;;e]z4kvH?O0cr	?Og8f0jrT
+Yth^zoPcq^ mXOk~w>+ ~NmrbS:7Z3V>D K-yh5yVdV3eV%2ylpUL*V&o[fVW9;Agx7toOX:8q;<gwytp>=BXe*F1QMUO|gRUi<yU>_e7>:F?][n^]M16ww}7V%Mkc)FppsV8+y%*9U_w&
+1[57|>E{@q[X ?Z5o:*-.{qJ2ZLABE@"Cy+.VdE@;1`9ORZB&&K93ss#mt^b/2Q*Vx?+vFFt2RoLHaXhcV?hL0z`?T#cm'T*wNuyX-gC"[Nd+l/"[}Rd7l"[<8{8zGpl0QITi`^.o~i"%,Ln[#j{5^~`7AM&\=38%j4.,TXRj 'qhYp,b\,rn'2Y_Y_}Rd{}FWo,ru'^XP^W=cA{]pUuL#UGQHYPj 	KA%3K j
+@,)X)S`	(@%")AQ$y%<Mx_&8
+u;'[r2oJ1fxn{
+Y 6}-F_R&0o`nz8cR\lP5w6.FR<aFwRn3%A,!c	83K5,!]Tg	:(BDPANJK
+@IicMYyWY#>XYyFe9jXuyPC"'Y>k,9o9nr38`,r(hD	*z	-k	wawe(P,je`xYZbU9,5X/B,T@=bb$E'?Y7/S2v'OSw@By'M`c:9[vaE?rW~4G2S5ol1\UGC]![c:Kl 5K ?K\wDjniYR'[|SrhEOv?~:zx+SeBRg>tDDJ%^kI,-ioWCR[K|wZ#y>c|7WE#WJ>GEz
+gJWs^zRJR~|)Gf$/3c)~w	(o22vz\4Ao10U]Hwo+1@b'D:0O$wKo_!1gNug:xQ<wO-1Tb5!Mxtc<??3g}}>&P>&PCy3%s$+%KVjNg?&??y1;c?JUdF-oY*
+]->2+{kQ=f/G_]m8Fc94M;+f|7$"_@/++`w.<K}~~-xx{)BowH[~egqZ=wY\8[vp:C5=\7Y\GH"r/F_
++dcV.ol?v}o~l9sm^vZslYHmVuzVw2ucN5[xC.ol%0tR-!2t!*GBCt[_u:q>k&9b52:zwc>bl|.w4rwM=z7;Xww?6H'<Z3V3]w$s[s2B1=<<wyZ
+s40y+:>k``{y^`{yWAfws50mc$2:>%so&Dc;W1).
+)HcVx_"ar2H}}yXQ&g${>+O:1tk A.\\"^"^"^Il<cF~~?t}Y)pJH`l+Q+y(k@ { A5s&fV
+\?'}elZzz_%(V|)%P?:V<6.u*!)VN?But[(w!|kLc=*Ej9wE\rq
+uzzYcmb7h0WZ.^,Y.~K-Xbn?-<W\M\'>s#sUM_U$W=Z
+ZB:=:+/[uEvS
+^{S}Vl(u5Nki\#-+_TspxH5Tsi"dTs0h*-WkSi!FoZ {kVsH5[TsH5^	;9xOvUVsPz}m1^pp}6><=K*hSiuY}kT\<uU.uOARiTBD:!"VH-
+^T};>rc*FD=B]PhT$:R(RHO| E4RHW| eRKv0eY*R)Ml;P@o)4l;PCY] R@{)l; eA
+([~])@5XUO*z
+PmwS STe]J,)P( Tz
+P5)@XUOz
+PARTe]\Q5)~U\fOeydUrow_)b3t]_apO-(Q/gF;Zuz<?16dwJ)B{3=g~?m}ipwCs}}5U#s=!)';5	W
+9_#TJ/m+d)l*5"AYn9:\Wwv[[/+tIBCS	]7}54mzcO/Z\mV>xmlkv	6AeStNSIV-?XFh+:CBF2X.kTl=v:.-+K=$>6DggYAW\nklnsOl]7b/npEarDNk+~,(Y.;i(wP?cq+sm5Trm=A)y!PiBTAD "ehyPy@!4yDD&V@-Db4o	F&r4o	G&4o	Hp
+)IYl&4o	hJ&*4o	hK&.Y51G
+	hM4oJ|	hM%6@q7]f;	#i$yl'a>Q5	TM4oy!@=AEhU";P7  -Pe*jD"jE* j	%Bs?&E5*y/{5Ja  K2~MNo}qzSzjxSi{)KKl7]~o* Sz_,Q*/U"BM/IQA_W/w{_XY9]5j/3|^?Ei@z.DKkn)
+&HC"
+?l'?OL0$o|;)F>q!)|r5e>RIRI-Ro?.gL,e.M
+$T
+?'dM>+>ucU:U&_=-M->E3kT4kV+0?}(^w9l2MA^ 3@v4q!ir$YI2	& _ir	<& oir	<GD "4>'
+D"ry\AD "g7D"ry\BD>W-D"ry\CD!"w=D"ryH2G|$N""/	9<ED""_inm/"xWFQU
+}yCPyGxW}??~[7;{+3)QOJ?(t5yDaUm3}`Mqm8q*3 +vP(&Tk'W
+U*S~?Uj4g<{mps[)}GkypOrG~?"GL-iYF#Diexko1hS?aOukV% p`}<J A%z{P3Lh'L?8}-)9?A^wc]l~[A_>15cQ|WO']V-p;VS[
+ozQ&gDQ6A?4-+v-;JQqc]mXXzY#KZvZO*mh_[MgL
+zV]=4U-\S. -<GI|o6ycxSv Q95HL&1>>?v'?(l?f3=!jO7VU&zs-4s.3CJo_(-4KZoi,%-$%ii~I+}_f_k-5g,Fe?i7sUw:9d4KCiwx,!oJH$j\:?<?xgx;t4G]5Xm
+$w\<w_:lEiS>+:u>}5_y.\V^#na([^lT;RHrZ7._Ka++yX~ex0FM /^*^{
+Z_W%ZrRsJ|3kej2oXkTZ3/.>ZgBk*_?stQpEENq&+(ohn-O6]R6N9(*	Iye=Wx{*W|c"gH:o EL*uWW=X:=/3
+(U"@3\yO=a_i~r~J(x#H|'Ty{JqpT<!m=Gp!;WqC$D!!XDjk
+V-#"ZGD$m%"ZLDh9iF`A"%EDkUEDED+-"Z\Dhy"FD+1"ZdDh:}`RFDV,7"Zosl<%GDkN:!XvD`GDkOZ},?"ZD  "zB+ g]-; @D/@D^="z!xo
+"zJwAD^=
+"zD8u ~Q[?DHa#!WBD	="z)DTc!BDE2!'CDo
+"z6Dn!CDo"z>D~"'DDo""zFD!)P/%"zLD9{2xQBM"WED=,"zYD4 o(w	P>@ 9dB#B3#!4n$_Ra?'Yb`n!9N_Wr*~8^{UwWMk6zG?5[vj]G:?2|z;v54XDpF?q4Df_w4olo_3ZoqC[= 7X2WEwtksh6}X<Gx!{/owdabxcCyvi1n"kQn}bWO8z_n3iCJ}
+b]SCqu
+7o~cMcHM!.8}O1'O$p\bFL7$t'UeHnOcHiO9V}j0^W[;^g\nt_^a9fwdmalt\1	2<Y[g}ak?yFwvMO4)JI5"RMGD#")S`hO.P]? U`]P	
+rA-( \PBP
+vAU(u`T]P
+vAu(`T]P#
+vA(u`T]P+
+rAA(#5`T]P7
+vA(`T]P?`:Fud:FdQ=Y{~k`B,cTcGufnZSMMA.8!9SjO.>	` `
+(s@.
+v,9@\0`&(SA]0`L`>(B.
+vP]0)Y`L`^(Cf\05`n(Cf]0=`L`(SD.#
+v$Qf]0My`L!)
+rTg&#h(]M2}ESF.3
+r5|QmU-T~,<}?M!(?\/5Kw~jC{FsRR_>j]X+>a-l]7!_78W[F1|NQ|Zi|ARRoJ-OZ.-s!GYV+~qq=7csM!})hL1P% XYrV% gK,g	5<K@.YRYr2% yY2g	H-ydj% J,YCb	K	I
+-_#%[	?r/ xr5
+,	zsWL8j+].x/nEPf.$v^+pi0&[L) OLr}R!fg^b)vXrS8yW81G?OQ(7S
+qocXxOt +REI2S'-	:YL4/i"C?_
+V?|\Ok4?OJ?[\0IYG&^..zI\q:nemqoqoPrk#DjUqQ9LTSqS^7[m}0C\yqOss;vu*;dq@gqOm_~`yH<tnwxn$wxPydahNS}}Z/O=}kw-;'|vcp+Sc;ysmm_ZJ]n[K7:.	k!|{p`37 s#7?h	?#Km$'U&o0/Ry0n!VN-V%U)6<O=;LO-3/SN |3N<=u@.M\|U\- :%/QUd_EV%k7-%$gDVuh=Y[/%F&pKY""a"!X[VId_{8Vc_"z
+9V*.Z""Z1222<8jf_6':,q9d__`BvqVC`_1o^XWX6Vmc_6V5m+ZXW*gc_aj<	
+&D~X:"	kk6V%XdXW"CF0hIK~)z&Z%hx-f3wrNy!s'G:%?<~(^+'(U-1.I{Aq&KJW#9O=6qU2B)gx |_Wv9=AQoFKX/(]|dG0m_hxD
+vigavrTF[kno^m/|VOwCt>V]IBc^!q[QZbzg[tRCgisff?	-mJhs-ZvtA:~MqN5tMbi47#ua{6hmkV8:}<f#bqK}a
+vxxEY?]a2hNLC;3[kCZBS^	
+ xwRY(!F#'hA%q(~,_MJ)\,pAS
+L[4!N)\:pAS@Z M,RHJ)(Rx@JI(DRx@Ji(Rx@ B H@&J(Rx@.J($t} kyRx@<J($""	BR
+HI)< &R
+HJ)< *R
+K)< /@bJ	HhB 5rS
+N)< y~D*B'-ivR
+rg/kBZ(cP,bg~=CR9`'/Q?-.9qKZnJ\jjp<}yBWw_L	nm'4{{
+rwd767,^@n'9m~r}ft>j}T[7&wm<AK+^}~cqa
+g/fO^)3a`&lS
+f<"5[,CH<`	a(G'")"+"--E!FaE!0(vBzZc0P(@@DqHhhhEbE# *Z4E# 2Z4bE# :Z4#HDJ3+8@4 DL338@:TdC7sSn5k1{y'o?=%<UUZ}s6wyr{:i5,s.;\2!T3tS)RfZ}5oYj61#'_%pFsV8za:26\nbFr%eJ
+gRp4~(]8^"PX{]E@e<`^gF$~roA\xP3B7Z%
+cGDa(@1U0JVx*QS
+`\i(-!/9<,ai$7~|cai#=rGGA2e"BM zPa!JA)?Ew3fGF0VyU)9i>RYdW:L$tgQ_pHs
+]/(7?*'6LZV1GW	"_+t8
+3l\OIb}@]O'N=?5z5 kl]""/
+6rb086-==7&rGC3*'#!')=dG,J=*G7g+2&%/&HM7s{{2c7Zt7?\fgos
+glt7_bq9WEFps\3sk~V}-V}
+}
+kYv: hu@z5.l5nMCk5[Nt([:uuiW)TW9Uj:$:7ba+ok}d-#ROYRaQ	]v+jHnM>[|pk-icSsfh:+2VSecxr5{~bl|Z}7uF	&+>gQ<sbub"dQ[`|]%c
+|R n
+H@[ )
+ID"2!"TtA@,B "H2D$ pH:D$>|H@B !"DDR""1HPD$)!%""q	H`B 1!&R@pD$9!NGD	  $(,048<@??T$BP&DT(QAQAQQQAQD$|]'*"!(#"*$"*%"*&!('"*(!()"**Jv{@'?Wa]+//4a9uWW:?'x5t<}?S_eqaYGHv/_BZ:/ftuq}g:~tZ7o^$W]elW\0}tlcNfX>/sat~iItl^:^v]y&:bK
+Vvvysux	aim&{%O0=Z?]M:!QA-a]y:v#9:6u$:t;N?u:2,k}tvzuJC
+g]+CH3t|t&t:>]jtdV:OoI"u~3cx]Z=|p	>E}NwU*U2/zY,4pQae2W8YO~=5{^Awv%Jy	S ? ZpmpB|DWW{OY4-Al>#+3]W^MorSNzp9Vyh]3)82'=JyFjedr8cs+&TG%rD4_o	)]i9Z-RZTNGc6ry=xGP^/;glsJb 5P
+0*|].zo'|w_=,|kRkmL0YL~"V{-F
+C_T{RY	9_-6L/8	CkfGfeGof1$WJUq)L3d<URo_Y?M>S`|9	[y"BO\JYy35p>b/ix{)QB_FQsM_NsrU^_a+df+Od^5uZ{kH}1*?^P}^rp[=\Rwi8zKM@YVD!fQ Pn&@q(q8qHqXqh !0!P!pQJf0tR*!Ta)
+CCCK'!Eom||g3P|O5ZM9RV:T~s?w>%8x/>?L(?PC
+ zF*rG(c3'??3+eSwycL1eq~mOK${CSU29Z#)cf_OH0f*9G*<cIVH9~JRY 4Y$Co,bLJJzW4fU|;t"YG<0,3D`^o_c97nU&,n3Sn`@	c=*QEheO_\<9\yC@ X5`MqXlG1	O/ >;?OPo1NL5egA*/bL2r@J	d{Sz%i/>3F{j
+}0m_&>\/	r\%5jP"335vac\Vnl0/G' g
+|ZFB=??f6MOUF,Nf*ER_|+F60ww\<tkp#59j>o
+C_8+Xe2g17ZSgM;uin-3[%K(
+hB+;/D;iE%/J#c].*Rdh">08lQ""un60h0p0x "@"`0x18EEAFFFGAGGGD8"yT0lG9djJ+ejA(Y63=sz^|K4/j~:/zW;+_~bq\1OJ/gr]=Lzkd[?%Y'|s=W{l.:{IYO|aSonkF8\|5@%~07|qt<Lc[4d}*`g6LU*uguojFdr@DY < D"29Q^ 3D"2DD9eJdKn13!dNn'wGD "=D"D	pB=OyCx/8$DC~Oh6 p
+ 
\ No newline at end of file
Index: venv/Lib/site-packages/dateutil/zoneinfo/rebuild.py
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/venv/Lib/site-packages/dateutil/zoneinfo/rebuild.py b/venv/Lib/site-packages/dateutil/zoneinfo/rebuild.py
new file mode 100644
--- /dev/null	(date 1616406051845)
+++ b/venv/Lib/site-packages/dateutil/zoneinfo/rebuild.py	(date 1616406051845)
@@ -0,0 +1,53 @@
+import logging
+import os
+import tempfile
+import shutil
+import json
+from subprocess import check_call
+from tarfile import TarFile
+
+from dateutil.zoneinfo import METADATA_FN, ZONEFILENAME
+
+
+def rebuild(filename, tag=None, format="gz", zonegroups=[], metadata=None):
+    """Rebuild the internal timezone info in dateutil/zoneinfo/zoneinfo*tar*
+
+    filename is the timezone tarball from ``ftp.iana.org/tz``.
+
+    """
+    tmpdir = tempfile.mkdtemp()
+    zonedir = os.path.join(tmpdir, "zoneinfo")
+    moduledir = os.path.dirname(__file__)
+    try:
+        with TarFile.open(filename) as tf:
+            for name in zonegroups:
+                tf.extract(name, tmpdir)
+            filepaths = [os.path.join(tmpdir, n) for n in zonegroups]
+            try:
+                check_call(["zic", "-d", zonedir] + filepaths)
+            except OSError as e:
+                _print_on_nosuchfile(e)
+                raise
+        # write metadata file
+        with open(os.path.join(zonedir, METADATA_FN), 'w') as f:
+            json.dump(metadata, f, indent=4, sort_keys=True)
+        target = os.path.join(moduledir, ZONEFILENAME)
+        with TarFile.open(target, "w:%s" % format) as tf:
+            for entry in os.listdir(zonedir):
+                entrypath = os.path.join(zonedir, entry)
+                tf.add(entrypath, entry)
+    finally:
+        shutil.rmtree(tmpdir)
+
+
+def _print_on_nosuchfile(e):
+    """Print helpful troubleshooting message
+
+    e is an exception raised by subprocess.check_call()
+
+    """
+    if e.errno == 2:
+        logging.error(
+            "Could not find zic. Perhaps you need to install "
+            "libc-bin or some other package that provides it, "
+            "or it's not in your PATH?")
Index: venv/Lib/site-packages/dateutil/zoneinfo/__init__.py
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/venv/Lib/site-packages/dateutil/zoneinfo/__init__.py b/venv/Lib/site-packages/dateutil/zoneinfo/__init__.py
new file mode 100644
--- /dev/null	(date 1616406051845)
+++ b/venv/Lib/site-packages/dateutil/zoneinfo/__init__.py	(date 1616406051845)
@@ -0,0 +1,167 @@
+# -*- coding: utf-8 -*-
+import warnings
+import json
+
+from tarfile import TarFile
+from pkgutil import get_data
+from io import BytesIO
+
+from dateutil.tz import tzfile as _tzfile
+
+__all__ = ["get_zonefile_instance", "gettz", "gettz_db_metadata"]
+
+ZONEFILENAME = "dateutil-zoneinfo.tar.gz"
+METADATA_FN = 'METADATA'
+
+
+class tzfile(_tzfile):
+    def __reduce__(self):
+        return (gettz, (self._filename,))
+
+
+def getzoneinfofile_stream():
+    try:
+        return BytesIO(get_data(__name__, ZONEFILENAME))
+    except IOError as e:  # TODO  switch to FileNotFoundError?
+        warnings.warn("I/O error({0}): {1}".format(e.errno, e.strerror))
+        return None
+
+
+class ZoneInfoFile(object):
+    def __init__(self, zonefile_stream=None):
+        if zonefile_stream is not None:
+            with TarFile.open(fileobj=zonefile_stream) as tf:
+                self.zones = {zf.name: tzfile(tf.extractfile(zf), filename=zf.name)
+                              for zf in tf.getmembers()
+                              if zf.isfile() and zf.name != METADATA_FN}
+                # deal with links: They'll point to their parent object. Less
+                # waste of memory
+                links = {zl.name: self.zones[zl.linkname]
+                         for zl in tf.getmembers() if
+                         zl.islnk() or zl.issym()}
+                self.zones.update(links)
+                try:
+                    metadata_json = tf.extractfile(tf.getmember(METADATA_FN))
+                    metadata_str = metadata_json.read().decode('UTF-8')
+                    self.metadata = json.loads(metadata_str)
+                except KeyError:
+                    # no metadata in tar file
+                    self.metadata = None
+        else:
+            self.zones = {}
+            self.metadata = None
+
+    def get(self, name, default=None):
+        """
+        Wrapper for :func:`ZoneInfoFile.zones.get`. This is a convenience method
+        for retrieving zones from the zone dictionary.
+
+        :param name:
+            The name of the zone to retrieve. (Generally IANA zone names)
+
+        :param default:
+            The value to return in the event of a missing key.
+
+        .. versionadded:: 2.6.0
+
+        """
+        return self.zones.get(name, default)
+
+
+# The current API has gettz as a module function, although in fact it taps into
+# a stateful class. So as a workaround for now, without changing the API, we
+# will create a new "global" class instance the first time a user requests a
+# timezone. Ugly, but adheres to the api.
+#
+# TODO: Remove after deprecation period.
+_CLASS_ZONE_INSTANCE = []
+
+
+def get_zonefile_instance(new_instance=False):
+    """
+    This is a convenience function which provides a :class:`ZoneInfoFile`
+    instance using the data provided by the ``dateutil`` package. By default, it
+    caches a single instance of the ZoneInfoFile object and returns that.
+
+    :param new_instance:
+        If ``True``, a new instance of :class:`ZoneInfoFile` is instantiated and
+        used as the cached instance for the next call. Otherwise, new instances
+        are created only as necessary.
+
+    :return:
+        Returns a :class:`ZoneInfoFile` object.
+
+    .. versionadded:: 2.6
+    """
+    if new_instance:
+        zif = None
+    else:
+        zif = getattr(get_zonefile_instance, '_cached_instance', None)
+
+    if zif is None:
+        zif = ZoneInfoFile(getzoneinfofile_stream())
+
+        get_zonefile_instance._cached_instance = zif
+
+    return zif
+
+
+def gettz(name):
+    """
+    This retrieves a time zone from the local zoneinfo tarball that is packaged
+    with dateutil.
+
+    :param name:
+        An IANA-style time zone name, as found in the zoneinfo file.
+
+    :return:
+        Returns a :class:`dateutil.tz.tzfile` time zone object.
+
+    .. warning::
+        It is generally inadvisable to use this function, and it is only
+        provided for API compatibility with earlier versions. This is *not*
+        equivalent to ``dateutil.tz.gettz()``, which selects an appropriate
+        time zone based on the inputs, favoring system zoneinfo. This is ONLY
+        for accessing the dateutil-specific zoneinfo (which may be out of
+        date compared to the system zoneinfo).
+
+    .. deprecated:: 2.6
+        If you need to use a specific zoneinfofile over the system zoneinfo,
+        instantiate a :class:`dateutil.zoneinfo.ZoneInfoFile` object and call
+        :func:`dateutil.zoneinfo.ZoneInfoFile.get(name)` instead.
+
+        Use :func:`get_zonefile_instance` to retrieve an instance of the
+        dateutil-provided zoneinfo.
+    """
+    warnings.warn("zoneinfo.gettz() will be removed in future versions, "
+                  "to use the dateutil-provided zoneinfo files, instantiate a "
+                  "ZoneInfoFile object and use ZoneInfoFile.zones.get() "
+                  "instead. See the documentation for details.",
+                  DeprecationWarning)
+
+    if len(_CLASS_ZONE_INSTANCE) == 0:
+        _CLASS_ZONE_INSTANCE.append(ZoneInfoFile(getzoneinfofile_stream()))
+    return _CLASS_ZONE_INSTANCE[0].zones.get(name)
+
+
+def gettz_db_metadata():
+    """ Get the zonefile metadata
+
+    See `zonefile_metadata`_
+
+    :returns:
+        A dictionary with the database metadata
+
+    .. deprecated:: 2.6
+        See deprecation warning in :func:`zoneinfo.gettz`. To get metadata,
+        query the attribute ``zoneinfo.ZoneInfoFile.metadata``.
+    """
+    warnings.warn("zoneinfo.gettz_db_metadata() will be removed in future "
+                  "versions, to use the dateutil-provided zoneinfo files, "
+                  "ZoneInfoFile object and query the 'metadata' attribute "
+                  "instead. See the documentation for details.",
+                  DeprecationWarning)
+
+    if len(_CLASS_ZONE_INSTANCE) == 0:
+        _CLASS_ZONE_INSTANCE.append(ZoneInfoFile(getzoneinfofile_stream()))
+    return _CLASS_ZONE_INSTANCE[0].metadata
diff --git a/venv/Lib/site-packages/tests/web_client/__init__.py b/venv/Lib/site-packages/tests/web_client/__init__.py
new file mode 100644
diff --git a/venv/Lib/site-packages/usp/objects/__init__.py b/venv/Lib/site-packages/usp/objects/__init__.py
new file mode 100644
diff --git a/venv/Lib/site-packages/usp/web_client/__init__.py b/venv/Lib/site-packages/usp/web_client/__init__.py
new file mode 100644
