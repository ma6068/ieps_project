Index: martin.py
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.BaseRevisionTextPatchEP
<+>import hashlib\r\nimport requests\r\nimport sys\r\nimport database.db as database\r\n\r\n######## HTML CONTENT #########\r\nurl = 'https://www.google.com/'\r\nr = requests.get(url)\r\na = r.text\r\n#print(a)\r\n########### end ##############\r\n\r\n\r\n############### HASH ####################\r\nhash_object = hashlib.sha256(a.encode())\r\nhex_dig = hash_object.hexdigest()\r\n#print(hex_dig)\r\n############## end ###############\r\n\r\n\r\n############### ARGUMENTI ####################\r\n#crawders = (sys.argv[1])\r\n#if int(crawders) < 1:\r\n#    crawders = 1\r\n#print(crawders)\r\n############## end ###############\r\n\r\n\r\n############### BAZA PROVERIKA ####################\r\ndb = database.DB()\r\ndb.connectDB()\r\ndb.createTables()\r\nsite_id = db.insertSite('www.facebook.com', None, None)\r\ndb.insertPage(site_id, 'DUPLICATE', 'www.insta.com', 'htlm<>blabla', '123', None)\r\n############## end ###############
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/martin.py b/martin.py
--- a/martin.py	(revision 48cf78b8e352c858f8694bf85e266f5db91a6860)
+++ b/martin.py	(date 1616415586074)
@@ -1,19 +1,22 @@
 import hashlib
-import requests
 import sys
+from pip._vendor import requests
 import database.db as database
+import urllib.robotparser
 
 ######## HTML CONTENT #########
-url = 'https://www.google.com/'
+url = 'https://www.gov.si/'
 r = requests.get(url)
 a = r.text
 #print(a)
+hash_object = hashlib.sha256(a.encode())
+hex_dig = hash_object.hexdigest()
 ########### end ##############
 
 
 ############### HASH ####################
-hash_object = hashlib.sha256(a.encode())
-hex_dig = hash_object.hexdigest()
+#hash_object = hashlib.sha256(a.encode())
+#hex_dig = hash_object.hexdigest()
 #print(hex_dig)
 ############## end ###############
 
@@ -27,9 +30,11 @@
 
 
 ############### BAZA PROVERIKA ####################
-db = database.DB()
-db.connectDB()
-db.createTables()
-site_id = db.insertSite('www.facebook.com', None, None)
-db.insertPage(site_id, 'DUPLICATE', 'www.insta.com', 'htlm<>blabla', '123', None)
-############## end ###############
\ No newline at end of file
+#db = database.DB()
+#db.connectDB()
+#db.createTables()
+#site_id = db.insertSite('www.facebook.com', None, None)
+#db.insertPage(site_id, 'DUPLICATE', 'www.insta.com', 'htlm<>blabla', '123', None)
+############## end ###############
+
+
Index: latest/Lib/site-packages/beautifulsoup4-4.9.3.dist-info/METADATA
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/latest/Lib/site-packages/beautifulsoup4-4.9.3.dist-info/METADATA b/latest/Lib/site-packages/beautifulsoup4-4.9.3.dist-info/METADATA
new file mode 100644
--- /dev/null	(date 1616411342146)
+++ b/latest/Lib/site-packages/beautifulsoup4-4.9.3.dist-info/METADATA	(date 1616411342146)
@@ -0,0 +1,132 @@
+Metadata-Version: 2.1
+Name: beautifulsoup4
+Version: 4.9.3
+Summary: Screen-scraping library
+Home-page: http://www.crummy.com/software/BeautifulSoup/bs4/
+Author: Leonard Richardson
+Author-email: leonardr@segfault.org
+License: MIT
+Download-URL: http://www.crummy.com/software/BeautifulSoup/bs4/download/
+Platform: UNKNOWN
+Classifier: Development Status :: 5 - Production/Stable
+Classifier: Intended Audience :: Developers
+Classifier: License :: OSI Approved :: MIT License
+Classifier: Programming Language :: Python
+Classifier: Programming Language :: Python :: 2.7
+Classifier: Programming Language :: Python :: 3
+Classifier: Topic :: Text Processing :: Markup :: HTML
+Classifier: Topic :: Text Processing :: Markup :: XML
+Classifier: Topic :: Text Processing :: Markup :: SGML
+Classifier: Topic :: Software Development :: Libraries :: Python Modules
+Description-Content-Type: text/markdown
+Requires-Dist: soupsieve (<2.0,>1.2) ; python_version < "3.0"
+Requires-Dist: soupsieve (>1.2) ; python_version >= "3.0"
+Provides-Extra: html5lib
+Requires-Dist: html5lib ; extra == 'html5lib'
+Provides-Extra: lxml
+Requires-Dist: lxml ; extra == 'lxml'
+
+Beautiful Soup is a library that makes it easy to scrape information
+from web pages. It sits atop an HTML or XML parser, providing Pythonic
+idioms for iterating, searching, and modifying the parse tree.
+
+# Quick start
+
+```
+>>> from bs4 import BeautifulSoup
+>>> soup = BeautifulSoup("<p>Some<b>bad<i>HTML")
+>>> print(soup.prettify())
+<html>
+ <body>
+  <p>
+   Some
+   <b>
+    bad
+    <i>
+     HTML
+    </i>
+   </b>
+  </p>
+ </body>
+</html>
+>>> soup.find(text="bad")
+'bad'
+>>> soup.i
+<i>HTML</i>
+#
+>>> soup = BeautifulSoup("<tag1>Some<tag2/>bad<tag3>XML", "xml")
+#
+>>> print(soup.prettify())
+<?xml version="1.0" encoding="utf-8"?>
+<tag1>
+ Some
+ <tag2/>
+ bad
+ <tag3>
+  XML
+ </tag3>
+</tag1>
+```
+
+To go beyond the basics, [comprehensive documentation is available](http://www.crummy.com/software/BeautifulSoup/bs4/doc/).
+
+# Links
+
+* [Homepage](http://www.crummy.com/software/BeautifulSoup/bs4/)
+* [Documentation](http://www.crummy.com/software/BeautifulSoup/bs4/doc/)
+* [Discussion group](http://groups.google.com/group/beautifulsoup/)
+* [Development](https://code.launchpad.net/beautifulsoup/)
+* [Bug tracker](https://bugs.launchpad.net/beautifulsoup/)
+* [Complete changelog](https://bazaar.launchpad.net/~leonardr/beautifulsoup/bs4/view/head:/CHANGELOG)
+
+# Note on Python 2 sunsetting
+
+Since 2012, Beautiful Soup has been developed as a Python 2 library
+which is automatically converted to Python 3 code as necessary. This
+makes it impossible to take advantage of some features of Python
+3.
+
+For this reason, I plan to discontinue Beautiful Soup's Python 2
+support at some point after December 31, 2020: one year after the
+sunset date for Python 2 itself. Beyond that point, new Beautiful Soup
+development will exclusively target Python 3. Of course, older
+releases of Beautiful Soup, which support both versions, will continue
+to be available.
+
+# Supporting the project
+
+If you use Beautiful Soup as part of your professional work, please consider a
+[Tidelift subscription](https://tidelift.com/subscription/pkg/pypi-beautifulsoup4?utm_source=pypi-beautifulsoup4&utm_medium=referral&utm_campaign=readme).
+This will support many of the free software projects your organization
+depends on, not just Beautiful Soup.
+
+If you use Beautiful Soup for personal projects, the best way to say
+thank you is to read
+[Tool Safety](https://www.crummy.com/software/BeautifulSoup/zine/), a zine I
+wrote about what Beautiful Soup has taught me about software
+development.
+
+# Building the documentation
+
+The bs4/doc/ directory contains full documentation in Sphinx
+format. Run `make html` in that directory to create HTML
+documentation.
+
+# Running the unit tests
+
+Beautiful Soup supports unit test discovery from the project root directory:
+
+```
+$ nosetests
+```
+
+```
+$ python -m unittest discover -s bs4
+```
+
+If you checked out the source tree, you should see a script in the
+home directory called test-all-versions. This script will run the unit
+tests under Python 2, then create a temporary Python 3 conversion of
+the source and run the unit tests again under Python 3.
+
+
Index: latest/Lib/site-packages/beautifulsoup4-4.9.3.dist-info/RECORD
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/latest/Lib/site-packages/beautifulsoup4-4.9.3.dist-info/RECORD b/latest/Lib/site-packages/beautifulsoup4-4.9.3.dist-info/RECORD
new file mode 100644
--- /dev/null	(date 1616411343081)
+++ b/latest/Lib/site-packages/beautifulsoup4-4.9.3.dist-info/RECORD	(date 1616411343081)
@@ -0,0 +1,41 @@
+beautifulsoup4-4.9.3.dist-info/AUTHORS,sha256=uSIdbrBb1sobdXl7VrlUvuvim2dN9kF3MH4Edn0WKGE,2176
+beautifulsoup4-4.9.3.dist-info/COPYING.txt,sha256=pH6lEjYJhGT-C09Vl0NZC1MwVtngD0nsv4Apn6tH4jE,1315
+beautifulsoup4-4.9.3.dist-info/INSTALLER,sha256=zuuue4knoyJ-UwPPXg8fezS7VCrXJQrAP7zeNuwvFQg,4
+beautifulsoup4-4.9.3.dist-info/LICENSE,sha256=ynIn3bnu1syAnhV_Z7Ag543eBjJAAB0RhW-FxJy25CM,1447
+beautifulsoup4-4.9.3.dist-info/METADATA,sha256=iY3LTmChfV6eWiLC4MPfy_FZL9pllucV7IzOVrF117Q,4190
+beautifulsoup4-4.9.3.dist-info/RECORD,,
+beautifulsoup4-4.9.3.dist-info/REQUESTED,sha256=47DEQpj8HBSa-_TImW-5JCeuQeRkm5NMpJWZG3hSuFU,0
+beautifulsoup4-4.9.3.dist-info/WHEEL,sha256=g4nMs7d-Xl9-xC9XovUrsDHGXt-FT0E17Yqo92DEfvY,92
+beautifulsoup4-4.9.3.dist-info/top_level.txt,sha256=H8VT-IuPWLzQqwG9_eChjXDJ1z0H9RRebdSR90Bjnkw,4
+bs4/__init__.py,sha256=Xg4iRoWU7bD9HQo8OCHh6BP9g74T8n37QjQFhT3_GLA,32102
+bs4/__pycache__/__init__.cpython-39.pyc,,
+bs4/__pycache__/dammit.cpython-39.pyc,,
+bs4/__pycache__/diagnose.cpython-39.pyc,,
+bs4/__pycache__/element.cpython-39.pyc,,
+bs4/__pycache__/formatter.cpython-39.pyc,,
+bs4/__pycache__/testing.cpython-39.pyc,,
+bs4/builder/__init__.py,sha256=dJcyrx6CdAuKQhg5KfpKTAEQeDKvIW3PWHo-0aKDaLg,19777
+bs4/builder/__pycache__/__init__.cpython-39.pyc,,
+bs4/builder/__pycache__/_html5lib.cpython-39.pyc,,
+bs4/builder/__pycache__/_htmlparser.cpython-39.pyc,,
+bs4/builder/__pycache__/_lxml.cpython-39.pyc,,
+bs4/builder/_html5lib.py,sha256=hDxlzVrAku_eU7zEt4gZ-sAXzG58GvkLfMz6P4zUqoA,18748
+bs4/builder/_htmlparser.py,sha256=80-Nb3QXS3PrSa-ReEBTh1X8-C2HkLFLLAbC0fSKuoU,18405
+bs4/builder/_lxml.py,sha256=e4w91RZi3NII_QYe2e1-EiN_BxQtgJPSRwQ8Xgz41ZA,12234
+bs4/dammit.py,sha256=k_XPB3kbZsHM01ckf9BxCUB2Eu2dIQ3d3DDt7UEv9RA,34130
+bs4/diagnose.py,sha256=WOzytCTkvqh_fGhqYlMyaYVjtH50w4jbdf1Fd0iundE,7755
+bs4/element.py,sha256=DbavvJfetuG3GWM_mOsNPVk7WuyQtJQ6qti8FFzwZvE,81650
+bs4/formatter.py,sha256=Wayv1d6fUc9BSCa2k9uhvWwm89xCukdtJhyi9Sxvkuc,5654
+bs4/testing.py,sha256=8C72bkPqP_zPzpP-f9i1qtlNuKonHD-VtamNxUKwIBE,45930
+bs4/tests/__init__.py,sha256=bdUBDE750n7qNEfue7-3a1fBaUxJlvZMkvJvZa-lbYs,27
+bs4/tests/__pycache__/__init__.cpython-39.pyc,,
+bs4/tests/__pycache__/test_lxml.cpython-39.pyc,,
+bs4/tests/__pycache__/test_soup.cpython-39.pyc,,
+bs4/tests/__pycache__/test_tree.cpython-39.pyc,,
+bs4/tests/test_builder_registry.py,sha256=pllfRpArh9TYhjjRUiu1wITr9Ryyv4hiaAtRjij-k4E,5582
+bs4/tests/test_docs.py,sha256=FXfz2bGL4Xe0q6duwpmg9hmFiZuU4DVJPNZ0hTb6aH4,1067
+bs4/tests/test_html5lib.py,sha256=eWnLGHek_RO_TMq0Ixpb1RF3BEDrvhenMf2eaEBjjsg,6754
+bs4/tests/test_htmlparser.py,sha256=3294XvFbWVe0AYoTlnLPEDW_a0Om0BKRcsrwlJbxUaI,3941
+bs4/tests/test_lxml.py,sha256=xJr8eDrtHSb_vQw88lYEKyfdM1Hel4-dBaz14vQq78M,4105
+bs4/tests/test_soup.py,sha256=EhE1dhHKyctNu0y2l0ql6FOHg9qliEt8Kh7jfCx1lDw,29303
+bs4/tests/test_tree.py,sha256=UsXGvnlTBKixno0sbnFllZo6pm-7EiSvOY1dOeWcqFg,89437
Index: latest/Lib/site-packages/beautifulsoup4-4.9.3.dist-info/top_level.txt
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/latest/Lib/site-packages/beautifulsoup4-4.9.3.dist-info/top_level.txt b/latest/Lib/site-packages/beautifulsoup4-4.9.3.dist-info/top_level.txt
new file mode 100644
--- /dev/null	(date 1616411342150)
+++ b/latest/Lib/site-packages/beautifulsoup4-4.9.3.dist-info/top_level.txt	(date 1616411342150)
@@ -0,0 +1,1 @@
+bs4
Index: latest/Lib/site-packages/beautifulsoup4-4.9.3.dist-info/WHEEL
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/latest/Lib/site-packages/beautifulsoup4-4.9.3.dist-info/WHEEL b/latest/Lib/site-packages/beautifulsoup4-4.9.3.dist-info/WHEEL
new file mode 100644
--- /dev/null	(date 1616411342148)
+++ b/latest/Lib/site-packages/beautifulsoup4-4.9.3.dist-info/WHEEL	(date 1616411342148)
@@ -0,0 +1,5 @@
+Wheel-Version: 1.0
+Generator: bdist_wheel (0.34.2)
+Root-Is-Purelib: true
+Tag: py3-none-any
+
Index: latest/Lib/site-packages/soupsieve-2.2.1.dist-info/INSTALLER
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/latest/Lib/site-packages/soupsieve-2.2.1.dist-info/INSTALLER b/latest/Lib/site-packages/soupsieve-2.2.1.dist-info/INSTALLER
new file mode 100644
--- /dev/null	(date 1616411341953)
+++ b/latest/Lib/site-packages/soupsieve-2.2.1.dist-info/INSTALLER	(date 1616411341953)
@@ -0,0 +1,1 @@
+pip
Index: latest/Lib/site-packages/soupsieve-2.2.1.dist-info/LICENSE.md
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/latest/Lib/site-packages/soupsieve-2.2.1.dist-info/LICENSE.md b/latest/Lib/site-packages/soupsieve-2.2.1.dist-info/LICENSE.md
new file mode 100644
--- /dev/null	(date 1616411341749)
+++ b/latest/Lib/site-packages/soupsieve-2.2.1.dist-info/LICENSE.md	(date 1616411341749)
@@ -0,0 +1,21 @@
+MIT License
+
+Copyright (c) 2018 - 2021 Isaac Muse <isaacmuse@gmail.com>
+
+Permission is hereby granted, free of charge, to any person obtaining a copy
+of this software and associated documentation files (the "Software"), to deal
+in the Software without restriction, including without limitation the rights
+to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
+copies of the Software, and to permit persons to whom the Software is
+furnished to do so, subject to the following conditions:
+
+The above copyright notice and this permission notice shall be included in all
+copies or substantial portions of the Software.
+
+THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
+IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
+FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
+AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
+LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
+OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
+SOFTWARE.
Index: latest/Lib/site-packages/soupsieve-2.2.1.dist-info/METADATA
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/latest/Lib/site-packages/soupsieve-2.2.1.dist-info/METADATA b/latest/Lib/site-packages/soupsieve-2.2.1.dist-info/METADATA
new file mode 100644
--- /dev/null	(date 1616411341751)
+++ b/latest/Lib/site-packages/soupsieve-2.2.1.dist-info/METADATA	(date 1616411341751)
@@ -0,0 +1,124 @@
+Metadata-Version: 2.1
+Name: soupsieve
+Version: 2.2.1
+Summary: A modern CSS selector implementation for Beautiful Soup.
+Home-page: https://github.com/facelessuser/soupsieve
+Author: Isaac Muse
+Author-email: Isaac.Muse@gmail.com
+License: MIT License
+Keywords: CSS HTML XML selector filter query soup
+Platform: UNKNOWN
+Classifier: Development Status :: 5 - Production/Stable
+Classifier: Environment :: Console
+Classifier: Intended Audience :: Developers
+Classifier: License :: OSI Approved :: MIT License
+Classifier: Operating System :: OS Independent
+Classifier: Programming Language :: Python :: 3
+Classifier: Programming Language :: Python :: 3.6
+Classifier: Programming Language :: Python :: 3.7
+Classifier: Programming Language :: Python :: 3.8
+Classifier: Programming Language :: Python :: 3.9
+Classifier: Topic :: Internet :: WWW/HTTP :: Dynamic Content
+Classifier: Topic :: Software Development :: Libraries :: Python Modules
+Requires-Python: >=3.6
+Description-Content-Type: text/markdown
+Requires-Dist: backports.functools-lru-cache ; python_version < "3"
+
+[![Donate via PayPal][donate-image]][donate-link]
+[![Discord][discord-image]][discord-link]
+[![Build][github-ci-image]][github-ci-link]
+[![Coverage Status][codecov-image]][codecov-link]
+[![PyPI Version][pypi-image]][pypi-link]
+[![PyPI - Python Version][python-image]][pypi-link]
+![License][license-image-mit]
+
+# Soup Sieve
+
+## Overview
+
+Soup Sieve is a CSS selector library designed to be used with [Beautiful Soup 4][bs4]. It aims to provide selecting,
+matching, and filtering using modern CSS selectors. Soup Sieve currently provides selectors from the CSS level 1
+specifications up through the latest CSS level 4 drafts and beyond (though some are not yet implemented).
+
+Soup Sieve was written with the intent to replace Beautiful Soup's builtin select feature, and as of Beautiful Soup
+version 4.7.0, it now is :confetti_ball:. Soup Sieve can also be imported in order to use its API directly for
+more controlled, specialized parsing.
+
+Soup Sieve has implemented most of the CSS selectors up through the latest CSS draft specifications, though there are a
+number that don't make sense in a non-browser environment. Selectors that cannot provide meaningful functionality simply
+do not match anything. Some of the supported selectors are:
+
+- `.classes`
+- `#ids`
+- `[attributes=value]`
+- `parent child`
+- `parent > child`
+- `sibling ~ sibling`
+- `sibling + sibling`
+- `:not(element.class, element2.class)`
+- `:is(element.class, element2.class)`
+- `parent:has(> child)`
+- and [many more](https://facelessuser.github.io/soupsieve/selectors/)
+
+
+## Installation
+
+You must have Beautiful Soup already installed:
+
+```
+pip install beautifulsoup4
+```
+
+In most cases, assuming you've installed version 4.7.0, that should be all you need to do, but if you've installed via
+some alternative method, and Soup Sieve is not automatically installed for your, you can install it directly:
+
+```
+pip install soupsieve
+```
+
+If you want to manually install it from source, navigate to the root of the project and run
+
+```
+python setup.py build
+python setup.py install
+```
+
+## Documentation
+
+Documentation is found here: https://facelessuser.github.io/soupsieve/.
+
+## License
+
+MIT License
+
+Copyright (c) 2018 - 2021 Isaac Muse <isaacmuse@gmail.com>
+
+Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated
+documentation files (the "Software"), to deal in the Software without restriction, including without limitation the
+rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit
+persons to whom the Software is furnished to do so, subject to the following conditions:
+
+The above copyright notice and this permission notice shall be included in all copies or substantial portions of the
+Software.
+
+THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE
+WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR
+COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR
+OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.
+
+[bs4]: https://beautiful-soup-4.readthedocs.io/en/latest/#
+
+[github-ci-image]: https://github.com/facelessuser/soupsieve/workflows/build/badge.svg?branch=master&event=push
+[github-ci-link]: https://github.com/facelessuser/soupsieve/actions?query=workflow%3Abuild+branch%3Amaster
+[discord-image]: https://img.shields.io/discord/678289859768745989?logo=discord&logoColor=aaaaaa&color=mediumpurple&labelColor=333333
+[discord-link]:https://discord.gg/XBnPUZF
+[codecov-image]: https://img.shields.io/codecov/c/github/facelessuser/soupsieve/master.svg?logo=codecov&logoColor=aaaaaa&labelColor=333333
+[codecov-link]: https://codecov.io/github/facelessuser/soupsieve
+[pypi-image]: https://img.shields.io/pypi/v/soupsieve.svg?logo=pypi&logoColor=aaaaaa&labelColor=333333
+[pypi-link]: https://pypi.python.org/pypi/soupsieve
+[python-image]: https://img.shields.io/pypi/pyversions/soupsieve?logo=python&logoColor=aaaaaa&labelColor=333333
+[license-image-mit]: https://img.shields.io/badge/license-MIT-blue.svg?labelColor=333333
+[donate-image]: https://img.shields.io/badge/Donate-PayPal-3fabd1?logo=paypal
+[donate-link]: https://www.paypal.me/facelessuser
+
+
Index: latest/Lib/site-packages/soupsieve-2.2.1.dist-info/RECORD
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/latest/Lib/site-packages/soupsieve-2.2.1.dist-info/RECORD b/latest/Lib/site-packages/soupsieve-2.2.1.dist-info/RECORD
new file mode 100644
--- /dev/null	(date 1616411342013)
+++ b/latest/Lib/site-packages/soupsieve-2.2.1.dist-info/RECORD	(date 1616411342013)
@@ -0,0 +1,17 @@
+soupsieve-2.2.1.dist-info/INSTALLER,sha256=zuuue4knoyJ-UwPPXg8fezS7VCrXJQrAP7zeNuwvFQg,4
+soupsieve-2.2.1.dist-info/LICENSE.md,sha256=40p2D-i7Pjwf-qiKvklc925W-K48em3eDktBzQE8QdQ,1096
+soupsieve-2.2.1.dist-info/METADATA,sha256=EVZLpvt7iPpSVZK_sMJkmB5jJSzbkU6tM2_RSdtKSF4,5461
+soupsieve-2.2.1.dist-info/RECORD,,
+soupsieve-2.2.1.dist-info/WHEEL,sha256=OqRkF0eY5GHssMorFjlbTIq072vpHpF60fIQA6lS9xA,92
+soupsieve-2.2.1.dist-info/top_level.txt,sha256=kS763j7Vu4xw3auDglwOSD9nkRF-y3GIlM5Mv8UCqTM,10
+soupsieve/__init__.py,sha256=IKm1q-blJwecIvPXzEsXW58uc3QsOpSnDD8TLNUEVMk,3537
+soupsieve/__meta__.py,sha256=pSHj3z-xrmlcCc7ue4Zk0lDhza5OFuKei5KMPn4p5Aw,6657
+soupsieve/__pycache__/__init__.cpython-39.pyc,,
+soupsieve/__pycache__/css_match.cpython-39.pyc,,
+soupsieve/__pycache__/css_parser.cpython-39.pyc,,
+soupsieve/__pycache__/css_types.cpython-39.pyc,,
+soupsieve/__pycache__/util.cpython-39.pyc,,
+soupsieve/css_match.py,sha256=oYallFS-5mwQRjFbpSCqTCq0iRkgBqXhp5J-h7IuhTU,53883
+soupsieve/css_parser.py,sha256=ngyj2Pibjpmuu8iASq3vDUZKYwQK3UDgMiNRPO4MmZk,43793
+soupsieve/css_types.py,sha256=ZBnQF3S2ehUJDwDd20Io-P4YBeGAYbd6M9yuVMMMssc,8418
+soupsieve/util.py,sha256=CUCEITka6HS56q9Yfj1IoSCBsb2quXyMtqQJ5WBIVu8,2992
Index: latest/Lib/site-packages/soupsieve-2.2.1.dist-info/top_level.txt
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/latest/Lib/site-packages/soupsieve-2.2.1.dist-info/top_level.txt b/latest/Lib/site-packages/soupsieve-2.2.1.dist-info/top_level.txt
new file mode 100644
--- /dev/null	(date 1616411341760)
+++ b/latest/Lib/site-packages/soupsieve-2.2.1.dist-info/top_level.txt	(date 1616411341760)
@@ -0,0 +1,1 @@
+soupsieve
Index: latest/Lib/site-packages/soupsieve-2.2.1.dist-info/WHEEL
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/latest/Lib/site-packages/soupsieve-2.2.1.dist-info/WHEEL b/latest/Lib/site-packages/soupsieve-2.2.1.dist-info/WHEEL
new file mode 100644
--- /dev/null	(date 1616411341755)
+++ b/latest/Lib/site-packages/soupsieve-2.2.1.dist-info/WHEEL	(date 1616411341755)
@@ -0,0 +1,5 @@
+Wheel-Version: 1.0
+Generator: bdist_wheel (0.36.2)
+Root-Is-Purelib: true
+Tag: py3-none-any
+
Index: .idea/misc.xml
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.BaseRevisionTextPatchEP
<+><?xml version=\"1.0\" encoding=\"UTF-8\"?>\r\n<project version=\"4\">\r\n  <component name=\"ProjectRootManager\" version=\"2\" project-jdk-name=\"Python 3.6 (project1)\" project-jdk-type=\"Python SDK\" />\r\n</project>
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/.idea/misc.xml b/.idea/misc.xml
--- a/.idea/misc.xml	(revision 48cf78b8e352c858f8694bf85e266f5db91a6860)
+++ b/.idea/misc.xml	(date 1616410446319)
@@ -1,4 +1,4 @@
 <?xml version="1.0" encoding="UTF-8"?>
 <project version="4">
-  <component name="ProjectRootManager" version="2" project-jdk-name="Python 3.6 (project1)" project-jdk-type="Python SDK" />
+  <component name="ProjectRootManager" version="2" project-jdk-name="Python 3.9 (project1)" project-jdk-type="Python SDK" />
 </project>
\ No newline at end of file
Index: .idea/project1.iml
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.BaseRevisionTextPatchEP
<+><?xml version=\"1.0\" encoding=\"UTF-8\"?>\r\n<module type=\"PYTHON_MODULE\" version=\"4\">\r\n  <component name=\"NewModuleRootManager\">\r\n    <content url=\"file://$MODULE_DIR$\">\r\n      <excludeFolder url=\"file://$MODULE_DIR$/venv\" />\r\n    </content>\r\n    <orderEntry type=\"inheritedJdk\" />\r\n    <orderEntry type=\"sourceFolder\" forTests=\"false\" />\r\n  </component>\r\n  <component name=\"TestRunnerService\">\r\n    <option name=\"PROJECT_TEST_RUNNER\" value=\"Unittests\" />\r\n  </component>\r\n</module>
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/.idea/project1.iml b/.idea/project1.iml
--- a/.idea/project1.iml	(revision 48cf78b8e352c858f8694bf85e266f5db91a6860)
+++ b/.idea/project1.iml	(date 1616410446475)
@@ -3,8 +3,9 @@
   <component name="NewModuleRootManager">
     <content url="file://$MODULE_DIR$">
       <excludeFolder url="file://$MODULE_DIR$/venv" />
+      <excludeFolder url="file://$MODULE_DIR$/latest" />
     </content>
-    <orderEntry type="inheritedJdk" />
+    <orderEntry type="jdk" jdkName="Python 3.9 (project1)" jdkType="Python SDK" />
     <orderEntry type="sourceFolder" forTests="false" />
   </component>
   <component name="TestRunnerService">
Index: venv/Lib/site-packages/tests/web_client/test_requests_client.py
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/venv/Lib/site-packages/tests/web_client/test_requests_client.py b/venv/Lib/site-packages/tests/web_client/test_requests_client.py
new file mode 100644
--- /dev/null	(date 1616410446366)
+++ b/venv/Lib/site-packages/tests/web_client/test_requests_client.py	(date 1616410446366)
@@ -0,0 +1,142 @@
+import socket
+from http import HTTPStatus
+from unittest import TestCase
+
+import requests_mock
+
+from usp.__about__ import __version__
+from usp.web_client.abstract_client import (
+    AbstractWebClientSuccessResponse,
+    WebClientErrorResponse,
+)
+from usp.web_client.requests_client import RequestsWebClient
+
+
+class TestRequestsClient(TestCase):
+    TEST_BASE_URL = 'http://test_ultimate_sitemap_parser.com'  # mocked by HTTPretty
+    TEST_CONTENT_TYPE = 'text/html'
+
+    __slots__ = [
+        '__client',
+    ]
+
+    def setUp(self) -> None:
+        super().setUp()
+
+        self.__client = RequestsWebClient()
+
+    def test_get(self):
+        with requests_mock.Mocker() as m:
+            test_url = self.TEST_BASE_URL + '/'
+            test_content = 'This is a homepage.'
+
+            m.get(
+                test_url,
+                headers={'Content-Type': self.TEST_CONTENT_TYPE},
+                text=test_content,
+            )
+
+            response = self.__client.get(test_url)
+
+            assert response
+            assert isinstance(response, AbstractWebClientSuccessResponse)
+            assert response.status_code() == HTTPStatus.OK.value
+            assert response.status_message() == HTTPStatus.OK.phrase
+            assert response.header('Content-Type') == self.TEST_CONTENT_TYPE
+            assert response.header('content-type') == self.TEST_CONTENT_TYPE
+            assert response.header('nonexistent') is None
+            assert response.raw_data().decode('utf-8') == test_content
+
+    def test_get_user_agent(self):
+        with requests_mock.Mocker() as m:
+            test_url = self.TEST_BASE_URL + '/'
+
+            def content_user_agent(request, context):
+                context.status_code = HTTPStatus.OK.value
+                return request.headers.get('User-Agent', 'unknown')
+
+            m.get(
+                test_url,
+                text=content_user_agent,
+            )
+
+            response = self.__client.get(test_url)
+
+            assert response
+            assert isinstance(response, AbstractWebClientSuccessResponse)
+
+            content = response.raw_data().decode('utf-8')
+            assert content == 'ultimate_sitemap_parser/{}'.format(__version__)
+
+    def test_get_not_found(self):
+        with requests_mock.Mocker() as m:
+            test_url = self.TEST_BASE_URL + '/404.html'
+
+            m.get(
+                test_url,
+                status_code=HTTPStatus.NOT_FOUND.value,
+                reason=HTTPStatus.NOT_FOUND.phrase,
+                headers={'Content-Type': self.TEST_CONTENT_TYPE},
+                text='This page does not exist.',
+            )
+
+            response = self.__client.get(test_url)
+
+            assert response
+            assert isinstance(response, WebClientErrorResponse)
+            assert response.retryable() is False
+
+    def test_get_nonexistent_domain(self):
+        test_url = 'http://www.totallydoesnotexisthjkfsdhkfsd.com/some_page.html'
+
+        response = self.__client.get(test_url)
+
+        assert response
+        assert isinstance(response, WebClientErrorResponse)
+        assert response.retryable() is False
+        assert 'Failed to establish a new connection' in response.message()
+
+    def test_get_timeout(self):
+        sock = socket.socket()
+        sock.bind(('', 0))
+        socket_port = sock.getsockname()[1]
+        assert socket_port
+        sock.listen(1)
+
+        test_timeout = 1
+        test_url = 'http://127.0.0.1:{}/slow_page.html'.format(socket_port)
+
+        self.__client.set_timeout(test_timeout)
+
+        response = self.__client.get(test_url)
+
+        sock.close()
+
+        assert response
+        assert isinstance(response, WebClientErrorResponse)
+        assert response.retryable() is True
+        assert 'Read timed out' in response.message()
+
+    def test_get_max_response_data_length(self):
+        with requests_mock.Mocker() as m:
+            actual_length = 1024 * 1024
+            max_length = 1024 * 512
+
+            test_url = self.TEST_BASE_URL + '/huge_page.html'
+            test_content = 'a' * actual_length
+
+            m.get(
+                test_url,
+                headers={'Content-Type': self.TEST_CONTENT_TYPE},
+                text=test_content,
+            )
+
+            self.__client.set_max_response_data_length(max_length)
+
+            response = self.__client.get(test_url)
+
+            assert response
+            assert isinstance(response, AbstractWebClientSuccessResponse)
+
+            response_length = len(response.raw_data())
+            assert response_length == max_length
Index: venv/Lib/site-packages/usp/exceptions.py
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/venv/Lib/site-packages/usp/exceptions.py b/venv/Lib/site-packages/usp/exceptions.py
new file mode 100644
--- /dev/null	(date 1616410446601)
+++ b/venv/Lib/site-packages/usp/exceptions.py	(date 1616410446601)
@@ -0,0 +1,29 @@
+"""Exceptions used by the sitemap parser."""
+
+
+class SitemapException(Exception):
+    """
+    Problem due to which we can't run further, e.g. wrong input parameters.
+    """
+    pass
+
+
+class SitemapXMLParsingException(Exception):
+    """
+    XML parsing exception to be handled gracefully.
+    """
+    pass
+
+
+class GunzipException(Exception):
+    """
+    gunzip() exception.
+    """
+    pass
+
+
+class StripURLToHomepageException(Exception):
+    """
+    strip_url_to_homepage() exception.
+    """
+    pass
Index: venv/Lib/site-packages/usp/fetch_parse.py
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/venv/Lib/site-packages/usp/fetch_parse.py b/venv/Lib/site-packages/usp/fetch_parse.py
new file mode 100644
--- /dev/null	(date 1616410446632)
+++ b/venv/Lib/site-packages/usp/fetch_parse.py	(date 1616410446632)
@@ -0,0 +1,953 @@
+"""Sitemap fetchers and parsers."""
+
+import abc
+import re
+import xml.parsers.expat
+from collections import OrderedDict
+from decimal import Decimal
+from typing import Optional, Dict
+
+from .exceptions import SitemapException, SitemapXMLParsingException
+from .helpers import (
+    html_unescape_strip,
+    parse_iso8601_date,
+    get_url_retry_on_client_errors,
+    ungzipped_response_content,
+    is_http_url,
+    parse_rfc2822_date,
+)
+from .log import create_logger
+from .objects.page import (
+    SitemapPage,
+    SitemapNewsStory,
+    SitemapPageChangeFrequency,
+    SITEMAP_PAGE_DEFAULT_PRIORITY,
+)
+from .objects.sitemap import (
+    AbstractSitemap,
+    InvalidSitemap,
+    IndexRobotsTxtSitemap,
+    IndexXMLSitemap,
+    PagesXMLSitemap,
+    PagesTextSitemap,
+    PagesRSSSitemap,
+    PagesAtomSitemap,
+)
+from .web_client.abstract_client import (
+    AbstractWebClient,
+    AbstractWebClientSuccessResponse,
+    WebClientErrorResponse,
+)
+from .web_client.requests_client import RequestsWebClient
+
+log = create_logger(__name__)
+
+
+class SitemapFetcher(object):
+    """robots.txt / XML / plain text sitemap fetcher."""
+
+    __MAX_SITEMAP_SIZE = 100 * 1024 * 1024
+    """Max. uncompressed sitemap size.
+
+    Spec says it might be up to 50 MB but let's go for the full 100 MB here."""
+
+    __MAX_RECURSION_LEVEL = 10
+    """Max. recursion level in iterating over sub-sitemaps."""
+
+    __slots__ = [
+        '_url',
+        '_recursion_level',
+        '_web_client',
+    ]
+
+    def __init__(self, url: str, recursion_level: int, web_client: Optional[AbstractWebClient] = None):
+
+        if recursion_level > self.__MAX_RECURSION_LEVEL:
+            raise SitemapException("Recursion level exceeded {} for URL {}.".format(self.__MAX_RECURSION_LEVEL, url))
+
+        if not is_http_url(url):
+            raise SitemapException("URL {} is not a HTTP(s) URL.".format(url))
+
+        if not web_client:
+            web_client = RequestsWebClient()
+
+        web_client.set_max_response_data_length(self.__MAX_SITEMAP_SIZE)
+
+        self._url = url
+        self._web_client = web_client
+        self._recursion_level = recursion_level
+
+    def sitemap(self) -> AbstractSitemap:
+        log.info("Fetching level {} sitemap from {}...".format(self._recursion_level, self._url))
+        response = get_url_retry_on_client_errors(url=self._url, web_client=self._web_client)
+
+        if isinstance(response, WebClientErrorResponse):
+            return InvalidSitemap(
+                url=self._url,
+                reason="Unable to fetch sitemap from {}: {}".format(self._url, response.message()),
+            )
+
+        assert isinstance(response, AbstractWebClientSuccessResponse)
+
+        response_content = ungzipped_response_content(url=self._url, response=response)
+
+        # MIME types returned in Content-Type are unpredictable, so peek into the content instead
+        if response_content[:20].strip().startswith('<'):
+            # XML sitemap (the specific kind is to be determined later)
+            parser = XMLSitemapParser(
+                url=self._url,
+                content=response_content,
+                recursion_level=self._recursion_level,
+                web_client=self._web_client,
+            )
+
+        else:
+            # Assume that it's some sort of a text file (robots.txt or plain text sitemap)
+            if self._url.endswith('/robots.txt'):
+                parser = IndexRobotsTxtSitemapParser(
+                    url=self._url,
+                    content=response_content,
+                    recursion_level=self._recursion_level,
+                    web_client=self._web_client,
+                )
+            else:
+                parser = PlainTextSitemapParser(
+                    url=self._url,
+                    content=response_content,
+                    recursion_level=self._recursion_level,
+                    web_client=self._web_client,
+                )
+
+        log.info("Parsing sitemap from URL {}...".format(self._url))
+        sitemap = parser.sitemap()
+
+        return sitemap
+
+
+class AbstractSitemapParser(object, metaclass=abc.ABCMeta):
+    """Abstract robots.txt / XML / plain text sitemap parser."""
+
+    __slots__ = [
+        '_url',
+        '_content',
+        '_web_client',
+        '_recursion_level',
+    ]
+
+    def __init__(self, url: str, content: str, recursion_level: int, web_client: AbstractWebClient):
+        self._url = url
+        self._content = content
+        self._recursion_level = recursion_level
+        self._web_client = web_client
+
+    @abc.abstractmethod
+    def sitemap(self) -> AbstractSitemap:
+        raise NotImplementedError("Abstract method.")
+
+
+class IndexRobotsTxtSitemapParser(AbstractSitemapParser):
+    """robots.txt index sitemap parser."""
+
+    def __init__(self, url: str, content: str, recursion_level: int, web_client: AbstractWebClient):
+        super().__init__(url=url, content=content, recursion_level=recursion_level, web_client=web_client)
+
+        if not self._url.endswith('/robots.txt'):
+            raise SitemapException("URL does not look like robots.txt URL: {}".format(self._url))
+
+    def sitemap(self) -> AbstractSitemap:
+
+        # Serves as an ordered set because we want to deduplicate URLs but also retain the order
+        sitemap_urls = OrderedDict()
+
+        for robots_txt_line in self._content.splitlines():
+            robots_txt_line = robots_txt_line.strip()
+            # robots.txt is supposed to be case sensitive but who cares in these Node.js times?
+            robots_txt_line = robots_txt_line.lower()
+            sitemap_match = re.search(r'^site-?map:\s*(.+?)$', robots_txt_line, flags=re.IGNORECASE)
+            if sitemap_match:
+                sitemap_url = sitemap_match.group(1)
+                if is_http_url(sitemap_url):
+                    sitemap_urls[sitemap_url] = True
+                else:
+                    log.warning("Sitemap URL {} doesn't look like an URL, skipping".format(sitemap_url))
+
+        sub_sitemaps = []
+
+        for sitemap_url in sitemap_urls.keys():
+            fetcher = SitemapFetcher(
+                url=sitemap_url,
+                recursion_level=self._recursion_level,
+                web_client=self._web_client,
+            )
+            fetched_sitemap = fetcher.sitemap()
+            sub_sitemaps.append(fetched_sitemap)
+
+        index_sitemap = IndexRobotsTxtSitemap(url=self._url, sub_sitemaps=sub_sitemaps)
+
+        return index_sitemap
+
+
+class PlainTextSitemapParser(AbstractSitemapParser):
+    """Plain text sitemap parser."""
+
+    def sitemap(self) -> AbstractSitemap:
+
+        story_urls = OrderedDict()
+
+        for story_url in self._content.splitlines():
+            story_url = story_url.strip()
+            if not story_url:
+                continue
+            if is_http_url(story_url):
+                story_urls[story_url] = True
+            else:
+                log.warning("Story URL {} doesn't look like an URL, skipping".format(story_url))
+
+        pages = []
+        for page_url in story_urls.keys():
+            page = SitemapPage(url=page_url)
+            pages.append(page)
+
+        text_sitemap = PagesTextSitemap(url=self._url, pages=pages)
+
+        return text_sitemap
+
+
+class XMLSitemapParser(AbstractSitemapParser):
+    """XML sitemap parser."""
+
+    __XML_NAMESPACE_SEPARATOR = ' '
+
+    __slots__ = [
+        '_concrete_parser',
+    ]
+
+    def __init__(self, url: str, content: str, recursion_level: int, web_client: AbstractWebClient):
+        super().__init__(url=url, content=content, recursion_level=recursion_level, web_client=web_client)
+
+        # Will be initialized when the type of sitemap is known
+        self._concrete_parser = None
+
+    def sitemap(self) -> AbstractSitemap:
+
+        parser = xml.parsers.expat.ParserCreate(namespace_separator=self.__XML_NAMESPACE_SEPARATOR)
+        parser.StartElementHandler = self._xml_element_start
+        parser.EndElementHandler = self._xml_element_end
+        parser.CharacterDataHandler = self._xml_char_data
+
+        try:
+            is_final = True
+            parser.Parse(self._content, is_final)
+        except Exception as ex:
+            # Some sitemap XML files might end abruptly because webservers might be timing out on returning huge XML
+            # files so don't return InvalidSitemap() but try to get as much pages as possible
+            log.error("Parsing sitemap from URL {} failed: {}".format(self._url, ex))
+
+        if not self._concrete_parser:
+            return InvalidSitemap(
+                url=self._url,
+                reason="No parsers support sitemap from {}".format(self._url),
+            )
+
+        return self._concrete_parser.sitemap()
+
+    @classmethod
+    def __normalize_xml_element_name(cls, name: str):
+        """
+        Replace the namespace URL in the argument element name with internal namespace.
+
+        * Elements from http://www.sitemaps.org/schemas/sitemap/0.9 namespace will be prefixed with "sitemap:",
+          e.g. "<loc>" will become "<sitemap:loc>"
+
+        * Elements from http://www.google.com/schemas/sitemap-news/0.9 namespace will be prefixed with "news:",
+          e.g. "<publication>" will become "<news:publication>"
+
+        For non-sitemap namespaces, return the element name with the namespace stripped.
+
+        :param name: Namespace URL plus XML element name, e.g. "http://www.sitemaps.org/schemas/sitemap/0.9 loc"
+        :return: Internal namespace name plus element name, e.g. "sitemap loc"
+        """
+
+        name_parts = name.split(cls.__XML_NAMESPACE_SEPARATOR)
+
+        if len(name_parts) == 1:
+            namespace_url = ''
+            name = name_parts[0]
+
+        elif len(name_parts) == 2:
+            namespace_url = name_parts[0]
+            name = name_parts[1]
+
+        else:
+            raise SitemapXMLParsingException("Unable to determine namespace for element '{}'".format(name))
+
+        if '/sitemap/' in namespace_url:
+            name = 'sitemap:{}'.format(name)
+        elif '/sitemap-news/' in namespace_url:
+            name = 'news:{}'.format(name)
+        else:
+            # We don't care about the rest of the namespaces, so just keep the plain element name
+            pass
+
+        return name
+
+    def _xml_element_start(self, name: str, attrs: Dict[str, str]) -> None:
+
+        name = self.__normalize_xml_element_name(name)
+
+        if self._concrete_parser:
+            self._concrete_parser.xml_element_start(name=name, attrs=attrs)
+
+        else:
+
+            # Root element -- initialize concrete parser
+            if name == 'sitemap:urlset':
+                self._concrete_parser = PagesXMLSitemapParser(
+                    url=self._url,
+                )
+
+            elif name == 'sitemap:sitemapindex':
+                self._concrete_parser = IndexXMLSitemapParser(
+                    url=self._url,
+                    web_client=self._web_client,
+                    recursion_level=self._recursion_level,
+                )
+
+            elif name == 'rss':
+                self._concrete_parser = PagesRSSSitemapParser(
+                    url=self._url,
+                )
+
+            elif name == 'feed':
+                self._concrete_parser = PagesAtomSitemapParser(
+                    url=self._url,
+                )
+
+            else:
+                raise SitemapXMLParsingException("Unsupported root element '{}'.".format(name))
+
+    def _xml_element_end(self, name: str) -> None:
+
+        name = self.__normalize_xml_element_name(name)
+
+        if not self._concrete_parser:
+            raise SitemapXMLParsingException("Concrete sitemap parser should be set by now.")
+
+        self._concrete_parser.xml_element_end(name=name)
+
+    def _xml_char_data(self, data: str) -> None:
+
+        if not self._concrete_parser:
+            raise SitemapXMLParsingException("Concrete sitemap parser should be set by now.")
+
+        self._concrete_parser.xml_char_data(data=data)
+
+
+class AbstractXMLSitemapParser(object, metaclass=abc.ABCMeta):
+    """
+    Abstract XML sitemap parser.
+    """
+
+    __slots__ = [
+        # URL of the sitemap that is being parsed
+        '_url',
+
+        # Last encountered character data
+        '_last_char_data',
+
+        '_last_handler_call_was_xml_char_data',
+    ]
+
+    def __init__(self, url: str):
+        self._url = url
+        self._last_char_data = ''
+        self._last_handler_call_was_xml_char_data = False
+
+    def xml_element_start(self, name: str, attrs: Dict[str, str]) -> None:
+        self._last_handler_call_was_xml_char_data = False
+        pass
+
+    def xml_element_end(self, name: str) -> None:
+        # End of any element always resets last encountered character data
+        self._last_char_data = ''
+        self._last_handler_call_was_xml_char_data = False
+
+    def xml_char_data(self, data: str) -> None:
+        # Handler might be called multiple times for what essentially is a single string, e.g. in case of entities
+        # ("ABC &amp; DEF"), so this is why we're appending
+        if self._last_handler_call_was_xml_char_data:
+            self._last_char_data += data
+        else:
+            self._last_char_data = data
+
+        self._last_handler_call_was_xml_char_data = True
+
+    @abc.abstractmethod
+    def sitemap(self) -> AbstractSitemap:
+        raise NotImplementedError("Abstract method.")
+
+
+class IndexXMLSitemapParser(AbstractXMLSitemapParser):
+    """
+    Index XML sitemap parser.
+    """
+
+    __slots__ = [
+        '_web_client',
+        '_recursion_level',
+
+        # List of sub-sitemap URLs found in this index sitemap
+        '_sub_sitemap_urls',
+    ]
+
+    def __init__(self, url: str, web_client: AbstractWebClient, recursion_level: int):
+        super().__init__(url=url)
+
+        self._web_client = web_client
+        self._recursion_level = recursion_level
+        self._sub_sitemap_urls = []
+
+    def xml_element_end(self, name: str) -> None:
+
+        if name == 'sitemap:loc':
+            sub_sitemap_url = html_unescape_strip(self._last_char_data)
+            if not is_http_url(sub_sitemap_url):
+                log.warning("Sub-sitemap URL does not look like one: {}".format(sub_sitemap_url))
+
+            else:
+                if sub_sitemap_url not in self._sub_sitemap_urls:
+                    self._sub_sitemap_urls.append(sub_sitemap_url)
+
+        super().xml_element_end(name=name)
+
+    def sitemap(self) -> AbstractSitemap:
+
+        sub_sitemaps = []
+
+        for sub_sitemap_url in self._sub_sitemap_urls:
+
+            # URL might be invalid, or recursion limit might have been reached
+            try:
+                fetcher = SitemapFetcher(url=sub_sitemap_url,
+                                         recursion_level=self._recursion_level + 1,
+                                         web_client=self._web_client)
+                fetched_sitemap = fetcher.sitemap()
+            except Exception as ex:
+                fetched_sitemap = InvalidSitemap(
+                    url=sub_sitemap_url,
+                    reason="Unable to add sub-sitemap from URL {}: {}".format(sub_sitemap_url, str(ex)),
+                )
+
+            sub_sitemaps.append(fetched_sitemap)
+
+        index_sitemap = IndexXMLSitemap(url=self._url, sub_sitemaps=sub_sitemaps)
+
+        return index_sitemap
+
+
+class PagesXMLSitemapParser(AbstractXMLSitemapParser):
+    """
+    Pages XML sitemap parser.
+    """
+
+    class Page(object):
+        """Simple data class for holding various properties for a single <url> entry while parsing."""
+
+        __slots__ = [
+            'url',
+            'last_modified',
+            'change_frequency',
+            'priority',
+            'news_title',
+            'news_publish_date',
+            'news_publication_name',
+            'news_publication_language',
+            'news_access',
+            'news_genres',
+            'news_keywords',
+            'news_stock_tickers',
+        ]
+
+        def __init__(self):
+            self.url = None
+            self.last_modified = None
+            self.change_frequency = None
+            self.priority = None
+            self.news_title = None
+            self.news_publish_date = None
+            self.news_publication_name = None
+            self.news_publication_language = None
+            self.news_access = None
+            self.news_genres = None
+            self.news_keywords = None
+            self.news_stock_tickers = None
+
+        def __hash__(self):
+            return hash((
+                # Hash only the URL to be able to find unique ones
+                self.url,
+            ))
+
+        def page(self) -> Optional[SitemapPage]:
+            """Return constructed sitemap page if one has been completed, otherwise None."""
+
+            # Required
+            url = html_unescape_strip(self.url)
+            if not url:
+                log.error("URL is unset")
+                return None
+
+            last_modified = html_unescape_strip(self.last_modified)
+            if last_modified:
+                last_modified = parse_iso8601_date(last_modified)
+
+            change_frequency = html_unescape_strip(self.change_frequency)
+            if change_frequency:
+                change_frequency = change_frequency.lower()
+                if SitemapPageChangeFrequency.has_value(change_frequency):
+                    change_frequency = SitemapPageChangeFrequency(change_frequency)
+                else:
+                    log.warning("Invalid change frequency, defaulting to 'always'.".format(change_frequency))
+                    change_frequency = SitemapPageChangeFrequency.ALWAYS
+                assert isinstance(change_frequency, SitemapPageChangeFrequency)
+
+            priority = html_unescape_strip(self.priority)
+            if priority:
+                priority = Decimal(priority)
+
+                comp_zero = priority.compare(Decimal('0.0'))
+                comp_one = priority.compare(Decimal('1.0'))
+                if comp_zero in (Decimal('0'), Decimal('1') and comp_one in (Decimal('0'), Decimal('-1'))):
+                    # 0 <= priority <= 1
+                    pass
+                else:
+                    log.warning("Priority is not within 0 and 1: {}".format(priority))
+                    priority = SITEMAP_PAGE_DEFAULT_PRIORITY
+
+            else:
+                priority = SITEMAP_PAGE_DEFAULT_PRIORITY
+
+            news_title = html_unescape_strip(self.news_title)
+
+            news_publish_date = html_unescape_strip(self.news_publish_date)
+            if news_publish_date:
+                news_publish_date = parse_iso8601_date(date_string=news_publish_date)
+
+            news_publication_name = html_unescape_strip(self.news_publication_name)
+            news_publication_language = html_unescape_strip(self.news_publication_language)
+            news_access = html_unescape_strip(self.news_access)
+
+            news_genres = html_unescape_strip(self.news_genres)
+            if news_genres:
+                news_genres = [x.strip() for x in news_genres.split(',')]
+            else:
+                news_genres = []
+
+            news_keywords = html_unescape_strip(self.news_keywords)
+            if news_keywords:
+                news_keywords = [x.strip() for x in news_keywords.split(',')]
+            else:
+                news_keywords = []
+
+            news_stock_tickers = html_unescape_strip(self.news_stock_tickers)
+            if news_stock_tickers:
+                news_stock_tickers = [x.strip() for x in news_stock_tickers.split(',')]
+            else:
+                news_stock_tickers = []
+
+            sitemap_news_story = None
+            if news_title and news_publish_date:
+                sitemap_news_story = SitemapNewsStory(
+                    title=news_title,
+                    publish_date=news_publish_date,
+                    publication_name=news_publication_name,
+                    publication_language=news_publication_language,
+                    access=news_access,
+                    genres=news_genres,
+                    keywords=news_keywords,
+                    stock_tickers=news_stock_tickers,
+                )
+
+            return SitemapPage(
+                url=url,
+                last_modified=last_modified,
+                change_frequency=change_frequency,
+                priority=priority,
+                news_story=sitemap_news_story,
+            )
+
+    __slots__ = [
+        '_current_page',
+        '_pages',
+    ]
+
+    def __init__(self, url: str):
+        super().__init__(url=url)
+
+        self._current_page = None
+        self._pages = []
+
+    def xml_element_start(self, name: str, attrs: Dict[str, str]) -> None:
+
+        super().xml_element_start(name=name, attrs=attrs)
+
+        if name == 'sitemap:url':
+            if self._current_page:
+                raise SitemapXMLParsingException("Page is expected to be unset by <url>.")
+            self._current_page = self.Page()
+
+    def __require_last_char_data_to_be_set(self, name: str) -> None:
+        if not self._last_char_data:
+            raise SitemapXMLParsingException(
+                "Character data is expected to be set at the end of <{}>.".format(name)
+            )
+
+    def xml_element_end(self, name: str) -> None:
+
+        if not self._current_page and name != 'sitemap:urlset':
+            raise SitemapXMLParsingException("Page is expected to be set at the end of <{}>.".format(name))
+
+        if name == 'sitemap:url':
+            if self._current_page not in self._pages:
+                self._pages.append(self._current_page)
+            self._current_page = None
+
+        else:
+
+            if name == 'sitemap:loc':
+                # Every entry must have <loc>
+                self.__require_last_char_data_to_be_set(name=name)
+                self._current_page.url = self._last_char_data
+
+            elif name == 'sitemap:lastmod':
+                # Element might be present but character data might be empty
+                self._current_page.last_modified = self._last_char_data
+
+            elif name == 'sitemap:changefreq':
+                # Element might be present but character data might be empty
+                self._current_page.change_frequency = self._last_char_data
+
+            elif name == 'sitemap:priority':
+                # Element might be present but character data might be empty
+                self._current_page.priority = self._last_char_data
+
+            elif name == 'news:name':  # news/publication/name
+                # Element might be present but character data might be empty
+                self._current_page.news_publication_name = self._last_char_data
+
+            elif name == 'news:language':  # news/publication/language
+                # Element might be present but character data might be empty
+                self._current_page.news_publication_language = self._last_char_data
+
+            elif name == 'news:publication_date':
+                # Element might be present but character data might be empty
+                self._current_page.news_publish_date = self._last_char_data
+
+            elif name == 'news:title':
+                # Every Google News sitemap entry must have <title>
+                self.__require_last_char_data_to_be_set(name=name)
+                self._current_page.news_title = self._last_char_data
+
+            elif name == 'news:access':
+                # Element might be present but character data might be empty
+                self._current_page.news_access = self._last_char_data
+
+            elif name == 'news:keywords':
+                # Element might be present but character data might be empty
+                self._current_page.news_keywords = self._last_char_data
+
+            elif name == 'news:stock_tickers':
+                # Element might be present but character data might be empty
+                self._current_page.news_stock_tickers = self._last_char_data
+
+        super().xml_element_end(name=name)
+
+    def sitemap(self) -> AbstractSitemap:
+
+        pages = []
+
+        for page_row in self._pages:
+            page = page_row.page()
+            if page:
+                pages.append(page)
+
+        pages_sitemap = PagesXMLSitemap(url=self._url, pages=pages)
+
+        return pages_sitemap
+
+
+class PagesRSSSitemapParser(AbstractXMLSitemapParser):
+    """
+    Pages RSS 2.0 sitemap parser.
+
+    https://validator.w3.org/feed/docs/rss2.html
+    """
+
+    class Page(object):
+        """
+        Simple data class for holding various properties for a single <item> entry while parsing.
+        """
+
+        __slots__ = [
+            'link',
+            'title',
+            'description',
+            'publication_date',
+        ]
+
+        def __init__(self):
+            self.link = None
+            self.title = None
+            self.description = None
+            self.publication_date = None
+
+        def __hash__(self):
+            return hash((
+                # Hash only the URL
+                self.link,
+            ))
+
+        def page(self) -> Optional[SitemapPage]:
+            """Return constructed sitemap page if one has been completed, otherwise None."""
+
+            # Required
+            link = html_unescape_strip(self.link)
+            if not link:
+                log.error("Link is unset")
+                return None
+
+            title = html_unescape_strip(self.title)
+            description = html_unescape_strip(self.description)
+            if not (title or description):
+                log.error("Both title and description are unset")
+                return None
+
+            publication_date = html_unescape_strip(self.publication_date)
+            if publication_date:
+                publication_date = parse_rfc2822_date(publication_date)
+
+            return SitemapPage(
+                url=link,
+                news_story=SitemapNewsStory(
+                    title=title or description,
+                    publish_date=publication_date,
+                ),
+            )
+
+    __slots__ = [
+        '_current_page',
+        '_pages',
+    ]
+
+    def __init__(self, url: str):
+        super().__init__(url=url)
+
+        self._current_page = None
+        self._pages = []
+
+    def xml_element_start(self, name: str, attrs: Dict[str, str]) -> None:
+
+        super().xml_element_start(name=name, attrs=attrs)
+
+        if name == 'item':
+            if self._current_page:
+                raise SitemapXMLParsingException("Page is expected to be unset by <item>.")
+            self._current_page = self.Page()
+
+    def __require_last_char_data_to_be_set(self, name: str) -> None:
+        if not self._last_char_data:
+            raise SitemapXMLParsingException(
+                "Character data is expected to be set at the end of <{}>.".format(name)
+            )
+
+    def xml_element_end(self, name: str) -> None:
+
+        # If within <item> already
+        if self._current_page:
+
+            if name == 'item':
+                if self._current_page not in self._pages:
+                    self._pages.append(self._current_page)
+                self._current_page = None
+
+            else:
+
+                if name == 'link':
+                    # Every entry must have <link>
+                    self.__require_last_char_data_to_be_set(name=name)
+                    self._current_page.link = self._last_char_data
+
+                elif name == 'title':
+                    # Title (if set) can't be empty
+                    self.__require_last_char_data_to_be_set(name=name)
+                    self._current_page.title = self._last_char_data
+
+                elif name == 'description':
+                    # Description (if set) can't be empty
+                    self.__require_last_char_data_to_be_set(name=name)
+                    self._current_page.description = self._last_char_data
+
+                elif name == 'pubDate':
+                    # Element might be present but character data might be empty
+                    self._current_page.publication_date = self._last_char_data
+
+        super().xml_element_end(name=name)
+
+    def sitemap(self) -> AbstractSitemap:
+
+        pages = []
+
+        for page_row in self._pages:
+            page = page_row.page()
+            if page:
+                pages.append(page)
+
+        pages_sitemap = PagesRSSSitemap(url=self._url, pages=pages)
+
+        return pages_sitemap
+
+
+class PagesAtomSitemapParser(AbstractXMLSitemapParser):
+    """
+    Pages Atom 0.3 / 1.0 sitemap parser.
+
+    https://github.com/simplepie/simplepie-ng/wiki/Spec:-Atom-0.3
+    https://www.ietf.org/rfc/rfc4287.txt
+    http://rakaz.nl/2005/07/moving-from-atom-03-to-10.html
+    """
+
+    # FIXME merge with RSS parser class as there are too many similarities
+
+    class Page(object):
+        """Simple data class for holding various properties for a single <entry> entry while parsing."""
+
+        __slots__ = [
+            'link',
+            'title',
+            'description',
+            'publication_date',
+        ]
+
+        def __init__(self):
+            self.link = None
+            self.title = None
+            self.description = None
+            self.publication_date = None
+
+        def __hash__(self):
+            return hash((
+                # Hash only the URL
+                self.link,
+            ))
+
+        def page(self) -> Optional[SitemapPage]:
+            """Return constructed sitemap page if one has been completed, otherwise None."""
+
+            # Required
+            link = html_unescape_strip(self.link)
+            if not link:
+                log.error("Link is unset")
+                return None
+
+            title = html_unescape_strip(self.title)
+            description = html_unescape_strip(self.description)
+            if not (title or description):
+                log.error("Both title and description are unset")
+                return None
+
+            publication_date = html_unescape_strip(self.publication_date)
+            if publication_date:
+                publication_date = parse_rfc2822_date(publication_date)
+
+            return SitemapPage(
+                url=link,
+                news_story=SitemapNewsStory(
+                    title=title or description,
+                    publish_date=publication_date,
+                ),
+            )
+
+    __slots__ = [
+        '_current_page',
+        '_pages',
+        '_last_link_rel_self_href',
+    ]
+
+    def __init__(self, url: str):
+        super().__init__(url=url)
+
+        self._current_page = None
+        self._pages = []
+        self._last_link_rel_self_href = None
+
+    def xml_element_start(self, name: str, attrs: Dict[str, str]) -> None:
+
+        super().xml_element_start(name=name, attrs=attrs)
+
+        if name == 'entry':
+            if self._current_page:
+                raise SitemapXMLParsingException("Page is expected to be unset by <entry>.")
+            self._current_page = self.Page()
+
+        elif name == 'link':
+            if self._current_page:
+                if attrs.get('rel', 'self').lower() == 'self' or self._last_link_rel_self_href is None:
+                    self._last_link_rel_self_href = attrs.get('href', None)
+
+    def __require_last_char_data_to_be_set(self, name: str) -> None:
+        if not self._last_char_data:
+            raise SitemapXMLParsingException(
+                "Character data is expected to be set at the end of <{}>.".format(name)
+            )
+
+    def xml_element_end(self, name: str) -> None:
+
+        # If within <entry> already
+        if self._current_page:
+
+            if name == 'entry':
+
+                if self._last_link_rel_self_href:
+                    self._current_page.link = self._last_link_rel_self_href
+                    self._last_link_rel_self_href = None
+
+                    if self._current_page not in self._pages:
+                        self._pages.append(self._current_page)
+
+                self._current_page = None
+
+            else:
+
+                if name == 'title':
+                    # Title (if set) can't be empty
+                    self.__require_last_char_data_to_be_set(name=name)
+                    self._current_page.title = self._last_char_data
+
+                elif name == 'tagline' or name == 'summary':
+                    # Description (if set) can't be empty
+                    self.__require_last_char_data_to_be_set(name=name)
+                    self._current_page.description = self._last_char_data
+
+                elif name == 'issued' or name == 'published':
+                    # Element might be present but character data might be empty
+                    self._current_page.publication_date = self._last_char_data
+
+                elif name == 'updated':
+                    # No 'issued' or 'published' were set before
+                    if not self._current_page.publication_date:
+                        self._current_page.publication_date = self._last_char_data
+
+        super().xml_element_end(name=name)
+
+    def sitemap(self) -> AbstractSitemap:
+
+        pages = []
+
+        for page_row in self._pages:
+            page = page_row.page()
+            if page:
+                pages.append(page)
+
+        pages_sitemap = PagesAtomSitemap(url=self._url, pages=pages)
+
+        return pages_sitemap
Index: venv/Lib/site-packages/usp/helpers.py
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/venv/Lib/site-packages/usp/helpers.py b/venv/Lib/site-packages/usp/helpers.py
new file mode 100644
--- /dev/null	(date 1616410446663)
+++ b/venv/Lib/site-packages/usp/helpers.py	(date 1616410446663)
@@ -0,0 +1,257 @@
+"""Helper utilities."""
+
+import datetime
+import gzip as gzip_lib
+import html
+import re
+import time
+from typing import Optional
+from urllib.parse import urlparse, unquote_plus, urlunparse
+
+from dateutil.parser import parse as dateutil_parse
+
+from .exceptions import SitemapException, GunzipException, StripURLToHomepageException
+from .log import create_logger
+from .web_client.abstract_client import (
+    AbstractWebClient,
+    AbstractWebClientSuccessResponse,
+    WebClientErrorResponse,
+    AbstractWebClientResponse,
+)
+
+log = create_logger(__name__)
+
+__URL_REGEX = re.compile(r'^https?://[^\s/$.?#].[^\s]*$', re.IGNORECASE)
+"""Regular expression to match HTTP(s) URLs."""
+
+
+def is_http_url(url: str) -> bool:
+    """
+    Returns true if URL is of the "http" ("https") scheme.
+
+    :param url: URL to test.
+    :return: True if argument URL is of the "http" ("https") scheme.
+    """
+    if url is None:
+        log.debug("URL is None")
+        return False
+    if len(url) == 0:
+        log.debug("URL is empty")
+        return False
+
+    log.debug("Testing if URL '{}' is HTTP(s) URL".format(url))
+
+    if not re.search(__URL_REGEX, url):
+        log.debug("URL '{}' does not match URL's regexp".format(url))
+        return False
+
+    try:
+        # Try parsing the URL
+        uri = urlparse(url)
+        _ = urlunparse(uri)
+
+    except Exception as ex:
+        log.debug("Cannot parse URL {}: {}".format(url, ex))
+        return False
+
+    if not uri.scheme:
+        log.debug("Scheme is undefined for URL {}.".format(url))
+        return False
+    if not uri.scheme.lower() in ['http', 'https']:
+        log.debug("Scheme is not HTTP(s) for URL {}.".format(url))
+        return False
+    if not uri.hostname:
+        log.debug("Host is undefined for URL {}.".format(url))
+        return False
+
+    return True
+
+
+def html_unescape_strip(string: Optional[str]) -> Optional[str]:
+    """
+    Decode HTML entities, strip string, set to None if it's empty; ignore None as input.
+
+    :param string: String to decode HTML entities in.
+    :return: Stripped string with HTML entities decoded; None if parameter string was empty or None.
+    """
+    if string:
+        string = html.unescape(string)
+        string = string.strip()
+        if not string:
+            string = None
+    return string
+
+
+def parse_iso8601_date(date_string: str) -> datetime.datetime:
+    """
+    Parse ISO 8601 date (e.g. from sitemap's <publication_date>) into datetime.datetime object.
+
+    :param date_string: ISO 8601 date, e.g. "2018-01-12T21:57:27Z" or "1997-07-16T19:20:30+01:00".
+    :return: datetime.datetime object of a parsed date.
+    """
+    # FIXME parse known date formats faster
+
+    if not date_string:
+        raise SitemapException("Date string is unset.")
+
+    date = dateutil_parse(date_string)
+
+    return date
+
+
+def parse_rfc2822_date(date_string: str) -> datetime.datetime:
+    """
+    Parse RFC 2822 date (e.g. from Atom's <issued>) into datetime.datetime object.
+
+    :param date_string: RFC 2822 date, e.g. "Tue, 10 Aug 2010 20:43:53 -0000".
+    :return: datetime.datetime object of a parsed date.
+    """
+    # FIXME parse known date formats faster
+    return parse_iso8601_date(date_string)
+
+
+def get_url_retry_on_client_errors(url: str,
+                                   web_client: AbstractWebClient,
+                                   retry_count: int = 5,
+                                   sleep_between_retries: int = 1) -> AbstractWebClientResponse:
+    """
+    Fetch URL, retry on retryable errors.
+
+    :param url: URL to fetch.
+    :param web_client: Web client object to use for fetching.
+    :param retry_count: How many times to retry fetching the same URL.
+    :param sleep_between_retries: How long to sleep between retries, in seconds.
+    :return: Web client response object.
+    """
+    assert retry_count > 0, "Retry count must be positive."
+
+    response = None
+    for retry in range(0, retry_count):
+        log.info("Fetching URL {}...".format(url))
+        response = web_client.get(url)
+
+        if isinstance(response, WebClientErrorResponse):
+            log.warning(
+                "Request for URL {} failed: {}".format(
+                    url, response.message()
+                )
+            )
+
+            if response.retryable():
+                log.info("Retrying URL {} in {} seconds...".format(url, sleep_between_retries))
+                time.sleep(sleep_between_retries)
+
+            else:
+                log.info("Not retrying for URL {}".format(url))
+                return response
+
+        else:
+            return response
+
+    log.info("Giving up on URL {}".format(url))
+    return response
+
+
+def __response_is_gzipped_data(url: str, response: AbstractWebClientSuccessResponse) -> bool:
+    """
+    Return True if Response looks like it's gzipped.
+
+    :param url: URL the response was fetched from.
+    :param response: Response object.
+    :return: True if response looks like it might contain gzipped data.
+    """
+    uri = urlparse(url)
+    url_path = unquote_plus(uri.path)
+    content_type = response.header('content-type') or ''
+
+    if url_path.lower().endswith('.gz') or 'gzip' in content_type.lower():
+        return True
+
+    else:
+        return False
+
+
+def gunzip(data: bytes) -> bytes:
+    """
+    Gunzip data.
+
+    :param data: Gzipped data.
+    :return: Gunzipped data.
+    """
+
+    if data is None:
+        raise GunzipException("Data is None.")
+
+    if not isinstance(data, bytes):
+        raise GunzipException("Data is not bytes: %s" % str(data))
+
+    if len(data) == 0:
+        raise GunzipException("Data is empty (no way an empty string is a valid Gzip archive).")
+
+    try:
+        gunzipped_data = gzip_lib.decompress(data)
+    except Exception as ex:
+        raise GunzipException("Unable to gunzip data: %s" % str(ex))
+
+    if gunzipped_data is None:
+        raise GunzipException("Gunzipped data is None.")
+
+    if not isinstance(gunzipped_data, bytes):
+        raise GunzipException("Gunzipped data is not bytes.")
+
+    return gunzipped_data
+
+
+def ungzipped_response_content(url: str, response: AbstractWebClientSuccessResponse) -> str:
+    """
+    Return HTTP response's decoded content, gunzip it if necessary.
+
+    :param url: URL the response was fetched from.
+    :param response: Response object.
+    :return: Decoded and (if necessary) gunzipped response string.
+    """
+
+    data = response.raw_data()
+
+    if __response_is_gzipped_data(url=url, response=response):
+        try:
+            data = gunzip(data)
+        except GunzipException as ex:
+            # In case of an error, just assume that it's one of the non-gzipped sitemaps with ".gz" extension
+            log.error("Unable to gunzip response {}, maybe it's a non-gzipped sitemap: {}".format(response, ex))
+
+    # FIXME other encodings
+    data = data.decode('utf-8-sig', errors='replace')
+
+    assert isinstance(data, str)
+
+    return data
+
+
+def strip_url_to_homepage(url: str) -> str:
+    """
+    Strip URL to its homepage.
+
+    :param url: URL to strip, e.g. "http://www.example.com/page.html".
+    :return: Stripped homepage URL, e.g. "http://www.example.com/"
+    """
+    if not url:
+        raise StripURLToHomepageException("URL is empty.")
+
+    try:
+        uri = urlparse(url)
+        assert uri.scheme, "Scheme must be set."
+        assert uri.scheme.lower() in ['http', 'https'], "Scheme must be http:// or https://"
+        uri = (
+            uri.scheme,
+            uri.netloc,
+            '/',  # path
+            '',  # params
+            '',  # query
+            '',  # fragment
+        )
+        url = urlunparse(uri)
+    except Exception as ex:
+        raise StripURLToHomepageException("Unable to parse URL {}: {}".format(url, ex))
+
+    return url
Index: venv/Lib/site-packages/usp/log.py
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/venv/Lib/site-packages/usp/log.py b/venv/Lib/site-packages/usp/log.py
new file mode 100644
--- /dev/null	(date 1616410446679)
+++ b/venv/Lib/site-packages/usp/log.py	(date 1616410446679)
@@ -0,0 +1,91 @@
+"""Logging utilities."""
+
+import logging
+
+
+class Logger(object):
+    """
+    Logging helper class.
+    """
+
+    __LEVELS = {
+        'CRITICAL': logging.CRITICAL,
+        'ERROR': logging.ERROR,
+        'WARNING': logging.WARNING,
+        'INFO': logging.INFO,
+        'DEBUG': logging.DEBUG,
+    }
+    """Valid logging levels and their "logging" counterparts."""
+
+    __DEFAULT_LEVEL = 'INFO'
+    """Default logging level."""
+
+    __slots__ = [
+        # "logging" object
+        '__l',
+    ]
+
+    def __init__(self, name: str):
+        """
+        Initialize logger object for a given name.
+
+        :param name: Module name that the logger should be initialized for.
+        """
+
+        self.__l = logging.getLogger(name)
+        if not self.__l.handlers:
+            formatter = logging.Formatter(
+                fmt='%(asctime)s %(levelname)s %(name)s [%(process)d/%(threadName)s]: %(message)s'
+            )
+
+            handler = logging.StreamHandler()
+            handler.setFormatter(formatter)
+            self.__l.addHandler(handler)
+
+            self.__l.setLevel(self.__LEVELS[self.__DEFAULT_LEVEL])
+
+            # Don't propagate handler to root logger
+            # (http://stackoverflow.com/a/21127526/200603)
+            self.__l.propagate = False
+
+    def error(self, message: str) -> None:
+        """
+        Log error message.
+
+        :param message: Message to log.
+        """
+        self.__l.error(message)
+
+    def warning(self, message: str) -> None:
+        """
+        Log warning message.
+
+        :param message: Message to log.
+        """
+        self.__l.warning(message)
+
+    def info(self, message: str) -> None:
+        """
+        Log informational message.
+
+        :param message: Message to log.
+        """
+        self.__l.info(message)
+
+    def debug(self, message: str) -> None:
+        """
+        Log debugging message.
+
+        :param message: Message to log.
+        """
+        self.__l.debug(message)
+
+
+def create_logger(name: str) -> Logger:
+    """
+    Create and return Logger object.
+
+    :param name: Module name that the logger should be initialized for.
+    :return: Logger object.
+    """
+    return Logger(name=name)
Index: venv/Lib/site-packages/usp/tree.py
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/venv/Lib/site-packages/usp/tree.py b/venv/Lib/site-packages/usp/tree.py
new file mode 100644
--- /dev/null	(date 1616410446679)
+++ b/venv/Lib/site-packages/usp/tree.py	(date 1616410446679)
@@ -0,0 +1,80 @@
+"""Helpers to generate a sitemap tree."""
+
+from typing import Optional
+
+from .exceptions import SitemapException
+from .fetch_parse import SitemapFetcher
+from .helpers import is_http_url, strip_url_to_homepage
+from .log import create_logger
+from .objects.sitemap import AbstractSitemap, InvalidSitemap, IndexWebsiteSitemap, IndexRobotsTxtSitemap
+from .web_client.abstract_client import AbstractWebClient
+
+log = create_logger(__name__)
+
+_UNPUBLISHED_SITEMAP_PATHS = {
+    'sitemap.xml',
+    'sitemap.xml.gz',
+    'sitemap_index.xml',
+    'sitemap-index.xml',
+    'sitemap_index.xml.gz',
+    'sitemap-index.xml.gz',
+    '.sitemap.xml',
+    'sitemap',
+    'admin/config/search/xmlsitemap',
+    'sitemap/sitemap-index.xml',
+}
+"""Paths which are not exposed in robots.txt but might still contain a sitemap."""
+
+
+def sitemap_tree_for_homepage(homepage_url: str, web_client: Optional[AbstractWebClient] = None) -> AbstractSitemap:
+    """
+    Using a homepage URL, fetch the tree of sitemaps and pages listed in them.
+
+    :param homepage_url: Homepage URL of a website to fetch the sitemap tree for, e.g. "http://www.example.com/".
+    :param web_client: Web client implementation to use for fetching sitemaps.
+    :return: Root sitemap object of the fetched sitemap tree.
+    """
+
+    if not is_http_url(homepage_url):
+        raise SitemapException("URL {} is not a HTTP(s) URL.".format(homepage_url))
+
+    stripped_homepage_url = strip_url_to_homepage(url=homepage_url)
+    if homepage_url != stripped_homepage_url:
+        log.warning("Assuming that the homepage of {} is {}".format(homepage_url, stripped_homepage_url))
+        homepage_url = stripped_homepage_url
+
+    if not homepage_url.endswith('/'):
+        homepage_url += '/'
+    robots_txt_url = homepage_url + 'robots.txt'
+
+    sitemaps = []
+
+    robots_txt_fetcher = SitemapFetcher(url=robots_txt_url, web_client=web_client, recursion_level=0)
+    robots_txt_sitemap = robots_txt_fetcher.sitemap()
+    sitemaps.append(robots_txt_sitemap)
+
+    sitemap_urls_found_in_robots_txt = set()
+    if isinstance(robots_txt_sitemap, IndexRobotsTxtSitemap):
+        for sub_sitemap in robots_txt_sitemap.sub_sitemaps:
+            sitemap_urls_found_in_robots_txt.add(sub_sitemap.url)
+
+    for unpublished_sitemap_path in _UNPUBLISHED_SITEMAP_PATHS:
+        unpublished_sitemap_url = homepage_url + unpublished_sitemap_path
+
+        # Don't refetch URLs already found in robots.txt
+        if unpublished_sitemap_url not in sitemap_urls_found_in_robots_txt:
+
+            unpublished_sitemap_fetcher = SitemapFetcher(
+                url=unpublished_sitemap_url,
+                web_client=web_client,
+                recursion_level=0,
+            )
+            unpublished_sitemap = unpublished_sitemap_fetcher.sitemap()
+
+            # Skip the ones that weren't found
+            if not isinstance(unpublished_sitemap, InvalidSitemap):
+                sitemaps.append(unpublished_sitemap)
+
+    index_sitemap = IndexWebsiteSitemap(url=homepage_url, sub_sitemaps=sitemaps)
+
+    return index_sitemap
Index: venv/Lib/site-packages/usp/__about__.py
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/venv/Lib/site-packages/usp/__about__.py b/venv/Lib/site-packages/usp/__about__.py
new file mode 100644
--- /dev/null	(date 1616410446772)
+++ b/venv/Lib/site-packages/usp/__about__.py	(date 1616410446772)
@@ -0,0 +1,3 @@
+"""Package version."""
+
+__version__ = "0.5"
Index: venv/Lib/site-packages/usp/__init__.py
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/venv/Lib/site-packages/usp/__init__.py b/venv/Lib/site-packages/usp/__init__.py
new file mode 100644
--- /dev/null	(date 1616410446845)
+++ b/venv/Lib/site-packages/usp/__init__.py	(date 1616410446845)
@@ -0,0 +1,1 @@
+__all__ = ["tree"]
Index: venv/Lib/site-packages/usp/objects/page.py
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/venv/Lib/site-packages/usp/objects/page.py b/venv/Lib/site-packages/usp/objects/page.py
new file mode 100644
--- /dev/null	(date 1616410446853)
+++ b/venv/Lib/site-packages/usp/objects/page.py	(date 1616410446853)
@@ -0,0 +1,328 @@
+"""Objects that represent a page found in one of the sitemaps."""
+
+import datetime
+from decimal import Decimal
+from enum import Enum, unique
+from typing import List, Optional
+
+SITEMAP_PAGE_DEFAULT_PRIORITY = Decimal('0.5')
+"""Default sitemap page priority, as per the spec."""
+
+
+class SitemapNewsStory(object):
+    """
+    Single story derived from Google News XML sitemap.
+    """
+
+    __slots__ = [
+        '__title',
+        '__publish_date',
+        '__publication_name',
+        '__publication_language',
+        '__access',
+        '__genres',
+        '__keywords',
+        '__stock_tickers',
+    ]
+
+    def __init__(self,
+                 title: str,
+                 publish_date: datetime.datetime,
+                 publication_name: Optional[str] = None,
+                 publication_language: Optional[str] = None,
+                 access: Optional[str] = None,
+                 genres: List[str] = None,
+                 keywords: List[str] = None,
+                 stock_tickers: List[str] = None):
+        """
+        Initialize a new Google News story.
+
+        :param title: Story title.
+        :param publish_date: Story publication date.
+        :param publication_name: Name of the news publication in which the article appears in.
+        :param publication_language: Primary language of the news publication in which the article appears in.
+        :param access: Accessibility of the article.
+        :param genres: List of properties characterizing the content of the article.
+        :param keywords: List of keywords describing the topic of the article.
+        :param stock_tickers: List of up to 5 stock tickers that are the main subject of the article.
+        """
+
+        # Spec defines that some of the properties below are "required" but in practice not every website provides the
+        # required properties. So, we require only "title" and "publish_date" to be set.
+
+        self.__title = title
+        self.__publish_date = publish_date
+        self.__publication_name = publication_name
+        self.__publication_language = publication_language
+        self.__access = access
+        self.__genres = genres if genres else []
+        self.__keywords = keywords if keywords else []
+        self.__stock_tickers = stock_tickers if stock_tickers else []
+
+    def __eq__(self, other) -> bool:
+        if not isinstance(other, SitemapNewsStory):
+            raise NotImplemented
+
+        if self.title != other.title:
+            return False
+
+        if self.publish_date != other.publish_date:
+            return False
+
+        if self.publication_name != other.publication_name:
+            return False
+
+        if self.publication_language != other.publication_language:
+            return False
+
+        if self.access != other.access:
+            return False
+
+        if self.genres != other.genres:
+            return False
+
+        if self.keywords != other.keywords:
+            return False
+
+        if self.stock_tickers != other.stock_tickers:
+            return False
+
+        return True
+
+    def __hash__(self):
+        return hash((
+            self.title,
+            self.publish_date,
+            self.publication_name,
+            self.publication_language,
+            self.access,
+            self.genres,
+            self.keywords,
+            self.stock_tickers,
+        ))
+
+    def __repr__(self):
+        return (
+            "{self.__class__.__name__}("
+            "title={self.title}, "
+            "publish_date={self.publish_date}, "
+            "publication_name={self.publication_name}, "
+            "publication_language={self.publication_language}, "
+            "access={self.access}, "
+            "genres={self.genres}, "
+            "keywords={self.keywords}, "
+            "stock_tickers={self.stock_tickers}"
+            ")"
+        ).format(self=self)
+
+    @property
+    def title(self) -> str:
+        """
+        Return story title.
+
+        :return: Story title.
+        """
+        return self.__title
+
+    @property
+    def publish_date(self) -> datetime.datetime:
+        """
+        Return story publication date.
+
+        :return: Story publication date.
+        """
+        return self.__publish_date
+
+    @property
+    def publication_name(self) -> Optional[str]:
+        """
+        Return name of the news publication in which the article appears in.
+
+        :return: Name of the news publication in which the article appears in.
+        """
+        return self.__publication_name
+
+    @property
+    def publication_language(self) -> Optional[str]:
+        """Return primary language of the news publication in which the article appears in.
+
+        It should be an ISO 639 Language Code (either 2 or 3 letters).
+
+        :return: Primary language of the news publication in which the article appears in.
+        """
+        return self.__publication_language
+
+    @property
+    def access(self) -> Optional[str]:
+        """
+        Return accessibility of the article.
+
+        :return: Accessibility of the article.
+        """
+        return self.__access
+
+    @property
+    def genres(self) -> List[str]:
+        """
+        Return list of properties characterizing the content of the article.
+
+        Returns genres such as "PressRelease" or "UserGenerated".
+
+        :return: List of properties characterizing the content of the article
+        """
+        return self.__genres
+
+    @property
+    def keywords(self) -> List[str]:
+        """
+        Return list of keywords describing the topic of the article.
+
+        :return: List of keywords describing the topic of the article.
+        """
+        return self.__keywords
+
+    @property
+    def stock_tickers(self) -> List[str]:
+        """
+        Return list of up to 5 stock tickers that are the main subject of the article.
+
+        Each ticker must be prefixed by the name of its stock exchange, and must match its entry in Google Finance.
+        For example, "NASDAQ:AMAT" (but not "NASD:AMAT"), or "BOM:500325" (but not "BOM:RIL").
+
+        :return: List of up to 5 stock tickers that are the main subject of the article.
+        """
+        return self.__stock_tickers
+
+
+@unique
+class SitemapPageChangeFrequency(Enum):
+    """Change frequency of a sitemap URL."""
+
+    ALWAYS = 'always'
+    HOURLY = 'hourly'
+    DAILY = 'daily'
+    WEEKLY = 'weekly'
+    MONTHLY = 'monthly'
+    YEARLY = 'yearly'
+    NEVER = 'never'
+
+    @classmethod
+    def has_value(cls, value: str) -> bool:
+        """Test if enum has specified value."""
+        return any(value == item.value for item in cls)
+
+
+class SitemapPage(object):
+    """Single sitemap-derived page."""
+
+    __slots__ = [
+        '__url',
+        '__priority',
+        '__last_modified',
+        '__change_frequency',
+        '__news_story',
+    ]
+
+    def __init__(self,
+                 url: str,
+                 priority: Decimal = SITEMAP_PAGE_DEFAULT_PRIORITY,
+                 last_modified: Optional[datetime.datetime] = None,
+                 change_frequency: Optional[SitemapPageChangeFrequency] = None,
+                 news_story: Optional[SitemapNewsStory] = None):
+        """
+        Initialize a new sitemap-derived page.
+
+        :param url: Page URL.
+        :param priority: Priority of this URL relative to other URLs on your site.
+        :param last_modified: Date of last modification of the URL.
+        :param change_frequency: Change frequency of a sitemap URL.
+        :param news_story: Google News story attached to the URL.
+        """
+        self.__url = url
+        self.__priority = priority
+        self.__last_modified = last_modified
+        self.__change_frequency = change_frequency
+        self.__news_story = news_story
+
+    def __eq__(self, other) -> bool:
+        if not isinstance(other, SitemapPage):
+            raise NotImplemented
+
+        if self.url != other.url:
+            return False
+
+        if self.priority != other.priority:
+            return False
+
+        if self.last_modified != other.last_modified:
+            return False
+
+        if self.change_frequency != other.change_frequency:
+            return False
+
+        if self.news_story != other.news_story:
+            return False
+
+        return True
+
+    def __hash__(self):
+        return hash((
+            # Hash only the URL to be able to find unique pages later on
+            self.url,
+        ))
+
+    def __repr__(self):
+        return (
+            "{self.__class__.__name__}("
+            "url={self.url}, "
+            "priority={self.priority}, "
+            "last_modified={self.last_modified}, "
+            "change_frequency={self.change_frequency}, "
+            "news_story={self.news_story}"
+            ")"
+        ).format(self=self)
+
+    @property
+    def url(self) -> str:
+        """
+        Return page URL.
+
+        :return: Page URL.
+        """
+        return self.__url
+
+    @property
+    def priority(self) -> Decimal:
+        """
+        Return priority of this URL relative to other URLs on your site.
+
+        :return: Priority of this URL relative to other URLs on your site.
+        """
+        return self.__priority
+
+    @property
+    def last_modified(self) -> Optional[datetime.datetime]:
+        """
+        Return date of last modification of the URL.
+
+        :return: Date of last modification of the URL.
+        """
+        return self.__last_modified
+
+    @property
+    def change_frequency(self) -> Optional[SitemapPageChangeFrequency]:
+        """
+        Return change frequency of a sitemap URL.
+
+        :return: Change frequency of a sitemap URL.
+        """
+        return self.__change_frequency
+
+    @property
+    def news_story(self) -> Optional[SitemapNewsStory]:
+        """
+        Return Google News story attached to the URL.
+
+        :return: Google News story attached to the URL.
+        """
+        return self.__news_story
Index: venv/Lib/site-packages/usp/objects/sitemap.py
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/venv/Lib/site-packages/usp/objects/sitemap.py b/venv/Lib/site-packages/usp/objects/sitemap.py
new file mode 100644
--- /dev/null	(date 1616410446868)
+++ b/venv/Lib/site-packages/usp/objects/sitemap.py	(date 1616410446868)
@@ -0,0 +1,293 @@
+"""Objects that represent one of the found sitemaps."""
+
+import abc
+import os
+import pickle
+import tempfile
+from typing import List, Iterator
+
+from .page import SitemapPage
+
+
+class AbstractSitemap(object, metaclass=abc.ABCMeta):
+    """
+    Abstract sitemap.
+    """
+
+    __slots__ = [
+        '__url',
+    ]
+
+    def __init__(self, url: str):
+        """
+        Initialize a new sitemap.
+
+        :param url: Sitemap URL.
+        """
+        self.__url = url
+
+    def __eq__(self, other) -> bool:
+        if not isinstance(other, AbstractSitemap):
+            raise NotImplemented
+
+        if self.url != other.url:
+            return False
+
+        return True
+
+    def __hash__(self):
+        return hash((
+            self.url,
+        ))
+
+    def __repr__(self):
+        return (
+            "{self.__class__.__name__}("
+            "url={self.url}"
+            ")"
+        ).format(self=self)
+
+    @property
+    def url(self) -> str:
+        """
+        Return sitemap URL.
+
+        :return: Sitemap URL.
+        """
+        return self.__url
+
+    @abc.abstractmethod
+    def all_pages(self) -> Iterator[SitemapPage]:
+        """
+        Return iterator which yields all pages of this sitemap and linked sitemaps (if any).
+
+        :return: Iterator which yields all pages of this sitemap and linked sitemaps (if any).
+        """
+        raise NotImplementedError("Abstract method")
+
+
+class InvalidSitemap(AbstractSitemap):
+    """Invalid sitemap, e.g. the one that can't be parsed."""
+
+    __slots__ = [
+        '__reason',
+    ]
+
+    def __init__(self, url: str, reason: str):
+        """
+        Initialize a new invalid sitemap.
+
+        :param url: Sitemap URL.
+        :param reason: Reason why the sitemap is deemed invalid.
+        """
+        super().__init__(url=url)
+        self.__reason = reason
+
+    def __eq__(self, other) -> bool:
+        if not isinstance(other, InvalidSitemap):
+            raise NotImplemented
+
+        if self.url != other.url:
+            return False
+
+        if self.reason != other.reason:
+            return False
+
+        return True
+
+    def __repr__(self):
+        return (
+            "{self.__class__.__name__}("
+            "url={self.url}, "
+            "reason={self.reason}"
+            ")"
+        ).format(self=self)
+
+    @property
+    def reason(self) -> str:
+        """
+        Return reason why the sitemap is deemed invalid.
+
+        :return: Reason why the sitemap is deemed invalid.
+        """
+        return self.__reason
+
+    def all_pages(self) -> Iterator[SitemapPage]:
+        """
+        Return iterator which yields all pages of this sitemap and linked sitemaps (if any).
+
+        :return: Iterator which yields all pages of this sitemap and linked sitemaps (if any).
+        """
+        yield from []
+
+
+class AbstractPagesSitemap(AbstractSitemap, metaclass=abc.ABCMeta):
+    """Abstract sitemap that contains URLs to pages."""
+
+    __slots__ = [
+        '__pages_temp_file_path',
+    ]
+
+    def __init__(self, url: str, pages: List[SitemapPage]):
+        """
+        Initialize new pages sitemap.
+
+        :param url: Sitemap URL.
+        :param pages: List of pages found in a sitemap.
+        """
+        super().__init__(url=url)
+
+        temp_file, self.__pages_temp_file_path = tempfile.mkstemp()
+        with os.fdopen(temp_file, 'wb') as tmp:
+            pickle.dump(pages, tmp, protocol=pickle.HIGHEST_PROTOCOL)
+
+    def __del__(self):
+        os.unlink(self.__pages_temp_file_path)
+
+    def __eq__(self, other) -> bool:
+        if not isinstance(other, AbstractPagesSitemap):
+            raise NotImplemented
+
+        if self.url != other.url:
+            return False
+
+        if self.pages != other.pages:
+            return False
+
+        return True
+
+    def __repr__(self):
+        return (
+            "{self.__class__.__name__}("
+            "url={self.url}, "
+            "pages={self.pages}"
+            ")"
+        ).format(self=self)
+
+    @property
+    def pages(self) -> List[SitemapPage]:
+        """
+        Return list of pages found in a sitemap.
+
+        :return: List of pages found in a sitemap.
+        """
+        with open(self.__pages_temp_file_path, 'rb') as tmp:
+            pages = pickle.load(tmp)
+        return pages
+
+    def all_pages(self) -> Iterator[SitemapPage]:
+        """
+        Return iterator which yields all pages of this sitemap and linked sitemaps (if any).
+
+        :return: Iterator which yields all pages of this sitemap and linked sitemaps (if any).
+        """
+        for page in self.pages:
+            yield page
+
+
+class PagesXMLSitemap(AbstractPagesSitemap):
+    """
+    XML sitemap that contains URLs to pages.
+    """
+    pass
+
+
+class PagesTextSitemap(AbstractPagesSitemap):
+    """
+    Plain text sitemap that contains URLs to pages.
+    """
+    pass
+
+
+class PagesRSSSitemap(AbstractPagesSitemap):
+    """
+    RSS 2.0 sitemap that contains URLs to pages.
+    """
+    pass
+
+
+class PagesAtomSitemap(AbstractPagesSitemap):
+    """
+    RSS 0.3 / 1.0 sitemap that contains URLs to pages.
+    """
+    pass
+
+
+class AbstractIndexSitemap(AbstractSitemap):
+    """
+    Abstract sitemap with URLs to other sitemaps.
+    """
+
+    __slots__ = [
+        '__sub_sitemaps',
+    ]
+
+    def __init__(self, url: str, sub_sitemaps: List[AbstractSitemap]):
+        """
+        Initialize index sitemap.
+
+        :param url: Sitemap URL.
+        :param sub_sitemaps: Sub-sitemaps that are linked to from this sitemap.
+        """
+        super().__init__(url=url)
+        self.__sub_sitemaps = sub_sitemaps
+
+    def __eq__(self, other) -> bool:
+        if not isinstance(other, AbstractIndexSitemap):
+            raise NotImplemented
+
+        if self.url != other.url:
+            return False
+
+        if self.sub_sitemaps != other.sub_sitemaps:
+            return False
+
+        return True
+
+    def __repr__(self):
+        return (
+            "{self.__class__.__name__}("
+            "url={self.url}, "
+            "sub_sitemaps={self.sub_sitemaps}"
+            ")"
+        ).format(self=self)
+
+    @property
+    def sub_sitemaps(self) -> List[AbstractSitemap]:
+        """
+        Return sub-sitemaps that are linked to from this sitemap.
+
+        :return: Sub-sitemaps that are linked to from this sitemap.
+        """
+        return self.__sub_sitemaps
+
+    def all_pages(self) -> Iterator[SitemapPage]:
+        """
+        Return iterator which yields all pages of this sitemap and linked sitemaps (if any).
+
+        :return: Iterator which yields all pages of this sitemap and linked sitemaps (if any).
+        """
+        for sub_sitemap in self.sub_sitemaps:
+            for page in sub_sitemap.all_pages():
+                yield page
+
+
+class IndexWebsiteSitemap(AbstractIndexSitemap):
+    """
+    Website's root sitemaps, including robots.txt and extra ones.
+    """
+    pass
+
+
+class IndexXMLSitemap(AbstractIndexSitemap):
+    """
+    XML sitemap with URLs to other sitemaps.
+    """
+    pass
+
+
+class IndexRobotsTxtSitemap(AbstractIndexSitemap):
+    """
+    robots.txt sitemap with URLs to other sitemaps.
+    """
+    pass
Index: venv/Lib/site-packages/usp/web_client/abstract_client.py
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/venv/Lib/site-packages/usp/web_client/abstract_client.py b/venv/Lib/site-packages/usp/web_client/abstract_client.py
new file mode 100644
--- /dev/null	(date 1616410446884)
+++ b/venv/Lib/site-packages/usp/web_client/abstract_client.py	(date 1616410446884)
@@ -0,0 +1,183 @@
+"""Abstract web client class."""
+
+import abc
+from http import HTTPStatus
+from typing import Optional
+
+RETRYABLE_HTTP_STATUS_CODES = {
+
+    # Some servers return "400 Bad Request" initially but upon retry start working again, no idea why
+    HTTPStatus.BAD_REQUEST.value,
+
+    # If we timed out requesting stuff, we can just try again
+    HTTPStatus.REQUEST_TIMEOUT.value,
+
+    # If we got rate limited, it makes sense to wait a bit
+    HTTPStatus.TOO_MANY_REQUESTS.value,
+
+    # Server might be just fine on a subsequent attempt
+    HTTPStatus.INTERNAL_SERVER_ERROR.value,
+
+    # Upstream might reappear on a retry
+    HTTPStatus.BAD_GATEWAY.value,
+
+    # Service might become available again on a retry
+    HTTPStatus.SERVICE_UNAVAILABLE.value,
+
+    # Upstream might reappear on a retry
+    HTTPStatus.GATEWAY_TIMEOUT.value,
+
+    # (unofficial) 509 Bandwidth Limit Exceeded (Apache Web Server/cPanel)
+    509,
+
+    # (unofficial) 598 Network read timeout error
+    598,
+
+    # (unofficial, nginx) 499 Client Closed Request
+    499,
+
+    # (unofficial, Cloudflare) 520 Unknown Error
+    520,
+
+    # (unofficial, Cloudflare) 521 Web Server Is Down
+    521,
+
+    # (unofficial, Cloudflare) 522 Connection Timed Out
+    522,
+
+    # (unofficial, Cloudflare) 523 Origin Is Unreachable
+    523,
+
+    # (unofficial, Cloudflare) 524 A Timeout Occurred
+    524,
+
+    # (unofficial, Cloudflare) 525 SSL Handshake Failed
+    525,
+
+    # (unofficial, Cloudflare) 526 Invalid SSL Certificate
+    526,
+
+    # (unofficial, Cloudflare) 527 Railgun Error
+    527,
+
+    # (unofficial, Cloudflare) 530 Origin DNS Error
+    530,
+
+}
+"""HTTP status codes on which a request should be retried."""
+
+
+class AbstractWebClientResponse(object, metaclass=abc.ABCMeta):
+    """
+    Abstract response.
+    """
+    pass
+
+
+class AbstractWebClientSuccessResponse(AbstractWebClientResponse, metaclass=abc.ABCMeta):
+    """
+    Successful response.
+    """
+
+    @abc.abstractmethod
+    def status_code(self) -> int:
+        """
+        Return HTTP status code of the response.
+
+        :return: HTTP status code of the response, e.g. 200.
+        """
+        raise NotImplementedError("Abstract method.")
+
+    @abc.abstractmethod
+    def status_message(self) -> str:
+        """
+        Return HTTP status message of the response.
+
+        :return: HTTP status message of the response, e.g. "OK".
+        """
+        raise NotImplementedError("Abstract method.")
+
+    @abc.abstractmethod
+    def header(self, case_insensitive_name: str) -> Optional[str]:
+        """
+        Return HTTP header value for a given case-insensitive name, or None if such header wasn't set.
+
+        :param case_insensitive_name: HTTP header's name, e.g. "Content-Type".
+        :return: HTTP header's value, or None if it was unset.
+        """
+        raise NotImplementedError("Abstract method.")
+
+    @abc.abstractmethod
+    def raw_data(self) -> bytes:
+        """
+        Return encoded raw data of the response.
+
+        :return: Encoded raw data of the response.
+        """
+        raise NotImplementedError("Abstract method.")
+
+
+class WebClientErrorResponse(AbstractWebClientResponse, metaclass=abc.ABCMeta):
+    """
+    Error response.
+    """
+
+    __slots__ = [
+        '_message',
+        '_retryable',
+    ]
+
+    def __init__(self, message: str, retryable: bool):
+        """
+        Constructor.
+
+        :param message: Message describing what went wrong.
+        :param retryable: True if the request should be retried.
+        """
+        super().__init__()
+        self._message = message
+        self._retryable = retryable
+
+    def message(self) -> str:
+        """
+        Return message describing what went wrong.
+
+        :return: Message describing what went wrong.
+        """
+        return self._message
+
+    def retryable(self) -> bool:
+        """
+        Return True if request should be retried.
+
+        :return: True if request should be retried.
+        """
+        return self._retryable
+
+
+class AbstractWebClient(object, metaclass=abc.ABCMeta):
+    """
+    Abstract web client to be used by the sitemap fetcher.
+    """
+
+    @abc.abstractmethod
+    def set_max_response_data_length(self, max_response_data_length: int) -> None:
+        """
+        Set the maximum number of bytes that the web client will fetch.
+
+        :param max_response_data_length: Maximum number of bytes that the web client will fetch.
+        """
+        raise NotImplementedError("Abstract method.")
+
+    @abc.abstractmethod
+    def get(self, url: str) -> AbstractWebClientResponse:
+        """
+        Fetch an URL and return a response.
+
+        Method shouldn't throw exceptions on connection errors (including timeouts); instead, such errors should be
+        reported via Response object.
+
+        :param url: URL to fetch.
+        :return: Response object.
+        """
+        raise NotImplementedError("Abstract method.")
Index: venv/Lib/site-packages/usp/web_client/requests_client.py
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/venv/Lib/site-packages/usp/web_client/requests_client.py b/venv/Lib/site-packages/usp/web_client/requests_client.py
new file mode 100644
--- /dev/null	(date 1616410446899)
+++ b/venv/Lib/site-packages/usp/web_client/requests_client.py	(date 1616410446899)
@@ -0,0 +1,119 @@
+"""requests-based implementation of web client class."""
+
+from http import HTTPStatus
+from typing import Optional
+
+import requests
+
+from .abstract_client import (
+    AbstractWebClient,
+    AbstractWebClientResponse,
+    AbstractWebClientSuccessResponse,
+    WebClientErrorResponse,
+    RETRYABLE_HTTP_STATUS_CODES,
+)
+from usp.__about__ import __version__
+
+
+class RequestsWebClientSuccessResponse(AbstractWebClientSuccessResponse):
+    """
+    requests-based successful response.
+    """
+
+    __slots__ = [
+        '__requests_response',
+        '__max_response_data_length',
+    ]
+
+    def __init__(self, requests_response: requests.Response, max_response_data_length: Optional[int] = None):
+        self.__requests_response = requests_response
+        self.__max_response_data_length = max_response_data_length
+
+    def status_code(self) -> int:
+        return int(self.__requests_response.status_code)
+
+    def status_message(self) -> str:
+        message = self.__requests_response.reason
+        if not message:
+            message = HTTPStatus(self.status_code(), None).phrase
+        return message
+
+    def header(self, case_insensitive_name: str) -> Optional[str]:
+        return self.__requests_response.headers.get(case_insensitive_name.lower(), None)
+
+    def raw_data(self) -> bytes:
+        if self.__max_response_data_length:
+            data = self.__requests_response.content[:self.__max_response_data_length]
+        else:
+            data = self.__requests_response.content
+
+        return data
+
+
+class RequestsWebClientErrorResponse(WebClientErrorResponse):
+    """
+    requests-based error response.
+    """
+    pass
+
+
+class RequestsWebClient(AbstractWebClient):
+    """requests-based web client to be used by the sitemap fetcher."""
+
+    __USER_AGENT = 'ultimate_sitemap_parser/{}'.format(__version__)
+
+    __HTTP_REQUEST_TIMEOUT = 60
+    """
+    HTTP request timeout.
+
+    Some webservers might be generating huge sitemaps on the fly, so this is why it's rather big.
+    """
+
+    __slots__ = [
+        '__max_response_data_length',
+        '__timeout',
+    ]
+
+    def __init__(self):
+        self.__max_response_data_length = None
+        self.__timeout = self.__HTTP_REQUEST_TIMEOUT
+
+    def set_timeout(self, timeout: int) -> None:
+        """Set HTTP request timeout."""
+        # Used mostly for testing
+        self.__timeout = timeout
+
+    def set_max_response_data_length(self, max_response_data_length: int) -> None:
+        self.__max_response_data_length = max_response_data_length
+
+    def get(self, url: str) -> AbstractWebClientResponse:
+        try:
+            response = requests.get(
+                url,
+                timeout=self.__timeout,
+                stream=True,
+                headers={'User-Agent': self.__USER_AGENT},
+            )
+        except requests.exceptions.Timeout as ex:
+            # Retryable timeouts
+            return RequestsWebClientErrorResponse(message=str(ex), retryable=True)
+
+        except requests.exceptions.RequestException as ex:
+            # Other errors, e.g. redirect loops
+            return RequestsWebClientErrorResponse(message=str(ex), retryable=False)
+
+        else:
+
+            if 200 <= response.status_code < 300:
+                return RequestsWebClientSuccessResponse(
+                    requests_response=response,
+                    max_response_data_length=self.__max_response_data_length,
+                )
+            else:
+
+                message = '{} {}'.format(response.status_code, response.reason)
+
+                if response.status_code in RETRYABLE_HTTP_STATUS_CODES:
+                    return RequestsWebClientErrorResponse(message=message, retryable=True)
+                else:
+                    return RequestsWebClientErrorResponse(message=message, retryable=False)
Index: latest/Lib/site-packages/psycopg2/compat.py
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/latest/Lib/site-packages/psycopg2/compat.py b/latest/Lib/site-packages/psycopg2/compat.py
new file mode 100644
--- /dev/null	(date 1616410446978)
+++ b/latest/Lib/site-packages/psycopg2/compat.py	(date 1616410446978)
@@ -0,0 +1,19 @@
+import sys
+
+__all__ = ['string_types', 'text_type', 'lru_cache']
+
+if sys.version_info[0] == 2:
+    # Python 2
+    PY2 = True
+    PY3 = False
+    string_types = basestring,
+    text_type = unicode
+    from ._lru_cache import lru_cache
+
+else:
+    # Python 3
+    PY2 = False
+    PY3 = True
+    string_types = str,
+    text_type = str
+    from functools import lru_cache
Index: latest/Lib/site-packages/psycopg2/errorcodes.py
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/latest/Lib/site-packages/psycopg2/errorcodes.py b/latest/Lib/site-packages/psycopg2/errorcodes.py
new file mode 100644
--- /dev/null	(date 1616410447009)
+++ b/latest/Lib/site-packages/psycopg2/errorcodes.py	(date 1616410447009)
@@ -0,0 +1,447 @@
+"""Error codes for PostgresSQL
+
+This module contains symbolic names for all PostgreSQL error codes.
+"""
+# psycopg2/errorcodes.py - PostgreSQL error codes
+#
+# Copyright (C) 2006-2019 Johan Dahlin  <jdahlin@async.com.br>
+# Copyright (C) 2020 The Psycopg Team
+#
+# psycopg2 is free software: you can redistribute it and/or modify it
+# under the terms of the GNU Lesser General Public License as published
+# by the Free Software Foundation, either version 3 of the License, or
+# (at your option) any later version.
+#
+# In addition, as a special exception, the copyright holders give
+# permission to link this program with the OpenSSL library (or with
+# modified versions of OpenSSL that use the same license as OpenSSL),
+# and distribute linked combinations including the two.
+#
+# You must obey the GNU Lesser General Public License in all respects for
+# all of the code used other than OpenSSL.
+#
+# psycopg2 is distributed in the hope that it will be useful, but WITHOUT
+# ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or
+# FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public
+# License for more details.
+#
+# Based on:
+#
+#   https://www.postgresql.org/docs/current/static/errcodes-appendix.html
+#
+
+
+def lookup(code, _cache={}):
+    """Lookup an error code or class code and return its symbolic name.
+
+    Raise `KeyError` if the code is not found.
+    """
+    if _cache:
+        return _cache[code]
+
+    # Generate the lookup map at first usage.
+    tmp = {}
+    for k, v in globals().items():
+        if isinstance(v, str) and len(v) in (2, 5):
+            # Strip trailing underscore used to disambiguate duplicate values
+            tmp[v] = k.rstrip("_")
+
+    assert tmp
+
+    # Atomic update, to avoid race condition on import (bug #382)
+    _cache.update(tmp)
+
+    return _cache[code]
+
+
+# autogenerated data: do not edit below this point.
+
+# Error classes
+CLASS_SUCCESSFUL_COMPLETION = '00'
+CLASS_WARNING = '01'
+CLASS_NO_DATA = '02'
+CLASS_SQL_STATEMENT_NOT_YET_COMPLETE = '03'
+CLASS_CONNECTION_EXCEPTION = '08'
+CLASS_TRIGGERED_ACTION_EXCEPTION = '09'
+CLASS_FEATURE_NOT_SUPPORTED = '0A'
+CLASS_INVALID_TRANSACTION_INITIATION = '0B'
+CLASS_LOCATOR_EXCEPTION = '0F'
+CLASS_INVALID_GRANTOR = '0L'
+CLASS_INVALID_ROLE_SPECIFICATION = '0P'
+CLASS_DIAGNOSTICS_EXCEPTION = '0Z'
+CLASS_CASE_NOT_FOUND = '20'
+CLASS_CARDINALITY_VIOLATION = '21'
+CLASS_DATA_EXCEPTION = '22'
+CLASS_INTEGRITY_CONSTRAINT_VIOLATION = '23'
+CLASS_INVALID_CURSOR_STATE = '24'
+CLASS_INVALID_TRANSACTION_STATE = '25'
+CLASS_INVALID_SQL_STATEMENT_NAME = '26'
+CLASS_TRIGGERED_DATA_CHANGE_VIOLATION = '27'
+CLASS_INVALID_AUTHORIZATION_SPECIFICATION = '28'
+CLASS_DEPENDENT_PRIVILEGE_DESCRIPTORS_STILL_EXIST = '2B'
+CLASS_INVALID_TRANSACTION_TERMINATION = '2D'
+CLASS_SQL_ROUTINE_EXCEPTION = '2F'
+CLASS_INVALID_CURSOR_NAME = '34'
+CLASS_EXTERNAL_ROUTINE_EXCEPTION = '38'
+CLASS_EXTERNAL_ROUTINE_INVOCATION_EXCEPTION = '39'
+CLASS_SAVEPOINT_EXCEPTION = '3B'
+CLASS_INVALID_CATALOG_NAME = '3D'
+CLASS_INVALID_SCHEMA_NAME = '3F'
+CLASS_TRANSACTION_ROLLBACK = '40'
+CLASS_SYNTAX_ERROR_OR_ACCESS_RULE_VIOLATION = '42'
+CLASS_WITH_CHECK_OPTION_VIOLATION = '44'
+CLASS_INSUFFICIENT_RESOURCES = '53'
+CLASS_PROGRAM_LIMIT_EXCEEDED = '54'
+CLASS_OBJECT_NOT_IN_PREREQUISITE_STATE = '55'
+CLASS_OPERATOR_INTERVENTION = '57'
+CLASS_SYSTEM_ERROR = '58'
+CLASS_SNAPSHOT_FAILURE = '72'
+CLASS_CONFIGURATION_FILE_ERROR = 'F0'
+CLASS_FOREIGN_DATA_WRAPPER_ERROR = 'HV'
+CLASS_PL_PGSQL_ERROR = 'P0'
+CLASS_INTERNAL_ERROR = 'XX'
+
+# Class 00 - Successful Completion
+SUCCESSFUL_COMPLETION = '00000'
+
+# Class 01 - Warning
+WARNING = '01000'
+NULL_VALUE_ELIMINATED_IN_SET_FUNCTION = '01003'
+STRING_DATA_RIGHT_TRUNCATION_ = '01004'
+PRIVILEGE_NOT_REVOKED = '01006'
+PRIVILEGE_NOT_GRANTED = '01007'
+IMPLICIT_ZERO_BIT_PADDING = '01008'
+DYNAMIC_RESULT_SETS_RETURNED = '0100C'
+DEPRECATED_FEATURE = '01P01'
+
+# Class 02 - No Data (this is also a warning class per the SQL standard)
+NO_DATA = '02000'
+NO_ADDITIONAL_DYNAMIC_RESULT_SETS_RETURNED = '02001'
+
+# Class 03 - SQL Statement Not Yet Complete
+SQL_STATEMENT_NOT_YET_COMPLETE = '03000'
+
+# Class 08 - Connection Exception
+CONNECTION_EXCEPTION = '08000'
+SQLCLIENT_UNABLE_TO_ESTABLISH_SQLCONNECTION = '08001'
+CONNECTION_DOES_NOT_EXIST = '08003'
+SQLSERVER_REJECTED_ESTABLISHMENT_OF_SQLCONNECTION = '08004'
+CONNECTION_FAILURE = '08006'
+TRANSACTION_RESOLUTION_UNKNOWN = '08007'
+PROTOCOL_VIOLATION = '08P01'
+
+# Class 09 - Triggered Action Exception
+TRIGGERED_ACTION_EXCEPTION = '09000'
+
+# Class 0A - Feature Not Supported
+FEATURE_NOT_SUPPORTED = '0A000'
+
+# Class 0B - Invalid Transaction Initiation
+INVALID_TRANSACTION_INITIATION = '0B000'
+
+# Class 0F - Locator Exception
+LOCATOR_EXCEPTION = '0F000'
+INVALID_LOCATOR_SPECIFICATION = '0F001'
+
+# Class 0L - Invalid Grantor
+INVALID_GRANTOR = '0L000'
+INVALID_GRANT_OPERATION = '0LP01'
+
+# Class 0P - Invalid Role Specification
+INVALID_ROLE_SPECIFICATION = '0P000'
+
+# Class 0Z - Diagnostics Exception
+DIAGNOSTICS_EXCEPTION = '0Z000'
+STACKED_DIAGNOSTICS_ACCESSED_WITHOUT_ACTIVE_HANDLER = '0Z002'
+
+# Class 20 - Case Not Found
+CASE_NOT_FOUND = '20000'
+
+# Class 21 - Cardinality Violation
+CARDINALITY_VIOLATION = '21000'
+
+# Class 22 - Data Exception
+DATA_EXCEPTION = '22000'
+STRING_DATA_RIGHT_TRUNCATION = '22001'
+NULL_VALUE_NO_INDICATOR_PARAMETER = '22002'
+NUMERIC_VALUE_OUT_OF_RANGE = '22003'
+NULL_VALUE_NOT_ALLOWED_ = '22004'
+ERROR_IN_ASSIGNMENT = '22005'
+INVALID_DATETIME_FORMAT = '22007'
+DATETIME_FIELD_OVERFLOW = '22008'
+INVALID_TIME_ZONE_DISPLACEMENT_VALUE = '22009'
+ESCAPE_CHARACTER_CONFLICT = '2200B'
+INVALID_USE_OF_ESCAPE_CHARACTER = '2200C'
+INVALID_ESCAPE_OCTET = '2200D'
+ZERO_LENGTH_CHARACTER_STRING = '2200F'
+MOST_SPECIFIC_TYPE_MISMATCH = '2200G'
+SEQUENCE_GENERATOR_LIMIT_EXCEEDED = '2200H'
+NOT_AN_XML_DOCUMENT = '2200L'
+INVALID_XML_DOCUMENT = '2200M'
+INVALID_XML_CONTENT = '2200N'
+INVALID_XML_COMMENT = '2200S'
+INVALID_XML_PROCESSING_INSTRUCTION = '2200T'
+INVALID_INDICATOR_PARAMETER_VALUE = '22010'
+SUBSTRING_ERROR = '22011'
+DIVISION_BY_ZERO = '22012'
+INVALID_PRECEDING_OR_FOLLOWING_SIZE = '22013'
+INVALID_ARGUMENT_FOR_NTILE_FUNCTION = '22014'
+INTERVAL_FIELD_OVERFLOW = '22015'
+INVALID_ARGUMENT_FOR_NTH_VALUE_FUNCTION = '22016'
+INVALID_CHARACTER_VALUE_FOR_CAST = '22018'
+INVALID_ESCAPE_CHARACTER = '22019'
+INVALID_REGULAR_EXPRESSION = '2201B'
+INVALID_ARGUMENT_FOR_LOGARITHM = '2201E'
+INVALID_ARGUMENT_FOR_POWER_FUNCTION = '2201F'
+INVALID_ARGUMENT_FOR_WIDTH_BUCKET_FUNCTION = '2201G'
+INVALID_ROW_COUNT_IN_LIMIT_CLAUSE = '2201W'
+INVALID_ROW_COUNT_IN_RESULT_OFFSET_CLAUSE = '2201X'
+INVALID_LIMIT_VALUE = '22020'
+CHARACTER_NOT_IN_REPERTOIRE = '22021'
+INDICATOR_OVERFLOW = '22022'
+INVALID_PARAMETER_VALUE = '22023'
+UNTERMINATED_C_STRING = '22024'
+INVALID_ESCAPE_SEQUENCE = '22025'
+STRING_DATA_LENGTH_MISMATCH = '22026'
+TRIM_ERROR = '22027'
+ARRAY_SUBSCRIPT_ERROR = '2202E'
+INVALID_TABLESAMPLE_REPEAT = '2202G'
+INVALID_TABLESAMPLE_ARGUMENT = '2202H'
+DUPLICATE_JSON_OBJECT_KEY_VALUE = '22030'
+INVALID_ARGUMENT_FOR_SQL_JSON_DATETIME_FUNCTION = '22031'
+INVALID_JSON_TEXT = '22032'
+INVALID_SQL_JSON_SUBSCRIPT = '22033'
+MORE_THAN_ONE_SQL_JSON_ITEM = '22034'
+NO_SQL_JSON_ITEM = '22035'
+NON_NUMERIC_SQL_JSON_ITEM = '22036'
+NON_UNIQUE_KEYS_IN_A_JSON_OBJECT = '22037'
+SINGLETON_SQL_JSON_ITEM_REQUIRED = '22038'
+SQL_JSON_ARRAY_NOT_FOUND = '22039'
+SQL_JSON_MEMBER_NOT_FOUND = '2203A'
+SQL_JSON_NUMBER_NOT_FOUND = '2203B'
+SQL_JSON_OBJECT_NOT_FOUND = '2203C'
+TOO_MANY_JSON_ARRAY_ELEMENTS = '2203D'
+TOO_MANY_JSON_OBJECT_MEMBERS = '2203E'
+SQL_JSON_SCALAR_REQUIRED = '2203F'
+FLOATING_POINT_EXCEPTION = '22P01'
+INVALID_TEXT_REPRESENTATION = '22P02'
+INVALID_BINARY_REPRESENTATION = '22P03'
+BAD_COPY_FILE_FORMAT = '22P04'
+UNTRANSLATABLE_CHARACTER = '22P05'
+NONSTANDARD_USE_OF_ESCAPE_CHARACTER = '22P06'
+
+# Class 23 - Integrity Constraint Violation
+INTEGRITY_CONSTRAINT_VIOLATION = '23000'
+RESTRICT_VIOLATION = '23001'
+NOT_NULL_VIOLATION = '23502'
+FOREIGN_KEY_VIOLATION = '23503'
+UNIQUE_VIOLATION = '23505'
+CHECK_VIOLATION = '23514'
+EXCLUSION_VIOLATION = '23P01'
+
+# Class 24 - Invalid Cursor State
+INVALID_CURSOR_STATE = '24000'
+
+# Class 25 - Invalid Transaction State
+INVALID_TRANSACTION_STATE = '25000'
+ACTIVE_SQL_TRANSACTION = '25001'
+BRANCH_TRANSACTION_ALREADY_ACTIVE = '25002'
+INAPPROPRIATE_ACCESS_MODE_FOR_BRANCH_TRANSACTION = '25003'
+INAPPROPRIATE_ISOLATION_LEVEL_FOR_BRANCH_TRANSACTION = '25004'
+NO_ACTIVE_SQL_TRANSACTION_FOR_BRANCH_TRANSACTION = '25005'
+READ_ONLY_SQL_TRANSACTION = '25006'
+SCHEMA_AND_DATA_STATEMENT_MIXING_NOT_SUPPORTED = '25007'
+HELD_CURSOR_REQUIRES_SAME_ISOLATION_LEVEL = '25008'
+NO_ACTIVE_SQL_TRANSACTION = '25P01'
+IN_FAILED_SQL_TRANSACTION = '25P02'
+IDLE_IN_TRANSACTION_SESSION_TIMEOUT = '25P03'
+
+# Class 26 - Invalid SQL Statement Name
+INVALID_SQL_STATEMENT_NAME = '26000'
+
+# Class 27 - Triggered Data Change Violation
+TRIGGERED_DATA_CHANGE_VIOLATION = '27000'
+
+# Class 28 - Invalid Authorization Specification
+INVALID_AUTHORIZATION_SPECIFICATION = '28000'
+INVALID_PASSWORD = '28P01'
+
+# Class 2B - Dependent Privilege Descriptors Still Exist
+DEPENDENT_PRIVILEGE_DESCRIPTORS_STILL_EXIST = '2B000'
+DEPENDENT_OBJECTS_STILL_EXIST = '2BP01'
+
+# Class 2D - Invalid Transaction Termination
+INVALID_TRANSACTION_TERMINATION = '2D000'
+
+# Class 2F - SQL Routine Exception
+SQL_ROUTINE_EXCEPTION = '2F000'
+MODIFYING_SQL_DATA_NOT_PERMITTED_ = '2F002'
+PROHIBITED_SQL_STATEMENT_ATTEMPTED_ = '2F003'
+READING_SQL_DATA_NOT_PERMITTED_ = '2F004'
+FUNCTION_EXECUTED_NO_RETURN_STATEMENT = '2F005'
+
+# Class 34 - Invalid Cursor Name
+INVALID_CURSOR_NAME = '34000'
+
+# Class 38 - External Routine Exception
+EXTERNAL_ROUTINE_EXCEPTION = '38000'
+CONTAINING_SQL_NOT_PERMITTED = '38001'
+MODIFYING_SQL_DATA_NOT_PERMITTED = '38002'
+PROHIBITED_SQL_STATEMENT_ATTEMPTED = '38003'
+READING_SQL_DATA_NOT_PERMITTED = '38004'
+
+# Class 39 - External Routine Invocation Exception
+EXTERNAL_ROUTINE_INVOCATION_EXCEPTION = '39000'
+INVALID_SQLSTATE_RETURNED = '39001'
+NULL_VALUE_NOT_ALLOWED = '39004'
+TRIGGER_PROTOCOL_VIOLATED = '39P01'
+SRF_PROTOCOL_VIOLATED = '39P02'
+EVENT_TRIGGER_PROTOCOL_VIOLATED = '39P03'
+
+# Class 3B - Savepoint Exception
+SAVEPOINT_EXCEPTION = '3B000'
+INVALID_SAVEPOINT_SPECIFICATION = '3B001'
+
+# Class 3D - Invalid Catalog Name
+INVALID_CATALOG_NAME = '3D000'
+
+# Class 3F - Invalid Schema Name
+INVALID_SCHEMA_NAME = '3F000'
+
+# Class 40 - Transaction Rollback
+TRANSACTION_ROLLBACK = '40000'
+SERIALIZATION_FAILURE = '40001'
+TRANSACTION_INTEGRITY_CONSTRAINT_VIOLATION = '40002'
+STATEMENT_COMPLETION_UNKNOWN = '40003'
+DEADLOCK_DETECTED = '40P01'
+
+# Class 42 - Syntax Error or Access Rule Violation
+SYNTAX_ERROR_OR_ACCESS_RULE_VIOLATION = '42000'
+INSUFFICIENT_PRIVILEGE = '42501'
+SYNTAX_ERROR = '42601'
+INVALID_NAME = '42602'
+INVALID_COLUMN_DEFINITION = '42611'
+NAME_TOO_LONG = '42622'
+DUPLICATE_COLUMN = '42701'
+AMBIGUOUS_COLUMN = '42702'
+UNDEFINED_COLUMN = '42703'
+UNDEFINED_OBJECT = '42704'
+DUPLICATE_OBJECT = '42710'
+DUPLICATE_ALIAS = '42712'
+DUPLICATE_FUNCTION = '42723'
+AMBIGUOUS_FUNCTION = '42725'
+GROUPING_ERROR = '42803'
+DATATYPE_MISMATCH = '42804'
+WRONG_OBJECT_TYPE = '42809'
+INVALID_FOREIGN_KEY = '42830'
+CANNOT_COERCE = '42846'
+UNDEFINED_FUNCTION = '42883'
+GENERATED_ALWAYS = '428C9'
+RESERVED_NAME = '42939'
+UNDEFINED_TABLE = '42P01'
+UNDEFINED_PARAMETER = '42P02'
+DUPLICATE_CURSOR = '42P03'
+DUPLICATE_DATABASE = '42P04'
+DUPLICATE_PREPARED_STATEMENT = '42P05'
+DUPLICATE_SCHEMA = '42P06'
+DUPLICATE_TABLE = '42P07'
+AMBIGUOUS_PARAMETER = '42P08'
+AMBIGUOUS_ALIAS = '42P09'
+INVALID_COLUMN_REFERENCE = '42P10'
+INVALID_CURSOR_DEFINITION = '42P11'
+INVALID_DATABASE_DEFINITION = '42P12'
+INVALID_FUNCTION_DEFINITION = '42P13'
+INVALID_PREPARED_STATEMENT_DEFINITION = '42P14'
+INVALID_SCHEMA_DEFINITION = '42P15'
+INVALID_TABLE_DEFINITION = '42P16'
+INVALID_OBJECT_DEFINITION = '42P17'
+INDETERMINATE_DATATYPE = '42P18'
+INVALID_RECURSION = '42P19'
+WINDOWING_ERROR = '42P20'
+COLLATION_MISMATCH = '42P21'
+INDETERMINATE_COLLATION = '42P22'
+
+# Class 44 - WITH CHECK OPTION Violation
+WITH_CHECK_OPTION_VIOLATION = '44000'
+
+# Class 53 - Insufficient Resources
+INSUFFICIENT_RESOURCES = '53000'
+DISK_FULL = '53100'
+OUT_OF_MEMORY = '53200'
+TOO_MANY_CONNECTIONS = '53300'
+CONFIGURATION_LIMIT_EXCEEDED = '53400'
+
+# Class 54 - Program Limit Exceeded
+PROGRAM_LIMIT_EXCEEDED = '54000'
+STATEMENT_TOO_COMPLEX = '54001'
+TOO_MANY_COLUMNS = '54011'
+TOO_MANY_ARGUMENTS = '54023'
+
+# Class 55 - Object Not In Prerequisite State
+OBJECT_NOT_IN_PREREQUISITE_STATE = '55000'
+OBJECT_IN_USE = '55006'
+CANT_CHANGE_RUNTIME_PARAM = '55P02'
+LOCK_NOT_AVAILABLE = '55P03'
+UNSAFE_NEW_ENUM_VALUE_USAGE = '55P04'
+
+# Class 57 - Operator Intervention
+OPERATOR_INTERVENTION = '57000'
+QUERY_CANCELED = '57014'
+ADMIN_SHUTDOWN = '57P01'
+CRASH_SHUTDOWN = '57P02'
+CANNOT_CONNECT_NOW = '57P03'
+DATABASE_DROPPED = '57P04'
+
+# Class 58 - System Error (errors external to PostgreSQL itself)
+SYSTEM_ERROR = '58000'
+IO_ERROR = '58030'
+UNDEFINED_FILE = '58P01'
+DUPLICATE_FILE = '58P02'
+
+# Class 72 - Snapshot Failure
+SNAPSHOT_TOO_OLD = '72000'
+
+# Class F0 - Configuration File Error
+CONFIG_FILE_ERROR = 'F0000'
+LOCK_FILE_EXISTS = 'F0001'
+
+# Class HV - Foreign Data Wrapper Error (SQL/MED)
+FDW_ERROR = 'HV000'
+FDW_OUT_OF_MEMORY = 'HV001'
+FDW_DYNAMIC_PARAMETER_VALUE_NEEDED = 'HV002'
+FDW_INVALID_DATA_TYPE = 'HV004'
+FDW_COLUMN_NAME_NOT_FOUND = 'HV005'
+FDW_INVALID_DATA_TYPE_DESCRIPTORS = 'HV006'
+FDW_INVALID_COLUMN_NAME = 'HV007'
+FDW_INVALID_COLUMN_NUMBER = 'HV008'
+FDW_INVALID_USE_OF_NULL_POINTER = 'HV009'
+FDW_INVALID_STRING_FORMAT = 'HV00A'
+FDW_INVALID_HANDLE = 'HV00B'
+FDW_INVALID_OPTION_INDEX = 'HV00C'
+FDW_INVALID_OPTION_NAME = 'HV00D'
+FDW_OPTION_NAME_NOT_FOUND = 'HV00J'
+FDW_REPLY_HANDLE = 'HV00K'
+FDW_UNABLE_TO_CREATE_EXECUTION = 'HV00L'
+FDW_UNABLE_TO_CREATE_REPLY = 'HV00M'
+FDW_UNABLE_TO_ESTABLISH_CONNECTION = 'HV00N'
+FDW_NO_SCHEMAS = 'HV00P'
+FDW_SCHEMA_NOT_FOUND = 'HV00Q'
+FDW_TABLE_NOT_FOUND = 'HV00R'
+FDW_FUNCTION_SEQUENCE_ERROR = 'HV010'
+FDW_TOO_MANY_HANDLES = 'HV014'
+FDW_INCONSISTENT_DESCRIPTOR_INFORMATION = 'HV021'
+FDW_INVALID_ATTRIBUTE_VALUE = 'HV024'
+FDW_INVALID_STRING_LENGTH_OR_BUFFER_LENGTH = 'HV090'
+FDW_INVALID_DESCRIPTOR_FIELD_IDENTIFIER = 'HV091'
+
+# Class P0 - PL/pgSQL Error
+PLPGSQL_ERROR = 'P0000'
+RAISE_EXCEPTION = 'P0001'
+NO_DATA_FOUND = 'P0002'
+TOO_MANY_ROWS = 'P0003'
+ASSERT_FAILURE = 'P0004'
+
+# Class XX - Internal Error
+INTERNAL_ERROR = 'XX000'
+DATA_CORRUPTED = 'XX001'
+INDEX_CORRUPTED = 'XX002'
Index: venv/Lib/site-packages/python_dateutil-2.8.1.dist-info/INSTALLER
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/venv/Lib/site-packages/python_dateutil-2.8.1.dist-info/INSTALLER b/venv/Lib/site-packages/python_dateutil-2.8.1.dist-info/INSTALLER
new file mode 100644
--- /dev/null	(date 1616410447103)
+++ b/venv/Lib/site-packages/python_dateutil-2.8.1.dist-info/INSTALLER	(date 1616410447103)
@@ -0,0 +1,1 @@
+pip
Index: latest/Lib/site-packages/psycopg2/errors.py
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/latest/Lib/site-packages/psycopg2/errors.py b/latest/Lib/site-packages/psycopg2/errors.py
new file mode 100644
--- /dev/null	(date 1616410447181)
+++ b/latest/Lib/site-packages/psycopg2/errors.py	(date 1616410447181)
@@ -0,0 +1,38 @@
+"""Error classes for PostgreSQL error codes
+"""
+
+# psycopg/errors.py - SQLSTATE and DB-API exceptions
+#
+# Copyright (C) 2018-2019 Daniele Varrazzo  <daniele.varrazzo@gmail.com>
+# Copyright (C) 2020 The Psycopg Team
+#
+# psycopg2 is free software: you can redistribute it and/or modify it
+# under the terms of the GNU Lesser General Public License as published
+# by the Free Software Foundation, either version 3 of the License, or
+# (at your option) any later version.
+#
+# In addition, as a special exception, the copyright holders give
+# permission to link this program with the OpenSSL library (or with
+# modified versions of OpenSSL that use the same license as OpenSSL),
+# and distribute linked combinations including the two.
+#
+# You must obey the GNU Lesser General Public License in all respects for
+# all of the code used other than OpenSSL.
+#
+# psycopg2 is distributed in the hope that it will be useful, but WITHOUT
+# ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or
+# FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public
+# License for more details.
+
+#
+# NOTE: the exceptions are injected into this module by the C extention.
+#
+
+
+def lookup(code):
+    """Lookup an error code and return its exception class.
+
+    Raise `!KeyError` if the code is not found.
+    """
+    from psycopg2._psycopg import sqlstate_errors   # avoid circular import
+    return sqlstate_errors[code]
Index: latest/Lib/site-packages/psycopg2/extensions.py
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/latest/Lib/site-packages/psycopg2/extensions.py b/latest/Lib/site-packages/psycopg2/extensions.py
new file mode 100644
--- /dev/null	(date 1616410447228)
+++ b/latest/Lib/site-packages/psycopg2/extensions.py	(date 1616410447228)
@@ -0,0 +1,221 @@
+"""psycopg extensions to the DBAPI-2.0
+
+This module holds all the extensions to the DBAPI-2.0 provided by psycopg.
+
+- `connection` -- the new-type inheritable connection class
+- `cursor` -- the new-type inheritable cursor class
+- `lobject` -- the new-type inheritable large object class
+- `adapt()` -- exposes the PEP-246_ compatible adapting mechanism used
+  by psycopg to adapt Python types to PostgreSQL ones
+
+.. _PEP-246: https://www.python.org/dev/peps/pep-0246/
+"""
+# psycopg/extensions.py - DBAPI-2.0 extensions specific to psycopg
+#
+# Copyright (C) 2003-2019 Federico Di Gregorio  <fog@debian.org>
+# Copyright (C) 2020 The Psycopg Team
+#
+# psycopg2 is free software: you can redistribute it and/or modify it
+# under the terms of the GNU Lesser General Public License as published
+# by the Free Software Foundation, either version 3 of the License, or
+# (at your option) any later version.
+#
+# In addition, as a special exception, the copyright holders give
+# permission to link this program with the OpenSSL library (or with
+# modified versions of OpenSSL that use the same license as OpenSSL),
+# and distribute linked combinations including the two.
+#
+# You must obey the GNU Lesser General Public License in all respects for
+# all of the code used other than OpenSSL.
+#
+# psycopg2 is distributed in the hope that it will be useful, but WITHOUT
+# ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or
+# FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public
+# License for more details.
+
+import re as _re
+
+from psycopg2._psycopg import (                             # noqa
+    BINARYARRAY, BOOLEAN, BOOLEANARRAY, BYTES, BYTESARRAY, DATE, DATEARRAY,
+    DATETIMEARRAY, DECIMAL, DECIMALARRAY, FLOAT, FLOATARRAY, INTEGER,
+    INTEGERARRAY, INTERVAL, INTERVALARRAY, LONGINTEGER, LONGINTEGERARRAY,
+    ROWIDARRAY, STRINGARRAY, TIME, TIMEARRAY, UNICODE, UNICODEARRAY,
+    AsIs, Binary, Boolean, Float, Int, QuotedString, )
+
+try:
+    from psycopg2._psycopg import (                         # noqa
+        MXDATE, MXDATETIME, MXDATETIMETZ, MXINTERVAL, MXTIME, MXDATEARRAY,
+        MXDATETIMEARRAY, MXDATETIMETZARRAY, MXINTERVALARRAY, MXTIMEARRAY,
+        DateFromMx, TimeFromMx, TimestampFromMx, IntervalFromMx, )
+except ImportError:
+    pass
+
+from psycopg2._psycopg import (                         # noqa
+    PYDATE, PYDATETIME, PYDATETIMETZ, PYINTERVAL, PYTIME, PYDATEARRAY,
+    PYDATETIMEARRAY, PYDATETIMETZARRAY, PYINTERVALARRAY, PYTIMEARRAY,
+    DateFromPy, TimeFromPy, TimestampFromPy, IntervalFromPy, )
+
+from psycopg2._psycopg import (                             # noqa
+    adapt, adapters, encodings, connection, cursor,
+    lobject, Xid, libpq_version, parse_dsn, quote_ident,
+    string_types, binary_types, new_type, new_array_type, register_type,
+    ISQLQuote, Notify, Diagnostics, Column, ConnectionInfo,
+    QueryCanceledError, TransactionRollbackError,
+    set_wait_callback, get_wait_callback, encrypt_password, )
+
+
+"""Isolation level values."""
+ISOLATION_LEVEL_AUTOCOMMIT = 0
+ISOLATION_LEVEL_READ_UNCOMMITTED = 4
+ISOLATION_LEVEL_READ_COMMITTED = 1
+ISOLATION_LEVEL_REPEATABLE_READ = 2
+ISOLATION_LEVEL_SERIALIZABLE = 3
+ISOLATION_LEVEL_DEFAULT = None
+
+
+"""psycopg connection status values."""
+STATUS_SETUP = 0
+STATUS_READY = 1
+STATUS_BEGIN = 2
+STATUS_SYNC = 3  # currently unused
+STATUS_ASYNC = 4  # currently unused
+STATUS_PREPARED = 5
+
+# This is a useful mnemonic to check if the connection is in a transaction
+STATUS_IN_TRANSACTION = STATUS_BEGIN
+
+
+"""psycopg asynchronous connection polling values"""
+POLL_OK = 0
+POLL_READ = 1
+POLL_WRITE = 2
+POLL_ERROR = 3
+
+
+"""Backend transaction status values."""
+TRANSACTION_STATUS_IDLE = 0
+TRANSACTION_STATUS_ACTIVE = 1
+TRANSACTION_STATUS_INTRANS = 2
+TRANSACTION_STATUS_INERROR = 3
+TRANSACTION_STATUS_UNKNOWN = 4
+
+
+def register_adapter(typ, callable):
+    """Register 'callable' as an ISQLQuote adapter for type 'typ'."""
+    adapters[(typ, ISQLQuote)] = callable
+
+
+# The SQL_IN class is the official adapter for tuples starting from 2.0.6.
+class SQL_IN(object):
+    """Adapt any iterable to an SQL quotable object."""
+    def __init__(self, seq):
+        self._seq = seq
+        self._conn = None
+
+    def prepare(self, conn):
+        self._conn = conn
+
+    def getquoted(self):
+        # this is the important line: note how every object in the
+        # list is adapted and then how getquoted() is called on it
+        pobjs = [adapt(o) for o in self._seq]
+        if self._conn is not None:
+            for obj in pobjs:
+                if hasattr(obj, 'prepare'):
+                    obj.prepare(self._conn)
+        qobjs = [o.getquoted() for o in pobjs]
+        return b'(' + b', '.join(qobjs) + b')'
+
+    def __str__(self):
+        return str(self.getquoted())
+
+
+class NoneAdapter(object):
+    """Adapt None to NULL.
+
+    This adapter is not used normally as a fast path in mogrify uses NULL,
+    but it makes easier to adapt composite types.
+    """
+    def __init__(self, obj):
+        pass
+
+    def getquoted(self, _null=b"NULL"):
+        return _null
+
+
+def make_dsn(dsn=None, **kwargs):
+    """Convert a set of keywords into a connection strings."""
+    if dsn is None and not kwargs:
+        return ''
+
+    # If no kwarg is specified don't mung the dsn, but verify it
+    if not kwargs:
+        parse_dsn(dsn)
+        return dsn
+
+    # Override the dsn with the parameters
+    if 'database' in kwargs:
+        if 'dbname' in kwargs:
+            raise TypeError(
+                "you can't specify both 'database' and 'dbname' arguments")
+        kwargs['dbname'] = kwargs.pop('database')
+
+    # Drop the None arguments
+    kwargs = {k: v for (k, v) in kwargs.items() if v is not None}
+
+    if dsn is not None:
+        tmp = parse_dsn(dsn)
+        tmp.update(kwargs)
+        kwargs = tmp
+
+    dsn = " ".join(["%s=%s" % (k, _param_escape(str(v)))
+        for (k, v) in kwargs.items()])
+
+    # verify that the returned dsn is valid
+    parse_dsn(dsn)
+
+    return dsn
+
+
+def _param_escape(s,
+        re_escape=_re.compile(r"([\\'])"),
+        re_space=_re.compile(r'\s')):
+    """
+    Apply the escaping rule required by PQconnectdb
+    """
+    if not s:
+        return "''"
+
+    s = re_escape.sub(r'\\\1', s)
+    if re_space.search(s):
+        s = "'" + s + "'"
+
+    return s
+
+
+# Create default json typecasters for PostgreSQL 9.2 oids
+from psycopg2._json import register_default_json, register_default_jsonb    # noqa
+
+try:
+    JSON, JSONARRAY = register_default_json()
+    JSONB, JSONBARRAY = register_default_jsonb()
+except ImportError:
+    pass
+
+del register_default_json, register_default_jsonb
+
+
+# Create default Range typecasters
+from psycopg2. _range import Range                              # noqa
+del Range
+
+
+# Add the "cleaned" version of the encodings to the key.
+# When the encoding is set its name is cleaned up from - and _ and turned
+# uppercase, so an encoding not respecting these rules wouldn't be found in the
+# encodings keys and would raise an exception with the unicode typecaster
+for k, v in list(encodings.items()):
+    k = k.replace('_', '').replace('-', '').upper()
+    encodings[k] = v
+
+del k, v
Index: venv/Lib/site-packages/python_dateutil-2.8.1.dist-info/LICENSE
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/venv/Lib/site-packages/python_dateutil-2.8.1.dist-info/LICENSE b/venv/Lib/site-packages/python_dateutil-2.8.1.dist-info/LICENSE
new file mode 100644
--- /dev/null	(date 1616410447259)
+++ b/venv/Lib/site-packages/python_dateutil-2.8.1.dist-info/LICENSE	(date 1616410447259)
@@ -0,0 +1,54 @@
+Copyright 2017- Paul Ganssle <paul@ganssle.io>
+Copyright 2017- dateutil contributors (see AUTHORS file)
+
+   Licensed under the Apache License, Version 2.0 (the "License");
+   you may not use this file except in compliance with the License.
+   You may obtain a copy of the License at
+
+       http://www.apache.org/licenses/LICENSE-2.0
+
+   Unless required by applicable law or agreed to in writing, software
+   distributed under the License is distributed on an "AS IS" BASIS,
+   WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+   See the License for the specific language governing permissions and
+   limitations under the License.
+
+The above license applies to all contributions after 2017-12-01, as well as
+all contributions that have been re-licensed (see AUTHORS file for the list of
+contributors who have re-licensed their code).
+--------------------------------------------------------------------------------
+dateutil - Extensions to the standard Python datetime module.
+
+Copyright (c) 2003-2011 - Gustavo Niemeyer <gustavo@niemeyer.net>
+Copyright (c) 2012-2014 - Tomi Pieviläinen <tomi.pievilainen@iki.fi>
+Copyright (c) 2014-2016 - Yaron de Leeuw <me@jarondl.net>
+Copyright (c) 2015-     - Paul Ganssle <paul@ganssle.io>
+Copyright (c) 2015-     - dateutil contributors (see AUTHORS file)
+
+All rights reserved.
+
+Redistribution and use in source and binary forms, with or without
+modification, are permitted provided that the following conditions are met:
+
+    * Redistributions of source code must retain the above copyright notice,
+      this list of conditions and the following disclaimer.
+    * Redistributions in binary form must reproduce the above copyright notice,
+      this list of conditions and the following disclaimer in the documentation
+      and/or other materials provided with the distribution.
+    * Neither the name of the copyright holder nor the names of its
+      contributors may be used to endorse or promote products derived from
+      this software without specific prior written permission.
+
+THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS
+"AS IS" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT
+LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR
+A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT OWNER OR
+CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL,
+EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO,
+PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR
+PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF
+LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING
+NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS
+SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
+
+The above BSD License Applies to all code, even that also covered by Apache 2.0.
\ No newline at end of file
Index: latest/Lib/site-packages/psycopg2/extras.py
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/latest/Lib/site-packages/psycopg2/extras.py b/latest/Lib/site-packages/psycopg2/extras.py
new file mode 100644
--- /dev/null	(date 1616410447367)
+++ b/latest/Lib/site-packages/psycopg2/extras.py	(date 1616410447367)
@@ -0,0 +1,1328 @@
+"""Miscellaneous goodies for psycopg2
+
+This module is a generic place used to hold little helper functions
+and classes until a better place in the distribution is found.
+"""
+# psycopg/extras.py - miscellaneous extra goodies for psycopg
+#
+# Copyright (C) 2003-2019 Federico Di Gregorio  <fog@debian.org>
+# Copyright (C) 2020 The Psycopg Team
+#
+# psycopg2 is free software: you can redistribute it and/or modify it
+# under the terms of the GNU Lesser General Public License as published
+# by the Free Software Foundation, either version 3 of the License, or
+# (at your option) any later version.
+#
+# In addition, as a special exception, the copyright holders give
+# permission to link this program with the OpenSSL library (or with
+# modified versions of OpenSSL that use the same license as OpenSSL),
+# and distribute linked combinations including the two.
+#
+# You must obey the GNU Lesser General Public License in all respects for
+# all of the code used other than OpenSSL.
+#
+# psycopg2 is distributed in the hope that it will be useful, but WITHOUT
+# ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or
+# FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public
+# License for more details.
+
+import os as _os
+import time as _time
+import re as _re
+from collections import namedtuple, OrderedDict
+
+import logging as _logging
+
+import psycopg2
+from psycopg2 import extensions as _ext
+from .extensions import cursor as _cursor
+from .extensions import connection as _connection
+from .extensions import adapt as _A, quote_ident
+from .compat import PY2, PY3, lru_cache
+
+from psycopg2._psycopg import (                             # noqa
+    REPLICATION_PHYSICAL, REPLICATION_LOGICAL,
+    ReplicationConnection as _replicationConnection,
+    ReplicationCursor as _replicationCursor,
+    ReplicationMessage)
+
+
+# expose the json adaptation stuff into the module
+from psycopg2._json import (                                # noqa
+    json, Json, register_json, register_default_json, register_default_jsonb)
+
+
+# Expose range-related objects
+from psycopg2._range import (                               # noqa
+    Range, NumericRange, DateRange, DateTimeRange, DateTimeTZRange,
+    register_range, RangeAdapter, RangeCaster)
+
+
+# Expose ipaddress-related objects
+from psycopg2._ipaddress import register_ipaddress          # noqa
+
+
+class DictCursorBase(_cursor):
+    """Base class for all dict-like cursors."""
+
+    def __init__(self, *args, **kwargs):
+        if 'row_factory' in kwargs:
+            row_factory = kwargs['row_factory']
+            del kwargs['row_factory']
+        else:
+            raise NotImplementedError(
+                "DictCursorBase can't be instantiated without a row factory.")
+        super(DictCursorBase, self).__init__(*args, **kwargs)
+        self._query_executed = False
+        self._prefetch = False
+        self.row_factory = row_factory
+
+    def fetchone(self):
+        if self._prefetch:
+            res = super(DictCursorBase, self).fetchone()
+        if self._query_executed:
+            self._build_index()
+        if not self._prefetch:
+            res = super(DictCursorBase, self).fetchone()
+        return res
+
+    def fetchmany(self, size=None):
+        if self._prefetch:
+            res = super(DictCursorBase, self).fetchmany(size)
+        if self._query_executed:
+            self._build_index()
+        if not self._prefetch:
+            res = super(DictCursorBase, self).fetchmany(size)
+        return res
+
+    def fetchall(self):
+        if self._prefetch:
+            res = super(DictCursorBase, self).fetchall()
+        if self._query_executed:
+            self._build_index()
+        if not self._prefetch:
+            res = super(DictCursorBase, self).fetchall()
+        return res
+
+    def __iter__(self):
+        try:
+            if self._prefetch:
+                res = super(DictCursorBase, self).__iter__()
+                first = next(res)
+            if self._query_executed:
+                self._build_index()
+            if not self._prefetch:
+                res = super(DictCursorBase, self).__iter__()
+                first = next(res)
+
+            yield first
+            while True:
+                yield next(res)
+        except StopIteration:
+            return
+
+
+class DictConnection(_connection):
+    """A connection that uses `DictCursor` automatically."""
+    def cursor(self, *args, **kwargs):
+        kwargs.setdefault('cursor_factory', self.cursor_factory or DictCursor)
+        return super(DictConnection, self).cursor(*args, **kwargs)
+
+
+class DictCursor(DictCursorBase):
+    """A cursor that keeps a list of column name -> index mappings__.
+
+    .. __: https://docs.python.org/glossary.html#term-mapping
+    """
+
+    def __init__(self, *args, **kwargs):
+        kwargs['row_factory'] = DictRow
+        super(DictCursor, self).__init__(*args, **kwargs)
+        self._prefetch = True
+
+    def execute(self, query, vars=None):
+        self.index = OrderedDict()
+        self._query_executed = True
+        return super(DictCursor, self).execute(query, vars)
+
+    def callproc(self, procname, vars=None):
+        self.index = OrderedDict()
+        self._query_executed = True
+        return super(DictCursor, self).callproc(procname, vars)
+
+    def _build_index(self):
+        if self._query_executed and self.description:
+            for i in range(len(self.description)):
+                self.index[self.description[i][0]] = i
+            self._query_executed = False
+
+
+class DictRow(list):
+    """A row object that allow by-column-name access to data."""
+
+    __slots__ = ('_index',)
+
+    def __init__(self, cursor):
+        self._index = cursor.index
+        self[:] = [None] * len(cursor.description)
+
+    def __getitem__(self, x):
+        if not isinstance(x, (int, slice)):
+            x = self._index[x]
+        return super(DictRow, self).__getitem__(x)
+
+    def __setitem__(self, x, v):
+        if not isinstance(x, (int, slice)):
+            x = self._index[x]
+        super(DictRow, self).__setitem__(x, v)
+
+    def items(self):
+        g = super(DictRow, self).__getitem__
+        return ((n, g(self._index[n])) for n in self._index)
+
+    def keys(self):
+        return iter(self._index)
+
+    def values(self):
+        g = super(DictRow, self).__getitem__
+        return (g(self._index[n]) for n in self._index)
+
+    def get(self, x, default=None):
+        try:
+            return self[x]
+        except Exception:
+            return default
+
+    def copy(self):
+        return OrderedDict(self.items())
+
+    def __contains__(self, x):
+        return x in self._index
+
+    def __reduce__(self):
+        # this is apparently useless, but it fixes #1073
+        return super(DictRow, self).__reduce__()
+
+    def __getstate__(self):
+        return self[:], self._index.copy()
+
+    def __setstate__(self, data):
+        self[:] = data[0]
+        self._index = data[1]
+
+    if PY2:
+        iterkeys = keys
+        itervalues = values
+        iteritems = items
+        has_key = __contains__
+
+        def keys(self):
+            return list(self.iterkeys())
+
+        def values(self):
+            return tuple(self.itervalues())
+
+        def items(self):
+            return list(self.iteritems())
+
+
+class RealDictConnection(_connection):
+    """A connection that uses `RealDictCursor` automatically."""
+    def cursor(self, *args, **kwargs):
+        kwargs.setdefault('cursor_factory', self.cursor_factory or RealDictCursor)
+        return super(RealDictConnection, self).cursor(*args, **kwargs)
+
+
+class RealDictCursor(DictCursorBase):
+    """A cursor that uses a real dict as the base type for rows.
+
+    Note that this cursor is extremely specialized and does not allow
+    the normal access (using integer indices) to fetched data. If you need
+    to access database rows both as a dictionary and a list, then use
+    the generic `DictCursor` instead of `!RealDictCursor`.
+    """
+    def __init__(self, *args, **kwargs):
+        kwargs['row_factory'] = RealDictRow
+        super(RealDictCursor, self).__init__(*args, **kwargs)
+
+    def execute(self, query, vars=None):
+        self.column_mapping = []
+        self._query_executed = True
+        return super(RealDictCursor, self).execute(query, vars)
+
+    def callproc(self, procname, vars=None):
+        self.column_mapping = []
+        self._query_executed = True
+        return super(RealDictCursor, self).callproc(procname, vars)
+
+    def _build_index(self):
+        if self._query_executed and self.description:
+            self.column_mapping = [d[0] for d in self.description]
+            self._query_executed = False
+
+
+class RealDictRow(OrderedDict):
+    """A `!dict` subclass representing a data record."""
+
+    def __init__(self, *args, **kwargs):
+        if args and isinstance(args[0], _cursor):
+            cursor = args[0]
+            args = args[1:]
+        else:
+            cursor = None
+
+        super(RealDictRow, self).__init__(*args, **kwargs)
+
+        if cursor is not None:
+            # Required for named cursors
+            if cursor.description and not cursor.column_mapping:
+                cursor._build_index()
+
+            # Store the cols mapping in the dict itself until the row is fully
+            # populated, so we don't need to add attributes to the class
+            # (hence keeping its maintenance, special pickle support, etc.)
+            self[RealDictRow] = cursor.column_mapping
+
+    def __setitem__(self, key, value):
+        if RealDictRow in self:
+            # We are in the row building phase
+            mapping = self[RealDictRow]
+            super(RealDictRow, self).__setitem__(mapping[key], value)
+            if key == len(mapping) - 1:
+                # Row building finished
+                del self[RealDictRow]
+            return
+
+        super(RealDictRow, self).__setitem__(key, value)
+
+
+class NamedTupleConnection(_connection):
+    """A connection that uses `NamedTupleCursor` automatically."""
+    def cursor(self, *args, **kwargs):
+        kwargs.setdefault('cursor_factory', self.cursor_factory or NamedTupleCursor)
+        return super(NamedTupleConnection, self).cursor(*args, **kwargs)
+
+
+class NamedTupleCursor(_cursor):
+    """A cursor that generates results as `~collections.namedtuple`.
+
+    `!fetch*()` methods will return named tuples instead of regular tuples, so
+    their elements can be accessed both as regular numeric items as well as
+    attributes.
+
+        >>> nt_cur = conn.cursor(cursor_factory=psycopg2.extras.NamedTupleCursor)
+        >>> rec = nt_cur.fetchone()
+        >>> rec
+        Record(id=1, num=100, data="abc'def")
+        >>> rec[1]
+        100
+        >>> rec.data
+        "abc'def"
+    """
+    Record = None
+    MAX_CACHE = 1024
+
+    def execute(self, query, vars=None):
+        self.Record = None
+        return super(NamedTupleCursor, self).execute(query, vars)
+
+    def executemany(self, query, vars):
+        self.Record = None
+        return super(NamedTupleCursor, self).executemany(query, vars)
+
+    def callproc(self, procname, vars=None):
+        self.Record = None
+        return super(NamedTupleCursor, self).callproc(procname, vars)
+
+    def fetchone(self):
+        t = super(NamedTupleCursor, self).fetchone()
+        if t is not None:
+            nt = self.Record
+            if nt is None:
+                nt = self.Record = self._make_nt()
+            return nt._make(t)
+
+    def fetchmany(self, size=None):
+        ts = super(NamedTupleCursor, self).fetchmany(size)
+        nt = self.Record
+        if nt is None:
+            nt = self.Record = self._make_nt()
+        return list(map(nt._make, ts))
+
+    def fetchall(self):
+        ts = super(NamedTupleCursor, self).fetchall()
+        nt = self.Record
+        if nt is None:
+            nt = self.Record = self._make_nt()
+        return list(map(nt._make, ts))
+
+    def __iter__(self):
+        try:
+            it = super(NamedTupleCursor, self).__iter__()
+            t = next(it)
+
+            nt = self.Record
+            if nt is None:
+                nt = self.Record = self._make_nt()
+
+            yield nt._make(t)
+
+            while True:
+                yield nt._make(next(it))
+        except StopIteration:
+            return
+
+    # ascii except alnum and underscore
+    _re_clean = _re.compile(
+        '[' + _re.escape(' !"#$%&\'()*+,-./:;<=>?@[\\]^`{|}~') + ']')
+
+    def _make_nt(self):
+        key = tuple(d[0] for d in self.description) if self.description else ()
+        return self._cached_make_nt(key)
+
+    @classmethod
+    def _do_make_nt(cls, key):
+        fields = []
+        for s in key:
+            s = cls._re_clean.sub('_', s)
+            # Python identifier cannot start with numbers, namedtuple fields
+            # cannot start with underscore. So...
+            if s[0] == '_' or '0' <= s[0] <= '9':
+                s = 'f' + s
+            fields.append(s)
+
+        nt = namedtuple("Record", fields)
+        return nt
+
+
+@lru_cache(512)
+def _cached_make_nt(cls, key):
+    return cls._do_make_nt(key)
+
+
+# Exposed for testability, and if someone wants to monkeypatch to tweak
+# the cache size.
+NamedTupleCursor._cached_make_nt = classmethod(_cached_make_nt)
+
+
+class LoggingConnection(_connection):
+    """A connection that logs all queries to a file or logger__ object.
+
+    .. __: https://docs.python.org/library/logging.html
+    """
+
+    def initialize(self, logobj):
+        """Initialize the connection to log to `!logobj`.
+
+        The `!logobj` parameter can be an open file object or a Logger/LoggerAdapter
+        instance from the standard logging module.
+        """
+        self._logobj = logobj
+        if _logging and isinstance(
+                logobj, (_logging.Logger, _logging.LoggerAdapter)):
+            self.log = self._logtologger
+        else:
+            self.log = self._logtofile
+
+    def filter(self, msg, curs):
+        """Filter the query before logging it.
+
+        This is the method to overwrite to filter unwanted queries out of the
+        log or to add some extra data to the output. The default implementation
+        just does nothing.
+        """
+        return msg
+
+    def _logtofile(self, msg, curs):
+        msg = self.filter(msg, curs)
+        if msg:
+            if PY3 and isinstance(msg, bytes):
+                msg = msg.decode(_ext.encodings[self.encoding], 'replace')
+            self._logobj.write(msg + _os.linesep)
+
+    def _logtologger(self, msg, curs):
+        msg = self.filter(msg, curs)
+        if msg:
+            self._logobj.debug(msg)
+
+    def _check(self):
+        if not hasattr(self, '_logobj'):
+            raise self.ProgrammingError(
+                "LoggingConnection object has not been initialize()d")
+
+    def cursor(self, *args, **kwargs):
+        self._check()
+        kwargs.setdefault('cursor_factory', self.cursor_factory or LoggingCursor)
+        return super(LoggingConnection, self).cursor(*args, **kwargs)
+
+
+class LoggingCursor(_cursor):
+    """A cursor that logs queries using its connection logging facilities."""
+
+    def execute(self, query, vars=None):
+        try:
+            return super(LoggingCursor, self).execute(query, vars)
+        finally:
+            self.connection.log(self.query, self)
+
+    def callproc(self, procname, vars=None):
+        try:
+            return super(LoggingCursor, self).callproc(procname, vars)
+        finally:
+            self.connection.log(self.query, self)
+
+
+class MinTimeLoggingConnection(LoggingConnection):
+    """A connection that logs queries based on execution time.
+
+    This is just an example of how to sub-class `LoggingConnection` to
+    provide some extra filtering for the logged queries. Both the
+    `initialize()` and `filter()` methods are overwritten to make sure
+    that only queries executing for more than ``mintime`` ms are logged.
+
+    Note that this connection uses the specialized cursor
+    `MinTimeLoggingCursor`.
+    """
+    def initialize(self, logobj, mintime=0):
+        LoggingConnection.initialize(self, logobj)
+        self._mintime = mintime
+
+    def filter(self, msg, curs):
+        t = (_time.time() - curs.timestamp) * 1000
+        if t > self._mintime:
+            if PY3 and isinstance(msg, bytes):
+                msg = msg.decode(_ext.encodings[self.encoding], 'replace')
+            return msg + _os.linesep + "  (execution time: %d ms)" % t
+
+    def cursor(self, *args, **kwargs):
+        kwargs.setdefault('cursor_factory',
+            self.cursor_factory or MinTimeLoggingCursor)
+        return LoggingConnection.cursor(self, *args, **kwargs)
+
+
+class MinTimeLoggingCursor(LoggingCursor):
+    """The cursor sub-class companion to `MinTimeLoggingConnection`."""
+
+    def execute(self, query, vars=None):
+        self.timestamp = _time.time()
+        return LoggingCursor.execute(self, query, vars)
+
+    def callproc(self, procname, vars=None):
+        self.timestamp = _time.time()
+        return LoggingCursor.callproc(self, procname, vars)
+
+
+class LogicalReplicationConnection(_replicationConnection):
+
+    def __init__(self, *args, **kwargs):
+        kwargs['replication_type'] = REPLICATION_LOGICAL
+        super(LogicalReplicationConnection, self).__init__(*args, **kwargs)
+
+
+class PhysicalReplicationConnection(_replicationConnection):
+
+    def __init__(self, *args, **kwargs):
+        kwargs['replication_type'] = REPLICATION_PHYSICAL
+        super(PhysicalReplicationConnection, self).__init__(*args, **kwargs)
+
+
+class StopReplication(Exception):
+    """
+    Exception used to break out of the endless loop in
+    `~ReplicationCursor.consume_stream()`.
+
+    Subclass of `~exceptions.Exception`.  Intentionally *not* inherited from
+    `~psycopg2.Error` as occurrence of this exception does not indicate an
+    error.
+    """
+    pass
+
+
+class ReplicationCursor(_replicationCursor):
+    """A cursor used for communication on replication connections."""
+
+    def create_replication_slot(self, slot_name, slot_type=None, output_plugin=None):
+        """Create streaming replication slot."""
+
+        command = "CREATE_REPLICATION_SLOT %s " % quote_ident(slot_name, self)
+
+        if slot_type is None:
+            slot_type = self.connection.replication_type
+
+        if slot_type == REPLICATION_LOGICAL:
+            if output_plugin is None:
+                raise psycopg2.ProgrammingError(
+                    "output plugin name is required to create "
+                    "logical replication slot")
+
+            command += "LOGICAL %s" % quote_ident(output_plugin, self)
+
+        elif slot_type == REPLICATION_PHYSICAL:
+            if output_plugin is not None:
+                raise psycopg2.ProgrammingError(
+                    "cannot specify output plugin name when creating "
+                    "physical replication slot")
+
+            command += "PHYSICAL"
+
+        else:
+            raise psycopg2.ProgrammingError(
+                "unrecognized replication type: %s" % repr(slot_type))
+
+        self.execute(command)
+
+    def drop_replication_slot(self, slot_name):
+        """Drop streaming replication slot."""
+
+        command = "DROP_REPLICATION_SLOT %s" % quote_ident(slot_name, self)
+        self.execute(command)
+
+    def start_replication(
+            self, slot_name=None, slot_type=None, start_lsn=0,
+            timeline=0, options=None, decode=False, status_interval=10):
+        """Start replication stream."""
+
+        command = "START_REPLICATION "
+
+        if slot_type is None:
+            slot_type = self.connection.replication_type
+
+        if slot_type == REPLICATION_LOGICAL:
+            if slot_name:
+                command += "SLOT %s " % quote_ident(slot_name, self)
+            else:
+                raise psycopg2.ProgrammingError(
+                    "slot name is required for logical replication")
+
+            command += "LOGICAL "
+
+        elif slot_type == REPLICATION_PHYSICAL:
+            if slot_name:
+                command += "SLOT %s " % quote_ident(slot_name, self)
+            # don't add "PHYSICAL", before 9.4 it was just START_REPLICATION XXX/XXX
+
+        else:
+            raise psycopg2.ProgrammingError(
+                "unrecognized replication type: %s" % repr(slot_type))
+
+        if type(start_lsn) is str:
+            lsn = start_lsn.split('/')
+            lsn = "%X/%08X" % (int(lsn[0], 16), int(lsn[1], 16))
+        else:
+            lsn = "%X/%08X" % ((start_lsn >> 32) & 0xFFFFFFFF,
+                               start_lsn & 0xFFFFFFFF)
+
+        command += lsn
+
+        if timeline != 0:
+            if slot_type == REPLICATION_LOGICAL:
+                raise psycopg2.ProgrammingError(
+                    "cannot specify timeline for logical replication")
+
+            command += " TIMELINE %d" % timeline
+
+        if options:
+            if slot_type == REPLICATION_PHYSICAL:
+                raise psycopg2.ProgrammingError(
+                    "cannot specify output plugin options for physical replication")
+
+            command += " ("
+            for k, v in options.items():
+                if not command.endswith('('):
+                    command += ", "
+                command += "%s %s" % (quote_ident(k, self), _A(str(v)))
+            command += ")"
+
+        self.start_replication_expert(
+            command, decode=decode, status_interval=status_interval)
+
+    # allows replication cursors to be used in select.select() directly
+    def fileno(self):
+        return self.connection.fileno()
+
+
+# a dbtype and adapter for Python UUID type
+
+class UUID_adapter(object):
+    """Adapt Python's uuid.UUID__ type to PostgreSQL's uuid__.
+
+    .. __: https://docs.python.org/library/uuid.html
+    .. __: https://www.postgresql.org/docs/current/static/datatype-uuid.html
+    """
+
+    def __init__(self, uuid):
+        self._uuid = uuid
+
+    def __conform__(self, proto):
+        if proto is _ext.ISQLQuote:
+            return self
+
+    def getquoted(self):
+        return ("'%s'::uuid" % self._uuid).encode('utf8')
+
+    def __str__(self):
+        return "'%s'::uuid" % self._uuid
+
+
+def register_uuid(oids=None, conn_or_curs=None):
+    """Create the UUID type and an uuid.UUID adapter.
+
+    :param oids: oid for the PostgreSQL :sql:`uuid` type, or 2-items sequence
+        with oids of the type and the array. If not specified, use PostgreSQL
+        standard oids.
+    :param conn_or_curs: where to register the typecaster. If not specified,
+        register it globally.
+    """
+
+    import uuid
+
+    if not oids:
+        oid1 = 2950
+        oid2 = 2951
+    elif isinstance(oids, (list, tuple)):
+        oid1, oid2 = oids
+    else:
+        oid1 = oids
+        oid2 = 2951
+
+    _ext.UUID = _ext.new_type((oid1, ), "UUID",
+            lambda data, cursor: data and uuid.UUID(data) or None)
+    _ext.UUIDARRAY = _ext.new_array_type((oid2,), "UUID[]", _ext.UUID)
+
+    _ext.register_type(_ext.UUID, conn_or_curs)
+    _ext.register_type(_ext.UUIDARRAY, conn_or_curs)
+    _ext.register_adapter(uuid.UUID, UUID_adapter)
+
+    return _ext.UUID
+
+
+# a type, dbtype and adapter for PostgreSQL inet type
+
+class Inet(object):
+    """Wrap a string to allow for correct SQL-quoting of inet values.
+
+    Note that this adapter does NOT check the passed value to make
+    sure it really is an inet-compatible address but DOES call adapt()
+    on it to make sure it is impossible to execute an SQL-injection
+    by passing an evil value to the initializer.
+    """
+    def __init__(self, addr):
+        self.addr = addr
+
+    def __repr__(self):
+        return "%s(%r)" % (self.__class__.__name__, self.addr)
+
+    def prepare(self, conn):
+        self._conn = conn
+
+    def getquoted(self):
+        obj = _A(self.addr)
+        if hasattr(obj, 'prepare'):
+            obj.prepare(self._conn)
+        return obj.getquoted() + b"::inet"
+
+    def __conform__(self, proto):
+        if proto is _ext.ISQLQuote:
+            return self
+
+    def __str__(self):
+        return str(self.addr)
+
+
+def register_inet(oid=None, conn_or_curs=None):
+    """Create the INET type and an Inet adapter.
+
+    :param oid: oid for the PostgreSQL :sql:`inet` type, or 2-items sequence
+        with oids of the type and the array. If not specified, use PostgreSQL
+        standard oids.
+    :param conn_or_curs: where to register the typecaster. If not specified,
+        register it globally.
+    """
+    import warnings
+    warnings.warn(
+        "the inet adapter is deprecated, it's not very useful",
+        DeprecationWarning)
+
+    if not oid:
+        oid1 = 869
+        oid2 = 1041
+    elif isinstance(oid, (list, tuple)):
+        oid1, oid2 = oid
+    else:
+        oid1 = oid
+        oid2 = 1041
+
+    _ext.INET = _ext.new_type((oid1, ), "INET",
+            lambda data, cursor: data and Inet(data) or None)
+    _ext.INETARRAY = _ext.new_array_type((oid2, ), "INETARRAY", _ext.INET)
+
+    _ext.register_type(_ext.INET, conn_or_curs)
+    _ext.register_type(_ext.INETARRAY, conn_or_curs)
+
+    return _ext.INET
+
+
+def wait_select(conn):
+    """Wait until a connection or cursor has data available.
+
+    The function is an example of a wait callback to be registered with
+    `~psycopg2.extensions.set_wait_callback()`. This function uses
+    :py:func:`~select.select()` to wait for data to become available, and
+    therefore is able to handle/receive SIGINT/KeyboardInterrupt.
+    """
+    import select
+    from psycopg2.extensions import POLL_OK, POLL_READ, POLL_WRITE
+
+    while True:
+        try:
+            state = conn.poll()
+            if state == POLL_OK:
+                break
+            elif state == POLL_READ:
+                select.select([conn.fileno()], [], [])
+            elif state == POLL_WRITE:
+                select.select([], [conn.fileno()], [])
+            else:
+                raise conn.OperationalError("bad state from poll: %s" % state)
+        except KeyboardInterrupt:
+            conn.cancel()
+            # the loop will be broken by a server error
+            continue
+
+
+def _solve_conn_curs(conn_or_curs):
+    """Return the connection and a DBAPI cursor from a connection or cursor."""
+    if conn_or_curs is None:
+        raise psycopg2.ProgrammingError("no connection or cursor provided")
+
+    if hasattr(conn_or_curs, 'execute'):
+        conn = conn_or_curs.connection
+        curs = conn.cursor(cursor_factory=_cursor)
+    else:
+        conn = conn_or_curs
+        curs = conn.cursor(cursor_factory=_cursor)
+
+    return conn, curs
+
+
+class HstoreAdapter(object):
+    """Adapt a Python dict to the hstore syntax."""
+    def __init__(self, wrapped):
+        self.wrapped = wrapped
+
+    def prepare(self, conn):
+        self.conn = conn
+
+        # use an old-style getquoted implementation if required
+        if conn.info.server_version < 90000:
+            self.getquoted = self._getquoted_8
+
+    def _getquoted_8(self):
+        """Use the operators available in PG pre-9.0."""
+        if not self.wrapped:
+            return b"''::hstore"
+
+        adapt = _ext.adapt
+        rv = []
+        for k, v in self.wrapped.items():
+            k = adapt(k)
+            k.prepare(self.conn)
+            k = k.getquoted()
+
+            if v is not None:
+                v = adapt(v)
+                v.prepare(self.conn)
+                v = v.getquoted()
+            else:
+                v = b'NULL'
+
+            # XXX this b'ing is painfully inefficient!
+            rv.append(b"(" + k + b" => " + v + b")")
+
+        return b"(" + b'||'.join(rv) + b")"
+
+    def _getquoted_9(self):
+        """Use the hstore(text[], text[]) function."""
+        if not self.wrapped:
+            return b"''::hstore"
+
+        k = _ext.adapt(list(self.wrapped.keys()))
+        k.prepare(self.conn)
+        v = _ext.adapt(list(self.wrapped.values()))
+        v.prepare(self.conn)
+        return b"hstore(" + k.getquoted() + b", " + v.getquoted() + b")"
+
+    getquoted = _getquoted_9
+
+    _re_hstore = _re.compile(r"""
+        # hstore key:
+        # a string of normal or escaped chars
+        "((?: [^"\\] | \\. )*)"
+        \s*=>\s* # hstore value
+        (?:
+            NULL # the value can be null - not catched
+            # or a quoted string like the key
+            | "((?: [^"\\] | \\. )*)"
+        )
+        (?:\s*,\s*|$) # pairs separated by comma or end of string.
+    """, _re.VERBOSE)
+
+    @classmethod
+    def parse(self, s, cur, _bsdec=_re.compile(r"\\(.)")):
+        """Parse an hstore representation in a Python string.
+
+        The hstore is represented as something like::
+
+            "a"=>"1", "b"=>"2"
+
+        with backslash-escaped strings.
+        """
+        if s is None:
+            return None
+
+        rv = {}
+        start = 0
+        for m in self._re_hstore.finditer(s):
+            if m is None or m.start() != start:
+                raise psycopg2.InterfaceError(
+                    "error parsing hstore pair at char %d" % start)
+            k = _bsdec.sub(r'\1', m.group(1))
+            v = m.group(2)
+            if v is not None:
+                v = _bsdec.sub(r'\1', v)
+
+            rv[k] = v
+            start = m.end()
+
+        if start < len(s):
+            raise psycopg2.InterfaceError(
+                "error parsing hstore: unparsed data after char %d" % start)
+
+        return rv
+
+    @classmethod
+    def parse_unicode(self, s, cur):
+        """Parse an hstore returning unicode keys and values."""
+        if s is None:
+            return None
+
+        s = s.decode(_ext.encodings[cur.connection.encoding])
+        return self.parse(s, cur)
+
+    @classmethod
+    def get_oids(self, conn_or_curs):
+        """Return the lists of OID of the hstore and hstore[] types.
+        """
+        conn, curs = _solve_conn_curs(conn_or_curs)
+
+        # Store the transaction status of the connection to revert it after use
+        conn_status = conn.status
+
+        # column typarray not available before PG 8.3
+        typarray = conn.info.server_version >= 80300 and "typarray" or "NULL"
+
+        rv0, rv1 = [], []
+
+        # get the oid for the hstore
+        curs.execute("""\
+SELECT t.oid, %s
+FROM pg_type t JOIN pg_namespace ns
+    ON typnamespace = ns.oid
+WHERE typname = 'hstore';
+""" % typarray)
+        for oids in curs:
+            rv0.append(oids[0])
+            rv1.append(oids[1])
+
+        # revert the status of the connection as before the command
+        if (conn_status != _ext.STATUS_IN_TRANSACTION
+        and not conn.autocommit):
+            conn.rollback()
+
+        return tuple(rv0), tuple(rv1)
+
+
+def register_hstore(conn_or_curs, globally=False, unicode=False,
+                    oid=None, array_oid=None):
+    r"""Register adapter and typecaster for `!dict`\-\ |hstore| conversions.
+
+    :param conn_or_curs: a connection or cursor: the typecaster will be
+        registered only on this object unless *globally* is set to `!True`
+    :param globally: register the adapter globally, not only on *conn_or_curs*
+    :param unicode: if `!True`, keys and values returned from the database
+        will be `!unicode` instead of `!str`. The option is not available on
+        Python 3
+    :param oid: the OID of the |hstore| type if known. If not, it will be
+        queried on *conn_or_curs*.
+    :param array_oid: the OID of the |hstore| array type if known. If not, it
+        will be queried on *conn_or_curs*.
+
+    The connection or cursor passed to the function will be used to query the
+    database and look for the OID of the |hstore| type (which may be different
+    across databases). If querying is not desirable (e.g. with
+    :ref:`asynchronous connections <async-support>`) you may specify it in the
+    *oid* parameter, which can be found using a query such as :sql:`SELECT
+    'hstore'::regtype::oid`. Analogously you can obtain a value for *array_oid*
+    using a query such as :sql:`SELECT 'hstore[]'::regtype::oid`.
+
+    Note that, when passing a dictionary from Python to the database, both
+    strings and unicode keys and values are supported. Dictionaries returned
+    from the database have keys/values according to the *unicode* parameter.
+
+    The |hstore| contrib module must be already installed in the database
+    (executing the ``hstore.sql`` script in your ``contrib`` directory).
+    Raise `~psycopg2.ProgrammingError` if the type is not found.
+    """
+    if oid is None:
+        oid = HstoreAdapter.get_oids(conn_or_curs)
+        if oid is None or not oid[0]:
+            raise psycopg2.ProgrammingError(
+                "hstore type not found in the database. "
+                "please install it from your 'contrib/hstore.sql' file")
+        else:
+            array_oid = oid[1]
+            oid = oid[0]
+
+    if isinstance(oid, int):
+        oid = (oid,)
+
+    if array_oid is not None:
+        if isinstance(array_oid, int):
+            array_oid = (array_oid,)
+        else:
+            array_oid = tuple([x for x in array_oid if x])
+
+    # create and register the typecaster
+    if PY2 and unicode:
+        cast = HstoreAdapter.parse_unicode
+    else:
+        cast = HstoreAdapter.parse
+
+    HSTORE = _ext.new_type(oid, "HSTORE", cast)
+    _ext.register_type(HSTORE, not globally and conn_or_curs or None)
+    _ext.register_adapter(dict, HstoreAdapter)
+
+    if array_oid:
+        HSTOREARRAY = _ext.new_array_type(array_oid, "HSTOREARRAY", HSTORE)
+        _ext.register_type(HSTOREARRAY, not globally and conn_or_curs or None)
+
+
+class CompositeCaster(object):
+    """Helps conversion of a PostgreSQL composite type into a Python object.
+
+    The class is usually created by the `register_composite()` function.
+    You may want to create and register manually instances of the class if
+    querying the database at registration time is not desirable (such as when
+    using an :ref:`asynchronous connections <async-support>`).
+
+    """
+    def __init__(self, name, oid, attrs, array_oid=None, schema=None):
+        self.name = name
+        self.schema = schema
+        self.oid = oid
+        self.array_oid = array_oid
+
+        self.attnames = [a[0] for a in attrs]
+        self.atttypes = [a[1] for a in attrs]
+        self._create_type(name, self.attnames)
+        self.typecaster = _ext.new_type((oid,), name, self.parse)
+        if array_oid:
+            self.array_typecaster = _ext.new_array_type(
+                (array_oid,), "%sARRAY" % name, self.typecaster)
+        else:
+            self.array_typecaster = None
+
+    def parse(self, s, curs):
+        if s is None:
+            return None
+
+        tokens = self.tokenize(s)
+        if len(tokens) != len(self.atttypes):
+            raise psycopg2.DataError(
+                "expecting %d components for the type %s, %d found instead" %
+                (len(self.atttypes), self.name, len(tokens)))
+
+        values = [curs.cast(oid, token)
+            for oid, token in zip(self.atttypes, tokens)]
+
+        return self.make(values)
+
+    def make(self, values):
+        """Return a new Python object representing the data being casted.
+
+        *values* is the list of attributes, already casted into their Python
+        representation.
+
+        You can subclass this method to :ref:`customize the composite cast
+        <custom-composite>`.
+        """
+
+        return self._ctor(values)
+
+    _re_tokenize = _re.compile(r"""
+  \(? ([,)])                        # an empty token, representing NULL
+| \(? " ((?: [^"] | "")*) " [,)]    # or a quoted string
+| \(? ([^",)]+) [,)]                # or an unquoted string
+    """, _re.VERBOSE)
+
+    _re_undouble = _re.compile(r'(["\\])\1')
+
+    @classmethod
+    def tokenize(self, s):
+        rv = []
+        for m in self._re_tokenize.finditer(s):
+            if m is None:
+                raise psycopg2.InterfaceError("can't parse type: %r" % s)
+            if m.group(1) is not None:
+                rv.append(None)
+            elif m.group(2) is not None:
+                rv.append(self._re_undouble.sub(r"\1", m.group(2)))
+            else:
+                rv.append(m.group(3))
+
+        return rv
+
+    def _create_type(self, name, attnames):
+        self.type = namedtuple(name, attnames)
+        self._ctor = self.type._make
+
+    @classmethod
+    def _from_db(self, name, conn_or_curs):
+        """Return a `CompositeCaster` instance for the type *name*.
+
+        Raise `ProgrammingError` if the type is not found.
+        """
+        conn, curs = _solve_conn_curs(conn_or_curs)
+
+        # Store the transaction status of the connection to revert it after use
+        conn_status = conn.status
+
+        # Use the correct schema
+        if '.' in name:
+            schema, tname = name.split('.', 1)
+        else:
+            tname = name
+            schema = 'public'
+
+        # column typarray not available before PG 8.3
+        typarray = conn.info.server_version >= 80300 and "typarray" or "NULL"
+
+        # get the type oid and attributes
+        curs.execute("""\
+SELECT t.oid, %s, attname, atttypid
+FROM pg_type t
+JOIN pg_namespace ns ON typnamespace = ns.oid
+JOIN pg_attribute a ON attrelid = typrelid
+WHERE typname = %%s AND nspname = %%s
+    AND attnum > 0 AND NOT attisdropped
+ORDER BY attnum;
+""" % typarray, (tname, schema))
+
+        recs = curs.fetchall()
+
+        # revert the status of the connection as before the command
+        if (conn_status != _ext.STATUS_IN_TRANSACTION
+        and not conn.autocommit):
+            conn.rollback()
+
+        if not recs:
+            raise psycopg2.ProgrammingError(
+                "PostgreSQL type '%s' not found" % name)
+
+        type_oid = recs[0][0]
+        array_oid = recs[0][1]
+        type_attrs = [(r[2], r[3]) for r in recs]
+
+        return self(tname, type_oid, type_attrs,
+            array_oid=array_oid, schema=schema)
+
+
+def register_composite(name, conn_or_curs, globally=False, factory=None):
+    """Register a typecaster to convert a composite type into a tuple.
+
+    :param name: the name of a PostgreSQL composite type, e.g. created using
+        the |CREATE TYPE|_ command
+    :param conn_or_curs: a connection or cursor used to find the type oid and
+        components; the typecaster is registered in a scope limited to this
+        object, unless *globally* is set to `!True`
+    :param globally: if `!False` (default) register the typecaster only on
+        *conn_or_curs*, otherwise register it globally
+    :param factory: if specified it should be a `CompositeCaster` subclass: use
+        it to :ref:`customize how to cast composite types <custom-composite>`
+    :return: the registered `CompositeCaster` or *factory* instance
+        responsible for the conversion
+    """
+    if factory is None:
+        factory = CompositeCaster
+
+    caster = factory._from_db(name, conn_or_curs)
+    _ext.register_type(caster.typecaster, not globally and conn_or_curs or None)
+
+    if caster.array_typecaster is not None:
+        _ext.register_type(
+            caster.array_typecaster, not globally and conn_or_curs or None)
+
+    return caster
+
+
+def _paginate(seq, page_size):
+    """Consume an iterable and return it in chunks.
+
+    Every chunk is at most `page_size`. Never return an empty chunk.
+    """
+    page = []
+    it = iter(seq)
+    while True:
+        try:
+            for i in range(page_size):
+                page.append(next(it))
+            yield page
+            page = []
+        except StopIteration:
+            if page:
+                yield page
+            return
+
+
+def execute_batch(cur, sql, argslist, page_size=100):
+    r"""Execute groups of statements in fewer server roundtrips.
+
+    Execute *sql* several times, against all parameters set (sequences or
+    mappings) found in *argslist*.
+
+    The function is semantically similar to
+
+    .. parsed-literal::
+
+        *cur*\.\ `~cursor.executemany`\ (\ *sql*\ , *argslist*\ )
+
+    but has a different implementation: Psycopg will join the statements into
+    fewer multi-statement commands, each one containing at most *page_size*
+    statements, resulting in a reduced number of server roundtrips.
+
+    After the execution of the function the `cursor.rowcount` property will
+    **not** contain a total result.
+
+    """
+    for page in _paginate(argslist, page_size=page_size):
+        sqls = [cur.mogrify(sql, args) for args in page]
+        cur.execute(b";".join(sqls))
+
+
+def execute_values(cur, sql, argslist, template=None, page_size=100, fetch=False):
+    '''Execute a statement using :sql:`VALUES` with a sequence of parameters.
+
+    :param cur: the cursor to use to execute the query.
+
+    :param sql: the query to execute. It must contain a single ``%s``
+        placeholder, which will be replaced by a `VALUES list`__.
+        Example: ``"INSERT INTO mytable (id, f1, f2) VALUES %s"``.
+
+    :param argslist: sequence of sequences or dictionaries with the arguments
+        to send to the query. The type and content must be consistent with
+        *template*.
+
+    :param template: the snippet to merge to every item in *argslist* to
+        compose the query.
+
+        - If the *argslist* items are sequences it should contain positional
+          placeholders (e.g. ``"(%s, %s, %s)"``, or ``"(%s, %s, 42)``" if there
+          are constants value...).
+
+        - If the *argslist* items are mappings it should contain named
+          placeholders (e.g. ``"(%(id)s, %(f1)s, 42)"``).
+
+        If not specified, assume the arguments are sequence and use a simple
+        positional template (i.e.  ``(%s, %s, ...)``), with the number of
+        placeholders sniffed by the first element in *argslist*.
+
+    :param page_size: maximum number of *argslist* items to include in every
+        statement. If there are more items the function will execute more than
+        one statement.
+
+    :param fetch: if `!True` return the query results into a list (like in a
+        `~cursor.fetchall()`).  Useful for queries with :sql:`RETURNING`
+        clause.
+
+    .. __: https://www.postgresql.org/docs/current/static/queries-values.html
+
+    After the execution of the function the `cursor.rowcount` property will
+    **not** contain a total result.
+
+    While :sql:`INSERT` is an obvious candidate for this function it is
+    possible to use it with other statements, for example::
+
+        >>> cur.execute(
+        ... "create table test (id int primary key, v1 int, v2 int)")
+
+        >>> execute_values(cur,
+        ... "INSERT INTO test (id, v1, v2) VALUES %s",
+        ... [(1, 2, 3), (4, 5, 6), (7, 8, 9)])
+
+        >>> execute_values(cur,
+        ... """UPDATE test SET v1 = data.v1 FROM (VALUES %s) AS data (id, v1)
+        ... WHERE test.id = data.id""",
+        ... [(1, 20), (4, 50)])
+
+        >>> cur.execute("select * from test order by id")
+        >>> cur.fetchall()
+        [(1, 20, 3), (4, 50, 6), (7, 8, 9)])
+
+    '''
+    from psycopg2.sql import Composable
+    if isinstance(sql, Composable):
+        sql = sql.as_string(cur)
+
+    # we can't just use sql % vals because vals is bytes: if sql is bytes
+    # there will be some decoding error because of stupid codec used, and Py3
+    # doesn't implement % on bytes.
+    if not isinstance(sql, bytes):
+        sql = sql.encode(_ext.encodings[cur.connection.encoding])
+    pre, post = _split_sql(sql)
+
+    result = [] if fetch else None
+    for page in _paginate(argslist, page_size=page_size):
+        if template is None:
+            template = b'(' + b','.join([b'%s'] * len(page[0])) + b')'
+        parts = pre[:]
+        for args in page:
+            parts.append(cur.mogrify(template, args))
+            parts.append(b',')
+        parts[-1:] = post
+        cur.execute(b''.join(parts))
+        if fetch:
+            result.extend(cur.fetchall())
+
+    return result
+
+
+def _split_sql(sql):
+    """Split *sql* on a single ``%s`` placeholder.
+
+    Split on the %s, perform %% replacement and return pre, post lists of
+    snippets.
+    """
+    curr = pre = []
+    post = []
+    tokens = _re.split(br'(%.)', sql)
+    for token in tokens:
+        if len(token) != 2 or token[:1] != b'%':
+            curr.append(token)
+            continue
+
+        if token[1:] == b's':
+            if curr is pre:
+                curr = post
+            else:
+                raise ValueError(
+                    "the query contains more than one '%s' placeholder")
+        elif token[1:] == b'%':
+            curr.append(b'%')
+        else:
+            raise ValueError("unsupported format character: '%s'"
+                % token[1:].decode('ascii', 'replace'))
+
+    if curr is pre:
+        raise ValueError("the query doesn't contain any '%s' placeholder")
+
+    return pre, post
Index: venv/Lib/site-packages/python_dateutil-2.8.1.dist-info/METADATA
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/venv/Lib/site-packages/python_dateutil-2.8.1.dist-info/METADATA b/venv/Lib/site-packages/python_dateutil-2.8.1.dist-info/METADATA
new file mode 100644
--- /dev/null	(date 1616410447408)
+++ b/venv/Lib/site-packages/python_dateutil-2.8.1.dist-info/METADATA	(date 1616410447408)
@@ -0,0 +1,200 @@
+Metadata-Version: 2.1
+Name: python-dateutil
+Version: 2.8.1
+Summary: Extensions to the standard Python datetime module
+Home-page: https://dateutil.readthedocs.io
+Author: Gustavo Niemeyer
+Author-email: gustavo@niemeyer.net
+Maintainer: Paul Ganssle
+Maintainer-email: dateutil@python.org
+License: Dual License
+Platform: UNKNOWN
+Classifier: Development Status :: 5 - Production/Stable
+Classifier: Intended Audience :: Developers
+Classifier: License :: OSI Approved :: BSD License
+Classifier: License :: OSI Approved :: Apache Software License
+Classifier: Programming Language :: Python
+Classifier: Programming Language :: Python :: 2
+Classifier: Programming Language :: Python :: 2.7
+Classifier: Programming Language :: Python :: 3
+Classifier: Programming Language :: Python :: 3.3
+Classifier: Programming Language :: Python :: 3.4
+Classifier: Programming Language :: Python :: 3.5
+Classifier: Programming Language :: Python :: 3.6
+Classifier: Programming Language :: Python :: 3.7
+Classifier: Programming Language :: Python :: 3.8
+Classifier: Topic :: Software Development :: Libraries
+Requires-Python: !=3.0.*,!=3.1.*,!=3.2.*,>=2.7
+Description-Content-Type: text/x-rst
+Requires-Dist: six (>=1.5)
+
+dateutil - powerful extensions to datetime
+==========================================
+
+|pypi| |support| |licence|
+
+|gitter| |readthedocs|
+
+|travis| |appveyor| |pipelines| |coverage|
+
+.. |pypi| image:: https://img.shields.io/pypi/v/python-dateutil.svg?style=flat-square
+    :target: https://pypi.org/project/python-dateutil/
+    :alt: pypi version
+
+.. |support| image:: https://img.shields.io/pypi/pyversions/python-dateutil.svg?style=flat-square
+    :target: https://pypi.org/project/python-dateutil/
+    :alt: supported Python version
+
+.. |travis| image:: https://img.shields.io/travis/dateutil/dateutil/master.svg?style=flat-square&label=Travis%20Build
+    :target: https://travis-ci.org/dateutil/dateutil
+    :alt: travis build status
+
+.. |appveyor| image:: https://img.shields.io/appveyor/ci/dateutil/dateutil/master.svg?style=flat-square&logo=appveyor
+    :target: https://ci.appveyor.com/project/dateutil/dateutil
+    :alt: appveyor build status
+
+.. |pipelines| image:: https://dev.azure.com/pythondateutilazure/dateutil/_apis/build/status/dateutil.dateutil?branchName=master
+    :target: https://dev.azure.com/pythondateutilazure/dateutil/_build/latest?definitionId=1&branchName=master
+    :alt: azure pipelines build status
+
+.. |coverage| image:: https://codecov.io/github/dateutil/dateutil/coverage.svg?branch=master
+    :target: https://codecov.io/github/dateutil/dateutil?branch=master
+    :alt: Code coverage
+
+.. |gitter| image:: https://badges.gitter.im/dateutil/dateutil.svg
+   :alt: Join the chat at https://gitter.im/dateutil/dateutil
+   :target: https://gitter.im/dateutil/dateutil
+
+.. |licence| image:: https://img.shields.io/pypi/l/python-dateutil.svg?style=flat-square
+    :target: https://pypi.org/project/python-dateutil/
+    :alt: licence
+
+.. |readthedocs| image:: https://img.shields.io/readthedocs/dateutil/latest.svg?style=flat-square&label=Read%20the%20Docs
+   :alt: Read the documentation at https://dateutil.readthedocs.io/en/latest/
+   :target: https://dateutil.readthedocs.io/en/latest/
+
+The `dateutil` module provides powerful extensions to
+the standard `datetime` module, available in Python.
+
+Installation
+============
+`dateutil` can be installed from PyPI using `pip` (note that the package name is
+different from the importable name)::
+
+    pip install python-dateutil
+
+Download
+========
+dateutil is available on PyPI
+https://pypi.org/project/python-dateutil/
+
+The documentation is hosted at:
+https://dateutil.readthedocs.io/en/stable/
+
+Code
+====
+The code and issue tracker are hosted on GitHub:
+https://github.com/dateutil/dateutil/
+
+Features
+========
+
+* Computing of relative deltas (next month, next year,
+  next Monday, last week of month, etc);
+* Computing of relative deltas between two given
+  date and/or datetime objects;
+* Computing of dates based on very flexible recurrence rules,
+  using a superset of the `iCalendar <https://www.ietf.org/rfc/rfc2445.txt>`_
+  specification. Parsing of RFC strings is supported as well.
+* Generic parsing of dates in almost any string format;
+* Timezone (tzinfo) implementations for tzfile(5) format
+  files (/etc/localtime, /usr/share/zoneinfo, etc), TZ
+  environment string (in all known formats), iCalendar
+  format files, given ranges (with help from relative deltas),
+  local machine timezone, fixed offset timezone, UTC timezone,
+  and Windows registry-based time zones.
+* Internal up-to-date world timezone information based on
+  Olson's database.
+* Computing of Easter Sunday dates for any given year,
+  using Western, Orthodox or Julian algorithms;
+* A comprehensive test suite.
+
+Quick example
+=============
+Here's a snapshot, just to give an idea about the power of the
+package. For more examples, look at the documentation.
+
+Suppose you want to know how much time is left, in
+years/months/days/etc, before the next easter happening on a
+year with a Friday 13th in August, and you want to get today's
+date out of the "date" unix system command. Here is the code:
+
+.. code-block:: python3
+
+    >>> from dateutil.relativedelta import *
+    >>> from dateutil.easter import *
+    >>> from dateutil.rrule import *
+    >>> from dateutil.parser import *
+    >>> from datetime import *
+    >>> now = parse("Sat Oct 11 17:13:46 UTC 2003")
+    >>> today = now.date()
+    >>> year = rrule(YEARLY,dtstart=now,bymonth=8,bymonthday=13,byweekday=FR)[0].year
+    >>> rdelta = relativedelta(easter(year), today)
+    >>> print("Today is: %s" % today)
+    Today is: 2003-10-11
+    >>> print("Year with next Aug 13th on a Friday is: %s" % year)
+    Year with next Aug 13th on a Friday is: 2004
+    >>> print("How far is the Easter of that year: %s" % rdelta)
+    How far is the Easter of that year: relativedelta(months=+6)
+    >>> print("And the Easter of that year is: %s" % (today+rdelta))
+    And the Easter of that year is: 2004-04-11
+
+Being exactly 6 months ahead was **really** a coincidence :)
+
+Contributing
+============
+
+We welcome many types of contributions - bug reports, pull requests (code, infrastructure or documentation fixes). For more information about how to contribute to the project, see the ``CONTRIBUTING.md`` file in the repository.
+
+
+Author
+======
+The dateutil module was written by Gustavo Niemeyer <gustavo@niemeyer.net>
+in 2003.
+
+It is maintained by:
+
+* Gustavo Niemeyer <gustavo@niemeyer.net> 2003-2011
+* Tomi Pieviläinen <tomi.pievilainen@iki.fi> 2012-2014
+* Yaron de Leeuw <me@jarondl.net> 2014-2016
+* Paul Ganssle <paul@ganssle.io> 2015-
+
+Starting with version 2.4.1, all source and binary distributions will be signed
+by a PGP key that has, at the very least, been signed by the key which made the
+previous release. A table of release signing keys can be found below:
+
+===========  ============================
+Releases     Signing key fingerprint
+===========  ============================
+2.4.1-       `6B49 ACBA DCF6 BD1C A206 67AB CD54 FCE3 D964 BEFB`_ (|pgp_mirror|_)
+===========  ============================
+
+
+Contact
+=======
+Our mailing list is available at `dateutil@python.org <https://mail.python.org/mailman/listinfo/dateutil>`_. As it is hosted by the PSF, it is subject to the `PSF code of
+conduct <https://www.python.org/psf/codeofconduct/>`_.
+
+License
+=======
+
+All contributions after December 1, 2017 released under dual license - either `Apache 2.0 License <https://www.apache.org/licenses/LICENSE-2.0>`_ or the `BSD 3-Clause License <https://opensource.org/licenses/BSD-3-Clause>`_. Contributions before December 1, 2017 - except those those explicitly relicensed - are released only under the BSD 3-Clause License.
+
+
+.. _6B49 ACBA DCF6 BD1C A206 67AB CD54 FCE3 D964 BEFB:
+   https://pgp.mit.edu/pks/lookup?op=vindex&search=0xCD54FCE3D964BEFB
+
+.. |pgp_mirror| replace:: mirror
+.. _pgp_mirror: https://sks-keyservers.net/pks/lookup?op=vindex&search=0xCD54FCE3D964BEFB
+
+
Index: latest/Lib/site-packages/psycopg2/pool.py
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/latest/Lib/site-packages/psycopg2/pool.py b/latest/Lib/site-packages/psycopg2/pool.py
new file mode 100644
--- /dev/null	(date 1616410447486)
+++ b/latest/Lib/site-packages/psycopg2/pool.py	(date 1616410447486)
@@ -0,0 +1,187 @@
+"""Connection pooling for psycopg2
+
+This module implements thread-safe (and not) connection pools.
+"""
+# psycopg/pool.py - pooling code for psycopg
+#
+# Copyright (C) 2003-2019 Federico Di Gregorio  <fog@debian.org>
+# Copyright (C) 2020 The Psycopg Team
+#
+# psycopg2 is free software: you can redistribute it and/or modify it
+# under the terms of the GNU Lesser General Public License as published
+# by the Free Software Foundation, either version 3 of the License, or
+# (at your option) any later version.
+#
+# In addition, as a special exception, the copyright holders give
+# permission to link this program with the OpenSSL library (or with
+# modified versions of OpenSSL that use the same license as OpenSSL),
+# and distribute linked combinations including the two.
+#
+# You must obey the GNU Lesser General Public License in all respects for
+# all of the code used other than OpenSSL.
+#
+# psycopg2 is distributed in the hope that it will be useful, but WITHOUT
+# ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or
+# FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public
+# License for more details.
+
+import psycopg2
+from psycopg2 import extensions as _ext
+
+
+class PoolError(psycopg2.Error):
+    pass
+
+
+class AbstractConnectionPool(object):
+    """Generic key-based pooling code."""
+
+    def __init__(self, minconn, maxconn, *args, **kwargs):
+        """Initialize the connection pool.
+
+        New 'minconn' connections are created immediately calling 'connfunc'
+        with given parameters. The connection pool will support a maximum of
+        about 'maxconn' connections.
+        """
+        self.minconn = int(minconn)
+        self.maxconn = int(maxconn)
+        self.closed = False
+
+        self._args = args
+        self._kwargs = kwargs
+
+        self._pool = []
+        self._used = {}
+        self._rused = {}    # id(conn) -> key map
+        self._keys = 0
+
+        for i in range(self.minconn):
+            self._connect()
+
+    def _connect(self, key=None):
+        """Create a new connection and assign it to 'key' if not None."""
+        conn = psycopg2.connect(*self._args, **self._kwargs)
+        if key is not None:
+            self._used[key] = conn
+            self._rused[id(conn)] = key
+        else:
+            self._pool.append(conn)
+        return conn
+
+    def _getkey(self):
+        """Return a new unique key."""
+        self._keys += 1
+        return self._keys
+
+    def _getconn(self, key=None):
+        """Get a free connection and assign it to 'key' if not None."""
+        if self.closed:
+            raise PoolError("connection pool is closed")
+        if key is None:
+            key = self._getkey()
+
+        if key in self._used:
+            return self._used[key]
+
+        if self._pool:
+            self._used[key] = conn = self._pool.pop()
+            self._rused[id(conn)] = key
+            return conn
+        else:
+            if len(self._used) == self.maxconn:
+                raise PoolError("connection pool exhausted")
+            return self._connect(key)
+
+    def _putconn(self, conn, key=None, close=False):
+        """Put away a connection."""
+        if self.closed:
+            raise PoolError("connection pool is closed")
+
+        if key is None:
+            key = self._rused.get(id(conn))
+            if key is None:
+                raise PoolError("trying to put unkeyed connection")
+
+        if len(self._pool) < self.minconn and not close:
+            # Return the connection into a consistent state before putting
+            # it back into the pool
+            if not conn.closed:
+                status = conn.info.transaction_status
+                if status == _ext.TRANSACTION_STATUS_UNKNOWN:
+                    # server connection lost
+                    conn.close()
+                elif status != _ext.TRANSACTION_STATUS_IDLE:
+                    # connection in error or in transaction
+                    conn.rollback()
+                    self._pool.append(conn)
+                else:
+                    # regular idle connection
+                    self._pool.append(conn)
+            # If the connection is closed, we just discard it.
+        else:
+            conn.close()
+
+        # here we check for the presence of key because it can happen that a
+        # thread tries to put back a connection after a call to close
+        if not self.closed or key in self._used:
+            del self._used[key]
+            del self._rused[id(conn)]
+
+    def _closeall(self):
+        """Close all connections.
+
+        Note that this can lead to some code fail badly when trying to use
+        an already closed connection. If you call .closeall() make sure
+        your code can deal with it.
+        """
+        if self.closed:
+            raise PoolError("connection pool is closed")
+        for conn in self._pool + list(self._used.values()):
+            try:
+                conn.close()
+            except Exception:
+                pass
+        self.closed = True
+
+
+class SimpleConnectionPool(AbstractConnectionPool):
+    """A connection pool that can't be shared across different threads."""
+
+    getconn = AbstractConnectionPool._getconn
+    putconn = AbstractConnectionPool._putconn
+    closeall = AbstractConnectionPool._closeall
+
+
+class ThreadedConnectionPool(AbstractConnectionPool):
+    """A connection pool that works with the threading module."""
+
+    def __init__(self, minconn, maxconn, *args, **kwargs):
+        """Initialize the threading lock."""
+        import threading
+        AbstractConnectionPool.__init__(
+            self, minconn, maxconn, *args, **kwargs)
+        self._lock = threading.Lock()
+
+    def getconn(self, key=None):
+        """Get a free connection and assign it to 'key' if not None."""
+        self._lock.acquire()
+        try:
+            return self._getconn(key)
+        finally:
+            self._lock.release()
+
+    def putconn(self, conn=None, key=None, close=False):
+        """Put away an unused connection."""
+        self._lock.acquire()
+        try:
+            self._putconn(conn, key, close)
+        finally:
+            self._lock.release()
+
+    def closeall(self):
+        """Close all connections (even the one currently in use.)"""
+        self._lock.acquire()
+        try:
+            self._closeall()
+        finally:
+            self._lock.release()
Index: venv/Lib/site-packages/python_dateutil-2.8.1.dist-info/RECORD
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/venv/Lib/site-packages/python_dateutil-2.8.1.dist-info/RECORD b/venv/Lib/site-packages/python_dateutil-2.8.1.dist-info/RECORD
new file mode 100644
--- /dev/null	(date 1616410447518)
+++ b/venv/Lib/site-packages/python_dateutil-2.8.1.dist-info/RECORD	(date 1616410447518)
@@ -0,0 +1,44 @@
+dateutil/__init__.py,sha256=lXElASqwYGwqlrSWSeX19JwF5Be9tNecDa9ebk-0gmk,222
+dateutil/__pycache__/__init__.cpython-36.pyc,,
+dateutil/__pycache__/_common.cpython-36.pyc,,
+dateutil/__pycache__/_version.cpython-36.pyc,,
+dateutil/__pycache__/easter.cpython-36.pyc,,
+dateutil/__pycache__/relativedelta.cpython-36.pyc,,
+dateutil/__pycache__/rrule.cpython-36.pyc,,
+dateutil/__pycache__/tzwin.cpython-36.pyc,,
+dateutil/__pycache__/utils.cpython-36.pyc,,
+dateutil/_common.py,sha256=77w0yytkrxlYbSn--lDVPUMabUXRR9I3lBv_vQRUqUY,932
+dateutil/_version.py,sha256=U1JNX8P5pUNBtcStwfGyAUIMMHGZXhiTDTVXgAUWxs4,116
+dateutil/easter.py,sha256=0liVsgqSx-NPhaFevOJaYgEbrSu2oQQ2o9m_OEBdc-s,2684
+dateutil/parser/__init__.py,sha256=wWk6GFuxTpjoggCGtgkceJoti4pVjl4_fHQXpNOaSYg,1766
+dateutil/parser/__pycache__/__init__.cpython-36.pyc,,
+dateutil/parser/__pycache__/_parser.cpython-36.pyc,,
+dateutil/parser/__pycache__/isoparser.cpython-36.pyc,,
+dateutil/parser/_parser.py,sha256=F0w8h9txvatnYAmeJ1MMbIAvZHRzy3iFjv-AZqRovNs,58804
+dateutil/parser/isoparser.py,sha256=BeEEqIeqhcgik5Cp1_G5Aztsqayp-MAr3aVqAKo1XRc,13098
+dateutil/relativedelta.py,sha256=GjVxqpAVWnG67rdbf7pkoIlJvQqmju9NSfGCcqblc7U,24904
+dateutil/rrule.py,sha256=dStRcOIj8jul-BurMKguc_IBckY-Qci1K6EYqNW8eUg,66514
+dateutil/tz/__init__.py,sha256=F-Mz13v6jYseklQf9Te9J6nzcLDmq47gORa61K35_FA,444
+dateutil/tz/__pycache__/__init__.cpython-36.pyc,,
+dateutil/tz/__pycache__/_common.cpython-36.pyc,,
+dateutil/tz/__pycache__/_factories.cpython-36.pyc,,
+dateutil/tz/__pycache__/tz.cpython-36.pyc,,
+dateutil/tz/__pycache__/win.cpython-36.pyc,,
+dateutil/tz/_common.py,sha256=cgzDTANsOXvEc86cYF77EsliuSab8Puwpsl5-bX3_S4,12977
+dateutil/tz/_factories.py,sha256=unb6XQNXrPMveksTCU-Ag8jmVZs4SojoPUcAHpWnrvU,2569
+dateutil/tz/tz.py,sha256=npaGnA2M2LGUUerXzAml9rMM-BE771igYFcFETeC3JE,62851
+dateutil/tz/win.py,sha256=xJszWgSwE1xPx_HJj4ZkepyukC_hNy016WMcXhbRaB8,12935
+dateutil/tzwin.py,sha256=7Ar4vdQCnnM0mKR3MUjbIKsZrBVfHgdwsJZc_mGYRew,59
+dateutil/utils.py,sha256=Agvhi7i3HuJdwHYCe9lDS63l_LNFUUlB2hmR3ZKNYwE,1959
+dateutil/zoneinfo/__init__.py,sha256=KYg0pthCMjcp5MXSEiBJn3nMjZeNZav7rlJw5-tz1S4,5889
+dateutil/zoneinfo/__pycache__/__init__.cpython-36.pyc,,
+dateutil/zoneinfo/__pycache__/rebuild.cpython-36.pyc,,
+dateutil/zoneinfo/dateutil-zoneinfo.tar.gz,sha256=6bZJKrN3mhnCqMgQgFSllQNNbtld9AnuPaRIXWoSH4o,153315
+dateutil/zoneinfo/rebuild.py,sha256=2uFJQiW3Fl8fVogrSXisJMpLeHI1zGwpvBFF43QdeF0,1719
+python_dateutil-2.8.1.dist-info/INSTALLER,sha256=zuuue4knoyJ-UwPPXg8fezS7VCrXJQrAP7zeNuwvFQg,4
+python_dateutil-2.8.1.dist-info/LICENSE,sha256=ugD1Gg2SgjtaHN4n2LW50jIeZ-2NqbwWPv-W1eF-V34,2889
+python_dateutil-2.8.1.dist-info/METADATA,sha256=u7pGPxvY3bP0MsvsWab9OeTybTnbLX011vZxRW12I1Y,7988
+python_dateutil-2.8.1.dist-info/RECORD,,
+python_dateutil-2.8.1.dist-info/WHEEL,sha256=8zNYZbwQSXoB9IfXOjPfeNwvAsALAjffgk27FqvCWbo,110
+python_dateutil-2.8.1.dist-info/top_level.txt,sha256=4tjdWkhRZvF7LA_BYe_L9gB2w_p2a-z5y6ArjaRkot8,9
+python_dateutil-2.8.1.dist-info/zip-safe,sha256=AbpHGcgLb-kRsJGnwFEktk7uzpZOCcBY74-YBdrKVGs,1
Index: venv/Lib/site-packages/python_dateutil-2.8.1.dist-info/top_level.txt
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/venv/Lib/site-packages/python_dateutil-2.8.1.dist-info/top_level.txt b/venv/Lib/site-packages/python_dateutil-2.8.1.dist-info/top_level.txt
new file mode 100644
--- /dev/null	(date 1616410447674)
+++ b/venv/Lib/site-packages/python_dateutil-2.8.1.dist-info/top_level.txt	(date 1616410447674)
@@ -0,0 +1,1 @@
+dateutil
Index: latest/Lib/site-packages/psycopg2/sql.py
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/latest/Lib/site-packages/psycopg2/sql.py b/latest/Lib/site-packages/psycopg2/sql.py
new file mode 100644
--- /dev/null	(date 1616410447721)
+++ b/latest/Lib/site-packages/psycopg2/sql.py	(date 1616410447721)
@@ -0,0 +1,456 @@
+"""SQL composition utility module
+"""
+
+# psycopg/sql.py - SQL composition utility module
+#
+# Copyright (C) 2016-2019 Daniele Varrazzo  <daniele.varrazzo@gmail.com>
+# Copyright (C) 2020 The Psycopg Team
+#
+# psycopg2 is free software: you can redistribute it and/or modify it
+# under the terms of the GNU Lesser General Public License as published
+# by the Free Software Foundation, either version 3 of the License, or
+# (at your option) any later version.
+#
+# In addition, as a special exception, the copyright holders give
+# permission to link this program with the OpenSSL library (or with
+# modified versions of OpenSSL that use the same license as OpenSSL),
+# and distribute linked combinations including the two.
+#
+# You must obey the GNU Lesser General Public License in all respects for
+# all of the code used other than OpenSSL.
+#
+# psycopg2 is distributed in the hope that it will be useful, but WITHOUT
+# ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or
+# FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public
+# License for more details.
+
+import string
+
+from psycopg2 import extensions as ext
+from psycopg2.compat import PY3, string_types
+
+
+_formatter = string.Formatter()
+
+
+class Composable(object):
+    """
+    Abstract base class for objects that can be used to compose an SQL string.
+
+    `!Composable` objects can be passed directly to `~cursor.execute()`,
+    `~cursor.executemany()`, `~cursor.copy_expert()` in place of the query
+    string.
+
+    `!Composable` objects can be joined using the ``+`` operator: the result
+    will be a `Composed` instance containing the objects joined. The operator
+    ``*`` is also supported with an integer argument: the result is a
+    `!Composed` instance containing the left argument repeated as many times as
+    requested.
+    """
+    def __init__(self, wrapped):
+        self._wrapped = wrapped
+
+    def __repr__(self):
+        return "%s(%r)" % (self.__class__.__name__, self._wrapped)
+
+    def as_string(self, context):
+        """
+        Return the string value of the object.
+
+        :param context: the context to evaluate the string into.
+        :type context: `connection` or `cursor`
+
+        The method is automatically invoked by `~cursor.execute()`,
+        `~cursor.executemany()`, `~cursor.copy_expert()` if a `!Composable` is
+        passed instead of the query string.
+        """
+        raise NotImplementedError
+
+    def __add__(self, other):
+        if isinstance(other, Composed):
+            return Composed([self]) + other
+        if isinstance(other, Composable):
+            return Composed([self]) + Composed([other])
+        else:
+            return NotImplemented
+
+    def __mul__(self, n):
+        return Composed([self] * n)
+
+    def __eq__(self, other):
+        return type(self) is type(other) and self._wrapped == other._wrapped
+
+    def __ne__(self, other):
+        return not self.__eq__(other)
+
+
+class Composed(Composable):
+    """
+    A `Composable` object made of a sequence of `!Composable`.
+
+    The object is usually created using `!Composable` operators and methods.
+    However it is possible to create a `!Composed` directly specifying a
+    sequence of `!Composable` as arguments.
+
+    Example::
+
+        >>> comp = sql.Composed(
+        ...     [sql.SQL("insert into "), sql.Identifier("table")])
+        >>> print(comp.as_string(conn))
+        insert into "table"
+
+    `!Composed` objects are iterable (so they can be used in `SQL.join` for
+    instance).
+    """
+    def __init__(self, seq):
+        wrapped = []
+        for i in seq:
+            if not isinstance(i, Composable):
+                raise TypeError(
+                    "Composed elements must be Composable, got %r instead" % i)
+            wrapped.append(i)
+
+        super(Composed, self).__init__(wrapped)
+
+    @property
+    def seq(self):
+        """The list of the content of the `!Composed`."""
+        return list(self._wrapped)
+
+    def as_string(self, context):
+        rv = []
+        for i in self._wrapped:
+            rv.append(i.as_string(context))
+        return ''.join(rv)
+
+    def __iter__(self):
+        return iter(self._wrapped)
+
+    def __add__(self, other):
+        if isinstance(other, Composed):
+            return Composed(self._wrapped + other._wrapped)
+        if isinstance(other, Composable):
+            return Composed(self._wrapped + [other])
+        else:
+            return NotImplemented
+
+    def join(self, joiner):
+        """
+        Return a new `!Composed` interposing the *joiner* with the `!Composed` items.
+
+        The *joiner* must be a `SQL` or a string which will be interpreted as
+        an `SQL`.
+
+        Example::
+
+            >>> fields = sql.Identifier('foo') + sql.Identifier('bar')  # a Composed
+            >>> print(fields.join(', ').as_string(conn))
+            "foo", "bar"
+
+        """
+        if isinstance(joiner, string_types):
+            joiner = SQL(joiner)
+        elif not isinstance(joiner, SQL):
+            raise TypeError(
+                "Composed.join() argument must be a string or an SQL")
+
+        return joiner.join(self)
+
+
+class SQL(Composable):
+    """
+    A `Composable` representing a snippet of SQL statement.
+
+    `!SQL` exposes `join()` and `format()` methods useful to create a template
+    where to merge variable parts of a query (for instance field or table
+    names).
+
+    The *string* doesn't undergo any form of escaping, so it is not suitable to
+    represent variable identifiers or values: you should only use it to pass
+    constant strings representing templates or snippets of SQL statements; use
+    other objects such as `Identifier` or `Literal` to represent variable
+    parts.
+
+    Example::
+
+        >>> query = sql.SQL("select {0} from {1}").format(
+        ...    sql.SQL(', ').join([sql.Identifier('foo'), sql.Identifier('bar')]),
+        ...    sql.Identifier('table'))
+        >>> print(query.as_string(conn))
+        select "foo", "bar" from "table"
+    """
+    def __init__(self, string):
+        if not isinstance(string, string_types):
+            raise TypeError("SQL values must be strings")
+        super(SQL, self).__init__(string)
+
+    @property
+    def string(self):
+        """The string wrapped by the `!SQL` object."""
+        return self._wrapped
+
+    def as_string(self, context):
+        return self._wrapped
+
+    def format(self, *args, **kwargs):
+        """
+        Merge `Composable` objects into a template.
+
+        :param `Composable` args: parameters to replace to numbered
+            (``{0}``, ``{1}``) or auto-numbered (``{}``) placeholders
+        :param `Composable` kwargs: parameters to replace to named (``{name}``)
+            placeholders
+        :return: the union of the `!SQL` string with placeholders replaced
+        :rtype: `Composed`
+
+        The method is similar to the Python `str.format()` method: the string
+        template supports auto-numbered (``{}``), numbered (``{0}``,
+        ``{1}``...), and named placeholders (``{name}``), with positional
+        arguments replacing the numbered placeholders and keywords replacing
+        the named ones. However placeholder modifiers (``{0!r}``, ``{0:<10}``)
+        are not supported. Only `!Composable` objects can be passed to the
+        template.
+
+        Example::
+
+            >>> print(sql.SQL("select * from {} where {} = %s")
+            ...     .format(sql.Identifier('people'), sql.Identifier('id'))
+            ...     .as_string(conn))
+            select * from "people" where "id" = %s
+
+            >>> print(sql.SQL("select * from {tbl} where {pkey} = %s")
+            ...     .format(tbl=sql.Identifier('people'), pkey=sql.Identifier('id'))
+            ...     .as_string(conn))
+            select * from "people" where "id" = %s
+
+        """
+        rv = []
+        autonum = 0
+        for pre, name, spec, conv in _formatter.parse(self._wrapped):
+            if spec:
+                raise ValueError("no format specification supported by SQL")
+            if conv:
+                raise ValueError("no format conversion supported by SQL")
+            if pre:
+                rv.append(SQL(pre))
+
+            if name is None:
+                continue
+
+            if name.isdigit():
+                if autonum:
+                    raise ValueError(
+                        "cannot switch from automatic field numbering to manual")
+                rv.append(args[int(name)])
+                autonum = None
+
+            elif not name:
+                if autonum is None:
+                    raise ValueError(
+                        "cannot switch from manual field numbering to automatic")
+                rv.append(args[autonum])
+                autonum += 1
+
+            else:
+                rv.append(kwargs[name])
+
+        return Composed(rv)
+
+    def join(self, seq):
+        """
+        Join a sequence of `Composable`.
+
+        :param seq: the elements to join.
+        :type seq: iterable of `!Composable`
+
+        Use the `!SQL` object's *string* to separate the elements in *seq*.
+        Note that `Composed` objects are iterable too, so they can be used as
+        argument for this method.
+
+        Example::
+
+            >>> snip = sql.SQL(', ').join(
+            ...     sql.Identifier(n) for n in ['foo', 'bar', 'baz'])
+            >>> print(snip.as_string(conn))
+            "foo", "bar", "baz"
+        """
+        rv = []
+        it = iter(seq)
+        try:
+            rv.append(next(it))
+        except StopIteration:
+            pass
+        else:
+            for i in it:
+                rv.append(self)
+                rv.append(i)
+
+        return Composed(rv)
+
+
+class Identifier(Composable):
+    """
+    A `Composable` representing an SQL identifier or a dot-separated sequence.
+
+    Identifiers usually represent names of database objects, such as tables or
+    fields. PostgreSQL identifiers follow `different rules`__ than SQL string
+    literals for escaping (e.g. they use double quotes instead of single).
+
+    .. __: https://www.postgresql.org/docs/current/static/sql-syntax-lexical.html# \
+        SQL-SYNTAX-IDENTIFIERS
+
+    Example::
+
+        >>> t1 = sql.Identifier("foo")
+        >>> t2 = sql.Identifier("ba'r")
+        >>> t3 = sql.Identifier('ba"z')
+        >>> print(sql.SQL(', ').join([t1, t2, t3]).as_string(conn))
+        "foo", "ba'r", "ba""z"
+
+    Multiple strings can be passed to the object to represent a qualified name,
+    i.e. a dot-separated sequence of identifiers.
+
+    Example::
+
+        >>> query = sql.SQL("select {} from {}").format(
+        ...     sql.Identifier("table", "field"),
+        ...     sql.Identifier("schema", "table"))
+        >>> print(query.as_string(conn))
+        select "table"."field" from "schema"."table"
+
+    """
+    def __init__(self, *strings):
+        if not strings:
+            raise TypeError("Identifier cannot be empty")
+
+        for s in strings:
+            if not isinstance(s, string_types):
+                raise TypeError("SQL identifier parts must be strings")
+
+        super(Identifier, self).__init__(strings)
+
+    @property
+    def strings(self):
+        """A tuple with the strings wrapped by the `Identifier`."""
+        return self._wrapped
+
+    @property
+    def string(self):
+        """The string wrapped by the `Identifier`.
+        """
+        if len(self._wrapped) == 1:
+            return self._wrapped[0]
+        else:
+            raise AttributeError(
+                "the Identifier wraps more than one than one string")
+
+    def __repr__(self):
+        return "%s(%s)" % (
+            self.__class__.__name__,
+            ', '.join(map(repr, self._wrapped)))
+
+    def as_string(self, context):
+        return '.'.join(ext.quote_ident(s, context) for s in self._wrapped)
+
+
+class Literal(Composable):
+    """
+    A `Composable` representing an SQL value to include in a query.
+
+    Usually you will want to include placeholders in the query and pass values
+    as `~cursor.execute()` arguments. If however you really really need to
+    include a literal value in the query you can use this object.
+
+    The string returned by `!as_string()` follows the normal :ref:`adaptation
+    rules <python-types-adaptation>` for Python objects.
+
+    Example::
+
+        >>> s1 = sql.Literal("foo")
+        >>> s2 = sql.Literal("ba'r")
+        >>> s3 = sql.Literal(42)
+        >>> print(sql.SQL(', ').join([s1, s2, s3]).as_string(conn))
+        'foo', 'ba''r', 42
+
+    """
+    @property
+    def wrapped(self):
+        """The object wrapped by the `!Literal`."""
+        return self._wrapped
+
+    def as_string(self, context):
+        # is it a connection or cursor?
+        if isinstance(context, ext.connection):
+            conn = context
+        elif isinstance(context, ext.cursor):
+            conn = context.connection
+        else:
+            raise TypeError("context must be a connection or a cursor")
+
+        a = ext.adapt(self._wrapped)
+        if hasattr(a, 'prepare'):
+            a.prepare(conn)
+
+        rv = a.getquoted()
+        if PY3 and isinstance(rv, bytes):
+            rv = rv.decode(ext.encodings[conn.encoding])
+
+        return rv
+
+
+class Placeholder(Composable):
+    """A `Composable` representing a placeholder for query parameters.
+
+    If the name is specified, generate a named placeholder (e.g. ``%(name)s``),
+    otherwise generate a positional placeholder (e.g. ``%s``).
+
+    The object is useful to generate SQL queries with a variable number of
+    arguments.
+
+    Examples::
+
+        >>> names = ['foo', 'bar', 'baz']
+
+        >>> q1 = sql.SQL("insert into table ({}) values ({})").format(
+        ...     sql.SQL(', ').join(map(sql.Identifier, names)),
+        ...     sql.SQL(', ').join(sql.Placeholder() * len(names)))
+        >>> print(q1.as_string(conn))
+        insert into table ("foo", "bar", "baz") values (%s, %s, %s)
+
+        >>> q2 = sql.SQL("insert into table ({}) values ({})").format(
+        ...     sql.SQL(', ').join(map(sql.Identifier, names)),
+        ...     sql.SQL(', ').join(map(sql.Placeholder, names)))
+        >>> print(q2.as_string(conn))
+        insert into table ("foo", "bar", "baz") values (%(foo)s, %(bar)s, %(baz)s)
+
+    """
+
+    def __init__(self, name=None):
+        if isinstance(name, string_types):
+            if ')' in name:
+                raise ValueError("invalid name: %r" % name)
+
+        elif name is not None:
+            raise TypeError("expected string or None as name, got %r" % name)
+
+        super(Placeholder, self).__init__(name)
+
+    @property
+    def name(self):
+        """The name of the `!Placeholder`."""
+        return self._wrapped
+
+    def __repr__(self):
+        return "Placeholder(%r)" % (
+            self._wrapped if self._wrapped is not None else '',)
+
+    def as_string(self, context):
+        if self._wrapped is not None:
+            return "%%(%s)s" % self._wrapped
+        else:
+            return "%s"
+
+
+# Literals
+NULL = SQL("NULL")
+DEFAULT = SQL("DEFAULT")
Index: venv/Lib/site-packages/python_dateutil-2.8.1.dist-info/WHEEL
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/venv/Lib/site-packages/python_dateutil-2.8.1.dist-info/WHEEL b/venv/Lib/site-packages/python_dateutil-2.8.1.dist-info/WHEEL
new file mode 100644
--- /dev/null	(date 1616410447783)
+++ b/venv/Lib/site-packages/python_dateutil-2.8.1.dist-info/WHEEL	(date 1616410447783)
@@ -0,0 +1,6 @@
+Wheel-Version: 1.0
+Generator: bdist_wheel (0.33.6)
+Root-Is-Purelib: true
+Tag: py2-none-any
+Tag: py3-none-any
+
Index: latest/Lib/site-packages/psycopg2/tz.py
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/latest/Lib/site-packages/psycopg2/tz.py b/latest/Lib/site-packages/psycopg2/tz.py
new file mode 100644
--- /dev/null	(date 1616410447830)
+++ b/latest/Lib/site-packages/psycopg2/tz.py	(date 1616410447830)
@@ -0,0 +1,139 @@
+"""tzinfo implementations for psycopg2
+
+This module holds two different tzinfo implementations that can be used as
+the 'tzinfo' argument to datetime constructors, directly passed to psycopg
+functions or used to set the .tzinfo_factory attribute in cursors.
+"""
+# psycopg/tz.py - tzinfo implementation
+#
+# Copyright (C) 2003-2019 Federico Di Gregorio  <fog@debian.org>
+# Copyright (C) 2020 The Psycopg Team
+#
+# psycopg2 is free software: you can redistribute it and/or modify it
+# under the terms of the GNU Lesser General Public License as published
+# by the Free Software Foundation, either version 3 of the License, or
+# (at your option) any later version.
+#
+# In addition, as a special exception, the copyright holders give
+# permission to link this program with the OpenSSL library (or with
+# modified versions of OpenSSL that use the same license as OpenSSL),
+# and distribute linked combinations including the two.
+#
+# You must obey the GNU Lesser General Public License in all respects for
+# all of the code used other than OpenSSL.
+#
+# psycopg2 is distributed in the hope that it will be useful, but WITHOUT
+# ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or
+# FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public
+# License for more details.
+
+import datetime
+import time
+
+ZERO = datetime.timedelta(0)
+
+
+class FixedOffsetTimezone(datetime.tzinfo):
+    """Fixed offset in minutes east from UTC.
+
+    This is exactly the implementation__ found in Python 2.3.x documentation,
+    with a small change to the `!__init__()` method to allow for pickling
+    and a default name in the form ``sHH:MM`` (``s`` is the sign.).
+
+    The implementation also caches instances. During creation, if a
+    FixedOffsetTimezone instance has previously been created with the same
+    offset and name that instance will be returned. This saves memory and
+    improves comparability.
+
+    .. __: https://docs.python.org/library/datetime.html
+    """
+    _name = None
+    _offset = ZERO
+
+    _cache = {}
+
+    def __init__(self, offset=None, name=None):
+        if offset is not None:
+            self._offset = datetime.timedelta(minutes=offset)
+        if name is not None:
+            self._name = name
+
+    def __new__(cls, offset=None, name=None):
+        """Return a suitable instance created earlier if it exists
+        """
+        key = (offset, name)
+        try:
+            return cls._cache[key]
+        except KeyError:
+            tz = super(FixedOffsetTimezone, cls).__new__(cls, offset, name)
+            cls._cache[key] = tz
+            return tz
+
+    def __repr__(self):
+        offset_mins = self._offset.seconds // 60 + self._offset.days * 24 * 60
+        return "psycopg2.tz.FixedOffsetTimezone(offset=%r, name=%r)" \
+            % (offset_mins, self._name)
+
+    def __getinitargs__(self):
+        offset_mins = self._offset.seconds // 60 + self._offset.days * 24 * 60
+        return offset_mins, self._name
+
+    def utcoffset(self, dt):
+        return self._offset
+
+    def tzname(self, dt):
+        if self._name is not None:
+            return self._name
+        else:
+            seconds = self._offset.seconds + self._offset.days * 86400
+            hours, seconds = divmod(seconds, 3600)
+            minutes = seconds / 60
+            if minutes:
+                return "%+03d:%d" % (hours, minutes)
+            else:
+                return "%+03d" % hours
+
+    def dst(self, dt):
+        return ZERO
+
+
+STDOFFSET = datetime.timedelta(seconds=-time.timezone)
+if time.daylight:
+    DSTOFFSET = datetime.timedelta(seconds=-time.altzone)
+else:
+    DSTOFFSET = STDOFFSET
+DSTDIFF = DSTOFFSET - STDOFFSET
+
+
+class LocalTimezone(datetime.tzinfo):
+    """Platform idea of local timezone.
+
+    This is the exact implementation from the Python 2.3 documentation.
+    """
+    def utcoffset(self, dt):
+        if self._isdst(dt):
+            return DSTOFFSET
+        else:
+            return STDOFFSET
+
+    def dst(self, dt):
+        if self._isdst(dt):
+            return DSTDIFF
+        else:
+            return ZERO
+
+    def tzname(self, dt):
+        return time.tzname[self._isdst(dt)]
+
+    def _isdst(self, dt):
+        tt = (dt.year, dt.month, dt.day,
+              dt.hour, dt.minute, dt.second,
+              dt.weekday(), 0, -1)
+        stamp = time.mktime(tt)
+        tt = time.localtime(stamp)
+        return tt.tm_isdst > 0
+
+
+LOCAL = LocalTimezone()
+
+# TODO: pre-generate some interesting time zones?
Index: venv/Lib/site-packages/python_dateutil-2.8.1.dist-info/zip-safe
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/venv/Lib/site-packages/python_dateutil-2.8.1.dist-info/zip-safe b/venv/Lib/site-packages/python_dateutil-2.8.1.dist-info/zip-safe
new file mode 100644
--- /dev/null	(date 1616410447885)
+++ b/venv/Lib/site-packages/python_dateutil-2.8.1.dist-info/zip-safe	(date 1616410447885)
@@ -0,0 +1,1 @@
+
Index: latest/Lib/site-packages/psycopg2/_ipaddress.py
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/latest/Lib/site-packages/psycopg2/_ipaddress.py b/latest/Lib/site-packages/psycopg2/_ipaddress.py
new file mode 100644
--- /dev/null	(date 1616410448169)
+++ b/latest/Lib/site-packages/psycopg2/_ipaddress.py	(date 1616410448169)
@@ -0,0 +1,91 @@
+"""Implementation of the ipaddres-based network types adaptation
+"""
+
+# psycopg/_ipaddress.py - Ipaddres-based network types adaptation
+#
+# Copyright (C) 2016-2019 Daniele Varrazzo  <daniele.varrazzo@gmail.com>
+# Copyright (C) 2020 The Psycopg Team
+#
+# psycopg2 is free software: you can redistribute it and/or modify it
+# under the terms of the GNU Lesser General Public License as published
+# by the Free Software Foundation, either version 3 of the License, or
+# (at your option) any later version.
+#
+# In addition, as a special exception, the copyright holders give
+# permission to link this program with the OpenSSL library (or with
+# modified versions of OpenSSL that use the same license as OpenSSL),
+# and distribute linked combinations including the two.
+#
+# You must obey the GNU Lesser General Public License in all respects for
+# all of the code used other than OpenSSL.
+#
+# psycopg2 is distributed in the hope that it will be useful, but WITHOUT
+# ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or
+# FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public
+# License for more details.
+
+from psycopg2.extensions import (
+    new_type, new_array_type, register_type, register_adapter, QuotedString)
+from psycopg2.compat import text_type
+
+# The module is imported on register_ipaddress
+ipaddress = None
+
+# The typecasters are created only once
+_casters = None
+
+
+def register_ipaddress(conn_or_curs=None):
+    """
+    Register conversion support between `ipaddress` objects and `network types`__.
+
+    :param conn_or_curs: the scope where to register the type casters.
+        If `!None` register them globally.
+
+    After the function is called, PostgreSQL :sql:`inet` values will be
+    converted into `~ipaddress.IPv4Interface` or `~ipaddress.IPv6Interface`
+    objects, :sql:`cidr` values into into `~ipaddress.IPv4Network` or
+    `~ipaddress.IPv6Network`.
+
+    .. __: https://www.postgresql.org/docs/current/static/datatype-net-types.html
+    """
+    global ipaddress
+    import ipaddress
+
+    global _casters
+    if _casters is None:
+        _casters = _make_casters()
+
+    for c in _casters:
+        register_type(c, conn_or_curs)
+
+    for t in [ipaddress.IPv4Interface, ipaddress.IPv6Interface,
+              ipaddress.IPv4Network, ipaddress.IPv6Network]:
+        register_adapter(t, adapt_ipaddress)
+
+
+def _make_casters():
+    inet = new_type((869,), 'INET', cast_interface)
+    ainet = new_array_type((1041,), 'INET[]', inet)
+
+    cidr = new_type((650,), 'CIDR', cast_network)
+    acidr = new_array_type((651,), 'CIDR[]', cidr)
+
+    return [inet, ainet, cidr, acidr]
+
+
+def cast_interface(s, cur=None):
+    if s is None:
+        return None
+    # Py2 version force the use of unicode. meh.
+    return ipaddress.ip_interface(text_type(s))
+
+
+def cast_network(s, cur=None):
+    if s is None:
+        return None
+    return ipaddress.ip_network(text_type(s))
+
+
+def adapt_ipaddress(obj):
+    return QuotedString(str(obj))
Index: latest/Lib/site-packages/psycopg2/_json.py
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/latest/Lib/site-packages/psycopg2/_json.py b/latest/Lib/site-packages/psycopg2/_json.py
new file mode 100644
--- /dev/null	(date 1616410448200)
+++ b/latest/Lib/site-packages/psycopg2/_json.py	(date 1616410448200)
@@ -0,0 +1,204 @@
+"""Implementation of the JSON adaptation objects
+
+This module exists to avoid a circular import problem: pyscopg2.extras depends
+on psycopg2.extension, so I can't create the default JSON typecasters in
+extensions importing register_json from extras.
+"""
+
+# psycopg/_json.py - Implementation of the JSON adaptation objects
+#
+# Copyright (C) 2012-2019 Daniele Varrazzo  <daniele.varrazzo@gmail.com>
+# Copyright (C) 2020 The Psycopg Team
+#
+# psycopg2 is free software: you can redistribute it and/or modify it
+# under the terms of the GNU Lesser General Public License as published
+# by the Free Software Foundation, either version 3 of the License, or
+# (at your option) any later version.
+#
+# In addition, as a special exception, the copyright holders give
+# permission to link this program with the OpenSSL library (or with
+# modified versions of OpenSSL that use the same license as OpenSSL),
+# and distribute linked combinations including the two.
+#
+# You must obey the GNU Lesser General Public License in all respects for
+# all of the code used other than OpenSSL.
+#
+# psycopg2 is distributed in the hope that it will be useful, but WITHOUT
+# ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or
+# FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public
+# License for more details.
+
+import json
+
+from psycopg2._psycopg import ISQLQuote, QuotedString
+from psycopg2._psycopg import new_type, new_array_type, register_type
+from psycopg2.compat import PY2
+
+
+# oids from PostgreSQL 9.2
+JSON_OID = 114
+JSONARRAY_OID = 199
+
+# oids from PostgreSQL 9.4
+JSONB_OID = 3802
+JSONBARRAY_OID = 3807
+
+
+class Json(object):
+    """
+    An `~psycopg2.extensions.ISQLQuote` wrapper to adapt a Python object to
+    :sql:`json` data type.
+
+    `!Json` can be used to wrap any object supported by the provided *dumps*
+    function. If none is provided, the standard :py:func:`json.dumps()` is
+    used.
+
+    """
+    def __init__(self, adapted, dumps=None):
+        self.adapted = adapted
+        self._conn = None
+        self._dumps = dumps or json.dumps
+
+    def __conform__(self, proto):
+        if proto is ISQLQuote:
+            return self
+
+    def dumps(self, obj):
+        """Serialize *obj* in JSON format.
+
+        The default is to call `!json.dumps()` or the *dumps* function
+        provided in the constructor. You can override this method to create a
+        customized JSON wrapper.
+        """
+        return self._dumps(obj)
+
+    def prepare(self, conn):
+        self._conn = conn
+
+    def getquoted(self):
+        s = self.dumps(self.adapted)
+        qs = QuotedString(s)
+        if self._conn is not None:
+            qs.prepare(self._conn)
+        return qs.getquoted()
+
+    if PY2:
+        def __str__(self):
+            return self.getquoted()
+    else:
+        def __str__(self):
+            # getquoted is binary in Py3
+            return self.getquoted().decode('ascii', 'replace')
+
+
+def register_json(conn_or_curs=None, globally=False, loads=None,
+                  oid=None, array_oid=None, name='json'):
+    """Create and register typecasters converting :sql:`json` type to Python objects.
+
+    :param conn_or_curs: a connection or cursor used to find the :sql:`json`
+        and :sql:`json[]` oids; the typecasters are registered in a scope
+        limited to this object, unless *globally* is set to `!True`. It can be
+        `!None` if the oids are provided
+    :param globally: if `!False` register the typecasters only on
+        *conn_or_curs*, otherwise register them globally
+    :param loads: the function used to parse the data into a Python object. If
+        `!None` use `!json.loads()`, where `!json` is the module chosen
+        according to the Python version (see above)
+    :param oid: the OID of the :sql:`json` type if known; If not, it will be
+        queried on *conn_or_curs*
+    :param array_oid: the OID of the :sql:`json[]` array type if known;
+        if not, it will be queried on *conn_or_curs*
+    :param name: the name of the data type to look for in *conn_or_curs*
+
+    The connection or cursor passed to the function will be used to query the
+    database and look for the OID of the :sql:`json` type (or an alternative
+    type if *name* if provided). No query is performed if *oid* and *array_oid*
+    are provided.  Raise `~psycopg2.ProgrammingError` if the type is not found.
+
+    """
+    if oid is None:
+        oid, array_oid = _get_json_oids(conn_or_curs, name)
+
+    JSON, JSONARRAY = _create_json_typecasters(
+        oid, array_oid, loads=loads, name=name.upper())
+
+    register_type(JSON, not globally and conn_or_curs or None)
+
+    if JSONARRAY is not None:
+        register_type(JSONARRAY, not globally and conn_or_curs or None)
+
+    return JSON, JSONARRAY
+
+
+def register_default_json(conn_or_curs=None, globally=False, loads=None):
+    """
+    Create and register :sql:`json` typecasters for PostgreSQL 9.2 and following.
+
+    Since PostgreSQL 9.2 :sql:`json` is a builtin type, hence its oid is known
+    and fixed. This function allows specifying a customized *loads* function
+    for the default :sql:`json` type without querying the database.
+    All the parameters have the same meaning of `register_json()`.
+    """
+    return register_json(conn_or_curs=conn_or_curs, globally=globally,
+        loads=loads, oid=JSON_OID, array_oid=JSONARRAY_OID)
+
+
+def register_default_jsonb(conn_or_curs=None, globally=False, loads=None):
+    """
+    Create and register :sql:`jsonb` typecasters for PostgreSQL 9.4 and following.
+
+    As in `register_default_json()`, the function allows to register a
+    customized *loads* function for the :sql:`jsonb` type at its known oid for
+    PostgreSQL 9.4 and following versions.  All the parameters have the same
+    meaning of `register_json()`.
+    """
+    return register_json(conn_or_curs=conn_or_curs, globally=globally,
+        loads=loads, oid=JSONB_OID, array_oid=JSONBARRAY_OID, name='jsonb')
+
+
+def _create_json_typecasters(oid, array_oid, loads=None, name='JSON'):
+    """Create typecasters for json data type."""
+    if loads is None:
+        loads = json.loads
+
+    def typecast_json(s, cur):
+        if s is None:
+            return None
+        return loads(s)
+
+    JSON = new_type((oid, ), name, typecast_json)
+    if array_oid is not None:
+        JSONARRAY = new_array_type((array_oid, ), "%sARRAY" % name, JSON)
+    else:
+        JSONARRAY = None
+
+    return JSON, JSONARRAY
+
+
+def _get_json_oids(conn_or_curs, name='json'):
+    # lazy imports
+    from psycopg2.extensions import STATUS_IN_TRANSACTION
+    from psycopg2.extras import _solve_conn_curs
+
+    conn, curs = _solve_conn_curs(conn_or_curs)
+
+    # Store the transaction status of the connection to revert it after use
+    conn_status = conn.status
+
+    # column typarray not available before PG 8.3
+    typarray = conn.info.server_version >= 80300 and "typarray" or "NULL"
+
+    # get the oid for the hstore
+    curs.execute(
+        "SELECT t.oid, %s FROM pg_type t WHERE t.typname = %%s;"
+        % typarray, (name,))
+    r = curs.fetchone()
+
+    # revert the status of the connection as before the command
+    if conn_status != STATUS_IN_TRANSACTION and not conn.autocommit:
+        conn.rollback()
+
+    if not r:
+        raise conn.ProgrammingError("%s data type not found" % name)
+
+    return r
Index: venv/Lib/site-packages/ultimate_sitemap_parser-0.5.dist-info/INSTALLER
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/venv/Lib/site-packages/ultimate_sitemap_parser-0.5.dist-info/INSTALLER b/venv/Lib/site-packages/ultimate_sitemap_parser-0.5.dist-info/INSTALLER
new file mode 100644
--- /dev/null	(date 1616410448468)
+++ b/venv/Lib/site-packages/ultimate_sitemap_parser-0.5.dist-info/INSTALLER	(date 1616410448468)
@@ -0,0 +1,1 @@
+pip
Index: venv/Lib/site-packages/ultimate_sitemap_parser-0.5.dist-info/LICENSE.txt
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/venv/Lib/site-packages/ultimate_sitemap_parser-0.5.dist-info/LICENSE.txt b/venv/Lib/site-packages/ultimate_sitemap_parser-0.5.dist-info/LICENSE.txt
new file mode 100644
--- /dev/null	(date 1616410448614)
+++ b/venv/Lib/site-packages/ultimate_sitemap_parser-0.5.dist-info/LICENSE.txt	(date 1616410448614)
@@ -0,0 +1,11 @@
+Copyright (C) 2018 Linas Valiukas, Hal Roberts, 2018 Media Cloud project
+
+This program is free software: you can redistribute it and/or modify
+it under the terms of the GNU General Public License as published by
+the Free Software Foundation, either version 3 of the License, or
+any later version.
+
+This program is distributed in the hope that it will be useful,
+but WITHOUT ANY WARRANTY; without even the implied warranty of
+MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+GNU General Public License for more details <http://www.gnu.org/licenses/>.
Index: latest/Lib/site-packages/psycopg2/_lru_cache.py
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/latest/Lib/site-packages/psycopg2/_lru_cache.py b/latest/Lib/site-packages/psycopg2/_lru_cache.py
new file mode 100644
--- /dev/null	(date 1616410448661)
+++ b/latest/Lib/site-packages/psycopg2/_lru_cache.py	(date 1616410448661)
@@ -0,0 +1,104 @@
+"""
+LRU cache implementation for Python 2.7
+
+Ported from http://code.activestate.com/recipes/578078/ and simplified for our
+use (only support maxsize > 0 and positional arguments).
+"""
+
+from collections import namedtuple
+from functools import update_wrapper
+from threading import RLock
+
+_CacheInfo = namedtuple("CacheInfo", ["hits", "misses", "maxsize", "currsize"])
+
+
+def lru_cache(maxsize=100):
+    """Least-recently-used cache decorator.
+
+    Arguments to the cached function must be hashable.
+
+    See:  http://en.wikipedia.org/wiki/Cache_algorithms#Least_Recently_Used
+
+    """
+    def decorating_function(user_function):
+
+        cache = dict()
+        stats = [0, 0]                  # make statistics updateable non-locally
+        HITS, MISSES = 0, 1             # names for the stats fields
+        cache_get = cache.get           # bound method to lookup key or return None
+        _len = len                      # localize the global len() function
+        lock = RLock()                  # linkedlist updates aren't threadsafe
+        root = []                       # root of the circular doubly linked list
+        root[:] = [root, root, None, None]      # initialize by pointing to self
+        nonlocal_root = [root]                  # make updateable non-locally
+        PREV, NEXT, KEY, RESULT = 0, 1, 2, 3    # names for the link fields
+
+        assert maxsize and maxsize > 0, "maxsize %s not supported" % maxsize
+
+        def wrapper(*args):
+            # size limited caching that tracks accesses by recency
+            key = args
+            with lock:
+                link = cache_get(key)
+                if link is not None:
+                    # record recent use of the key by moving it to the
+                    # front of the list
+                    root, = nonlocal_root
+                    link_prev, link_next, key, result = link
+                    link_prev[NEXT] = link_next
+                    link_next[PREV] = link_prev
+                    last = root[PREV]
+                    last[NEXT] = root[PREV] = link
+                    link[PREV] = last
+                    link[NEXT] = root
+                    stats[HITS] += 1
+                    return result
+            result = user_function(*args)
+            with lock:
+                root, = nonlocal_root
+                if key in cache:
+                    # getting here means that this same key was added to the
+                    # cache while the lock was released.  since the link
+                    # update is already done, we need only return the
+                    # computed result and update the count of misses.
+                    pass
+                elif _len(cache) >= maxsize:
+                    # use the old root to store the new key and result
+                    oldroot = root
+                    oldroot[KEY] = key
+                    oldroot[RESULT] = result
+                    # empty the oldest link and make it the new root
+                    root = nonlocal_root[0] = oldroot[NEXT]
+                    oldkey = root[KEY]
+                    # oldvalue = root[RESULT]
+                    root[KEY] = root[RESULT] = None
+                    # now update the cache dictionary for the new links
+                    del cache[oldkey]
+                    cache[key] = oldroot
+                else:
+                    # put result in a new link at the front of the list
+                    last = root[PREV]
+                    link = [last, root, key, result]
+                    last[NEXT] = root[PREV] = cache[key] = link
+                stats[MISSES] += 1
+            return result
+
+        def cache_info():
+            """Report cache statistics"""
+            with lock:
+                return _CacheInfo(stats[HITS], stats[MISSES], maxsize, len(cache))
+
+        def cache_clear():
+            """Clear the cache and cache statistics"""
+            with lock:
+                cache.clear()
+                root = nonlocal_root[0]
+                root[:] = [root, root, None, None]
+                stats[:] = [0, 0]
+
+        wrapper.__wrapped__ = user_function
+        wrapper.cache_info = cache_info
+        wrapper.cache_clear = cache_clear
+        return update_wrapper(wrapper, user_function)
+
+    return decorating_function
Index: venv/Lib/site-packages/ultimate_sitemap_parser-0.5.dist-info/METADATA
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/venv/Lib/site-packages/ultimate_sitemap_parser-0.5.dist-info/METADATA b/venv/Lib/site-packages/ultimate_sitemap_parser-0.5.dist-info/METADATA
new file mode 100644
--- /dev/null	(date 1616410448677)
+++ b/venv/Lib/site-packages/ultimate_sitemap_parser-0.5.dist-info/METADATA	(date 1616410448677)
@@ -0,0 +1,106 @@
+Metadata-Version: 2.1
+Name: ultimate-sitemap-parser
+Version: 0.5
+Summary: Ultimate Sitemap Parser
+Home-page: https://github.com/berkmancenter/mediacloud-ultimate_sitemap_parser
+Author: Linas Valiukas, Hal Roberts, Media Cloud project
+Author-email: linas@media.mit.edu, hroberts@cyber.law.harvard.edu
+License: GPLv3+
+Keywords: sitemap sitemap-xml parser
+Platform: UNKNOWN
+Classifier: Development Status :: 3 - Alpha
+Classifier: Intended Audience :: Developers
+Classifier: Intended Audience :: Information Technology
+Classifier: License :: OSI Approved :: GNU General Public License v3 or later (GPLv3+)
+Classifier: Programming Language :: Python
+Classifier: Operating System :: OS Independent
+Classifier: Programming Language :: Python :: 3.5
+Classifier: Programming Language :: Python :: 3.6
+Classifier: Programming Language :: Python :: 3.7
+Classifier: Programming Language :: Python :: 3.8
+Classifier: Programming Language :: Python :: 3 :: Only
+Classifier: Programming Language :: Python :: Implementation :: PyPy
+Classifier: Topic :: Internet :: WWW/HTTP :: Indexing/Search
+Classifier: Topic :: Text Processing :: Indexing
+Classifier: Topic :: Text Processing :: Markup :: XML
+Requires-Python: >=3.5
+Requires-Dist: python-dateutil (<3.0.0,>=2.1)
+Requires-Dist: requests (>=2.2.1)
+Provides-Extra: test
+Requires-Dist: requests-mock (<2.0,>=1.6.0) ; extra == 'test'
+Requires-Dist: pytest (>=2.8) ; extra == 'test'
+
+.. image:: https://travis-ci.org/berkmancenter/mediacloud-ultimate_sitemap_parser.svg?branch=develop
+    :target: https://travis-ci.org/berkmancenter/mediacloud-ultimate_sitemap_parser
+    :alt: Build Status
+
+.. image:: https://readthedocs.org/projects/ultimate-sitemap-parser/badge/?version=latest
+    :target: https://ultimate-sitemap-parser.readthedocs.io/en/latest/?badge=latest
+    :alt: Documentation Status
+
+.. image:: https://coveralls.io/repos/github/berkmancenter/mediacloud-ultimate_sitemap_parser/badge.svg?branch=develop
+    :target: https://coveralls.io/github/berkmancenter/mediacloud-ultimate_sitemap_parser?branch=develop
+    :alt: Coverage Status
+
+.. image:: https://badge.fury.io/py/ultimate-sitemap-parser.svg
+    :target: https://badge.fury.io/py/ultimate-sitemap-parser
+    :alt: PyPI package
+
+
+Website sitemap parser for Python 3.5+.
+
+
+Features
+========
+
+- Supports all sitemap formats:
+
+  - `XML sitemaps <https://www.sitemaps.org/protocol.html#xmlTagDefinitions>`_
+  - `Google News sitemaps <https://support.google.com/news/publisher-center/answer/74288?hl=en>`_
+  - `plain text sitemaps <https://www.sitemaps.org/protocol.html#otherformats>`_
+  - `RSS 2.0 / Atom 0.3 / Atom 1.0 sitemaps <https://www.sitemaps.org/protocol.html#otherformats>`_
+  - `Sitemaps linked from robots.txt <https://developers.google.com/search/reference/robots_txt#sitemap>`_
+
+- Field-tested with ~1 million URLs as part of the `Media Cloud project <https://mediacloud.org/>`_
+- Error-tolerant with more common sitemap bugs
+- Tries to find sitemaps not listed in ``robots.txt``
+- Uses fast and memory efficient Expat XML parsing
+- Doesn't consume much memory even with massive sitemap hierarchies
+- Provides a generated sitemap tree as easy to use object tree
+- Supports using a custom web client
+- Uses a small number of actively maintained third-party modules
+- Reasonably tested
+
+
+Installation
+============
+
+.. code:: sh
+
+    pip install ultimate_sitemap_parser
+
+
+Usage
+=====
+
+.. code:: python
+
+    from usp.tree import sitemap_tree_for_homepage
+
+    tree = sitemap_tree_for_homepage('https://www.nytimes.com/')
+    print(tree)
+
+``sitemap_tree_for_homepage()`` will return a tree of ``AbstractSitemap`` subclass objects that represent the sitemap
+hierarchy found on the website; see a `reference of AbstractSitemap subclasses <https://ultimate-sitemap-parser.readthedocs.io/en/latest/usp.objects.html#module-usp.objects.sitemap>`_.
+
+If you'd like to just list all the pages found in all of the sitemaps within the website, consider using ``all_pages()`` method:
+
+.. code:: python
+
+    # all_pages() returns an Iterator
+    for page in tree.all_pages():
+        print(page)
+
+``all_pages()`` method will return an iterator yielding ``SitemapPage`` objects; see a `reference of SitemapPage <https://ultimate-sitemap-parser.readthedocs.io/en/latest/usp.objects.html#module-usp.objects.page>`_.
+
+
Index: venv/Lib/site-packages/ultimate_sitemap_parser-0.5.dist-info/RECORD
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/venv/Lib/site-packages/ultimate_sitemap_parser-0.5.dist-info/RECORD b/venv/Lib/site-packages/ultimate_sitemap_parser-0.5.dist-info/RECORD
new file mode 100644
--- /dev/null	(date 1616410448692)
+++ b/venv/Lib/site-packages/ultimate_sitemap_parser-0.5.dist-info/RECORD	(date 1616410448692)
@@ -0,0 +1,37 @@
+tests/web_client/__init__.py,sha256=47DEQpj8HBSa-_TImW-5JCeuQeRkm5NMpJWZG3hSuFU,0
+tests/web_client/__pycache__/__init__.cpython-36.pyc,,
+tests/web_client/__pycache__/test_requests_client.cpython-36.pyc,,
+tests/web_client/test_requests_client.py,sha256=mvOkZoNFRQ3Fcf0yMlTvlQkAQzJWgK3UKULR8rXxQAU,4555
+ultimate_sitemap_parser-0.5.dist-info/INSTALLER,sha256=zuuue4knoyJ-UwPPXg8fezS7VCrXJQrAP7zeNuwvFQg,4
+ultimate_sitemap_parser-0.5.dist-info/LICENSE.txt,sha256=Lxmp2QWPY2vwKV3zBqXnBgUgO4eGkVFbq1D-Ku7ZM9o,563
+ultimate_sitemap_parser-0.5.dist-info/METADATA,sha256=vZuBo09fLOhKl_HobzO6EdZE_39CSI-Bq2exyKIqHH8,4311
+ultimate_sitemap_parser-0.5.dist-info/RECORD,,
+ultimate_sitemap_parser-0.5.dist-info/WHEEL,sha256=h_aVn5OB2IERUjMbi2pucmR_zzWJtk303YXvhh60NJ8,110
+ultimate_sitemap_parser-0.5.dist-info/top_level.txt,sha256=6N_xHi3dkDlyZGtjAScqpFvW7pWn_-DKc_enuOgJ9pc,10
+ultimate_sitemap_parser-0.5.dist-info/zip-safe,sha256=AbpHGcgLb-kRsJGnwFEktk7uzpZOCcBY74-YBdrKVGs,1
+usp/__about__.py,sha256=JO_svODkyyw_sJSP6bLSaugifIq-x9R1fy6R2iUm350,44
+usp/__init__.py,sha256=ArqlCCgLAwY-stWooojyWBI5iedyb6gSz9Y7wkCNr2M,19
+usp/__pycache__/__about__.cpython-36.pyc,,
+usp/__pycache__/__init__.cpython-36.pyc,,
+usp/__pycache__/exceptions.cpython-36.pyc,,
+usp/__pycache__/fetch_parse.cpython-36.pyc,,
+usp/__pycache__/helpers.cpython-36.pyc,,
+usp/__pycache__/log.cpython-36.pyc,,
+usp/__pycache__/tree.cpython-36.pyc,,
+usp/exceptions.py,sha256=kxftRkYOCUw0O-p0U0rHmq9b1ZdCSClWyCz8SqNotJE,504
+usp/fetch_parse.py,sha256=Xcj6lxHHLK3Nq-vJaEyIz5iFs5XIpNTAqhtAOWgQaEM,32997
+usp/helpers.py,sha256=MxVmoec0-CNr6qlmbZ4slubNKb4xvmrbAfGD2G9BXkw,7729
+usp/log.py,sha256=DVgABM2yWPx-HFfqoGBzg_t92oR5CFo2qjPQjzttmfI,2181
+usp/objects/__init__.py,sha256=47DEQpj8HBSa-_TImW-5JCeuQeRkm5NMpJWZG3hSuFU,0
+usp/objects/__pycache__/__init__.cpython-36.pyc,,
+usp/objects/__pycache__/page.cpython-36.pyc,,
+usp/objects/__pycache__/sitemap.cpython-36.pyc,,
+usp/objects/page.py,sha256=-8fxw_nduDxmWLI72-yGJr8VtuPGiHEvaGNPcYxxx9s,9820
+usp/objects/sitemap.py,sha256=XXbJ91kBORxmmNb_lGSJZ9TbXImCNATkx--qvjIrSlk,7055
+usp/tree.py,sha256=qKQsxXy6ZeDs8OwOulsxoosMF7iyV_tLjyz1dxzkITg,3044
+usp/web_client/__init__.py,sha256=47DEQpj8HBSa-_TImW-5JCeuQeRkm5NMpJWZG3hSuFU,0
+usp/web_client/__pycache__/__init__.cpython-36.pyc,,
+usp/web_client/__pycache__/abstract_client.cpython-36.pyc,,
+usp/web_client/__pycache__/requests_client.cpython-36.pyc,,
+usp/web_client/abstract_client.py,sha256=zl4jJvgfyMfSow1GUm2CIMpd3YTd3JlF_3PcYeB6lpk,4886
+usp/web_client/requests_client.py,sha256=VN7lbMG-eb06aIsNYJKSumIGvh-m5IKZPOyGpHVEpPU,3789
Index: latest/Lib/site-packages/psycopg2/_range.py
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/latest/Lib/site-packages/psycopg2/_range.py b/latest/Lib/site-packages/psycopg2/_range.py
new file mode 100644
--- /dev/null	(date 1616410448723)
+++ b/latest/Lib/site-packages/psycopg2/_range.py	(date 1616410448723)
@@ -0,0 +1,539 @@
+"""Implementation of the Range type and adaptation
+
+"""
+
+# psycopg/_range.py - Implementation of the Range type and adaptation
+#
+# Copyright (C) 2012-2019 Daniele Varrazzo  <daniele.varrazzo@gmail.com>
+# Copyright (C) 2020 The Psycopg Team
+#
+# psycopg2 is free software: you can redistribute it and/or modify it
+# under the terms of the GNU Lesser General Public License as published
+# by the Free Software Foundation, either version 3 of the License, or
+# (at your option) any later version.
+#
+# In addition, as a special exception, the copyright holders give
+# permission to link this program with the OpenSSL library (or with
+# modified versions of OpenSSL that use the same license as OpenSSL),
+# and distribute linked combinations including the two.
+#
+# You must obey the GNU Lesser General Public License in all respects for
+# all of the code used other than OpenSSL.
+#
+# psycopg2 is distributed in the hope that it will be useful, but WITHOUT
+# ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or
+# FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public
+# License for more details.
+
+import re
+
+from psycopg2._psycopg import ProgrammingError, InterfaceError
+from psycopg2.extensions import ISQLQuote, adapt, register_adapter
+from psycopg2.extensions import new_type, new_array_type, register_type
+from psycopg2.compat import string_types
+
+
+class Range(object):
+    """Python representation for a PostgreSQL |range|_ type.
+
+    :param lower: lower bound for the range. `!None` means unbound
+    :param upper: upper bound for the range. `!None` means unbound
+    :param bounds: one of the literal strings ``()``, ``[)``, ``(]``, ``[]``,
+        representing whether the lower or upper bounds are included
+    :param empty: if `!True`, the range is empty
+
+    """
+    __slots__ = ('_lower', '_upper', '_bounds')
+
+    def __init__(self, lower=None, upper=None, bounds='[)', empty=False):
+        if not empty:
+            if bounds not in ('[)', '(]', '()', '[]'):
+                raise ValueError("bound flags not valid: %r" % bounds)
+
+            self._lower = lower
+            self._upper = upper
+            self._bounds = bounds
+        else:
+            self._lower = self._upper = self._bounds = None
+
+    def __repr__(self):
+        if self._bounds is None:
+            return "%s(empty=True)" % self.__class__.__name__
+        else:
+            return "%s(%r, %r, %r)" % (self.__class__.__name__,
+                self._lower, self._upper, self._bounds)
+
+    def __str__(self):
+        if self._bounds is None:
+            return 'empty'
+
+        items = [
+            self._bounds[0],
+            str(self._lower),
+            ', ',
+            str(self._upper),
+            self._bounds[1]
+        ]
+        return ''.join(items)
+
+    @property
+    def lower(self):
+        """The lower bound of the range. `!None` if empty or unbound."""
+        return self._lower
+
+    @property
+    def upper(self):
+        """The upper bound of the range. `!None` if empty or unbound."""
+        return self._upper
+
+    @property
+    def isempty(self):
+        """`!True` if the range is empty."""
+        return self._bounds is None
+
+    @property
+    def lower_inf(self):
+        """`!True` if the range doesn't have a lower bound."""
+        if self._bounds is None:
+            return False
+        return self._lower is None
+
+    @property
+    def upper_inf(self):
+        """`!True` if the range doesn't have an upper bound."""
+        if self._bounds is None:
+            return False
+        return self._upper is None
+
+    @property
+    def lower_inc(self):
+        """`!True` if the lower bound is included in the range."""
+        if self._bounds is None or self._lower is None:
+            return False
+        return self._bounds[0] == '['
+
+    @property
+    def upper_inc(self):
+        """`!True` if the upper bound is included in the range."""
+        if self._bounds is None or self._upper is None:
+            return False
+        return self._bounds[1] == ']'
+
+    def __contains__(self, x):
+        if self._bounds is None:
+            return False
+
+        if self._lower is not None:
+            if self._bounds[0] == '[':
+                if x < self._lower:
+                    return False
+            else:
+                if x <= self._lower:
+                    return False
+
+        if self._upper is not None:
+            if self._bounds[1] == ']':
+                if x > self._upper:
+                    return False
+            else:
+                if x >= self._upper:
+                    return False
+
+        return True
+
+    def __bool__(self):
+        return self._bounds is not None
+
+    def __nonzero__(self):
+        # Python 2 compatibility
+        return type(self).__bool__(self)
+
+    def __eq__(self, other):
+        if not isinstance(other, Range):
+            return False
+        return (self._lower == other._lower
+            and self._upper == other._upper
+            and self._bounds == other._bounds)
+
+    def __ne__(self, other):
+        return not self.__eq__(other)
+
+    def __hash__(self):
+        return hash((self._lower, self._upper, self._bounds))
+
+    # as the postgres docs describe for the server-side stuff,
+    # ordering is rather arbitrary, but will remain stable
+    # and consistent.
+
+    def __lt__(self, other):
+        if not isinstance(other, Range):
+            return NotImplemented
+        for attr in ('_lower', '_upper', '_bounds'):
+            self_value = getattr(self, attr)
+            other_value = getattr(other, attr)
+            if self_value == other_value:
+                pass
+            elif self_value is None:
+                return True
+            elif other_value is None:
+                return False
+            else:
+                return self_value < other_value
+        return False
+
+    def __le__(self, other):
+        if self == other:
+            return True
+        else:
+            return self.__lt__(other)
+
+    def __gt__(self, other):
+        if isinstance(other, Range):
+            return other.__lt__(self)
+        else:
+            return NotImplemented
+
+    def __ge__(self, other):
+        if self == other:
+            return True
+        else:
+            return self.__gt__(other)
+
+    def __getstate__(self):
+        return {slot: getattr(self, slot)
+            for slot in self.__slots__ if hasattr(self, slot)}
+
+    def __setstate__(self, state):
+        for slot, value in state.items():
+            setattr(self, slot, value)
+
+
+def register_range(pgrange, pyrange, conn_or_curs, globally=False):
+    """Create and register an adapter and the typecasters to convert between
+    a PostgreSQL |range|_ type and a PostgreSQL `Range` subclass.
+
+    :param pgrange: the name of the PostgreSQL |range| type. Can be
+        schema-qualified
+    :param pyrange: a `Range` strict subclass, or just a name to give to a new
+        class
+    :param conn_or_curs: a connection or cursor used to find the oid of the
+        range and its subtype; the typecaster is registered in a scope limited
+        to this object, unless *globally* is set to `!True`
+    :param globally: if `!False` (default) register the typecaster only on
+        *conn_or_curs*, otherwise register it globally
+    :return: `RangeCaster` instance responsible for the conversion
+
+    If a string is passed to *pyrange*, a new `Range` subclass is created
+    with such name and will be available as the `~RangeCaster.range` attribute
+    of the returned `RangeCaster` object.
+
+    The function queries the database on *conn_or_curs* to inspect the
+    *pgrange* type and raises `~psycopg2.ProgrammingError` if the type is not
+    found.  If querying the database is not advisable, use directly the
+    `RangeCaster` class and register the adapter and typecasters using the
+    provided functions.
+
+    """
+    caster = RangeCaster._from_db(pgrange, pyrange, conn_or_curs)
+    caster._register(not globally and conn_or_curs or None)
+    return caster
+
+
+class RangeAdapter(object):
+    """`ISQLQuote` adapter for `Range` subclasses.
+
+    This is an abstract class: concrete classes must set a `name` class
+    attribute or override `getquoted()`.
+    """
+    name = None
+
+    def __init__(self, adapted):
+        self.adapted = adapted
+
+    def __conform__(self, proto):
+        if self._proto is ISQLQuote:
+            return self
+
+    def prepare(self, conn):
+        self._conn = conn
+
+    def getquoted(self):
+        if self.name is None:
+            raise NotImplementedError(
+                'RangeAdapter must be subclassed overriding its name '
+                'or the getquoted() method')
+
+        r = self.adapted
+        if r.isempty:
+            return b"'empty'::" + self.name.encode('utf8')
+
+        if r.lower is not None:
+            a = adapt(r.lower)
+            if hasattr(a, 'prepare'):
+                a.prepare(self._conn)
+            lower = a.getquoted()
+        else:
+            lower = b'NULL'
+
+        if r.upper is not None:
+            a = adapt(r.upper)
+            if hasattr(a, 'prepare'):
+                a.prepare(self._conn)
+            upper = a.getquoted()
+        else:
+            upper = b'NULL'
+
+        return self.name.encode('utf8') + b'(' + lower + b', ' + upper \
+            + b", '" + r._bounds.encode('utf8') + b"')"
+
+
+class RangeCaster(object):
+    """Helper class to convert between `Range` and PostgreSQL range types.
+
+    Objects of this class are usually created by `register_range()`. Manual
+    creation could be useful if querying the database is not advisable: in
+    this case the oids must be provided.
+    """
+    def __init__(self, pgrange, pyrange, oid, subtype_oid, array_oid=None):
+        self.subtype_oid = subtype_oid
+        self._create_ranges(pgrange, pyrange)
+
+        name = self.adapter.name or self.adapter.__class__.__name__
+
+        self.typecaster = new_type((oid,), name, self.parse)
+
+        if array_oid is not None:
+            self.array_typecaster = new_array_type(
+                (array_oid,), name + "ARRAY", self.typecaster)
+        else:
+            self.array_typecaster = None
+
+    def _create_ranges(self, pgrange, pyrange):
+        """Create Range and RangeAdapter classes if needed."""
+        # if got a string create a new RangeAdapter concrete type (with a name)
+        # else take it as an adapter. Passing an adapter should be considered
+        # an implementation detail and is not documented. It is currently used
+        # for the numeric ranges.
+        self.adapter = None
+        if isinstance(pgrange, string_types):
+            self.adapter = type(pgrange, (RangeAdapter,), {})
+            self.adapter.name = pgrange
+        else:
+            try:
+                if issubclass(pgrange, RangeAdapter) \
+                        and pgrange is not RangeAdapter:
+                    self.adapter = pgrange
+            except TypeError:
+                pass
+
+        if self.adapter is None:
+            raise TypeError(
+                'pgrange must be a string or a RangeAdapter strict subclass')
+
+        self.range = None
+        try:
+            if isinstance(pyrange, string_types):
+                self.range = type(pyrange, (Range,), {})
+            if issubclass(pyrange, Range) and pyrange is not Range:
+                self.range = pyrange
+        except TypeError:
+            pass
+
+        if self.range is None:
+            raise TypeError(
+                'pyrange must be a type or a Range strict subclass')
+
+    @classmethod
+    def _from_db(self, name, pyrange, conn_or_curs):
+        """Return a `RangeCaster` instance for the type *pgrange*.
+
+        Raise `ProgrammingError` if the type is not found.
+        """
+        from psycopg2.extensions import STATUS_IN_TRANSACTION
+        from psycopg2.extras import _solve_conn_curs
+        conn, curs = _solve_conn_curs(conn_or_curs)
+
+        if conn.info.server_version < 90200:
+            raise ProgrammingError("range types not available in version %s"
+                % conn.info.server_version)
+
+        # Store the transaction status of the connection to revert it after use
+        conn_status = conn.status
+
+        # Use the correct schema
+        if '.' in name:
+            schema, tname = name.split('.', 1)
+        else:
+            tname = name
+            schema = 'public'
+
+        # get the type oid and attributes
+        try:
+            curs.execute("""\
+select rngtypid, rngsubtype,
+    (select typarray from pg_type where oid = rngtypid)
+from pg_range r
+join pg_type t on t.oid = rngtypid
+join pg_namespace ns on ns.oid = typnamespace
+where typname = %s and ns.nspname = %s;
+""", (tname, schema))
+
+        except ProgrammingError:
+            if not conn.autocommit:
+                conn.rollback()
+            raise
+        else:
+            rec = curs.fetchone()
+
+            # revert the status of the connection as before the command
+            if (conn_status != STATUS_IN_TRANSACTION
+            and not conn.autocommit):
+                conn.rollback()
+
+        if not rec:
+            raise ProgrammingError(
+                "PostgreSQL type '%s' not found" % name)
+
+        type, subtype, array = rec
+
+        return RangeCaster(name, pyrange,
+            oid=type, subtype_oid=subtype, array_oid=array)
+
+    _re_range = re.compile(r"""
+        ( \(|\[ )                   # lower bound flag
+        (?:                         # lower bound:
+          " ( (?: [^"] | "")* ) "   #   - a quoted string
+          | ( [^",]+ )              #   - or an unquoted string
+        )?                          #   - or empty (not catched)
+        ,
+        (?:                         # upper bound:
+          " ( (?: [^"] | "")* ) "   #   - a quoted string
+          | ( [^"\)\]]+ )           #   - or an unquoted string
+        )?                          #   - or empty (not catched)
+        ( \)|\] )                   # upper bound flag
+        """, re.VERBOSE)
+
+    _re_undouble = re.compile(r'(["\\])\1')
+
+    def parse(self, s, cur=None):
+        if s is None:
+            return None
+
+        if s == 'empty':
+            return self.range(empty=True)
+
+        m = self._re_range.match(s)
+        if m is None:
+            raise InterfaceError("failed to parse range: '%s'" % s)
+
+        lower = m.group(3)
+        if lower is None:
+            lower = m.group(2)
+            if lower is not None:
+                lower = self._re_undouble.sub(r"\1", lower)
+
+        upper = m.group(5)
+        if upper is None:
+            upper = m.group(4)
+            if upper is not None:
+                upper = self._re_undouble.sub(r"\1", upper)
+
+        if cur is not None:
+            lower = cur.cast(self.subtype_oid, lower)
+            upper = cur.cast(self.subtype_oid, upper)
+
+        bounds = m.group(1) + m.group(6)
+
+        return self.range(lower, upper, bounds)
+
+    def _register(self, scope=None):
+        register_type(self.typecaster, scope)
+        if self.array_typecaster is not None:
+            register_type(self.array_typecaster, scope)
+
+        register_adapter(self.range, self.adapter)
+
+
+class NumericRange(Range):
+    """A `Range` suitable to pass Python numeric types to a PostgreSQL range.
+
+    PostgreSQL types :sql:`int4range`, :sql:`int8range`, :sql:`numrange` are
+    casted into `!NumericRange` instances.
+    """
+    pass
+
+
+class DateRange(Range):
+    """Represents :sql:`daterange` values."""
+    pass
+
+
+class DateTimeRange(Range):
+    """Represents :sql:`tsrange` values."""
+    pass
+
+
+class DateTimeTZRange(Range):
+    """Represents :sql:`tstzrange` values."""
+    pass
+
+
+# Special adaptation for NumericRange. Allows to pass number range regardless
+# of whether they are ints, floats and what size of ints are, which are
+# pointless in Python world. On the way back, no numeric range is casted to
+# NumericRange, but only to their subclasses
+
+class NumberRangeAdapter(RangeAdapter):
+    """Adapt a range if the subtype doesn't need quotes."""
+    def getquoted(self):
+        r = self.adapted
+        if r.isempty:
+            return b"'empty'"
+
+        if not r.lower_inf:
+            # not exactly: we are relying that none of these object is really
+            # quoted (they are numbers). Also, I'm lazy and not preparing the
+            # adapter because I assume encoding doesn't matter for these
+            # objects.
+            lower = adapt(r.lower).getquoted().decode('ascii')
+        else:
+            lower = ''
+
+        if not r.upper_inf:
+            upper = adapt(r.upper).getquoted().decode('ascii')
+        else:
+            upper = ''
+
+        return ("'%s%s,%s%s'" % (
+            r._bounds[0], lower, upper, r._bounds[1])).encode('ascii')
+
+
+# TODO: probably won't work with infs, nans and other tricky cases.
+register_adapter(NumericRange, NumberRangeAdapter)
+
+# Register globally typecasters and adapters for builtin range types.
+
+# note: the adapter is registered more than once, but this is harmless.
+int4range_caster = RangeCaster(NumberRangeAdapter, NumericRange,
+    oid=3904, subtype_oid=23, array_oid=3905)
+int4range_caster._register()
+
+int8range_caster = RangeCaster(NumberRangeAdapter, NumericRange,
+    oid=3926, subtype_oid=20, array_oid=3927)
+int8range_caster._register()
+
+numrange_caster = RangeCaster(NumberRangeAdapter, NumericRange,
+    oid=3906, subtype_oid=1700, array_oid=3907)
+numrange_caster._register()
+
+daterange_caster = RangeCaster('daterange', DateRange,
+    oid=3912, subtype_oid=1082, array_oid=3913)
+daterange_caster._register()
+
+tsrange_caster = RangeCaster('tsrange', DateTimeRange,
+    oid=3908, subtype_oid=1114, array_oid=3909)
+tsrange_caster._register()
+
+tstzrange_caster = RangeCaster('tstzrange', DateTimeTZRange,
+    oid=3910, subtype_oid=1184, array_oid=3911)
+tstzrange_caster._register()
Index: venv/Lib/site-packages/ultimate_sitemap_parser-0.5.dist-info/top_level.txt
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/venv/Lib/site-packages/ultimate_sitemap_parser-0.5.dist-info/top_level.txt b/venv/Lib/site-packages/ultimate_sitemap_parser-0.5.dist-info/top_level.txt
new file mode 100644
--- /dev/null	(date 1616410448924)
+++ b/venv/Lib/site-packages/ultimate_sitemap_parser-0.5.dist-info/top_level.txt	(date 1616410448924)
@@ -0,0 +1,2 @@
+tests
+usp
Index: latest/Lib/site-packages/psycopg2/__init__.py
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/latest/Lib/site-packages/psycopg2/__init__.py b/latest/Lib/site-packages/psycopg2/__init__.py
new file mode 100644
--- /dev/null	(date 1616410448932)
+++ b/latest/Lib/site-packages/psycopg2/__init__.py	(date 1616410448932)
@@ -0,0 +1,131 @@
+"""A Python driver for PostgreSQL
+
+psycopg is a PostgreSQL_ database adapter for the Python_ programming
+language. This is version 2, a complete rewrite of the original code to
+provide new-style classes for connection and cursor objects and other sweet
+candies. Like the original, psycopg 2 was written with the aim of being very
+small and fast, and stable as a rock.
+
+Homepage: https://psycopg.org/
+
+.. _PostgreSQL: https://www.postgresql.org/
+.. _Python: https://www.python.org/
+
+:Groups:
+  * `Connections creation`: connect
+  * `Value objects constructors`: Binary, Date, DateFromTicks, Time,
+    TimeFromTicks, Timestamp, TimestampFromTicks
+"""
+# psycopg/__init__.py - initialization of the psycopg module
+#
+# Copyright (C) 2003-2019 Federico Di Gregorio  <fog@debian.org>
+# Copyright (C) 2020 The Psycopg Team
+#
+# psycopg2 is free software: you can redistribute it and/or modify it
+# under the terms of the GNU Lesser General Public License as published
+# by the Free Software Foundation, either version 3 of the License, or
+# (at your option) any later version.
+#
+# In addition, as a special exception, the copyright holders give
+# permission to link this program with the OpenSSL library (or with
+# modified versions of OpenSSL that use the same license as OpenSSL),
+# and distribute linked combinations including the two.
+#
+# You must obey the GNU Lesser General Public License in all respects for
+# all of the code used other than OpenSSL.
+#
+# psycopg2 is distributed in the hope that it will be useful, but WITHOUT
+# ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or
+# FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public
+# License for more details.
+
+# Import modules needed by _psycopg to allow tools like py2exe to do
+# their work without bothering about the module dependencies.
+
+# Note: the first internal import should be _psycopg, otherwise the real cause
+# of a failed loading of the C module may get hidden, see
+# https://archives.postgresql.org/psycopg/2011-02/msg00044.php
+
+# Import the DBAPI-2.0 stuff into top-level module.
+
+from psycopg2._psycopg import (                     # noqa
+    BINARY, NUMBER, STRING, DATETIME, ROWID,
+
+    Binary, Date, Time, Timestamp,
+    DateFromTicks, TimeFromTicks, TimestampFromTicks,
+
+    Error, Warning, DataError, DatabaseError, ProgrammingError, IntegrityError,
+    InterfaceError, InternalError, NotSupportedError, OperationalError,
+
+    _connect, apilevel, threadsafety, paramstyle,
+    __version__, __libpq_version__,
+)
+
+from psycopg2 import tz                             # noqa
+
+
+# Register default adapters.
+
+from psycopg2 import extensions as _ext
+_ext.register_adapter(tuple, _ext.SQL_IN)
+_ext.register_adapter(type(None), _ext.NoneAdapter)
+
+# Register the Decimal adapter here instead of in the C layer.
+# This way a new class is registered for each sub-interpreter.
+# See ticket #52
+from decimal import Decimal                         # noqa
+from psycopg2._psycopg import Decimal as Adapter    # noqa
+_ext.register_adapter(Decimal, Adapter)
+del Decimal, Adapter
+
+
+def connect(dsn=None, connection_factory=None, cursor_factory=None, **kwargs):
+    """
+    Create a new database connection.
+
+    The connection parameters can be specified as a string:
+
+        conn = psycopg2.connect("dbname=test user=postgres password=secret")
+
+    or using a set of keyword arguments:
+
+        conn = psycopg2.connect(database="test", user="postgres", password="secret")
+
+    Or as a mix of both. The basic connection parameters are:
+
+    - *dbname*: the database name
+    - *database*: the database name (only as keyword argument)
+    - *user*: user name used to authenticate
+    - *password*: password used to authenticate
+    - *host*: database host address (defaults to UNIX socket if not provided)
+    - *port*: connection port number (defaults to 5432 if not provided)
+
+    Using the *connection_factory* parameter a different class or connections
+    factory can be specified. It should be a callable object taking a dsn
+    argument.
+
+    Using the *cursor_factory* parameter, a new default cursor factory will be
+    used by cursor().
+
+    Using *async*=True an asynchronous connection will be created. *async_* is
+    a valid alias (for Python versions where ``async`` is a keyword).
+
+    Any other keyword parameter will be passed to the underlying client
+    library: the list of supported parameters depends on the library version.
+
+    """
+    kwasync = {}
+    if 'async' in kwargs:
+        kwasync['async'] = kwargs.pop('async')
+    if 'async_' in kwargs:
+        kwasync['async_'] = kwargs.pop('async_')
+
+    if dsn is None and not kwargs:
+        raise TypeError('missing dsn and no parameters')
+
+    dsn = _ext.make_dsn(dsn, **kwargs)
+    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
+    if cursor_factory is not None:
+        conn.cursor_factory = cursor_factory
+
+    return conn
Index: venv/Lib/site-packages/ultimate_sitemap_parser-0.5.dist-info/WHEEL
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/venv/Lib/site-packages/ultimate_sitemap_parser-0.5.dist-info/WHEEL b/venv/Lib/site-packages/ultimate_sitemap_parser-0.5.dist-info/WHEEL
new file mode 100644
--- /dev/null	(date 1616410448999)
+++ b/venv/Lib/site-packages/ultimate_sitemap_parser-0.5.dist-info/WHEEL	(date 1616410448999)
@@ -0,0 +1,6 @@
+Wheel-Version: 1.0
+Generator: bdist_wheel (0.33.4)
+Root-Is-Purelib: true
+Tag: py2-none-any
+Tag: py3-none-any
+
Index: venv/Lib/site-packages/ultimate_sitemap_parser-0.5.dist-info/zip-safe
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/venv/Lib/site-packages/ultimate_sitemap_parser-0.5.dist-info/zip-safe b/venv/Lib/site-packages/ultimate_sitemap_parser-0.5.dist-info/zip-safe
new file mode 100644
--- /dev/null	(date 1616410449093)
+++ b/venv/Lib/site-packages/ultimate_sitemap_parser-0.5.dist-info/zip-safe	(date 1616410449093)
@@ -0,0 +1,1 @@
+
Index: venv/Lib/site-packages/dateutil/easter.py
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/venv/Lib/site-packages/dateutil/easter.py b/venv/Lib/site-packages/dateutil/easter.py
new file mode 100644
--- /dev/null	(date 1616410449108)
+++ b/venv/Lib/site-packages/dateutil/easter.py	(date 1616410449108)
@@ -0,0 +1,89 @@
+# -*- coding: utf-8 -*-
+"""
+This module offers a generic easter computing method for any given year, using
+Western, Orthodox or Julian algorithms.
+"""
+
+import datetime
+
+__all__ = ["easter", "EASTER_JULIAN", "EASTER_ORTHODOX", "EASTER_WESTERN"]
+
+EASTER_JULIAN = 1
+EASTER_ORTHODOX = 2
+EASTER_WESTERN = 3
+
+
+def easter(year, method=EASTER_WESTERN):
+    """
+    This method was ported from the work done by GM Arts,
+    on top of the algorithm by Claus Tondering, which was
+    based in part on the algorithm of Ouding (1940), as
+    quoted in "Explanatory Supplement to the Astronomical
+    Almanac", P.  Kenneth Seidelmann, editor.
+
+    This algorithm implements three different easter
+    calculation methods:
+
+    1 - Original calculation in Julian calendar, valid in
+        dates after 326 AD
+    2 - Original method, with date converted to Gregorian
+        calendar, valid in years 1583 to 4099
+    3 - Revised method, in Gregorian calendar, valid in
+        years 1583 to 4099 as well
+
+    These methods are represented by the constants:
+
+    * ``EASTER_JULIAN   = 1``
+    * ``EASTER_ORTHODOX = 2``
+    * ``EASTER_WESTERN  = 3``
+
+    The default method is method 3.
+
+    More about the algorithm may be found at:
+
+    `GM Arts: Easter Algorithms <http://www.gmarts.org/index.php?go=415>`_
+
+    and
+
+    `The Calendar FAQ: Easter <https://www.tondering.dk/claus/cal/easter.php>`_
+
+    """
+
+    if not (1 <= method <= 3):
+        raise ValueError("invalid method")
+
+    # g - Golden year - 1
+    # c - Century
+    # h - (23 - Epact) mod 30
+    # i - Number of days from March 21 to Paschal Full Moon
+    # j - Weekday for PFM (0=Sunday, etc)
+    # p - Number of days from March 21 to Sunday on or before PFM
+    #     (-6 to 28 methods 1 & 3, to 56 for method 2)
+    # e - Extra days to add for method 2 (converting Julian
+    #     date to Gregorian date)
+
+    y = year
+    g = y % 19
+    e = 0
+    if method < 3:
+        # Old method
+        i = (19*g + 15) % 30
+        j = (y + y//4 + i) % 7
+        if method == 2:
+            # Extra dates to convert Julian to Gregorian date
+            e = 10
+            if y > 1600:
+                e = e + y//100 - 16 - (y//100 - 16)//4
+    else:
+        # New method
+        c = y//100
+        h = (c - c//4 - (8*c + 13)//25 + 19*g + 15) % 30
+        i = h - (h//28)*(1 - (h//28)*(29//(h + 1))*((21 - g)//11))
+        j = (y + y//4 + i + 2 - c + c//4) % 7
+
+    # p can be from -6 to 56 corresponding to dates 22 March to 23 May
+    # (later dates apply to method 2, although 23 May never actually occurs)
+    p = i - j + e
+    d = 1 + (p + 27 + (p + 6)//40) % 31
+    m = 3 + (p + 26)//30
+    return datetime.date(int(y), int(m), int(d))
Index: venv/Lib/site-packages/dateutil/relativedelta.py
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/venv/Lib/site-packages/dateutil/relativedelta.py b/venv/Lib/site-packages/dateutil/relativedelta.py
new file mode 100644
--- /dev/null	(date 1616410449124)
+++ b/venv/Lib/site-packages/dateutil/relativedelta.py	(date 1616410449124)
@@ -0,0 +1,599 @@
+# -*- coding: utf-8 -*-
+import datetime
+import calendar
+
+import operator
+from math import copysign
+
+from six import integer_types
+from warnings import warn
+
+from ._common import weekday
+
+MO, TU, WE, TH, FR, SA, SU = weekdays = tuple(weekday(x) for x in range(7))
+
+__all__ = ["relativedelta", "MO", "TU", "WE", "TH", "FR", "SA", "SU"]
+
+
+class relativedelta(object):
+    """
+    The relativedelta type is designed to be applied to an existing datetime and
+    can replace specific components of that datetime, or represents an interval
+    of time.
+
+    It is based on the specification of the excellent work done by M.-A. Lemburg
+    in his
+    `mx.DateTime <https://www.egenix.com/products/python/mxBase/mxDateTime/>`_ extension.
+    However, notice that this type does *NOT* implement the same algorithm as
+    his work. Do *NOT* expect it to behave like mx.DateTime's counterpart.
+
+    There are two different ways to build a relativedelta instance. The
+    first one is passing it two date/datetime classes::
+
+        relativedelta(datetime1, datetime2)
+
+    The second one is passing it any number of the following keyword arguments::
+
+        relativedelta(arg1=x,arg2=y,arg3=z...)
+
+        year, month, day, hour, minute, second, microsecond:
+            Absolute information (argument is singular); adding or subtracting a
+            relativedelta with absolute information does not perform an arithmetic
+            operation, but rather REPLACES the corresponding value in the
+            original datetime with the value(s) in relativedelta.
+
+        years, months, weeks, days, hours, minutes, seconds, microseconds:
+            Relative information, may be negative (argument is plural); adding
+            or subtracting a relativedelta with relative information performs
+            the corresponding arithmetic operation on the original datetime value
+            with the information in the relativedelta.
+
+        weekday: 
+            One of the weekday instances (MO, TU, etc) available in the
+            relativedelta module. These instances may receive a parameter N,
+            specifying the Nth weekday, which could be positive or negative
+            (like MO(+1) or MO(-2)). Not specifying it is the same as specifying
+            +1. You can also use an integer, where 0=MO. This argument is always
+            relative e.g. if the calculated date is already Monday, using MO(1)
+            or MO(-1) won't change the day. To effectively make it absolute, use
+            it in combination with the day argument (e.g. day=1, MO(1) for first
+            Monday of the month).
+
+        leapdays:
+            Will add given days to the date found, if year is a leap
+            year, and the date found is post 28 of february.
+
+        yearday, nlyearday:
+            Set the yearday or the non-leap year day (jump leap days).
+            These are converted to day/month/leapdays information.
+
+    There are relative and absolute forms of the keyword
+    arguments. The plural is relative, and the singular is
+    absolute. For each argument in the order below, the absolute form
+    is applied first (by setting each attribute to that value) and
+    then the relative form (by adding the value to the attribute).
+
+    The order of attributes considered when this relativedelta is
+    added to a datetime is:
+
+    1. Year
+    2. Month
+    3. Day
+    4. Hours
+    5. Minutes
+    6. Seconds
+    7. Microseconds
+
+    Finally, weekday is applied, using the rule described above.
+
+    For example
+
+    >>> from datetime import datetime
+    >>> from dateutil.relativedelta import relativedelta, MO
+    >>> dt = datetime(2018, 4, 9, 13, 37, 0)
+    >>> delta = relativedelta(hours=25, day=1, weekday=MO(1))
+    >>> dt + delta
+    datetime.datetime(2018, 4, 2, 14, 37)
+
+    First, the day is set to 1 (the first of the month), then 25 hours
+    are added, to get to the 2nd day and 14th hour, finally the
+    weekday is applied, but since the 2nd is already a Monday there is
+    no effect.
+
+    """
+
+    def __init__(self, dt1=None, dt2=None,
+                 years=0, months=0, days=0, leapdays=0, weeks=0,
+                 hours=0, minutes=0, seconds=0, microseconds=0,
+                 year=None, month=None, day=None, weekday=None,
+                 yearday=None, nlyearday=None,
+                 hour=None, minute=None, second=None, microsecond=None):
+
+        if dt1 and dt2:
+            # datetime is a subclass of date. So both must be date
+            if not (isinstance(dt1, datetime.date) and
+                    isinstance(dt2, datetime.date)):
+                raise TypeError("relativedelta only diffs datetime/date")
+
+            # We allow two dates, or two datetimes, so we coerce them to be
+            # of the same type
+            if (isinstance(dt1, datetime.datetime) !=
+                    isinstance(dt2, datetime.datetime)):
+                if not isinstance(dt1, datetime.datetime):
+                    dt1 = datetime.datetime.fromordinal(dt1.toordinal())
+                elif not isinstance(dt2, datetime.datetime):
+                    dt2 = datetime.datetime.fromordinal(dt2.toordinal())
+
+            self.years = 0
+            self.months = 0
+            self.days = 0
+            self.leapdays = 0
+            self.hours = 0
+            self.minutes = 0
+            self.seconds = 0
+            self.microseconds = 0
+            self.year = None
+            self.month = None
+            self.day = None
+            self.weekday = None
+            self.hour = None
+            self.minute = None
+            self.second = None
+            self.microsecond = None
+            self._has_time = 0
+
+            # Get year / month delta between the two
+            months = (dt1.year - dt2.year) * 12 + (dt1.month - dt2.month)
+            self._set_months(months)
+
+            # Remove the year/month delta so the timedelta is just well-defined
+            # time units (seconds, days and microseconds)
+            dtm = self.__radd__(dt2)
+
+            # If we've overshot our target, make an adjustment
+            if dt1 < dt2:
+                compare = operator.gt
+                increment = 1
+            else:
+                compare = operator.lt
+                increment = -1
+
+            while compare(dt1, dtm):
+                months += increment
+                self._set_months(months)
+                dtm = self.__radd__(dt2)
+
+            # Get the timedelta between the "months-adjusted" date and dt1
+            delta = dt1 - dtm
+            self.seconds = delta.seconds + delta.days * 86400
+            self.microseconds = delta.microseconds
+        else:
+            # Check for non-integer values in integer-only quantities
+            if any(x is not None and x != int(x) for x in (years, months)):
+                raise ValueError("Non-integer years and months are "
+                                 "ambiguous and not currently supported.")
+
+            # Relative information
+            self.years = int(years)
+            self.months = int(months)
+            self.days = days + weeks * 7
+            self.leapdays = leapdays
+            self.hours = hours
+            self.minutes = minutes
+            self.seconds = seconds
+            self.microseconds = microseconds
+
+            # Absolute information
+            self.year = year
+            self.month = month
+            self.day = day
+            self.hour = hour
+            self.minute = minute
+            self.second = second
+            self.microsecond = microsecond
+
+            if any(x is not None and int(x) != x
+                   for x in (year, month, day, hour,
+                             minute, second, microsecond)):
+                # For now we'll deprecate floats - later it'll be an error.
+                warn("Non-integer value passed as absolute information. " +
+                     "This is not a well-defined condition and will raise " +
+                     "errors in future versions.", DeprecationWarning)
+
+            if isinstance(weekday, integer_types):
+                self.weekday = weekdays[weekday]
+            else:
+                self.weekday = weekday
+
+            yday = 0
+            if nlyearday:
+                yday = nlyearday
+            elif yearday:
+                yday = yearday
+                if yearday > 59:
+                    self.leapdays = -1
+            if yday:
+                ydayidx = [31, 59, 90, 120, 151, 181, 212,
+                           243, 273, 304, 334, 366]
+                for idx, ydays in enumerate(ydayidx):
+                    if yday <= ydays:
+                        self.month = idx+1
+                        if idx == 0:
+                            self.day = yday
+                        else:
+                            self.day = yday-ydayidx[idx-1]
+                        break
+                else:
+                    raise ValueError("invalid year day (%d)" % yday)
+
+        self._fix()
+
+    def _fix(self):
+        if abs(self.microseconds) > 999999:
+            s = _sign(self.microseconds)
+            div, mod = divmod(self.microseconds * s, 1000000)
+            self.microseconds = mod * s
+            self.seconds += div * s
+        if abs(self.seconds) > 59:
+            s = _sign(self.seconds)
+            div, mod = divmod(self.seconds * s, 60)
+            self.seconds = mod * s
+            self.minutes += div * s
+        if abs(self.minutes) > 59:
+            s = _sign(self.minutes)
+            div, mod = divmod(self.minutes * s, 60)
+            self.minutes = mod * s
+            self.hours += div * s
+        if abs(self.hours) > 23:
+            s = _sign(self.hours)
+            div, mod = divmod(self.hours * s, 24)
+            self.hours = mod * s
+            self.days += div * s
+        if abs(self.months) > 11:
+            s = _sign(self.months)
+            div, mod = divmod(self.months * s, 12)
+            self.months = mod * s
+            self.years += div * s
+        if (self.hours or self.minutes or self.seconds or self.microseconds
+                or self.hour is not None or self.minute is not None or
+                self.second is not None or self.microsecond is not None):
+            self._has_time = 1
+        else:
+            self._has_time = 0
+
+    @property
+    def weeks(self):
+        return int(self.days / 7.0)
+
+    @weeks.setter
+    def weeks(self, value):
+        self.days = self.days - (self.weeks * 7) + value * 7
+
+    def _set_months(self, months):
+        self.months = months
+        if abs(self.months) > 11:
+            s = _sign(self.months)
+            div, mod = divmod(self.months * s, 12)
+            self.months = mod * s
+            self.years = div * s
+        else:
+            self.years = 0
+
+    def normalized(self):
+        """
+        Return a version of this object represented entirely using integer
+        values for the relative attributes.
+
+        >>> relativedelta(days=1.5, hours=2).normalized()
+        relativedelta(days=+1, hours=+14)
+
+        :return:
+            Returns a :class:`dateutil.relativedelta.relativedelta` object.
+        """
+        # Cascade remainders down (rounding each to roughly nearest microsecond)
+        days = int(self.days)
+
+        hours_f = round(self.hours + 24 * (self.days - days), 11)
+        hours = int(hours_f)
+
+        minutes_f = round(self.minutes + 60 * (hours_f - hours), 10)
+        minutes = int(minutes_f)
+
+        seconds_f = round(self.seconds + 60 * (minutes_f - minutes), 8)
+        seconds = int(seconds_f)
+
+        microseconds = round(self.microseconds + 1e6 * (seconds_f - seconds))
+
+        # Constructor carries overflow back up with call to _fix()
+        return self.__class__(years=self.years, months=self.months,
+                              days=days, hours=hours, minutes=minutes,
+                              seconds=seconds, microseconds=microseconds,
+                              leapdays=self.leapdays, year=self.year,
+                              month=self.month, day=self.day,
+                              weekday=self.weekday, hour=self.hour,
+                              minute=self.minute, second=self.second,
+                              microsecond=self.microsecond)
+
+    def __add__(self, other):
+        if isinstance(other, relativedelta):
+            return self.__class__(years=other.years + self.years,
+                                 months=other.months + self.months,
+                                 days=other.days + self.days,
+                                 hours=other.hours + self.hours,
+                                 minutes=other.minutes + self.minutes,
+                                 seconds=other.seconds + self.seconds,
+                                 microseconds=(other.microseconds +
+                                               self.microseconds),
+                                 leapdays=other.leapdays or self.leapdays,
+                                 year=(other.year if other.year is not None
+                                       else self.year),
+                                 month=(other.month if other.month is not None
+                                        else self.month),
+                                 day=(other.day if other.day is not None
+                                      else self.day),
+                                 weekday=(other.weekday if other.weekday is not None
+                                          else self.weekday),
+                                 hour=(other.hour if other.hour is not None
+                                       else self.hour),
+                                 minute=(other.minute if other.minute is not None
+                                         else self.minute),
+                                 second=(other.second if other.second is not None
+                                         else self.second),
+                                 microsecond=(other.microsecond if other.microsecond
+                                              is not None else
+                                              self.microsecond))
+        if isinstance(other, datetime.timedelta):
+            return self.__class__(years=self.years,
+                                  months=self.months,
+                                  days=self.days + other.days,
+                                  hours=self.hours,
+                                  minutes=self.minutes,
+                                  seconds=self.seconds + other.seconds,
+                                  microseconds=self.microseconds + other.microseconds,
+                                  leapdays=self.leapdays,
+                                  year=self.year,
+                                  month=self.month,
+                                  day=self.day,
+                                  weekday=self.weekday,
+                                  hour=self.hour,
+                                  minute=self.minute,
+                                  second=self.second,
+                                  microsecond=self.microsecond)
+        if not isinstance(other, datetime.date):
+            return NotImplemented
+        elif self._has_time and not isinstance(other, datetime.datetime):
+            other = datetime.datetime.fromordinal(other.toordinal())
+        year = (self.year or other.year)+self.years
+        month = self.month or other.month
+        if self.months:
+            assert 1 <= abs(self.months) <= 12
+            month += self.months
+            if month > 12:
+                year += 1
+                month -= 12
+            elif month < 1:
+                year -= 1
+                month += 12
+        day = min(calendar.monthrange(year, month)[1],
+                  self.day or other.day)
+        repl = {"year": year, "month": month, "day": day}
+        for attr in ["hour", "minute", "second", "microsecond"]:
+            value = getattr(self, attr)
+            if value is not None:
+                repl[attr] = value
+        days = self.days
+        if self.leapdays and month > 2 and calendar.isleap(year):
+            days += self.leapdays
+        ret = (other.replace(**repl)
+               + datetime.timedelta(days=days,
+                                    hours=self.hours,
+                                    minutes=self.minutes,
+                                    seconds=self.seconds,
+                                    microseconds=self.microseconds))
+        if self.weekday:
+            weekday, nth = self.weekday.weekday, self.weekday.n or 1
+            jumpdays = (abs(nth) - 1) * 7
+            if nth > 0:
+                jumpdays += (7 - ret.weekday() + weekday) % 7
+            else:
+                jumpdays += (ret.weekday() - weekday) % 7
+                jumpdays *= -1
+            ret += datetime.timedelta(days=jumpdays)
+        return ret
+
+    def __radd__(self, other):
+        return self.__add__(other)
+
+    def __rsub__(self, other):
+        return self.__neg__().__radd__(other)
+
+    def __sub__(self, other):
+        if not isinstance(other, relativedelta):
+            return NotImplemented   # In case the other object defines __rsub__
+        return self.__class__(years=self.years - other.years,
+                             months=self.months - other.months,
+                             days=self.days - other.days,
+                             hours=self.hours - other.hours,
+                             minutes=self.minutes - other.minutes,
+                             seconds=self.seconds - other.seconds,
+                             microseconds=self.microseconds - other.microseconds,
+                             leapdays=self.leapdays or other.leapdays,
+                             year=(self.year if self.year is not None
+                                   else other.year),
+                             month=(self.month if self.month is not None else
+                                    other.month),
+                             day=(self.day if self.day is not None else
+                                  other.day),
+                             weekday=(self.weekday if self.weekday is not None else
+                                      other.weekday),
+                             hour=(self.hour if self.hour is not None else
+                                   other.hour),
+                             minute=(self.minute if self.minute is not None else
+                                     other.minute),
+                             second=(self.second if self.second is not None else
+                                     other.second),
+                             microsecond=(self.microsecond if self.microsecond
+                                          is not None else
+                                          other.microsecond))
+
+    def __abs__(self):
+        return self.__class__(years=abs(self.years),
+                              months=abs(self.months),
+                              days=abs(self.days),
+                              hours=abs(self.hours),
+                              minutes=abs(self.minutes),
+                              seconds=abs(self.seconds),
+                              microseconds=abs(self.microseconds),
+                              leapdays=self.leapdays,
+                              year=self.year,
+                              month=self.month,
+                              day=self.day,
+                              weekday=self.weekday,
+                              hour=self.hour,
+                              minute=self.minute,
+                              second=self.second,
+                              microsecond=self.microsecond)
+
+    def __neg__(self):
+        return self.__class__(years=-self.years,
+                             months=-self.months,
+                             days=-self.days,
+                             hours=-self.hours,
+                             minutes=-self.minutes,
+                             seconds=-self.seconds,
+                             microseconds=-self.microseconds,
+                             leapdays=self.leapdays,
+                             year=self.year,
+                             month=self.month,
+                             day=self.day,
+                             weekday=self.weekday,
+                             hour=self.hour,
+                             minute=self.minute,
+                             second=self.second,
+                             microsecond=self.microsecond)
+
+    def __bool__(self):
+        return not (not self.years and
+                    not self.months and
+                    not self.days and
+                    not self.hours and
+                    not self.minutes and
+                    not self.seconds and
+                    not self.microseconds and
+                    not self.leapdays and
+                    self.year is None and
+                    self.month is None and
+                    self.day is None and
+                    self.weekday is None and
+                    self.hour is None and
+                    self.minute is None and
+                    self.second is None and
+                    self.microsecond is None)
+    # Compatibility with Python 2.x
+    __nonzero__ = __bool__
+
+    def __mul__(self, other):
+        try:
+            f = float(other)
+        except TypeError:
+            return NotImplemented
+
+        return self.__class__(years=int(self.years * f),
+                             months=int(self.months * f),
+                             days=int(self.days * f),
+                             hours=int(self.hours * f),
+                             minutes=int(self.minutes * f),
+                             seconds=int(self.seconds * f),
+                             microseconds=int(self.microseconds * f),
+                             leapdays=self.leapdays,
+                             year=self.year,
+                             month=self.month,
+                             day=self.day,
+                             weekday=self.weekday,
+                             hour=self.hour,
+                             minute=self.minute,
+                             second=self.second,
+                             microsecond=self.microsecond)
+
+    __rmul__ = __mul__
+
+    def __eq__(self, other):
+        if not isinstance(other, relativedelta):
+            return NotImplemented
+        if self.weekday or other.weekday:
+            if not self.weekday or not other.weekday:
+                return False
+            if self.weekday.weekday != other.weekday.weekday:
+                return False
+            n1, n2 = self.weekday.n, other.weekday.n
+            if n1 != n2 and not ((not n1 or n1 == 1) and (not n2 or n2 == 1)):
+                return False
+        return (self.years == other.years and
+                self.months == other.months and
+                self.days == other.days and
+                self.hours == other.hours and
+                self.minutes == other.minutes and
+                self.seconds == other.seconds and
+                self.microseconds == other.microseconds and
+                self.leapdays == other.leapdays and
+                self.year == other.year and
+                self.month == other.month and
+                self.day == other.day and
+                self.hour == other.hour and
+                self.minute == other.minute and
+                self.second == other.second and
+                self.microsecond == other.microsecond)
+
+    def __hash__(self):
+        return hash((
+            self.weekday,
+            self.years,
+            self.months,
+            self.days,
+            self.hours,
+            self.minutes,
+            self.seconds,
+            self.microseconds,
+            self.leapdays,
+            self.year,
+            self.month,
+            self.day,
+            self.hour,
+            self.minute,
+            self.second,
+            self.microsecond,
+        ))
+
+    def __ne__(self, other):
+        return not self.__eq__(other)
+
+    def __div__(self, other):
+        try:
+            reciprocal = 1 / float(other)
+        except TypeError:
+            return NotImplemented
+
+        return self.__mul__(reciprocal)
+
+    __truediv__ = __div__
+
+    def __repr__(self):
+        l = []
+        for attr in ["years", "months", "days", "leapdays",
+                     "hours", "minutes", "seconds", "microseconds"]:
+            value = getattr(self, attr)
+            if value:
+                l.append("{attr}={value:+g}".format(attr=attr, value=value))
+        for attr in ["year", "month", "day", "weekday",
+                     "hour", "minute", "second", "microsecond"]:
+            value = getattr(self, attr)
+            if value is not None:
+                l.append("{attr}={value}".format(attr=attr, value=repr(value)))
+        return "{classname}({attrs})".format(classname=self.__class__.__name__,
+                                             attrs=", ".join(l))
+
+
+def _sign(x):
+    return int(copysign(1, x))
+
+# vim:ts=4:sw=4:et
Index: venv/Lib/site-packages/dateutil/rrule.py
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/venv/Lib/site-packages/dateutil/rrule.py b/venv/Lib/site-packages/dateutil/rrule.py
new file mode 100644
--- /dev/null	(date 1616410449171)
+++ b/venv/Lib/site-packages/dateutil/rrule.py	(date 1616410449171)
@@ -0,0 +1,1735 @@
+# -*- coding: utf-8 -*-
+"""
+The rrule module offers a small, complete, and very fast, implementation of
+the recurrence rules documented in the
+`iCalendar RFC <https://tools.ietf.org/html/rfc5545>`_,
+including support for caching of results.
+"""
+import itertools
+import datetime
+import calendar
+import re
+import sys
+
+try:
+    from math import gcd
+except ImportError:
+    from fractions import gcd
+
+from six import advance_iterator, integer_types
+from six.moves import _thread, range
+import heapq
+
+from ._common import weekday as weekdaybase
+
+# For warning about deprecation of until and count
+from warnings import warn
+
+__all__ = ["rrule", "rruleset", "rrulestr",
+           "YEARLY", "MONTHLY", "WEEKLY", "DAILY",
+           "HOURLY", "MINUTELY", "SECONDLY",
+           "MO", "TU", "WE", "TH", "FR", "SA", "SU"]
+
+# Every mask is 7 days longer to handle cross-year weekly periods.
+M366MASK = tuple([1]*31+[2]*29+[3]*31+[4]*30+[5]*31+[6]*30 +
+                 [7]*31+[8]*31+[9]*30+[10]*31+[11]*30+[12]*31+[1]*7)
+M365MASK = list(M366MASK)
+M29, M30, M31 = list(range(1, 30)), list(range(1, 31)), list(range(1, 32))
+MDAY366MASK = tuple(M31+M29+M31+M30+M31+M30+M31+M31+M30+M31+M30+M31+M31[:7])
+MDAY365MASK = list(MDAY366MASK)
+M29, M30, M31 = list(range(-29, 0)), list(range(-30, 0)), list(range(-31, 0))
+NMDAY366MASK = tuple(M31+M29+M31+M30+M31+M30+M31+M31+M30+M31+M30+M31+M31[:7])
+NMDAY365MASK = list(NMDAY366MASK)
+M366RANGE = (0, 31, 60, 91, 121, 152, 182, 213, 244, 274, 305, 335, 366)
+M365RANGE = (0, 31, 59, 90, 120, 151, 181, 212, 243, 273, 304, 334, 365)
+WDAYMASK = [0, 1, 2, 3, 4, 5, 6]*55
+del M29, M30, M31, M365MASK[59], MDAY365MASK[59], NMDAY365MASK[31]
+MDAY365MASK = tuple(MDAY365MASK)
+M365MASK = tuple(M365MASK)
+
+FREQNAMES = ['YEARLY', 'MONTHLY', 'WEEKLY', 'DAILY', 'HOURLY', 'MINUTELY', 'SECONDLY']
+
+(YEARLY,
+ MONTHLY,
+ WEEKLY,
+ DAILY,
+ HOURLY,
+ MINUTELY,
+ SECONDLY) = list(range(7))
+
+# Imported on demand.
+easter = None
+parser = None
+
+
+class weekday(weekdaybase):
+    """
+    This version of weekday does not allow n = 0.
+    """
+    def __init__(self, wkday, n=None):
+        if n == 0:
+            raise ValueError("Can't create weekday with n==0")
+
+        super(weekday, self).__init__(wkday, n)
+
+
+MO, TU, WE, TH, FR, SA, SU = weekdays = tuple(weekday(x) for x in range(7))
+
+
+def _invalidates_cache(f):
+    """
+    Decorator for rruleset methods which may invalidate the
+    cached length.
+    """
+    def inner_func(self, *args, **kwargs):
+        rv = f(self, *args, **kwargs)
+        self._invalidate_cache()
+        return rv
+
+    return inner_func
+
+
+class rrulebase(object):
+    def __init__(self, cache=False):
+        if cache:
+            self._cache = []
+            self._cache_lock = _thread.allocate_lock()
+            self._invalidate_cache()
+        else:
+            self._cache = None
+            self._cache_complete = False
+            self._len = None
+
+    def __iter__(self):
+        if self._cache_complete:
+            return iter(self._cache)
+        elif self._cache is None:
+            return self._iter()
+        else:
+            return self._iter_cached()
+
+    def _invalidate_cache(self):
+        if self._cache is not None:
+            self._cache = []
+            self._cache_complete = False
+            self._cache_gen = self._iter()
+
+            if self._cache_lock.locked():
+                self._cache_lock.release()
+
+        self._len = None
+
+    def _iter_cached(self):
+        i = 0
+        gen = self._cache_gen
+        cache = self._cache
+        acquire = self._cache_lock.acquire
+        release = self._cache_lock.release
+        while gen:
+            if i == len(cache):
+                acquire()
+                if self._cache_complete:
+                    break
+                try:
+                    for j in range(10):
+                        cache.append(advance_iterator(gen))
+                except StopIteration:
+                    self._cache_gen = gen = None
+                    self._cache_complete = True
+                    break
+                release()
+            yield cache[i]
+            i += 1
+        while i < self._len:
+            yield cache[i]
+            i += 1
+
+    def __getitem__(self, item):
+        if self._cache_complete:
+            return self._cache[item]
+        elif isinstance(item, slice):
+            if item.step and item.step < 0:
+                return list(iter(self))[item]
+            else:
+                return list(itertools.islice(self,
+                                             item.start or 0,
+                                             item.stop or sys.maxsize,
+                                             item.step or 1))
+        elif item >= 0:
+            gen = iter(self)
+            try:
+                for i in range(item+1):
+                    res = advance_iterator(gen)
+            except StopIteration:
+                raise IndexError
+            return res
+        else:
+            return list(iter(self))[item]
+
+    def __contains__(self, item):
+        if self._cache_complete:
+            return item in self._cache
+        else:
+            for i in self:
+                if i == item:
+                    return True
+                elif i > item:
+                    return False
+        return False
+
+    # __len__() introduces a large performance penalty.
+    def count(self):
+        """ Returns the number of recurrences in this set. It will have go
+            trough the whole recurrence, if this hasn't been done before. """
+        if self._len is None:
+            for x in self:
+                pass
+        return self._len
+
+    def before(self, dt, inc=False):
+        """ Returns the last recurrence before the given datetime instance. The
+            inc keyword defines what happens if dt is an occurrence. With
+            inc=True, if dt itself is an occurrence, it will be returned. """
+        if self._cache_complete:
+            gen = self._cache
+        else:
+            gen = self
+        last = None
+        if inc:
+            for i in gen:
+                if i > dt:
+                    break
+                last = i
+        else:
+            for i in gen:
+                if i >= dt:
+                    break
+                last = i
+        return last
+
+    def after(self, dt, inc=False):
+        """ Returns the first recurrence after the given datetime instance. The
+            inc keyword defines what happens if dt is an occurrence. With
+            inc=True, if dt itself is an occurrence, it will be returned.  """
+        if self._cache_complete:
+            gen = self._cache
+        else:
+            gen = self
+        if inc:
+            for i in gen:
+                if i >= dt:
+                    return i
+        else:
+            for i in gen:
+                if i > dt:
+                    return i
+        return None
+
+    def xafter(self, dt, count=None, inc=False):
+        """
+        Generator which yields up to `count` recurrences after the given
+        datetime instance, equivalent to `after`.
+
+        :param dt:
+            The datetime at which to start generating recurrences.
+
+        :param count:
+            The maximum number of recurrences to generate. If `None` (default),
+            dates are generated until the recurrence rule is exhausted.
+
+        :param inc:
+            If `dt` is an instance of the rule and `inc` is `True`, it is
+            included in the output.
+
+        :yields: Yields a sequence of `datetime` objects.
+        """
+
+        if self._cache_complete:
+            gen = self._cache
+        else:
+            gen = self
+
+        # Select the comparison function
+        if inc:
+            comp = lambda dc, dtc: dc >= dtc
+        else:
+            comp = lambda dc, dtc: dc > dtc
+
+        # Generate dates
+        n = 0
+        for d in gen:
+            if comp(d, dt):
+                if count is not None:
+                    n += 1
+                    if n > count:
+                        break
+
+                yield d
+
+    def between(self, after, before, inc=False, count=1):
+        """ Returns all the occurrences of the rrule between after and before.
+        The inc keyword defines what happens if after and/or before are
+        themselves occurrences. With inc=True, they will be included in the
+        list, if they are found in the recurrence set. """
+        if self._cache_complete:
+            gen = self._cache
+        else:
+            gen = self
+        started = False
+        l = []
+        if inc:
+            for i in gen:
+                if i > before:
+                    break
+                elif not started:
+                    if i >= after:
+                        started = True
+                        l.append(i)
+                else:
+                    l.append(i)
+        else:
+            for i in gen:
+                if i >= before:
+                    break
+                elif not started:
+                    if i > after:
+                        started = True
+                        l.append(i)
+                else:
+                    l.append(i)
+        return l
+
+
+class rrule(rrulebase):
+    """
+    That's the base of the rrule operation. It accepts all the keywords
+    defined in the RFC as its constructor parameters (except byday,
+    which was renamed to byweekday) and more. The constructor prototype is::
+
+            rrule(freq)
+
+    Where freq must be one of YEARLY, MONTHLY, WEEKLY, DAILY, HOURLY, MINUTELY,
+    or SECONDLY.
+
+    .. note::
+        Per RFC section 3.3.10, recurrence instances falling on invalid dates
+        and times are ignored rather than coerced:
+
+            Recurrence rules may generate recurrence instances with an invalid
+            date (e.g., February 30) or nonexistent local time (e.g., 1:30 AM
+            on a day where the local time is moved forward by an hour at 1:00
+            AM).  Such recurrence instances MUST be ignored and MUST NOT be
+            counted as part of the recurrence set.
+
+        This can lead to possibly surprising behavior when, for example, the
+        start date occurs at the end of the month:
+
+        >>> from dateutil.rrule import rrule, MONTHLY
+        >>> from datetime import datetime
+        >>> start_date = datetime(2014, 12, 31)
+        >>> list(rrule(freq=MONTHLY, count=4, dtstart=start_date))
+        ... # doctest: +NORMALIZE_WHITESPACE
+        [datetime.datetime(2014, 12, 31, 0, 0),
+         datetime.datetime(2015, 1, 31, 0, 0),
+         datetime.datetime(2015, 3, 31, 0, 0),
+         datetime.datetime(2015, 5, 31, 0, 0)]
+
+    Additionally, it supports the following keyword arguments:
+
+    :param dtstart:
+        The recurrence start. Besides being the base for the recurrence,
+        missing parameters in the final recurrence instances will also be
+        extracted from this date. If not given, datetime.now() will be used
+        instead.
+    :param interval:
+        The interval between each freq iteration. For example, when using
+        YEARLY, an interval of 2 means once every two years, but with HOURLY,
+        it means once every two hours. The default interval is 1.
+    :param wkst:
+        The week start day. Must be one of the MO, TU, WE constants, or an
+        integer, specifying the first day of the week. This will affect
+        recurrences based on weekly periods. The default week start is got
+        from calendar.firstweekday(), and may be modified by
+        calendar.setfirstweekday().
+    :param count:
+        If given, this determines how many occurrences will be generated.
+
+        .. note::
+            As of version 2.5.0, the use of the keyword ``until`` in conjunction
+            with ``count`` is deprecated, to make sure ``dateutil`` is fully
+            compliant with `RFC-5545 Sec. 3.3.10 <https://tools.ietf.org/
+            html/rfc5545#section-3.3.10>`_. Therefore, ``until`` and ``count``
+            **must not** occur in the same call to ``rrule``.
+    :param until:
+        If given, this must be a datetime instance specifying the upper-bound
+        limit of the recurrence. The last recurrence in the rule is the greatest
+        datetime that is less than or equal to the value specified in the
+        ``until`` parameter.
+
+        .. note::
+            As of version 2.5.0, the use of the keyword ``until`` in conjunction
+            with ``count`` is deprecated, to make sure ``dateutil`` is fully
+            compliant with `RFC-5545 Sec. 3.3.10 <https://tools.ietf.org/
+            html/rfc5545#section-3.3.10>`_. Therefore, ``until`` and ``count``
+            **must not** occur in the same call to ``rrule``.
+    :param bysetpos:
+        If given, it must be either an integer, or a sequence of integers,
+        positive or negative. Each given integer will specify an occurrence
+        number, corresponding to the nth occurrence of the rule inside the
+        frequency period. For example, a bysetpos of -1 if combined with a
+        MONTHLY frequency, and a byweekday of (MO, TU, WE, TH, FR), will
+        result in the last work day of every month.
+    :param bymonth:
+        If given, it must be either an integer, or a sequence of integers,
+        meaning the months to apply the recurrence to.
+    :param bymonthday:
+        If given, it must be either an integer, or a sequence of integers,
+        meaning the month days to apply the recurrence to.
+    :param byyearday:
+        If given, it must be either an integer, or a sequence of integers,
+        meaning the year days to apply the recurrence to.
+    :param byeaster:
+        If given, it must be either an integer, or a sequence of integers,
+        positive or negative. Each integer will define an offset from the
+        Easter Sunday. Passing the offset 0 to byeaster will yield the Easter
+        Sunday itself. This is an extension to the RFC specification.
+    :param byweekno:
+        If given, it must be either an integer, or a sequence of integers,
+        meaning the week numbers to apply the recurrence to. Week numbers
+        have the meaning described in ISO8601, that is, the first week of
+        the year is that containing at least four days of the new year.
+    :param byweekday:
+        If given, it must be either an integer (0 == MO), a sequence of
+        integers, one of the weekday constants (MO, TU, etc), or a sequence
+        of these constants. When given, these variables will define the
+        weekdays where the recurrence will be applied. It's also possible to
+        use an argument n for the weekday instances, which will mean the nth
+        occurrence of this weekday in the period. For example, with MONTHLY,
+        or with YEARLY and BYMONTH, using FR(+1) in byweekday will specify the
+        first friday of the month where the recurrence happens. Notice that in
+        the RFC documentation, this is specified as BYDAY, but was renamed to
+        avoid the ambiguity of that keyword.
+    :param byhour:
+        If given, it must be either an integer, or a sequence of integers,
+        meaning the hours to apply the recurrence to.
+    :param byminute:
+        If given, it must be either an integer, or a sequence of integers,
+        meaning the minutes to apply the recurrence to.
+    :param bysecond:
+        If given, it must be either an integer, or a sequence of integers,
+        meaning the seconds to apply the recurrence to.
+    :param cache:
+        If given, it must be a boolean value specifying to enable or disable
+        caching of results. If you will use the same rrule instance multiple
+        times, enabling caching will improve the performance considerably.
+     """
+    def __init__(self, freq, dtstart=None,
+                 interval=1, wkst=None, count=None, until=None, bysetpos=None,
+                 bymonth=None, bymonthday=None, byyearday=None, byeaster=None,
+                 byweekno=None, byweekday=None,
+                 byhour=None, byminute=None, bysecond=None,
+                 cache=False):
+        super(rrule, self).__init__(cache)
+        global easter
+        if not dtstart:
+            if until and until.tzinfo:
+                dtstart = datetime.datetime.now(tz=until.tzinfo).replace(microsecond=0)
+            else:
+                dtstart = datetime.datetime.now().replace(microsecond=0)
+        elif not isinstance(dtstart, datetime.datetime):
+            dtstart = datetime.datetime.fromordinal(dtstart.toordinal())
+        else:
+            dtstart = dtstart.replace(microsecond=0)
+        self._dtstart = dtstart
+        self._tzinfo = dtstart.tzinfo
+        self._freq = freq
+        self._interval = interval
+        self._count = count
+
+        # Cache the original byxxx rules, if they are provided, as the _byxxx
+        # attributes do not necessarily map to the inputs, and this can be
+        # a problem in generating the strings. Only store things if they've
+        # been supplied (the string retrieval will just use .get())
+        self._original_rule = {}
+
+        if until and not isinstance(until, datetime.datetime):
+            until = datetime.datetime.fromordinal(until.toordinal())
+        self._until = until
+
+        if self._dtstart and self._until:
+            if (self._dtstart.tzinfo is not None) != (self._until.tzinfo is not None):
+                # According to RFC5545 Section 3.3.10:
+                # https://tools.ietf.org/html/rfc5545#section-3.3.10
+                #
+                # > If the "DTSTART" property is specified as a date with UTC
+                # > time or a date with local time and time zone reference,
+                # > then the UNTIL rule part MUST be specified as a date with
+                # > UTC time.
+                raise ValueError(
+                    'RRULE UNTIL values must be specified in UTC when DTSTART '
+                    'is timezone-aware'
+                )
+
+        if count is not None and until:
+            warn("Using both 'count' and 'until' is inconsistent with RFC 5545"
+                 " and has been deprecated in dateutil. Future versions will "
+                 "raise an error.", DeprecationWarning)
+
+        if wkst is None:
+            self._wkst = calendar.firstweekday()
+        elif isinstance(wkst, integer_types):
+            self._wkst = wkst
+        else:
+            self._wkst = wkst.weekday
+
+        if bysetpos is None:
+            self._bysetpos = None
+        elif isinstance(bysetpos, integer_types):
+            if bysetpos == 0 or not (-366 <= bysetpos <= 366):
+                raise ValueError("bysetpos must be between 1 and 366, "
+                                 "or between -366 and -1")
+            self._bysetpos = (bysetpos,)
+        else:
+            self._bysetpos = tuple(bysetpos)
+            for pos in self._bysetpos:
+                if pos == 0 or not (-366 <= pos <= 366):
+                    raise ValueError("bysetpos must be between 1 and 366, "
+                                     "or between -366 and -1")
+
+        if self._bysetpos:
+            self._original_rule['bysetpos'] = self._bysetpos
+
+        if (byweekno is None and byyearday is None and bymonthday is None and
+                byweekday is None and byeaster is None):
+            if freq == YEARLY:
+                if bymonth is None:
+                    bymonth = dtstart.month
+                    self._original_rule['bymonth'] = None
+                bymonthday = dtstart.day
+                self._original_rule['bymonthday'] = None
+            elif freq == MONTHLY:
+                bymonthday = dtstart.day
+                self._original_rule['bymonthday'] = None
+            elif freq == WEEKLY:
+                byweekday = dtstart.weekday()
+                self._original_rule['byweekday'] = None
+
+        # bymonth
+        if bymonth is None:
+            self._bymonth = None
+        else:
+            if isinstance(bymonth, integer_types):
+                bymonth = (bymonth,)
+
+            self._bymonth = tuple(sorted(set(bymonth)))
+
+            if 'bymonth' not in self._original_rule:
+                self._original_rule['bymonth'] = self._bymonth
+
+        # byyearday
+        if byyearday is None:
+            self._byyearday = None
+        else:
+            if isinstance(byyearday, integer_types):
+                byyearday = (byyearday,)
+
+            self._byyearday = tuple(sorted(set(byyearday)))
+            self._original_rule['byyearday'] = self._byyearday
+
+        # byeaster
+        if byeaster is not None:
+            if not easter:
+                from dateutil import easter
+            if isinstance(byeaster, integer_types):
+                self._byeaster = (byeaster,)
+            else:
+                self._byeaster = tuple(sorted(byeaster))
+
+            self._original_rule['byeaster'] = self._byeaster
+        else:
+            self._byeaster = None
+
+        # bymonthday
+        if bymonthday is None:
+            self._bymonthday = ()
+            self._bynmonthday = ()
+        else:
+            if isinstance(bymonthday, integer_types):
+                bymonthday = (bymonthday,)
+
+            bymonthday = set(bymonthday)            # Ensure it's unique
+
+            self._bymonthday = tuple(sorted(x for x in bymonthday if x > 0))
+            self._bynmonthday = tuple(sorted(x for x in bymonthday if x < 0))
+
+            # Storing positive numbers first, then negative numbers
+            if 'bymonthday' not in self._original_rule:
+                self._original_rule['bymonthday'] = tuple(
+                    itertools.chain(self._bymonthday, self._bynmonthday))
+
+        # byweekno
+        if byweekno is None:
+            self._byweekno = None
+        else:
+            if isinstance(byweekno, integer_types):
+                byweekno = (byweekno,)
+
+            self._byweekno = tuple(sorted(set(byweekno)))
+
+            self._original_rule['byweekno'] = self._byweekno
+
+        # byweekday / bynweekday
+        if byweekday is None:
+            self._byweekday = None
+            self._bynweekday = None
+        else:
+            # If it's one of the valid non-sequence types, convert to a
+            # single-element sequence before the iterator that builds the
+            # byweekday set.
+            if isinstance(byweekday, integer_types) or hasattr(byweekday, "n"):
+                byweekday = (byweekday,)
+
+            self._byweekday = set()
+            self._bynweekday = set()
+            for wday in byweekday:
+                if isinstance(wday, integer_types):
+                    self._byweekday.add(wday)
+                elif not wday.n or freq > MONTHLY:
+                    self._byweekday.add(wday.weekday)
+                else:
+                    self._bynweekday.add((wday.weekday, wday.n))
+
+            if not self._byweekday:
+                self._byweekday = None
+            elif not self._bynweekday:
+                self._bynweekday = None
+
+            if self._byweekday is not None:
+                self._byweekday = tuple(sorted(self._byweekday))
+                orig_byweekday = [weekday(x) for x in self._byweekday]
+            else:
+                orig_byweekday = ()
+
+            if self._bynweekday is not None:
+                self._bynweekday = tuple(sorted(self._bynweekday))
+                orig_bynweekday = [weekday(*x) for x in self._bynweekday]
+            else:
+                orig_bynweekday = ()
+
+            if 'byweekday' not in self._original_rule:
+                self._original_rule['byweekday'] = tuple(itertools.chain(
+                    orig_byweekday, orig_bynweekday))
+
+        # byhour
+        if byhour is None:
+            if freq < HOURLY:
+                self._byhour = {dtstart.hour}
+            else:
+                self._byhour = None
+        else:
+            if isinstance(byhour, integer_types):
+                byhour = (byhour,)
+
+            if freq == HOURLY:
+                self._byhour = self.__construct_byset(start=dtstart.hour,
+                                                      byxxx=byhour,
+                                                      base=24)
+            else:
+                self._byhour = set(byhour)
+
+            self._byhour = tuple(sorted(self._byhour))
+            self._original_rule['byhour'] = self._byhour
+
+        # byminute
+        if byminute is None:
+            if freq < MINUTELY:
+                self._byminute = {dtstart.minute}
+            else:
+                self._byminute = None
+        else:
+            if isinstance(byminute, integer_types):
+                byminute = (byminute,)
+
+            if freq == MINUTELY:
+                self._byminute = self.__construct_byset(start=dtstart.minute,
+                                                        byxxx=byminute,
+                                                        base=60)
+            else:
+                self._byminute = set(byminute)
+
+            self._byminute = tuple(sorted(self._byminute))
+            self._original_rule['byminute'] = self._byminute
+
+        # bysecond
+        if bysecond is None:
+            if freq < SECONDLY:
+                self._bysecond = ((dtstart.second,))
+            else:
+                self._bysecond = None
+        else:
+            if isinstance(bysecond, integer_types):
+                bysecond = (bysecond,)
+
+            self._bysecond = set(bysecond)
+
+            if freq == SECONDLY:
+                self._bysecond = self.__construct_byset(start=dtstart.second,
+                                                        byxxx=bysecond,
+                                                        base=60)
+            else:
+                self._bysecond = set(bysecond)
+
+            self._bysecond = tuple(sorted(self._bysecond))
+            self._original_rule['bysecond'] = self._bysecond
+
+        if self._freq >= HOURLY:
+            self._timeset = None
+        else:
+            self._timeset = []
+            for hour in self._byhour:
+                for minute in self._byminute:
+                    for second in self._bysecond:
+                        self._timeset.append(
+                            datetime.time(hour, minute, second,
+                                          tzinfo=self._tzinfo))
+            self._timeset.sort()
+            self._timeset = tuple(self._timeset)
+
+    def __str__(self):
+        """
+        Output a string that would generate this RRULE if passed to rrulestr.
+        This is mostly compatible with RFC5545, except for the
+        dateutil-specific extension BYEASTER.
+        """
+
+        output = []
+        h, m, s = [None] * 3
+        if self._dtstart:
+            output.append(self._dtstart.strftime('DTSTART:%Y%m%dT%H%M%S'))
+            h, m, s = self._dtstart.timetuple()[3:6]
+
+        parts = ['FREQ=' + FREQNAMES[self._freq]]
+        if self._interval != 1:
+            parts.append('INTERVAL=' + str(self._interval))
+
+        if self._wkst:
+            parts.append('WKST=' + repr(weekday(self._wkst))[0:2])
+
+        if self._count is not None:
+            parts.append('COUNT=' + str(self._count))
+
+        if self._until:
+            parts.append(self._until.strftime('UNTIL=%Y%m%dT%H%M%S'))
+
+        if self._original_rule.get('byweekday') is not None:
+            # The str() method on weekday objects doesn't generate
+            # RFC5545-compliant strings, so we should modify that.
+            original_rule = dict(self._original_rule)
+            wday_strings = []
+            for wday in original_rule['byweekday']:
+                if wday.n:
+                    wday_strings.append('{n:+d}{wday}'.format(
+                        n=wday.n,
+                        wday=repr(wday)[0:2]))
+                else:
+                    wday_strings.append(repr(wday))
+
+            original_rule['byweekday'] = wday_strings
+        else:
+            original_rule = self._original_rule
+
+        partfmt = '{name}={vals}'
+        for name, key in [('BYSETPOS', 'bysetpos'),
+                          ('BYMONTH', 'bymonth'),
+                          ('BYMONTHDAY', 'bymonthday'),
+                          ('BYYEARDAY', 'byyearday'),
+                          ('BYWEEKNO', 'byweekno'),
+                          ('BYDAY', 'byweekday'),
+                          ('BYHOUR', 'byhour'),
+                          ('BYMINUTE', 'byminute'),
+                          ('BYSECOND', 'bysecond'),
+                          ('BYEASTER', 'byeaster')]:
+            value = original_rule.get(key)
+            if value:
+                parts.append(partfmt.format(name=name, vals=(','.join(str(v)
+                                                             for v in value))))
+
+        output.append('RRULE:' + ';'.join(parts))
+        return '\n'.join(output)
+
+    def replace(self, **kwargs):
+        """Return new rrule with same attributes except for those attributes given new
+           values by whichever keyword arguments are specified."""
+        new_kwargs = {"interval": self._interval,
+                      "count": self._count,
+                      "dtstart": self._dtstart,
+                      "freq": self._freq,
+                      "until": self._until,
+                      "wkst": self._wkst,
+                      "cache": False if self._cache is None else True }
+        new_kwargs.update(self._original_rule)
+        new_kwargs.update(kwargs)
+        return rrule(**new_kwargs)
+
+    def _iter(self):
+        year, month, day, hour, minute, second, weekday, yearday, _ = \
+            self._dtstart.timetuple()
+
+        # Some local variables to speed things up a bit
+        freq = self._freq
+        interval = self._interval
+        wkst = self._wkst
+        until = self._until
+        bymonth = self._bymonth
+        byweekno = self._byweekno
+        byyearday = self._byyearday
+        byweekday = self._byweekday
+        byeaster = self._byeaster
+        bymonthday = self._bymonthday
+        bynmonthday = self._bynmonthday
+        bysetpos = self._bysetpos
+        byhour = self._byhour
+        byminute = self._byminute
+        bysecond = self._bysecond
+
+        ii = _iterinfo(self)
+        ii.rebuild(year, month)
+
+        getdayset = {YEARLY: ii.ydayset,
+                     MONTHLY: ii.mdayset,
+                     WEEKLY: ii.wdayset,
+                     DAILY: ii.ddayset,
+                     HOURLY: ii.ddayset,
+                     MINUTELY: ii.ddayset,
+                     SECONDLY: ii.ddayset}[freq]
+
+        if freq < HOURLY:
+            timeset = self._timeset
+        else:
+            gettimeset = {HOURLY: ii.htimeset,
+                          MINUTELY: ii.mtimeset,
+                          SECONDLY: ii.stimeset}[freq]
+            if ((freq >= HOURLY and
+                 self._byhour and hour not in self._byhour) or
+                (freq >= MINUTELY and
+                 self._byminute and minute not in self._byminute) or
+                (freq >= SECONDLY and
+                 self._bysecond and second not in self._bysecond)):
+                timeset = ()
+            else:
+                timeset = gettimeset(hour, minute, second)
+
+        total = 0
+        count = self._count
+        while True:
+            # Get dayset with the right frequency
+            dayset, start, end = getdayset(year, month, day)
+
+            # Do the "hard" work ;-)
+            filtered = False
+            for i in dayset[start:end]:
+                if ((bymonth and ii.mmask[i] not in bymonth) or
+                    (byweekno and not ii.wnomask[i]) or
+                    (byweekday and ii.wdaymask[i] not in byweekday) or
+                    (ii.nwdaymask and not ii.nwdaymask[i]) or
+                    (byeaster and not ii.eastermask[i]) or
+                    ((bymonthday or bynmonthday) and
+                     ii.mdaymask[i] not in bymonthday and
+                     ii.nmdaymask[i] not in bynmonthday) or
+                    (byyearday and
+                     ((i < ii.yearlen and i+1 not in byyearday and
+                       -ii.yearlen+i not in byyearday) or
+                      (i >= ii.yearlen and i+1-ii.yearlen not in byyearday and
+                       -ii.nextyearlen+i-ii.yearlen not in byyearday)))):
+                    dayset[i] = None
+                    filtered = True
+
+            # Output results
+            if bysetpos and timeset:
+                poslist = []
+                for pos in bysetpos:
+                    if pos < 0:
+                        daypos, timepos = divmod(pos, len(timeset))
+                    else:
+                        daypos, timepos = divmod(pos-1, len(timeset))
+                    try:
+                        i = [x for x in dayset[start:end]
+                             if x is not None][daypos]
+                        time = timeset[timepos]
+                    except IndexError:
+                        pass
+                    else:
+                        date = datetime.date.fromordinal(ii.yearordinal+i)
+                        res = datetime.datetime.combine(date, time)
+                        if res not in poslist:
+                            poslist.append(res)
+                poslist.sort()
+                for res in poslist:
+                    if until and res > until:
+                        self._len = total
+                        return
+                    elif res >= self._dtstart:
+                        if count is not None:
+                            count -= 1
+                            if count < 0:
+                                self._len = total
+                                return
+                        total += 1
+                        yield res
+            else:
+                for i in dayset[start:end]:
+                    if i is not None:
+                        date = datetime.date.fromordinal(ii.yearordinal + i)
+                        for time in timeset:
+                            res = datetime.datetime.combine(date, time)
+                            if until and res > until:
+                                self._len = total
+                                return
+                            elif res >= self._dtstart:
+                                if count is not None:
+                                    count -= 1
+                                    if count < 0:
+                                        self._len = total
+                                        return
+
+                                total += 1
+                                yield res
+
+            # Handle frequency and interval
+            fixday = False
+            if freq == YEARLY:
+                year += interval
+                if year > datetime.MAXYEAR:
+                    self._len = total
+                    return
+                ii.rebuild(year, month)
+            elif freq == MONTHLY:
+                month += interval
+                if month > 12:
+                    div, mod = divmod(month, 12)
+                    month = mod
+                    year += div
+                    if month == 0:
+                        month = 12
+                        year -= 1
+                    if year > datetime.MAXYEAR:
+                        self._len = total
+                        return
+                ii.rebuild(year, month)
+            elif freq == WEEKLY:
+                if wkst > weekday:
+                    day += -(weekday+1+(6-wkst))+self._interval*7
+                else:
+                    day += -(weekday-wkst)+self._interval*7
+                weekday = wkst
+                fixday = True
+            elif freq == DAILY:
+                day += interval
+                fixday = True
+            elif freq == HOURLY:
+                if filtered:
+                    # Jump to one iteration before next day
+                    hour += ((23-hour)//interval)*interval
+
+                if byhour:
+                    ndays, hour = self.__mod_distance(value=hour,
+                                                      byxxx=self._byhour,
+                                                      base=24)
+                else:
+                    ndays, hour = divmod(hour+interval, 24)
+
+                if ndays:
+                    day += ndays
+                    fixday = True
+
+                timeset = gettimeset(hour, minute, second)
+            elif freq == MINUTELY:
+                if filtered:
+                    # Jump to one iteration before next day
+                    minute += ((1439-(hour*60+minute))//interval)*interval
+
+                valid = False
+                rep_rate = (24*60)
+                for j in range(rep_rate // gcd(interval, rep_rate)):
+                    if byminute:
+                        nhours, minute = \
+                            self.__mod_distance(value=minute,
+                                                byxxx=self._byminute,
+                                                base=60)
+                    else:
+                        nhours, minute = divmod(minute+interval, 60)
+
+                    div, hour = divmod(hour+nhours, 24)
+                    if div:
+                        day += div
+                        fixday = True
+                        filtered = False
+
+                    if not byhour or hour in byhour:
+                        valid = True
+                        break
+
+                if not valid:
+                    raise ValueError('Invalid combination of interval and ' +
+                                     'byhour resulting in empty rule.')
+
+                timeset = gettimeset(hour, minute, second)
+            elif freq == SECONDLY:
+                if filtered:
+                    # Jump to one iteration before next day
+                    second += (((86399 - (hour * 3600 + minute * 60 + second))
+                                // interval) * interval)
+
+                rep_rate = (24 * 3600)
+                valid = False
+                for j in range(0, rep_rate // gcd(interval, rep_rate)):
+                    if bysecond:
+                        nminutes, second = \
+                            self.__mod_distance(value=second,
+                                                byxxx=self._bysecond,
+                                                base=60)
+                    else:
+                        nminutes, second = divmod(second+interval, 60)
+
+                    div, minute = divmod(minute+nminutes, 60)
+                    if div:
+                        hour += div
+                        div, hour = divmod(hour, 24)
+                        if div:
+                            day += div
+                            fixday = True
+
+                    if ((not byhour or hour in byhour) and
+                            (not byminute or minute in byminute) and
+                            (not bysecond or second in bysecond)):
+                        valid = True
+                        break
+
+                if not valid:
+                    raise ValueError('Invalid combination of interval, ' +
+                                     'byhour and byminute resulting in empty' +
+                                     ' rule.')
+
+                timeset = gettimeset(hour, minute, second)
+
+            if fixday and day > 28:
+                daysinmonth = calendar.monthrange(year, month)[1]
+                if day > daysinmonth:
+                    while day > daysinmonth:
+                        day -= daysinmonth
+                        month += 1
+                        if month == 13:
+                            month = 1
+                            year += 1
+                            if year > datetime.MAXYEAR:
+                                self._len = total
+                                return
+                        daysinmonth = calendar.monthrange(year, month)[1]
+                    ii.rebuild(year, month)
+
+    def __construct_byset(self, start, byxxx, base):
+        """
+        If a `BYXXX` sequence is passed to the constructor at the same level as
+        `FREQ` (e.g. `FREQ=HOURLY,BYHOUR={2,4,7},INTERVAL=3`), there are some
+        specifications which cannot be reached given some starting conditions.
+
+        This occurs whenever the interval is not coprime with the base of a
+        given unit and the difference between the starting position and the
+        ending position is not coprime with the greatest common denominator
+        between the interval and the base. For example, with a FREQ of hourly
+        starting at 17:00 and an interval of 4, the only valid values for
+        BYHOUR would be {21, 1, 5, 9, 13, 17}, because 4 and 24 are not
+        coprime.
+
+        :param start:
+            Specifies the starting position.
+        :param byxxx:
+            An iterable containing the list of allowed values.
+        :param base:
+            The largest allowable value for the specified frequency (e.g.
+            24 hours, 60 minutes).
+
+        This does not preserve the type of the iterable, returning a set, since
+        the values should be unique and the order is irrelevant, this will
+        speed up later lookups.
+
+        In the event of an empty set, raises a :exception:`ValueError`, as this
+        results in an empty rrule.
+        """
+
+        cset = set()
+
+        # Support a single byxxx value.
+        if isinstance(byxxx, integer_types):
+            byxxx = (byxxx, )
+
+        for num in byxxx:
+            i_gcd = gcd(self._interval, base)
+            # Use divmod rather than % because we need to wrap negative nums.
+            if i_gcd == 1 or divmod(num - start, i_gcd)[1] == 0:
+                cset.add(num)
+
+        if len(cset) == 0:
+            raise ValueError("Invalid rrule byxxx generates an empty set.")
+
+        return cset
+
+    def __mod_distance(self, value, byxxx, base):
+        """
+        Calculates the next value in a sequence where the `FREQ` parameter is
+        specified along with a `BYXXX` parameter at the same "level"
+        (e.g. `HOURLY` specified with `BYHOUR`).
+
+        :param value:
+            The old value of the component.
+        :param byxxx:
+            The `BYXXX` set, which should have been generated by
+            `rrule._construct_byset`, or something else which checks that a
+            valid rule is present.
+        :param base:
+            The largest allowable value for the specified frequency (e.g.
+            24 hours, 60 minutes).
+
+        If a valid value is not found after `base` iterations (the maximum
+        number before the sequence would start to repeat), this raises a
+        :exception:`ValueError`, as no valid values were found.
+
+        This returns a tuple of `divmod(n*interval, base)`, where `n` is the
+        smallest number of `interval` repetitions until the next specified
+        value in `byxxx` is found.
+        """
+        accumulator = 0
+        for ii in range(1, base + 1):
+            # Using divmod() over % to account for negative intervals
+            div, value = divmod(value + self._interval, base)
+            accumulator += div
+            if value in byxxx:
+                return (accumulator, value)
+
+
+class _iterinfo(object):
+    __slots__ = ["rrule", "lastyear", "lastmonth",
+                 "yearlen", "nextyearlen", "yearordinal", "yearweekday",
+                 "mmask", "mrange", "mdaymask", "nmdaymask",
+                 "wdaymask", "wnomask", "nwdaymask", "eastermask"]
+
+    def __init__(self, rrule):
+        for attr in self.__slots__:
+            setattr(self, attr, None)
+        self.rrule = rrule
+
+    def rebuild(self, year, month):
+        # Every mask is 7 days longer to handle cross-year weekly periods.
+        rr = self.rrule
+        if year != self.lastyear:
+            self.yearlen = 365 + calendar.isleap(year)
+            self.nextyearlen = 365 + calendar.isleap(year + 1)
+            firstyday = datetime.date(year, 1, 1)
+            self.yearordinal = firstyday.toordinal()
+            self.yearweekday = firstyday.weekday()
+
+            wday = datetime.date(year, 1, 1).weekday()
+            if self.yearlen == 365:
+                self.mmask = M365MASK
+                self.mdaymask = MDAY365MASK
+                self.nmdaymask = NMDAY365MASK
+                self.wdaymask = WDAYMASK[wday:]
+                self.mrange = M365RANGE
+            else:
+                self.mmask = M366MASK
+                self.mdaymask = MDAY366MASK
+                self.nmdaymask = NMDAY366MASK
+                self.wdaymask = WDAYMASK[wday:]
+                self.mrange = M366RANGE
+
+            if not rr._byweekno:
+                self.wnomask = None
+            else:
+                self.wnomask = [0]*(self.yearlen+7)
+                # no1wkst = firstwkst = self.wdaymask.index(rr._wkst)
+                no1wkst = firstwkst = (7-self.yearweekday+rr._wkst) % 7
+                if no1wkst >= 4:
+                    no1wkst = 0
+                    # Number of days in the year, plus the days we got
+                    # from last year.
+                    wyearlen = self.yearlen+(self.yearweekday-rr._wkst) % 7
+                else:
+                    # Number of days in the year, minus the days we
+                    # left in last year.
+                    wyearlen = self.yearlen-no1wkst
+                div, mod = divmod(wyearlen, 7)
+                numweeks = div+mod//4
+                for n in rr._byweekno:
+                    if n < 0:
+                        n += numweeks+1
+                    if not (0 < n <= numweeks):
+                        continue
+                    if n > 1:
+                        i = no1wkst+(n-1)*7
+                        if no1wkst != firstwkst:
+                            i -= 7-firstwkst
+                    else:
+                        i = no1wkst
+                    for j in range(7):
+                        self.wnomask[i] = 1
+                        i += 1
+                        if self.wdaymask[i] == rr._wkst:
+                            break
+                if 1 in rr._byweekno:
+                    # Check week number 1 of next year as well
+                    # TODO: Check -numweeks for next year.
+                    i = no1wkst+numweeks*7
+                    if no1wkst != firstwkst:
+                        i -= 7-firstwkst
+                    if i < self.yearlen:
+                        # If week starts in next year, we
+                        # don't care about it.
+                        for j in range(7):
+                            self.wnomask[i] = 1
+                            i += 1
+                            if self.wdaymask[i] == rr._wkst:
+                                break
+                if no1wkst:
+                    # Check last week number of last year as
+                    # well. If no1wkst is 0, either the year
+                    # started on week start, or week number 1
+                    # got days from last year, so there are no
+                    # days from last year's last week number in
+                    # this year.
+                    if -1 not in rr._byweekno:
+                        lyearweekday = datetime.date(year-1, 1, 1).weekday()
+                        lno1wkst = (7-lyearweekday+rr._wkst) % 7
+                        lyearlen = 365+calendar.isleap(year-1)
+                        if lno1wkst >= 4:
+                            lno1wkst = 0
+                            lnumweeks = 52+(lyearlen +
+                                            (lyearweekday-rr._wkst) % 7) % 7//4
+                        else:
+                            lnumweeks = 52+(self.yearlen-no1wkst) % 7//4
+                    else:
+                        lnumweeks = -1
+                    if lnumweeks in rr._byweekno:
+                        for i in range(no1wkst):
+                            self.wnomask[i] = 1
+
+        if (rr._bynweekday and (month != self.lastmonth or
+                                year != self.lastyear)):
+            ranges = []
+            if rr._freq == YEARLY:
+                if rr._bymonth:
+                    for month in rr._bymonth:
+                        ranges.append(self.mrange[month-1:month+1])
+                else:
+                    ranges = [(0, self.yearlen)]
+            elif rr._freq == MONTHLY:
+                ranges = [self.mrange[month-1:month+1]]
+            if ranges:
+                # Weekly frequency won't get here, so we may not
+                # care about cross-year weekly periods.
+                self.nwdaymask = [0]*self.yearlen
+                for first, last in ranges:
+                    last -= 1
+                    for wday, n in rr._bynweekday:
+                        if n < 0:
+                            i = last+(n+1)*7
+                            i -= (self.wdaymask[i]-wday) % 7
+                        else:
+                            i = first+(n-1)*7
+                            i += (7-self.wdaymask[i]+wday) % 7
+                        if first <= i <= last:
+                            self.nwdaymask[i] = 1
+
+        if rr._byeaster:
+            self.eastermask = [0]*(self.yearlen+7)
+            eyday = easter.easter(year).toordinal()-self.yearordinal
+            for offset in rr._byeaster:
+                self.eastermask[eyday+offset] = 1
+
+        self.lastyear = year
+        self.lastmonth = month
+
+    def ydayset(self, year, month, day):
+        return list(range(self.yearlen)), 0, self.yearlen
+
+    def mdayset(self, year, month, day):
+        dset = [None]*self.yearlen
+        start, end = self.mrange[month-1:month+1]
+        for i in range(start, end):
+            dset[i] = i
+        return dset, start, end
+
+    def wdayset(self, year, month, day):
+        # We need to handle cross-year weeks here.
+        dset = [None]*(self.yearlen+7)
+        i = datetime.date(year, month, day).toordinal()-self.yearordinal
+        start = i
+        for j in range(7):
+            dset[i] = i
+            i += 1
+            # if (not (0 <= i < self.yearlen) or
+            #    self.wdaymask[i] == self.rrule._wkst):
+            # This will cross the year boundary, if necessary.
+            if self.wdaymask[i] == self.rrule._wkst:
+                break
+        return dset, start, i
+
+    def ddayset(self, year, month, day):
+        dset = [None] * self.yearlen
+        i = datetime.date(year, month, day).toordinal() - self.yearordinal
+        dset[i] = i
+        return dset, i, i + 1
+
+    def htimeset(self, hour, minute, second):
+        tset = []
+        rr = self.rrule
+        for minute in rr._byminute:
+            for second in rr._bysecond:
+                tset.append(datetime.time(hour, minute, second,
+                                          tzinfo=rr._tzinfo))
+        tset.sort()
+        return tset
+
+    def mtimeset(self, hour, minute, second):
+        tset = []
+        rr = self.rrule
+        for second in rr._bysecond:
+            tset.append(datetime.time(hour, minute, second, tzinfo=rr._tzinfo))
+        tset.sort()
+        return tset
+
+    def stimeset(self, hour, minute, second):
+        return (datetime.time(hour, minute, second,
+                tzinfo=self.rrule._tzinfo),)
+
+
+class rruleset(rrulebase):
+    """ The rruleset type allows more complex recurrence setups, mixing
+    multiple rules, dates, exclusion rules, and exclusion dates. The type
+    constructor takes the following keyword arguments:
+
+    :param cache: If True, caching of results will be enabled, improving
+                  performance of multiple queries considerably. """
+
+    class _genitem(object):
+        def __init__(self, genlist, gen):
+            try:
+                self.dt = advance_iterator(gen)
+                genlist.append(self)
+            except StopIteration:
+                pass
+            self.genlist = genlist
+            self.gen = gen
+
+        def __next__(self):
+            try:
+                self.dt = advance_iterator(self.gen)
+            except StopIteration:
+                if self.genlist[0] is self:
+                    heapq.heappop(self.genlist)
+                else:
+                    self.genlist.remove(self)
+                    heapq.heapify(self.genlist)
+
+        next = __next__
+
+        def __lt__(self, other):
+            return self.dt < other.dt
+
+        def __gt__(self, other):
+            return self.dt > other.dt
+
+        def __eq__(self, other):
+            return self.dt == other.dt
+
+        def __ne__(self, other):
+            return self.dt != other.dt
+
+    def __init__(self, cache=False):
+        super(rruleset, self).__init__(cache)
+        self._rrule = []
+        self._rdate = []
+        self._exrule = []
+        self._exdate = []
+
+    @_invalidates_cache
+    def rrule(self, rrule):
+        """ Include the given :py:class:`rrule` instance in the recurrence set
+            generation. """
+        self._rrule.append(rrule)
+
+    @_invalidates_cache
+    def rdate(self, rdate):
+        """ Include the given :py:class:`datetime` instance in the recurrence
+            set generation. """
+        self._rdate.append(rdate)
+
+    @_invalidates_cache
+    def exrule(self, exrule):
+        """ Include the given rrule instance in the recurrence set exclusion
+            list. Dates which are part of the given recurrence rules will not
+            be generated, even if some inclusive rrule or rdate matches them.
+        """
+        self._exrule.append(exrule)
+
+    @_invalidates_cache
+    def exdate(self, exdate):
+        """ Include the given datetime instance in the recurrence set
+            exclusion list. Dates included that way will not be generated,
+            even if some inclusive rrule or rdate matches them. """
+        self._exdate.append(exdate)
+
+    def _iter(self):
+        rlist = []
+        self._rdate.sort()
+        self._genitem(rlist, iter(self._rdate))
+        for gen in [iter(x) for x in self._rrule]:
+            self._genitem(rlist, gen)
+        exlist = []
+        self._exdate.sort()
+        self._genitem(exlist, iter(self._exdate))
+        for gen in [iter(x) for x in self._exrule]:
+            self._genitem(exlist, gen)
+        lastdt = None
+        total = 0
+        heapq.heapify(rlist)
+        heapq.heapify(exlist)
+        while rlist:
+            ritem = rlist[0]
+            if not lastdt or lastdt != ritem.dt:
+                while exlist and exlist[0] < ritem:
+                    exitem = exlist[0]
+                    advance_iterator(exitem)
+                    if exlist and exlist[0] is exitem:
+                        heapq.heapreplace(exlist, exitem)
+                if not exlist or ritem != exlist[0]:
+                    total += 1
+                    yield ritem.dt
+                lastdt = ritem.dt
+            advance_iterator(ritem)
+            if rlist and rlist[0] is ritem:
+                heapq.heapreplace(rlist, ritem)
+        self._len = total
+
+
+
+
+class _rrulestr(object):
+    """ Parses a string representation of a recurrence rule or set of
+    recurrence rules.
+
+    :param s:
+        Required, a string defining one or more recurrence rules.
+
+    :param dtstart:
+        If given, used as the default recurrence start if not specified in the
+        rule string.
+
+    :param cache:
+        If set ``True`` caching of results will be enabled, improving
+        performance of multiple queries considerably.
+
+    :param unfold:
+        If set ``True`` indicates that a rule string is split over more
+        than one line and should be joined before processing.
+
+    :param forceset:
+        If set ``True`` forces a :class:`dateutil.rrule.rruleset` to
+        be returned.
+
+    :param compatible:
+        If set ``True`` forces ``unfold`` and ``forceset`` to be ``True``.
+
+    :param ignoretz:
+        If set ``True``, time zones in parsed strings are ignored and a naive
+        :class:`datetime.datetime` object is returned.
+
+    :param tzids:
+        If given, a callable or mapping used to retrieve a
+        :class:`datetime.tzinfo` from a string representation.
+        Defaults to :func:`dateutil.tz.gettz`.
+
+    :param tzinfos:
+        Additional time zone names / aliases which may be present in a string
+        representation.  See :func:`dateutil.parser.parse` for more
+        information.
+
+    :return:
+        Returns a :class:`dateutil.rrule.rruleset` or
+        :class:`dateutil.rrule.rrule`
+    """
+
+    _freq_map = {"YEARLY": YEARLY,
+                 "MONTHLY": MONTHLY,
+                 "WEEKLY": WEEKLY,
+                 "DAILY": DAILY,
+                 "HOURLY": HOURLY,
+                 "MINUTELY": MINUTELY,
+                 "SECONDLY": SECONDLY}
+
+    _weekday_map = {"MO": 0, "TU": 1, "WE": 2, "TH": 3,
+                    "FR": 4, "SA": 5, "SU": 6}
+
+    def _handle_int(self, rrkwargs, name, value, **kwargs):
+        rrkwargs[name.lower()] = int(value)
+
+    def _handle_int_list(self, rrkwargs, name, value, **kwargs):
+        rrkwargs[name.lower()] = [int(x) for x in value.split(',')]
+
+    _handle_INTERVAL = _handle_int
+    _handle_COUNT = _handle_int
+    _handle_BYSETPOS = _handle_int_list
+    _handle_BYMONTH = _handle_int_list
+    _handle_BYMONTHDAY = _handle_int_list
+    _handle_BYYEARDAY = _handle_int_list
+    _handle_BYEASTER = _handle_int_list
+    _handle_BYWEEKNO = _handle_int_list
+    _handle_BYHOUR = _handle_int_list
+    _handle_BYMINUTE = _handle_int_list
+    _handle_BYSECOND = _handle_int_list
+
+    def _handle_FREQ(self, rrkwargs, name, value, **kwargs):
+        rrkwargs["freq"] = self._freq_map[value]
+
+    def _handle_UNTIL(self, rrkwargs, name, value, **kwargs):
+        global parser
+        if not parser:
+            from dateutil import parser
+        try:
+            rrkwargs["until"] = parser.parse(value,
+                                             ignoretz=kwargs.get("ignoretz"),
+                                             tzinfos=kwargs.get("tzinfos"))
+        except ValueError:
+            raise ValueError("invalid until date")
+
+    def _handle_WKST(self, rrkwargs, name, value, **kwargs):
+        rrkwargs["wkst"] = self._weekday_map[value]
+
+    def _handle_BYWEEKDAY(self, rrkwargs, name, value, **kwargs):
+        """
+        Two ways to specify this: +1MO or MO(+1)
+        """
+        l = []
+        for wday in value.split(','):
+            if '(' in wday:
+                # If it's of the form TH(+1), etc.
+                splt = wday.split('(')
+                w = splt[0]
+                n = int(splt[1][:-1])
+            elif len(wday):
+                # If it's of the form +1MO
+                for i in range(len(wday)):
+                    if wday[i] not in '+-0123456789':
+                        break
+                n = wday[:i] or None
+                w = wday[i:]
+                if n:
+                    n = int(n)
+            else:
+                raise ValueError("Invalid (empty) BYDAY specification.")
+
+            l.append(weekdays[self._weekday_map[w]](n))
+        rrkwargs["byweekday"] = l
+
+    _handle_BYDAY = _handle_BYWEEKDAY
+
+    def _parse_rfc_rrule(self, line,
+                         dtstart=None,
+                         cache=False,
+                         ignoretz=False,
+                         tzinfos=None):
+        if line.find(':') != -1:
+            name, value = line.split(':')
+            if name != "RRULE":
+                raise ValueError("unknown parameter name")
+        else:
+            value = line
+        rrkwargs = {}
+        for pair in value.split(';'):
+            name, value = pair.split('=')
+            name = name.upper()
+            value = value.upper()
+            try:
+                getattr(self, "_handle_"+name)(rrkwargs, name, value,
+                                               ignoretz=ignoretz,
+                                               tzinfos=tzinfos)
+            except AttributeError:
+                raise ValueError("unknown parameter '%s'" % name)
+            except (KeyError, ValueError):
+                raise ValueError("invalid '%s': %s" % (name, value))
+        return rrule(dtstart=dtstart, cache=cache, **rrkwargs)
+
+    def _parse_date_value(self, date_value, parms, rule_tzids,
+                          ignoretz, tzids, tzinfos):
+        global parser
+        if not parser:
+            from dateutil import parser
+
+        datevals = []
+        value_found = False
+        TZID = None
+
+        for parm in parms:
+            if parm.startswith("TZID="):
+                try:
+                    tzkey = rule_tzids[parm.split('TZID=')[-1]]
+                except KeyError:
+                    continue
+                if tzids is None:
+                    from . import tz
+                    tzlookup = tz.gettz
+                elif callable(tzids):
+                    tzlookup = tzids
+                else:
+                    tzlookup = getattr(tzids, 'get', None)
+                    if tzlookup is None:
+                        msg = ('tzids must be a callable, mapping, or None, '
+                               'not %s' % tzids)
+                        raise ValueError(msg)
+
+                TZID = tzlookup(tzkey)
+                continue
+
+            # RFC 5445 3.8.2.4: The VALUE parameter is optional, but may be found
+            # only once.
+            if parm not in {"VALUE=DATE-TIME", "VALUE=DATE"}:
+                raise ValueError("unsupported parm: " + parm)
+            else:
+                if value_found:
+                    msg = ("Duplicate value parameter found in: " + parm)
+                    raise ValueError(msg)
+                value_found = True
+
+        for datestr in date_value.split(','):
+            date = parser.parse(datestr, ignoretz=ignoretz, tzinfos=tzinfos)
+            if TZID is not None:
+                if date.tzinfo is None:
+                    date = date.replace(tzinfo=TZID)
+                else:
+                    raise ValueError('DTSTART/EXDATE specifies multiple timezone')
+            datevals.append(date)
+
+        return datevals
+
+    def _parse_rfc(self, s,
+                   dtstart=None,
+                   cache=False,
+                   unfold=False,
+                   forceset=False,
+                   compatible=False,
+                   ignoretz=False,
+                   tzids=None,
+                   tzinfos=None):
+        global parser
+        if compatible:
+            forceset = True
+            unfold = True
+
+        TZID_NAMES = dict(map(
+            lambda x: (x.upper(), x),
+            re.findall('TZID=(?P<name>[^:]+):', s)
+        ))
+        s = s.upper()
+        if not s.strip():
+            raise ValueError("empty string")
+        if unfold:
+            lines = s.splitlines()
+            i = 0
+            while i < len(lines):
+                line = lines[i].rstrip()
+                if not line:
+                    del lines[i]
+                elif i > 0 and line[0] == " ":
+                    lines[i-1] += line[1:]
+                    del lines[i]
+                else:
+                    i += 1
+        else:
+            lines = s.split()
+        if (not forceset and len(lines) == 1 and (s.find(':') == -1 or
+                                                  s.startswith('RRULE:'))):
+            return self._parse_rfc_rrule(lines[0], cache=cache,
+                                         dtstart=dtstart, ignoretz=ignoretz,
+                                         tzinfos=tzinfos)
+        else:
+            rrulevals = []
+            rdatevals = []
+            exrulevals = []
+            exdatevals = []
+            for line in lines:
+                if not line:
+                    continue
+                if line.find(':') == -1:
+                    name = "RRULE"
+                    value = line
+                else:
+                    name, value = line.split(':', 1)
+                parms = name.split(';')
+                if not parms:
+                    raise ValueError("empty property name")
+                name = parms[0]
+                parms = parms[1:]
+                if name == "RRULE":
+                    for parm in parms:
+                        raise ValueError("unsupported RRULE parm: "+parm)
+                    rrulevals.append(value)
+                elif name == "RDATE":
+                    for parm in parms:
+                        if parm != "VALUE=DATE-TIME":
+                            raise ValueError("unsupported RDATE parm: "+parm)
+                    rdatevals.append(value)
+                elif name == "EXRULE":
+                    for parm in parms:
+                        raise ValueError("unsupported EXRULE parm: "+parm)
+                    exrulevals.append(value)
+                elif name == "EXDATE":
+                    exdatevals.extend(
+                        self._parse_date_value(value, parms,
+                                               TZID_NAMES, ignoretz,
+                                               tzids, tzinfos)
+                    )
+                elif name == "DTSTART":
+                    dtvals = self._parse_date_value(value, parms, TZID_NAMES,
+                                                    ignoretz, tzids, tzinfos)
+                    if len(dtvals) != 1:
+                        raise ValueError("Multiple DTSTART values specified:" +
+                                         value)
+                    dtstart = dtvals[0]
+                else:
+                    raise ValueError("unsupported property: "+name)
+            if (forceset or len(rrulevals) > 1 or rdatevals
+                    or exrulevals or exdatevals):
+                if not parser and (rdatevals or exdatevals):
+                    from dateutil import parser
+                rset = rruleset(cache=cache)
+                for value in rrulevals:
+                    rset.rrule(self._parse_rfc_rrule(value, dtstart=dtstart,
+                                                     ignoretz=ignoretz,
+                                                     tzinfos=tzinfos))
+                for value in rdatevals:
+                    for datestr in value.split(','):
+                        rset.rdate(parser.parse(datestr,
+                                                ignoretz=ignoretz,
+                                                tzinfos=tzinfos))
+                for value in exrulevals:
+                    rset.exrule(self._parse_rfc_rrule(value, dtstart=dtstart,
+                                                      ignoretz=ignoretz,
+                                                      tzinfos=tzinfos))
+                for value in exdatevals:
+                    rset.exdate(value)
+                if compatible and dtstart:
+                    rset.rdate(dtstart)
+                return rset
+            else:
+                return self._parse_rfc_rrule(rrulevals[0],
+                                             dtstart=dtstart,
+                                             cache=cache,
+                                             ignoretz=ignoretz,
+                                             tzinfos=tzinfos)
+
+    def __call__(self, s, **kwargs):
+        return self._parse_rfc(s, **kwargs)
+
+
+rrulestr = _rrulestr()
+
+# vim:ts=4:sw=4:et
Index: venv/Lib/site-packages/dateutil/tzwin.py
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/venv/Lib/site-packages/dateutil/tzwin.py b/venv/Lib/site-packages/dateutil/tzwin.py
new file mode 100644
--- /dev/null	(date 1616410449312)
+++ b/venv/Lib/site-packages/dateutil/tzwin.py	(date 1616410449312)
@@ -0,0 +1,2 @@
+# tzwin has moved to dateutil.tz.win
+from .tz.win import *
Index: venv/Lib/site-packages/dateutil/utils.py
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/venv/Lib/site-packages/dateutil/utils.py b/venv/Lib/site-packages/dateutil/utils.py
new file mode 100644
--- /dev/null	(date 1616410449312)
+++ b/venv/Lib/site-packages/dateutil/utils.py	(date 1616410449312)
@@ -0,0 +1,71 @@
+# -*- coding: utf-8 -*-
+"""
+This module offers general convenience and utility functions for dealing with
+datetimes.
+
+.. versionadded:: 2.7.0
+"""
+from __future__ import unicode_literals
+
+from datetime import datetime, time
+
+
+def today(tzinfo=None):
+    """
+    Returns a :py:class:`datetime` representing the current day at midnight
+
+    :param tzinfo:
+        The time zone to attach (also used to determine the current day).
+
+    :return:
+        A :py:class:`datetime.datetime` object representing the current day
+        at midnight.
+    """
+
+    dt = datetime.now(tzinfo)
+    return datetime.combine(dt.date(), time(0, tzinfo=tzinfo))
+
+
+def default_tzinfo(dt, tzinfo):
+    """
+    Sets the ``tzinfo`` parameter on naive datetimes only
+
+    This is useful for example when you are provided a datetime that may have
+    either an implicit or explicit time zone, such as when parsing a time zone
+    string.
+
+    .. doctest::
+
+        >>> from dateutil.tz import tzoffset
+        >>> from dateutil.parser import parse
+        >>> from dateutil.utils import default_tzinfo
+        >>> dflt_tz = tzoffset("EST", -18000)
+        >>> print(default_tzinfo(parse('2014-01-01 12:30 UTC'), dflt_tz))
+        2014-01-01 12:30:00+00:00
+        >>> print(default_tzinfo(parse('2014-01-01 12:30'), dflt_tz))
+        2014-01-01 12:30:00-05:00
+
+    :param dt:
+        The datetime on which to replace the time zone
+
+    :param tzinfo:
+        The :py:class:`datetime.tzinfo` subclass instance to assign to
+        ``dt`` if (and only if) it is naive.
+
+    :return:
+        Returns an aware :py:class:`datetime.datetime`.
+    """
+    if dt.tzinfo is not None:
+        return dt
+    else:
+        return dt.replace(tzinfo=tzinfo)
+
+
+def within_delta(dt1, dt2, delta):
+    """
+    Useful for comparing two datetimes that may a negilible difference
+    to be considered equal.
+    """
+    delta = abs(delta)
+    difference = dt1 - dt2
+    return -delta <= difference <= delta
Index: venv/Lib/site-packages/dateutil/_common.py
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/venv/Lib/site-packages/dateutil/_common.py b/venv/Lib/site-packages/dateutil/_common.py
new file mode 100644
--- /dev/null	(date 1616410449327)
+++ b/venv/Lib/site-packages/dateutil/_common.py	(date 1616410449327)
@@ -0,0 +1,43 @@
+"""
+Common code used in multiple modules.
+"""
+
+
+class weekday(object):
+    __slots__ = ["weekday", "n"]
+
+    def __init__(self, weekday, n=None):
+        self.weekday = weekday
+        self.n = n
+
+    def __call__(self, n):
+        if n == self.n:
+            return self
+        else:
+            return self.__class__(self.weekday, n)
+
+    def __eq__(self, other):
+        try:
+            if self.weekday != other.weekday or self.n != other.n:
+                return False
+        except AttributeError:
+            return False
+        return True
+
+    def __hash__(self):
+        return hash((
+          self.weekday,
+          self.n,
+        ))
+
+    def __ne__(self, other):
+        return not (self == other)
+
+    def __repr__(self):
+        s = ("MO", "TU", "WE", "TH", "FR", "SA", "SU")[self.weekday]
+        if not self.n:
+            return s
+        else:
+            return "%s(%+d)" % (s, self.n)
+
+# vim:ts=4:sw=4:et
Index: venv/Lib/site-packages/dateutil/_version.py
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/venv/Lib/site-packages/dateutil/_version.py b/venv/Lib/site-packages/dateutil/_version.py
new file mode 100644
--- /dev/null	(date 1616410449390)
+++ b/venv/Lib/site-packages/dateutil/_version.py	(date 1616410449390)
@@ -0,0 +1,4 @@
+# coding: utf-8
+# file generated by setuptools_scm
+# don't change, don't track in version control
+version = '2.8.1'
Index: venv/Lib/site-packages/dateutil/__init__.py
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/venv/Lib/site-packages/dateutil/__init__.py b/venv/Lib/site-packages/dateutil/__init__.py
new file mode 100644
--- /dev/null	(date 1616410449468)
+++ b/venv/Lib/site-packages/dateutil/__init__.py	(date 1616410449468)
@@ -0,0 +1,8 @@
+# -*- coding: utf-8 -*-
+try:
+    from ._version import version as __version__
+except ImportError:
+    __version__ = 'unknown'
+
+__all__ = ['easter', 'parser', 'relativedelta', 'rrule', 'tz',
+           'utils', 'zoneinfo']
Index: latest/Lib/site-packages/psycopg2-2.8.6.dist-info/INSTALLER
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/latest/Lib/site-packages/psycopg2-2.8.6.dist-info/INSTALLER b/latest/Lib/site-packages/psycopg2-2.8.6.dist-info/INSTALLER
new file mode 100644
--- /dev/null	(date 1616410449519)
+++ b/latest/Lib/site-packages/psycopg2-2.8.6.dist-info/INSTALLER	(date 1616410449519)
@@ -0,0 +1,1 @@
+pip
Index: venv/Lib/site-packages/dateutil/tz/tz.py
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/venv/Lib/site-packages/dateutil/tz/tz.py b/venv/Lib/site-packages/dateutil/tz/tz.py
new file mode 100644
--- /dev/null	(date 1616410449565)
+++ b/venv/Lib/site-packages/dateutil/tz/tz.py	(date 1616410449565)
@@ -0,0 +1,1849 @@
+# -*- coding: utf-8 -*-
+"""
+This module offers timezone implementations subclassing the abstract
+:py:class:`datetime.tzinfo` type. There are classes to handle tzfile format
+files (usually are in :file:`/etc/localtime`, :file:`/usr/share/zoneinfo`,
+etc), TZ environment string (in all known formats), given ranges (with help
+from relative deltas), local machine timezone, fixed offset timezone, and UTC
+timezone.
+"""
+import datetime
+import struct
+import time
+import sys
+import os
+import bisect
+import weakref
+from collections import OrderedDict
+
+import six
+from six import string_types
+from six.moves import _thread
+from ._common import tzname_in_python2, _tzinfo
+from ._common import tzrangebase, enfold
+from ._common import _validate_fromutc_inputs
+
+from ._factories import _TzSingleton, _TzOffsetFactory
+from ._factories import _TzStrFactory
+try:
+    from .win import tzwin, tzwinlocal
+except ImportError:
+    tzwin = tzwinlocal = None
+
+# For warning about rounding tzinfo
+from warnings import warn
+
+ZERO = datetime.timedelta(0)
+EPOCH = datetime.datetime.utcfromtimestamp(0)
+EPOCHORDINAL = EPOCH.toordinal()
+
+
+@six.add_metaclass(_TzSingleton)
+class tzutc(datetime.tzinfo):
+    """
+    This is a tzinfo object that represents the UTC time zone.
+
+    **Examples:**
+
+    .. doctest::
+
+        >>> from datetime import *
+        >>> from dateutil.tz import *
+
+        >>> datetime.now()
+        datetime.datetime(2003, 9, 27, 9, 40, 1, 521290)
+
+        >>> datetime.now(tzutc())
+        datetime.datetime(2003, 9, 27, 12, 40, 12, 156379, tzinfo=tzutc())
+
+        >>> datetime.now(tzutc()).tzname()
+        'UTC'
+
+    .. versionchanged:: 2.7.0
+        ``tzutc()`` is now a singleton, so the result of ``tzutc()`` will
+        always return the same object.
+
+        .. doctest::
+
+            >>> from dateutil.tz import tzutc, UTC
+            >>> tzutc() is tzutc()
+            True
+            >>> tzutc() is UTC
+            True
+    """
+    def utcoffset(self, dt):
+        return ZERO
+
+    def dst(self, dt):
+        return ZERO
+
+    @tzname_in_python2
+    def tzname(self, dt):
+        return "UTC"
+
+    def is_ambiguous(self, dt):
+        """
+        Whether or not the "wall time" of a given datetime is ambiguous in this
+        zone.
+
+        :param dt:
+            A :py:class:`datetime.datetime`, naive or time zone aware.
+
+
+        :return:
+            Returns ``True`` if ambiguous, ``False`` otherwise.
+
+        .. versionadded:: 2.6.0
+        """
+        return False
+
+    @_validate_fromutc_inputs
+    def fromutc(self, dt):
+        """
+        Fast track version of fromutc() returns the original ``dt`` object for
+        any valid :py:class:`datetime.datetime` object.
+        """
+        return dt
+
+    def __eq__(self, other):
+        if not isinstance(other, (tzutc, tzoffset)):
+            return NotImplemented
+
+        return (isinstance(other, tzutc) or
+                (isinstance(other, tzoffset) and other._offset == ZERO))
+
+    __hash__ = None
+
+    def __ne__(self, other):
+        return not (self == other)
+
+    def __repr__(self):
+        return "%s()" % self.__class__.__name__
+
+    __reduce__ = object.__reduce__
+
+
+#: Convenience constant providing a :class:`tzutc()` instance
+#:
+#: .. versionadded:: 2.7.0
+UTC = tzutc()
+
+
+@six.add_metaclass(_TzOffsetFactory)
+class tzoffset(datetime.tzinfo):
+    """
+    A simple class for representing a fixed offset from UTC.
+
+    :param name:
+        The timezone name, to be returned when ``tzname()`` is called.
+    :param offset:
+        The time zone offset in seconds, or (since version 2.6.0, represented
+        as a :py:class:`datetime.timedelta` object).
+    """
+    def __init__(self, name, offset):
+        self._name = name
+
+        try:
+            # Allow a timedelta
+            offset = offset.total_seconds()
+        except (TypeError, AttributeError):
+            pass
+
+        self._offset = datetime.timedelta(seconds=_get_supported_offset(offset))
+
+    def utcoffset(self, dt):
+        return self._offset
+
+    def dst(self, dt):
+        return ZERO
+
+    @tzname_in_python2
+    def tzname(self, dt):
+        return self._name
+
+    @_validate_fromutc_inputs
+    def fromutc(self, dt):
+        return dt + self._offset
+
+    def is_ambiguous(self, dt):
+        """
+        Whether or not the "wall time" of a given datetime is ambiguous in this
+        zone.
+
+        :param dt:
+            A :py:class:`datetime.datetime`, naive or time zone aware.
+        :return:
+            Returns ``True`` if ambiguous, ``False`` otherwise.
+
+        .. versionadded:: 2.6.0
+        """
+        return False
+
+    def __eq__(self, other):
+        if not isinstance(other, tzoffset):
+            return NotImplemented
+
+        return self._offset == other._offset
+
+    __hash__ = None
+
+    def __ne__(self, other):
+        return not (self == other)
+
+    def __repr__(self):
+        return "%s(%s, %s)" % (self.__class__.__name__,
+                               repr(self._name),
+                               int(self._offset.total_seconds()))
+
+    __reduce__ = object.__reduce__
+
+
+class tzlocal(_tzinfo):
+    """
+    A :class:`tzinfo` subclass built around the ``time`` timezone functions.
+    """
+    def __init__(self):
+        super(tzlocal, self).__init__()
+
+        self._std_offset = datetime.timedelta(seconds=-time.timezone)
+        if time.daylight:
+            self._dst_offset = datetime.timedelta(seconds=-time.altzone)
+        else:
+            self._dst_offset = self._std_offset
+
+        self._dst_saved = self._dst_offset - self._std_offset
+        self._hasdst = bool(self._dst_saved)
+        self._tznames = tuple(time.tzname)
+
+    def utcoffset(self, dt):
+        if dt is None and self._hasdst:
+            return None
+
+        if self._isdst(dt):
+            return self._dst_offset
+        else:
+            return self._std_offset
+
+    def dst(self, dt):
+        if dt is None and self._hasdst:
+            return None
+
+        if self._isdst(dt):
+            return self._dst_offset - self._std_offset
+        else:
+            return ZERO
+
+    @tzname_in_python2
+    def tzname(self, dt):
+        return self._tznames[self._isdst(dt)]
+
+    def is_ambiguous(self, dt):
+        """
+        Whether or not the "wall time" of a given datetime is ambiguous in this
+        zone.
+
+        :param dt:
+            A :py:class:`datetime.datetime`, naive or time zone aware.
+
+
+        :return:
+            Returns ``True`` if ambiguous, ``False`` otherwise.
+
+        .. versionadded:: 2.6.0
+        """
+        naive_dst = self._naive_is_dst(dt)
+        return (not naive_dst and
+                (naive_dst != self._naive_is_dst(dt - self._dst_saved)))
+
+    def _naive_is_dst(self, dt):
+        timestamp = _datetime_to_timestamp(dt)
+        return time.localtime(timestamp + time.timezone).tm_isdst
+
+    def _isdst(self, dt, fold_naive=True):
+        # We can't use mktime here. It is unstable when deciding if
+        # the hour near to a change is DST or not.
+        #
+        # timestamp = time.mktime((dt.year, dt.month, dt.day, dt.hour,
+        #                         dt.minute, dt.second, dt.weekday(), 0, -1))
+        # return time.localtime(timestamp).tm_isdst
+        #
+        # The code above yields the following result:
+        #
+        # >>> import tz, datetime
+        # >>> t = tz.tzlocal()
+        # >>> datetime.datetime(2003,2,15,23,tzinfo=t).tzname()
+        # 'BRDT'
+        # >>> datetime.datetime(2003,2,16,0,tzinfo=t).tzname()
+        # 'BRST'
+        # >>> datetime.datetime(2003,2,15,23,tzinfo=t).tzname()
+        # 'BRST'
+        # >>> datetime.datetime(2003,2,15,22,tzinfo=t).tzname()
+        # 'BRDT'
+        # >>> datetime.datetime(2003,2,15,23,tzinfo=t).tzname()
+        # 'BRDT'
+        #
+        # Here is a more stable implementation:
+        #
+        if not self._hasdst:
+            return False
+
+        # Check for ambiguous times:
+        dstval = self._naive_is_dst(dt)
+        fold = getattr(dt, 'fold', None)
+
+        if self.is_ambiguous(dt):
+            if fold is not None:
+                return not self._fold(dt)
+            else:
+                return True
+
+        return dstval
+
+    def __eq__(self, other):
+        if isinstance(other, tzlocal):
+            return (self._std_offset == other._std_offset and
+                    self._dst_offset == other._dst_offset)
+        elif isinstance(other, tzutc):
+            return (not self._hasdst and
+                    self._tznames[0] in {'UTC', 'GMT'} and
+                    self._std_offset == ZERO)
+        elif isinstance(other, tzoffset):
+            return (not self._hasdst and
+                    self._tznames[0] == other._name and
+                    self._std_offset == other._offset)
+        else:
+            return NotImplemented
+
+    __hash__ = None
+
+    def __ne__(self, other):
+        return not (self == other)
+
+    def __repr__(self):
+        return "%s()" % self.__class__.__name__
+
+    __reduce__ = object.__reduce__
+
+
+class _ttinfo(object):
+    __slots__ = ["offset", "delta", "isdst", "abbr",
+                 "isstd", "isgmt", "dstoffset"]
+
+    def __init__(self):
+        for attr in self.__slots__:
+            setattr(self, attr, None)
+
+    def __repr__(self):
+        l = []
+        for attr in self.__slots__:
+            value = getattr(self, attr)
+            if value is not None:
+                l.append("%s=%s" % (attr, repr(value)))
+        return "%s(%s)" % (self.__class__.__name__, ", ".join(l))
+
+    def __eq__(self, other):
+        if not isinstance(other, _ttinfo):
+            return NotImplemented
+
+        return (self.offset == other.offset and
+                self.delta == other.delta and
+                self.isdst == other.isdst and
+                self.abbr == other.abbr and
+                self.isstd == other.isstd and
+                self.isgmt == other.isgmt and
+                self.dstoffset == other.dstoffset)
+
+    __hash__ = None
+
+    def __ne__(self, other):
+        return not (self == other)
+
+    def __getstate__(self):
+        state = {}
+        for name in self.__slots__:
+            state[name] = getattr(self, name, None)
+        return state
+
+    def __setstate__(self, state):
+        for name in self.__slots__:
+            if name in state:
+                setattr(self, name, state[name])
+
+
+class _tzfile(object):
+    """
+    Lightweight class for holding the relevant transition and time zone
+    information read from binary tzfiles.
+    """
+    attrs = ['trans_list', 'trans_list_utc', 'trans_idx', 'ttinfo_list',
+             'ttinfo_std', 'ttinfo_dst', 'ttinfo_before', 'ttinfo_first']
+
+    def __init__(self, **kwargs):
+        for attr in self.attrs:
+            setattr(self, attr, kwargs.get(attr, None))
+
+
+class tzfile(_tzinfo):
+    """
+    This is a ``tzinfo`` subclass that allows one to use the ``tzfile(5)``
+    format timezone files to extract current and historical zone information.
+
+    :param fileobj:
+        This can be an opened file stream or a file name that the time zone
+        information can be read from.
+
+    :param filename:
+        This is an optional parameter specifying the source of the time zone
+        information in the event that ``fileobj`` is a file object. If omitted
+        and ``fileobj`` is a file stream, this parameter will be set either to
+        ``fileobj``'s ``name`` attribute or to ``repr(fileobj)``.
+
+    See `Sources for Time Zone and Daylight Saving Time Data
+    <https://data.iana.org/time-zones/tz-link.html>`_ for more information.
+    Time zone files can be compiled from the `IANA Time Zone database files
+    <https://www.iana.org/time-zones>`_ with the `zic time zone compiler
+    <https://www.freebsd.org/cgi/man.cgi?query=zic&sektion=8>`_
+
+    .. note::
+
+        Only construct a ``tzfile`` directly if you have a specific timezone
+        file on disk that you want to read into a Python ``tzinfo`` object.
+        If you want to get a ``tzfile`` representing a specific IANA zone,
+        (e.g. ``'America/New_York'``), you should call
+        :func:`dateutil.tz.gettz` with the zone identifier.
+
+
+    **Examples:**
+
+    Using the US Eastern time zone as an example, we can see that a ``tzfile``
+    provides time zone information for the standard Daylight Saving offsets:
+
+    .. testsetup:: tzfile
+
+        from dateutil.tz import gettz
+        from datetime import datetime
+
+    .. doctest:: tzfile
+
+        >>> NYC = gettz('America/New_York')
+        >>> NYC
+        tzfile('/usr/share/zoneinfo/America/New_York')
+
+        >>> print(datetime(2016, 1, 3, tzinfo=NYC))     # EST
+        2016-01-03 00:00:00-05:00
+
+        >>> print(datetime(2016, 7, 7, tzinfo=NYC))     # EDT
+        2016-07-07 00:00:00-04:00
+
+
+    The ``tzfile`` structure contains a fully history of the time zone,
+    so historical dates will also have the right offsets. For example, before
+    the adoption of the UTC standards, New York used local solar  mean time:
+
+    .. doctest:: tzfile
+
+       >>> print(datetime(1901, 4, 12, tzinfo=NYC))    # LMT
+       1901-04-12 00:00:00-04:56
+
+    And during World War II, New York was on "Eastern War Time", which was a
+    state of permanent daylight saving time:
+
+    .. doctest:: tzfile
+
+        >>> print(datetime(1944, 2, 7, tzinfo=NYC))    # EWT
+        1944-02-07 00:00:00-04:00
+
+    """
+
+    def __init__(self, fileobj, filename=None):
+        super(tzfile, self).__init__()
+
+        file_opened_here = False
+        if isinstance(fileobj, string_types):
+            self._filename = fileobj
+            fileobj = open(fileobj, 'rb')
+            file_opened_here = True
+        elif filename is not None:
+            self._filename = filename
+        elif hasattr(fileobj, "name"):
+            self._filename = fileobj.name
+        else:
+            self._filename = repr(fileobj)
+
+        if fileobj is not None:
+            if not file_opened_here:
+                fileobj = _nullcontext(fileobj)
+
+            with fileobj as file_stream:
+                tzobj = self._read_tzfile(file_stream)
+
+            self._set_tzdata(tzobj)
+
+    def _set_tzdata(self, tzobj):
+        """ Set the time zone data of this object from a _tzfile object """
+        # Copy the relevant attributes over as private attributes
+        for attr in _tzfile.attrs:
+            setattr(self, '_' + attr, getattr(tzobj, attr))
+
+    def _read_tzfile(self, fileobj):
+        out = _tzfile()
+
+        # From tzfile(5):
+        #
+        # The time zone information files used by tzset(3)
+        # begin with the magic characters "TZif" to identify
+        # them as time zone information files, followed by
+        # sixteen bytes reserved for future use, followed by
+        # six four-byte values of type long, written in a
+        # ``standard'' byte order (the high-order  byte
+        # of the value is written first).
+        if fileobj.read(4).decode() != "TZif":
+            raise ValueError("magic not found")
+
+        fileobj.read(16)
+
+        (
+            # The number of UTC/local indicators stored in the file.
+            ttisgmtcnt,
+
+            # The number of standard/wall indicators stored in the file.
+            ttisstdcnt,
+
+            # The number of leap seconds for which data is
+            # stored in the file.
+            leapcnt,
+
+            # The number of "transition times" for which data
+            # is stored in the file.
+            timecnt,
+
+            # The number of "local time types" for which data
+            # is stored in the file (must not be zero).
+            typecnt,
+
+            # The  number  of  characters  of "time zone
+            # abbreviation strings" stored in the file.
+            charcnt,
+
+        ) = struct.unpack(">6l", fileobj.read(24))
+
+        # The above header is followed by tzh_timecnt four-byte
+        # values  of  type long,  sorted  in ascending order.
+        # These values are written in ``standard'' byte order.
+        # Each is used as a transition time (as  returned  by
+        # time(2)) at which the rules for computing local time
+        # change.
+
+        if timecnt:
+            out.trans_list_utc = list(struct.unpack(">%dl" % timecnt,
+                                                    fileobj.read(timecnt*4)))
+        else:
+            out.trans_list_utc = []
+
+        # Next come tzh_timecnt one-byte values of type unsigned
+        # char; each one tells which of the different types of
+        # ``local time'' types described in the file is associated
+        # with the same-indexed transition time. These values
+        # serve as indices into an array of ttinfo structures that
+        # appears next in the file.
+
+        if timecnt:
+            out.trans_idx = struct.unpack(">%dB" % timecnt,
+                                          fileobj.read(timecnt))
+        else:
+            out.trans_idx = []
+
+        # Each ttinfo structure is written as a four-byte value
+        # for tt_gmtoff  of  type long,  in  a  standard  byte
+        # order, followed  by a one-byte value for tt_isdst
+        # and a one-byte  value  for  tt_abbrind.   In  each
+        # structure, tt_gmtoff  gives  the  number  of
+        # seconds to be added to UTC, tt_isdst tells whether
+        # tm_isdst should be set by  localtime(3),  and
+        # tt_abbrind serves  as an index into the array of
+        # time zone abbreviation characters that follow the
+        # ttinfo structure(s) in the file.
+
+        ttinfo = []
+
+        for i in range(typecnt):
+            ttinfo.append(struct.unpack(">lbb", fileobj.read(6)))
+
+        abbr = fileobj.read(charcnt).decode()
+
+        # Then there are tzh_leapcnt pairs of four-byte
+        # values, written in  standard byte  order;  the
+        # first  value  of  each pair gives the time (as
+        # returned by time(2)) at which a leap second
+        # occurs;  the  second  gives the  total  number of
+        # leap seconds to be applied after the given time.
+        # The pairs of values are sorted in ascending order
+        # by time.
+
+        # Not used, for now (but seek for correct file position)
+        if leapcnt:
+            fileobj.seek(leapcnt * 8, os.SEEK_CUR)
+
+        # Then there are tzh_ttisstdcnt standard/wall
+        # indicators, each stored as a one-byte value;
+        # they tell whether the transition times associated
+        # with local time types were specified as standard
+        # time or wall clock time, and are used when
+        # a time zone file is used in handling POSIX-style
+        # time zone environment variables.
+
+        if ttisstdcnt:
+            isstd = struct.unpack(">%db" % ttisstdcnt,
+                                  fileobj.read(ttisstdcnt))
+
+        # Finally, there are tzh_ttisgmtcnt UTC/local
+        # indicators, each stored as a one-byte value;
+        # they tell whether the transition times associated
+        # with local time types were specified as UTC or
+        # local time, and are used when a time zone file
+        # is used in handling POSIX-style time zone envi-
+        # ronment variables.
+
+        if ttisgmtcnt:
+            isgmt = struct.unpack(">%db" % ttisgmtcnt,
+                                  fileobj.read(ttisgmtcnt))
+
+        # Build ttinfo list
+        out.ttinfo_list = []
+        for i in range(typecnt):
+            gmtoff, isdst, abbrind = ttinfo[i]
+            gmtoff = _get_supported_offset(gmtoff)
+            tti = _ttinfo()
+            tti.offset = gmtoff
+            tti.dstoffset = datetime.timedelta(0)
+            tti.delta = datetime.timedelta(seconds=gmtoff)
+            tti.isdst = isdst
+            tti.abbr = abbr[abbrind:abbr.find('\x00', abbrind)]
+            tti.isstd = (ttisstdcnt > i and isstd[i] != 0)
+            tti.isgmt = (ttisgmtcnt > i and isgmt[i] != 0)
+            out.ttinfo_list.append(tti)
+
+        # Replace ttinfo indexes for ttinfo objects.
+        out.trans_idx = [out.ttinfo_list[idx] for idx in out.trans_idx]
+
+        # Set standard, dst, and before ttinfos. before will be
+        # used when a given time is before any transitions,
+        # and will be set to the first non-dst ttinfo, or to
+        # the first dst, if all of them are dst.
+        out.ttinfo_std = None
+        out.ttinfo_dst = None
+        out.ttinfo_before = None
+        if out.ttinfo_list:
+            if not out.trans_list_utc:
+                out.ttinfo_std = out.ttinfo_first = out.ttinfo_list[0]
+            else:
+                for i in range(timecnt-1, -1, -1):
+                    tti = out.trans_idx[i]
+                    if not out.ttinfo_std and not tti.isdst:
+                        out.ttinfo_std = tti
+                    elif not out.ttinfo_dst and tti.isdst:
+                        out.ttinfo_dst = tti
+
+                    if out.ttinfo_std and out.ttinfo_dst:
+                        break
+                else:
+                    if out.ttinfo_dst and not out.ttinfo_std:
+                        out.ttinfo_std = out.ttinfo_dst
+
+                for tti in out.ttinfo_list:
+                    if not tti.isdst:
+                        out.ttinfo_before = tti
+                        break
+                else:
+                    out.ttinfo_before = out.ttinfo_list[0]
+
+        # Now fix transition times to become relative to wall time.
+        #
+        # I'm not sure about this. In my tests, the tz source file
+        # is setup to wall time, and in the binary file isstd and
+        # isgmt are off, so it should be in wall time. OTOH, it's
+        # always in gmt time. Let me know if you have comments
+        # about this.
+        lastdst = None
+        lastoffset = None
+        lastdstoffset = None
+        lastbaseoffset = None
+        out.trans_list = []
+
+        for i, tti in enumerate(out.trans_idx):
+            offset = tti.offset
+            dstoffset = 0
+
+            if lastdst is not None:
+                if tti.isdst:
+                    if not lastdst:
+                        dstoffset = offset - lastoffset
+
+                    if not dstoffset and lastdstoffset:
+                        dstoffset = lastdstoffset
+
+                    tti.dstoffset = datetime.timedelta(seconds=dstoffset)
+                    lastdstoffset = dstoffset
+
+            # If a time zone changes its base offset during a DST transition,
+            # then you need to adjust by the previous base offset to get the
+            # transition time in local time. Otherwise you use the current
+            # base offset. Ideally, I would have some mathematical proof of
+            # why this is true, but I haven't really thought about it enough.
+            baseoffset = offset - dstoffset
+            adjustment = baseoffset
+            if (lastbaseoffset is not None and baseoffset != lastbaseoffset
+                    and tti.isdst != lastdst):
+                # The base DST has changed
+                adjustment = lastbaseoffset
+
+            lastdst = tti.isdst
+            lastoffset = offset
+            lastbaseoffset = baseoffset
+
+            out.trans_list.append(out.trans_list_utc[i] + adjustment)
+
+        out.trans_idx = tuple(out.trans_idx)
+        out.trans_list = tuple(out.trans_list)
+        out.trans_list_utc = tuple(out.trans_list_utc)
+
+        return out
+
+    def _find_last_transition(self, dt, in_utc=False):
+        # If there's no list, there are no transitions to find
+        if not self._trans_list:
+            return None
+
+        timestamp = _datetime_to_timestamp(dt)
+
+        # Find where the timestamp fits in the transition list - if the
+        # timestamp is a transition time, it's part of the "after" period.
+        trans_list = self._trans_list_utc if in_utc else self._trans_list
+        idx = bisect.bisect_right(trans_list, timestamp)
+
+        # We want to know when the previous transition was, so subtract off 1
+        return idx - 1
+
+    def _get_ttinfo(self, idx):
+        # For no list or after the last transition, default to _ttinfo_std
+        if idx is None or (idx + 1) >= len(self._trans_list):
+            return self._ttinfo_std
+
+        # If there is a list and the time is before it, return _ttinfo_before
+        if idx < 0:
+            return self._ttinfo_before
+
+        return self._trans_idx[idx]
+
+    def _find_ttinfo(self, dt):
+        idx = self._resolve_ambiguous_time(dt)
+
+        return self._get_ttinfo(idx)
+
+    def fromutc(self, dt):
+        """
+        The ``tzfile`` implementation of :py:func:`datetime.tzinfo.fromutc`.
+
+        :param dt:
+            A :py:class:`datetime.datetime` object.
+
+        :raises TypeError:
+            Raised if ``dt`` is not a :py:class:`datetime.datetime` object.
+
+        :raises ValueError:
+            Raised if this is called with a ``dt`` which does not have this
+            ``tzinfo`` attached.
+
+        :return:
+            Returns a :py:class:`datetime.datetime` object representing the
+            wall time in ``self``'s time zone.
+        """
+        # These isinstance checks are in datetime.tzinfo, so we'll preserve
+        # them, even if we don't care about duck typing.
+        if not isinstance(dt, datetime.datetime):
+            raise TypeError("fromutc() requires a datetime argument")
+
+        if dt.tzinfo is not self:
+            raise ValueError("dt.tzinfo is not self")
+
+        # First treat UTC as wall time and get the transition we're in.
+        idx = self._find_last_transition(dt, in_utc=True)
+        tti = self._get_ttinfo(idx)
+
+        dt_out = dt + datetime.timedelta(seconds=tti.offset)
+
+        fold = self.is_ambiguous(dt_out, idx=idx)
+
+        return enfold(dt_out, fold=int(fold))
+
+    def is_ambiguous(self, dt, idx=None):
+        """
+        Whether or not the "wall time" of a given datetime is ambiguous in this
+        zone.
+
+        :param dt:
+            A :py:class:`datetime.datetime`, naive or time zone aware.
+
+
+        :return:
+            Returns ``True`` if ambiguous, ``False`` otherwise.
+
+        .. versionadded:: 2.6.0
+        """
+        if idx is None:
+            idx = self._find_last_transition(dt)
+
+        # Calculate the difference in offsets from current to previous
+        timestamp = _datetime_to_timestamp(dt)
+        tti = self._get_ttinfo(idx)
+
+        if idx is None or idx <= 0:
+            return False
+
+        od = self._get_ttinfo(idx - 1).offset - tti.offset
+        tt = self._trans_list[idx]          # Transition time
+
+        return timestamp < tt + od
+
+    def _resolve_ambiguous_time(self, dt):
+        idx = self._find_last_transition(dt)
+
+        # If we have no transitions, return the index
+        _fold = self._fold(dt)
+        if idx is None or idx == 0:
+            return idx
+
+        # If it's ambiguous and we're in a fold, shift to a different index.
+        idx_offset = int(not _fold and self.is_ambiguous(dt, idx))
+
+        return idx - idx_offset
+
+    def utcoffset(self, dt):
+        if dt is None:
+            return None
+
+        if not self._ttinfo_std:
+            return ZERO
+
+        return self._find_ttinfo(dt).delta
+
+    def dst(self, dt):
+        if dt is None:
+            return None
+
+        if not self._ttinfo_dst:
+            return ZERO
+
+        tti = self._find_ttinfo(dt)
+
+        if not tti.isdst:
+            return ZERO
+
+        # The documentation says that utcoffset()-dst() must
+        # be constant for every dt.
+        return tti.dstoffset
+
+    @tzname_in_python2
+    def tzname(self, dt):
+        if not self._ttinfo_std or dt is None:
+            return None
+        return self._find_ttinfo(dt).abbr
+
+    def __eq__(self, other):
+        if not isinstance(other, tzfile):
+            return NotImplemented
+        return (self._trans_list == other._trans_list and
+                self._trans_idx == other._trans_idx and
+                self._ttinfo_list == other._ttinfo_list)
+
+    __hash__ = None
+
+    def __ne__(self, other):
+        return not (self == other)
+
+    def __repr__(self):
+        return "%s(%s)" % (self.__class__.__name__, repr(self._filename))
+
+    def __reduce__(self):
+        return self.__reduce_ex__(None)
+
+    def __reduce_ex__(self, protocol):
+        return (self.__class__, (None, self._filename), self.__dict__)
+
+
+class tzrange(tzrangebase):
+    """
+    The ``tzrange`` object is a time zone specified by a set of offsets and
+    abbreviations, equivalent to the way the ``TZ`` variable can be specified
+    in POSIX-like systems, but using Python delta objects to specify DST
+    start, end and offsets.
+
+    :param stdabbr:
+        The abbreviation for standard time (e.g. ``'EST'``).
+
+    :param stdoffset:
+        An integer or :class:`datetime.timedelta` object or equivalent
+        specifying the base offset from UTC.
+
+        If unspecified, +00:00 is used.
+
+    :param dstabbr:
+        The abbreviation for DST / "Summer" time (e.g. ``'EDT'``).
+
+        If specified, with no other DST information, DST is assumed to occur
+        and the default behavior or ``dstoffset``, ``start`` and ``end`` is
+        used. If unspecified and no other DST information is specified, it
+        is assumed that this zone has no DST.
+
+        If this is unspecified and other DST information is *is* specified,
+        DST occurs in the zone but the time zone abbreviation is left
+        unchanged.
+
+    :param dstoffset:
+        A an integer or :class:`datetime.timedelta` object or equivalent
+        specifying the UTC offset during DST. If unspecified and any other DST
+        information is specified, it is assumed to be the STD offset +1 hour.
+
+    :param start:
+        A :class:`relativedelta.relativedelta` object or equivalent specifying
+        the time and time of year that daylight savings time starts. To
+        specify, for example, that DST starts at 2AM on the 2nd Sunday in
+        March, pass:
+
+            ``relativedelta(hours=2, month=3, day=1, weekday=SU(+2))``
+
+        If unspecified and any other DST information is specified, the default
+        value is 2 AM on the first Sunday in April.
+
+    :param end:
+        A :class:`relativedelta.relativedelta` object or equivalent
+        representing the time and time of year that daylight savings time
+        ends, with the same specification method as in ``start``. One note is
+        that this should point to the first time in the *standard* zone, so if
+        a transition occurs at 2AM in the DST zone and the clocks are set back
+        1 hour to 1AM, set the ``hours`` parameter to +1.
+
+
+    **Examples:**
+
+    .. testsetup:: tzrange
+
+        from dateutil.tz import tzrange, tzstr
+
+    .. doctest:: tzrange
+
+        >>> tzstr('EST5EDT') == tzrange("EST", -18000, "EDT")
+        True
+
+        >>> from dateutil.relativedelta import *
+        >>> range1 = tzrange("EST", -18000, "EDT")
+        >>> range2 = tzrange("EST", -18000, "EDT", -14400,
+        ...                  relativedelta(hours=+2, month=4, day=1,
+        ...                                weekday=SU(+1)),
+        ...                  relativedelta(hours=+1, month=10, day=31,
+        ...                                weekday=SU(-1)))
+        >>> tzstr('EST5EDT') == range1 == range2
+        True
+
+    """
+    def __init__(self, stdabbr, stdoffset=None,
+                 dstabbr=None, dstoffset=None,
+                 start=None, end=None):
+
+        global relativedelta
+        from dateutil import relativedelta
+
+        self._std_abbr = stdabbr
+        self._dst_abbr = dstabbr
+
+        try:
+            stdoffset = stdoffset.total_seconds()
+        except (TypeError, AttributeError):
+            pass
+
+        try:
+            dstoffset = dstoffset.total_seconds()
+        except (TypeError, AttributeError):
+            pass
+
+        if stdoffset is not None:
+            self._std_offset = datetime.timedelta(seconds=stdoffset)
+        else:
+            self._std_offset = ZERO
+
+        if dstoffset is not None:
+            self._dst_offset = datetime.timedelta(seconds=dstoffset)
+        elif dstabbr and stdoffset is not None:
+            self._dst_offset = self._std_offset + datetime.timedelta(hours=+1)
+        else:
+            self._dst_offset = ZERO
+
+        if dstabbr and start is None:
+            self._start_delta = relativedelta.relativedelta(
+                hours=+2, month=4, day=1, weekday=relativedelta.SU(+1))
+        else:
+            self._start_delta = start
+
+        if dstabbr and end is None:
+            self._end_delta = relativedelta.relativedelta(
+                hours=+1, month=10, day=31, weekday=relativedelta.SU(-1))
+        else:
+            self._end_delta = end
+
+        self._dst_base_offset_ = self._dst_offset - self._std_offset
+        self.hasdst = bool(self._start_delta)
+
+    def transitions(self, year):
+        """
+        For a given year, get the DST on and off transition times, expressed
+        always on the standard time side. For zones with no transitions, this
+        function returns ``None``.
+
+        :param year:
+            The year whose transitions you would like to query.
+
+        :return:
+            Returns a :class:`tuple` of :class:`datetime.datetime` objects,
+            ``(dston, dstoff)`` for zones with an annual DST transition, or
+            ``None`` for fixed offset zones.
+        """
+        if not self.hasdst:
+            return None
+
+        base_year = datetime.datetime(year, 1, 1)
+
+        start = base_year + self._start_delta
+        end = base_year + self._end_delta
+
+        return (start, end)
+
+    def __eq__(self, other):
+        if not isinstance(other, tzrange):
+            return NotImplemented
+
+        return (self._std_abbr == other._std_abbr and
+                self._dst_abbr == other._dst_abbr and
+                self._std_offset == other._std_offset and
+                self._dst_offset == other._dst_offset and
+                self._start_delta == other._start_delta and
+                self._end_delta == other._end_delta)
+
+    @property
+    def _dst_base_offset(self):
+        return self._dst_base_offset_
+
+
+@six.add_metaclass(_TzStrFactory)
+class tzstr(tzrange):
+    """
+    ``tzstr`` objects are time zone objects specified by a time-zone string as
+    it would be passed to a ``TZ`` variable on POSIX-style systems (see
+    the `GNU C Library: TZ Variable`_ for more details).
+
+    There is one notable exception, which is that POSIX-style time zones use an
+    inverted offset format, so normally ``GMT+3`` would be parsed as an offset
+    3 hours *behind* GMT. The ``tzstr`` time zone object will parse this as an
+    offset 3 hours *ahead* of GMT. If you would like to maintain the POSIX
+    behavior, pass a ``True`` value to ``posix_offset``.
+
+    The :class:`tzrange` object provides the same functionality, but is
+    specified using :class:`relativedelta.relativedelta` objects. rather than
+    strings.
+
+    :param s:
+        A time zone string in ``TZ`` variable format. This can be a
+        :class:`bytes` (2.x: :class:`str`), :class:`str` (2.x:
+        :class:`unicode`) or a stream emitting unicode characters
+        (e.g. :class:`StringIO`).
+
+    :param posix_offset:
+        Optional. If set to ``True``, interpret strings such as ``GMT+3`` or
+        ``UTC+3`` as being 3 hours *behind* UTC rather than ahead, per the
+        POSIX standard.
+
+    .. caution::
+
+        Prior to version 2.7.0, this function also supported time zones
+        in the format:
+
+            * ``EST5EDT,4,0,6,7200,10,0,26,7200,3600``
+            * ``EST5EDT,4,1,0,7200,10,-1,0,7200,3600``
+
+        This format is non-standard and has been deprecated; this function
+        will raise a :class:`DeprecatedTZFormatWarning` until
+        support is removed in a future version.
+
+    .. _`GNU C Library: TZ Variable`:
+        https://www.gnu.org/software/libc/manual/html_node/TZ-Variable.html
+    """
+    def __init__(self, s, posix_offset=False):
+        global parser
+        from dateutil.parser import _parser as parser
+
+        self._s = s
+
+        res = parser._parsetz(s)
+        if res is None or res.any_unused_tokens:
+            raise ValueError("unknown string format")
+
+        # Here we break the compatibility with the TZ variable handling.
+        # GMT-3 actually *means* the timezone -3.
+        if res.stdabbr in ("GMT", "UTC") and not posix_offset:
+            res.stdoffset *= -1
+
+        # We must initialize it first, since _delta() needs
+        # _std_offset and _dst_offset set. Use False in start/end
+        # to avoid building it two times.
+        tzrange.__init__(self, res.stdabbr, res.stdoffset,
+                         res.dstabbr, res.dstoffset,
+                         start=False, end=False)
+
+        if not res.dstabbr:
+            self._start_delta = None
+            self._end_delta = None
+        else:
+            self._start_delta = self._delta(res.start)
+            if self._start_delta:
+                self._end_delta = self._delta(res.end, isend=1)
+
+        self.hasdst = bool(self._start_delta)
+
+    def _delta(self, x, isend=0):
+        from dateutil import relativedelta
+        kwargs = {}
+        if x.month is not None:
+            kwargs["month"] = x.month
+            if x.weekday is not None:
+                kwargs["weekday"] = relativedelta.weekday(x.weekday, x.week)
+                if x.week > 0:
+                    kwargs["day"] = 1
+                else:
+                    kwargs["day"] = 31
+            elif x.day:
+                kwargs["day"] = x.day
+        elif x.yday is not None:
+            kwargs["yearday"] = x.yday
+        elif x.jyday is not None:
+            kwargs["nlyearday"] = x.jyday
+        if not kwargs:
+            # Default is to start on first sunday of april, and end
+            # on last sunday of october.
+            if not isend:
+                kwargs["month"] = 4
+                kwargs["day"] = 1
+                kwargs["weekday"] = relativedelta.SU(+1)
+            else:
+                kwargs["month"] = 10
+                kwargs["day"] = 31
+                kwargs["weekday"] = relativedelta.SU(-1)
+        if x.time is not None:
+            kwargs["seconds"] = x.time
+        else:
+            # Default is 2AM.
+            kwargs["seconds"] = 7200
+        if isend:
+            # Convert to standard time, to follow the documented way
+            # of working with the extra hour. See the documentation
+            # of the tzinfo class.
+            delta = self._dst_offset - self._std_offset
+            kwargs["seconds"] -= delta.seconds + delta.days * 86400
+        return relativedelta.relativedelta(**kwargs)
+
+    def __repr__(self):
+        return "%s(%s)" % (self.__class__.__name__, repr(self._s))
+
+
+class _tzicalvtzcomp(object):
+    def __init__(self, tzoffsetfrom, tzoffsetto, isdst,
+                 tzname=None, rrule=None):
+        self.tzoffsetfrom = datetime.timedelta(seconds=tzoffsetfrom)
+        self.tzoffsetto = datetime.timedelta(seconds=tzoffsetto)
+        self.tzoffsetdiff = self.tzoffsetto - self.tzoffsetfrom
+        self.isdst = isdst
+        self.tzname = tzname
+        self.rrule = rrule
+
+
+class _tzicalvtz(_tzinfo):
+    def __init__(self, tzid, comps=[]):
+        super(_tzicalvtz, self).__init__()
+
+        self._tzid = tzid
+        self._comps = comps
+        self._cachedate = []
+        self._cachecomp = []
+        self._cache_lock = _thread.allocate_lock()
+
+    def _find_comp(self, dt):
+        if len(self._comps) == 1:
+            return self._comps[0]
+
+        dt = dt.replace(tzinfo=None)
+
+        try:
+            with self._cache_lock:
+                return self._cachecomp[self._cachedate.index(
+                    (dt, self._fold(dt)))]
+        except ValueError:
+            pass
+
+        lastcompdt = None
+        lastcomp = None
+
+        for comp in self._comps:
+            compdt = self._find_compdt(comp, dt)
+
+            if compdt and (not lastcompdt or lastcompdt < compdt):
+                lastcompdt = compdt
+                lastcomp = comp
+
+        if not lastcomp:
+            # RFC says nothing about what to do when a given
+            # time is before the first onset date. We'll look for the
+            # first standard component, or the first component, if
+            # none is found.
+            for comp in self._comps:
+                if not comp.isdst:
+                    lastcomp = comp
+                    break
+            else:
+                lastcomp = comp[0]
+
+        with self._cache_lock:
+            self._cachedate.insert(0, (dt, self._fold(dt)))
+            self._cachecomp.insert(0, lastcomp)
+
+            if len(self._cachedate) > 10:
+                self._cachedate.pop()
+                self._cachecomp.pop()
+
+        return lastcomp
+
+    def _find_compdt(self, comp, dt):
+        if comp.tzoffsetdiff < ZERO and self._fold(dt):
+            dt -= comp.tzoffsetdiff
+
+        compdt = comp.rrule.before(dt, inc=True)
+
+        return compdt
+
+    def utcoffset(self, dt):
+        if dt is None:
+            return None
+
+        return self._find_comp(dt).tzoffsetto
+
+    def dst(self, dt):
+        comp = self._find_comp(dt)
+        if comp.isdst:
+            return comp.tzoffsetdiff
+        else:
+            return ZERO
+
+    @tzname_in_python2
+    def tzname(self, dt):
+        return self._find_comp(dt).tzname
+
+    def __repr__(self):
+        return "<tzicalvtz %s>" % repr(self._tzid)
+
+    __reduce__ = object.__reduce__
+
+
+class tzical(object):
+    """
+    This object is designed to parse an iCalendar-style ``VTIMEZONE`` structure
+    as set out in `RFC 5545`_ Section 4.6.5 into one or more `tzinfo` objects.
+
+    :param `fileobj`:
+        A file or stream in iCalendar format, which should be UTF-8 encoded
+        with CRLF endings.
+
+    .. _`RFC 5545`: https://tools.ietf.org/html/rfc5545
+    """
+    def __init__(self, fileobj):
+        global rrule
+        from dateutil import rrule
+
+        if isinstance(fileobj, string_types):
+            self._s = fileobj
+            # ical should be encoded in UTF-8 with CRLF
+            fileobj = open(fileobj, 'r')
+        else:
+            self._s = getattr(fileobj, 'name', repr(fileobj))
+            fileobj = _nullcontext(fileobj)
+
+        self._vtz = {}
+
+        with fileobj as fobj:
+            self._parse_rfc(fobj.read())
+
+    def keys(self):
+        """
+        Retrieves the available time zones as a list.
+        """
+        return list(self._vtz.keys())
+
+    def get(self, tzid=None):
+        """
+        Retrieve a :py:class:`datetime.tzinfo` object by its ``tzid``.
+
+        :param tzid:
+            If there is exactly one time zone available, omitting ``tzid``
+            or passing :py:const:`None` value returns it. Otherwise a valid
+            key (which can be retrieved from :func:`keys`) is required.
+
+        :raises ValueError:
+            Raised if ``tzid`` is not specified but there are either more
+            or fewer than 1 zone defined.
+
+        :returns:
+            Returns either a :py:class:`datetime.tzinfo` object representing
+            the relevant time zone or :py:const:`None` if the ``tzid`` was
+            not found.
+        """
+        if tzid is None:
+            if len(self._vtz) == 0:
+                raise ValueError("no timezones defined")
+            elif len(self._vtz) > 1:
+                raise ValueError("more than one timezone available")
+            tzid = next(iter(self._vtz))
+
+        return self._vtz.get(tzid)
+
+    def _parse_offset(self, s):
+        s = s.strip()
+        if not s:
+            raise ValueError("empty offset")
+        if s[0] in ('+', '-'):
+            signal = (-1, +1)[s[0] == '+']
+            s = s[1:]
+        else:
+            signal = +1
+        if len(s) == 4:
+            return (int(s[:2]) * 3600 + int(s[2:]) * 60) * signal
+        elif len(s) == 6:
+            return (int(s[:2]) * 3600 + int(s[2:4]) * 60 + int(s[4:])) * signal
+        else:
+            raise ValueError("invalid offset: " + s)
+
+    def _parse_rfc(self, s):
+        lines = s.splitlines()
+        if not lines:
+            raise ValueError("empty string")
+
+        # Unfold
+        i = 0
+        while i < len(lines):
+            line = lines[i].rstrip()
+            if not line:
+                del lines[i]
+            elif i > 0 and line[0] == " ":
+                lines[i-1] += line[1:]
+                del lines[i]
+            else:
+                i += 1
+
+        tzid = None
+        comps = []
+        invtz = False
+        comptype = None
+        for line in lines:
+            if not line:
+                continue
+            name, value = line.split(':', 1)
+            parms = name.split(';')
+            if not parms:
+                raise ValueError("empty property name")
+            name = parms[0].upper()
+            parms = parms[1:]
+            if invtz:
+                if name == "BEGIN":
+                    if value in ("STANDARD", "DAYLIGHT"):
+                        # Process component
+                        pass
+                    else:
+                        raise ValueError("unknown component: "+value)
+                    comptype = value
+                    founddtstart = False
+                    tzoffsetfrom = None
+                    tzoffsetto = None
+                    rrulelines = []
+                    tzname = None
+                elif name == "END":
+                    if value == "VTIMEZONE":
+                        if comptype:
+                            raise ValueError("component not closed: "+comptype)
+                        if not tzid:
+                            raise ValueError("mandatory TZID not found")
+                        if not comps:
+                            raise ValueError(
+                                "at least one component is needed")
+                        # Process vtimezone
+                        self._vtz[tzid] = _tzicalvtz(tzid, comps)
+                        invtz = False
+                    elif value == comptype:
+                        if not founddtstart:
+                            raise ValueError("mandatory DTSTART not found")
+                        if tzoffsetfrom is None:
+                            raise ValueError(
+                                "mandatory TZOFFSETFROM not found")
+                        if tzoffsetto is None:
+                            raise ValueError(
+                                "mandatory TZOFFSETFROM not found")
+                        # Process component
+                        rr = None
+                        if rrulelines:
+                            rr = rrule.rrulestr("\n".join(rrulelines),
+                                                compatible=True,
+                                                ignoretz=True,
+                                                cache=True)
+                        comp = _tzicalvtzcomp(tzoffsetfrom, tzoffsetto,
+                                              (comptype == "DAYLIGHT"),
+                                              tzname, rr)
+                        comps.append(comp)
+                        comptype = None
+                    else:
+                        raise ValueError("invalid component end: "+value)
+                elif comptype:
+                    if name == "DTSTART":
+                        # DTSTART in VTIMEZONE takes a subset of valid RRULE
+                        # values under RFC 5545.
+                        for parm in parms:
+                            if parm != 'VALUE=DATE-TIME':
+                                msg = ('Unsupported DTSTART param in ' +
+                                       'VTIMEZONE: ' + parm)
+                                raise ValueError(msg)
+                        rrulelines.append(line)
+                        founddtstart = True
+                    elif name in ("RRULE", "RDATE", "EXRULE", "EXDATE"):
+                        rrulelines.append(line)
+                    elif name == "TZOFFSETFROM":
+                        if parms:
+                            raise ValueError(
+                                "unsupported %s parm: %s " % (name, parms[0]))
+                        tzoffsetfrom = self._parse_offset(value)
+                    elif name == "TZOFFSETTO":
+                        if parms:
+                            raise ValueError(
+                                "unsupported TZOFFSETTO parm: "+parms[0])
+                        tzoffsetto = self._parse_offset(value)
+                    elif name == "TZNAME":
+                        if parms:
+                            raise ValueError(
+                                "unsupported TZNAME parm: "+parms[0])
+                        tzname = value
+                    elif name == "COMMENT":
+                        pass
+                    else:
+                        raise ValueError("unsupported property: "+name)
+                else:
+                    if name == "TZID":
+                        if parms:
+                            raise ValueError(
+                                "unsupported TZID parm: "+parms[0])
+                        tzid = value
+                    elif name in ("TZURL", "LAST-MODIFIED", "COMMENT"):
+                        pass
+                    else:
+                        raise ValueError("unsupported property: "+name)
+            elif name == "BEGIN" and value == "VTIMEZONE":
+                tzid = None
+                comps = []
+                invtz = True
+
+    def __repr__(self):
+        return "%s(%s)" % (self.__class__.__name__, repr(self._s))
+
+
+if sys.platform != "win32":
+    TZFILES = ["/etc/localtime", "localtime"]
+    TZPATHS = ["/usr/share/zoneinfo",
+               "/usr/lib/zoneinfo",
+               "/usr/share/lib/zoneinfo",
+               "/etc/zoneinfo"]
+else:
+    TZFILES = []
+    TZPATHS = []
+
+
+def __get_gettz():
+    tzlocal_classes = (tzlocal,)
+    if tzwinlocal is not None:
+        tzlocal_classes += (tzwinlocal,)
+
+    class GettzFunc(object):
+        """
+        Retrieve a time zone object from a string representation
+
+        This function is intended to retrieve the :py:class:`tzinfo` subclass
+        that best represents the time zone that would be used if a POSIX
+        `TZ variable`_ were set to the same value.
+
+        If no argument or an empty string is passed to ``gettz``, local time
+        is returned:
+
+        .. code-block:: python3
+
+            >>> gettz()
+            tzfile('/etc/localtime')
+
+        This function is also the preferred way to map IANA tz database keys
+        to :class:`tzfile` objects:
+
+        .. code-block:: python3
+
+            >>> gettz('Pacific/Kiritimati')
+            tzfile('/usr/share/zoneinfo/Pacific/Kiritimati')
+
+        On Windows, the standard is extended to include the Windows-specific
+        zone names provided by the operating system:
+
+        .. code-block:: python3
+
+            >>> gettz('Egypt Standard Time')
+            tzwin('Egypt Standard Time')
+
+        Passing a GNU ``TZ`` style string time zone specification returns a
+        :class:`tzstr` object:
+
+        .. code-block:: python3
+
+            >>> gettz('AEST-10AEDT-11,M10.1.0/2,M4.1.0/3')
+            tzstr('AEST-10AEDT-11,M10.1.0/2,M4.1.0/3')
+
+        :param name:
+            A time zone name (IANA, or, on Windows, Windows keys), location of
+            a ``tzfile(5)`` zoneinfo file or ``TZ`` variable style time zone
+            specifier. An empty string, no argument or ``None`` is interpreted
+            as local time.
+
+        :return:
+            Returns an instance of one of ``dateutil``'s :py:class:`tzinfo`
+            subclasses.
+
+        .. versionchanged:: 2.7.0
+
+            After version 2.7.0, any two calls to ``gettz`` using the same
+            input strings will return the same object:
+
+            .. code-block:: python3
+
+                >>> tz.gettz('America/Chicago') is tz.gettz('America/Chicago')
+                True
+
+            In addition to improving performance, this ensures that
+            `"same zone" semantics`_ are used for datetimes in the same zone.
+
+
+        .. _`TZ variable`:
+            https://www.gnu.org/software/libc/manual/html_node/TZ-Variable.html
+
+        .. _`"same zone" semantics`:
+            https://blog.ganssle.io/articles/2018/02/aware-datetime-arithmetic.html
+        """
+        def __init__(self):
+
+            self.__instances = weakref.WeakValueDictionary()
+            self.__strong_cache_size = 8
+            self.__strong_cache = OrderedDict()
+            self._cache_lock = _thread.allocate_lock()
+
+        def __call__(self, name=None):
+            with self._cache_lock:
+                rv = self.__instances.get(name, None)
+
+                if rv is None:
+                    rv = self.nocache(name=name)
+                    if not (name is None
+                            or isinstance(rv, tzlocal_classes)
+                            or rv is None):
+                        # tzlocal is slightly more complicated than the other
+                        # time zone providers because it depends on environment
+                        # at construction time, so don't cache that.
+                        #
+                        # We also cannot store weak references to None, so we
+                        # will also not store that.
+                        self.__instances[name] = rv
+                    else:
+                        # No need for strong caching, return immediately
+                        return rv
+
+                self.__strong_cache[name] = self.__strong_cache.pop(name, rv)
+
+                if len(self.__strong_cache) > self.__strong_cache_size:
+                    self.__strong_cache.popitem(last=False)
+
+            return rv
+
+        def set_cache_size(self, size):
+            with self._cache_lock:
+                self.__strong_cache_size = size
+                while len(self.__strong_cache) > size:
+                    self.__strong_cache.popitem(last=False)
+
+        def cache_clear(self):
+            with self._cache_lock:
+                self.__instances = weakref.WeakValueDictionary()
+                self.__strong_cache.clear()
+
+        @staticmethod
+        def nocache(name=None):
+            """A non-cached version of gettz"""
+            tz = None
+            if not name:
+                try:
+                    name = os.environ["TZ"]
+                except KeyError:
+                    pass
+            if name is None or name == ":":
+                for filepath in TZFILES:
+                    if not os.path.isabs(filepath):
+                        filename = filepath
+                        for path in TZPATHS:
+                            filepath = os.path.join(path, filename)
+                            if os.path.isfile(filepath):
+                                break
+                        else:
+                            continue
+                    if os.path.isfile(filepath):
+                        try:
+                            tz = tzfile(filepath)
+                            break
+                        except (IOError, OSError, ValueError):
+                            pass
+                else:
+                    tz = tzlocal()
+            else:
+                try:
+                    if name.startswith(":"):
+                        name = name[1:]
+                except TypeError as e:
+                    if isinstance(name, bytes):
+                        new_msg = "gettz argument should be str, not bytes"
+                        six.raise_from(TypeError(new_msg), e)
+                    else:
+                        raise
+                if os.path.isabs(name):
+                    if os.path.isfile(name):
+                        tz = tzfile(name)
+                    else:
+                        tz = None
+                else:
+                    for path in TZPATHS:
+                        filepath = os.path.join(path, name)
+                        if not os.path.isfile(filepath):
+                            filepath = filepath.replace(' ', '_')
+                            if not os.path.isfile(filepath):
+                                continue
+                        try:
+                            tz = tzfile(filepath)
+                            break
+                        except (IOError, OSError, ValueError):
+                            pass
+                    else:
+                        tz = None
+                        if tzwin is not None:
+                            try:
+                                tz = tzwin(name)
+                            except (WindowsError, UnicodeEncodeError):
+                                # UnicodeEncodeError is for Python 2.7 compat
+                                tz = None
+
+                        if not tz:
+                            from dateutil.zoneinfo import get_zonefile_instance
+                            tz = get_zonefile_instance().get(name)
+
+                        if not tz:
+                            for c in name:
+                                # name is not a tzstr unless it has at least
+                                # one offset. For short values of "name", an
+                                # explicit for loop seems to be the fastest way
+                                # To determine if a string contains a digit
+                                if c in "0123456789":
+                                    try:
+                                        tz = tzstr(name)
+                                    except ValueError:
+                                        pass
+                                    break
+                            else:
+                                if name in ("GMT", "UTC"):
+                                    tz = UTC
+                                elif name in time.tzname:
+                                    tz = tzlocal()
+            return tz
+
+    return GettzFunc()
+
+
+gettz = __get_gettz()
+del __get_gettz
+
+
+def datetime_exists(dt, tz=None):
+    """
+    Given a datetime and a time zone, determine whether or not a given datetime
+    would fall in a gap.
+
+    :param dt:
+        A :class:`datetime.datetime` (whose time zone will be ignored if ``tz``
+        is provided.)
+
+    :param tz:
+        A :class:`datetime.tzinfo` with support for the ``fold`` attribute. If
+        ``None`` or not provided, the datetime's own time zone will be used.
+
+    :return:
+        Returns a boolean value whether or not the "wall time" exists in
+        ``tz``.
+
+    .. versionadded:: 2.7.0
+    """
+    if tz is None:
+        if dt.tzinfo is None:
+            raise ValueError('Datetime is naive and no time zone provided.')
+        tz = dt.tzinfo
+
+    dt = dt.replace(tzinfo=None)
+
+    # This is essentially a test of whether or not the datetime can survive
+    # a round trip to UTC.
+    dt_rt = dt.replace(tzinfo=tz).astimezone(UTC).astimezone(tz)
+    dt_rt = dt_rt.replace(tzinfo=None)
+
+    return dt == dt_rt
+
+
+def datetime_ambiguous(dt, tz=None):
+    """
+    Given a datetime and a time zone, determine whether or not a given datetime
+    is ambiguous (i.e if there are two times differentiated only by their DST
+    status).
+
+    :param dt:
+        A :class:`datetime.datetime` (whose time zone will be ignored if ``tz``
+        is provided.)
+
+    :param tz:
+        A :class:`datetime.tzinfo` with support for the ``fold`` attribute. If
+        ``None`` or not provided, the datetime's own time zone will be used.
+
+    :return:
+        Returns a boolean value whether or not the "wall time" is ambiguous in
+        ``tz``.
+
+    .. versionadded:: 2.6.0
+    """
+    if tz is None:
+        if dt.tzinfo is None:
+            raise ValueError('Datetime is naive and no time zone provided.')
+
+        tz = dt.tzinfo
+
+    # If a time zone defines its own "is_ambiguous" function, we'll use that.
+    is_ambiguous_fn = getattr(tz, 'is_ambiguous', None)
+    if is_ambiguous_fn is not None:
+        try:
+            return tz.is_ambiguous(dt)
+        except Exception:
+            pass
+
+    # If it doesn't come out and tell us it's ambiguous, we'll just check if
+    # the fold attribute has any effect on this particular date and time.
+    dt = dt.replace(tzinfo=tz)
+    wall_0 = enfold(dt, fold=0)
+    wall_1 = enfold(dt, fold=1)
+
+    same_offset = wall_0.utcoffset() == wall_1.utcoffset()
+    same_dst = wall_0.dst() == wall_1.dst()
+
+    return not (same_offset and same_dst)
+
+
+def resolve_imaginary(dt):
+    """
+    Given a datetime that may be imaginary, return an existing datetime.
+
+    This function assumes that an imaginary datetime represents what the
+    wall time would be in a zone had the offset transition not occurred, so
+    it will always fall forward by the transition's change in offset.
+
+    .. doctest::
+
+        >>> from dateutil import tz
+        >>> from datetime import datetime
+        >>> NYC = tz.gettz('America/New_York')
+        >>> print(tz.resolve_imaginary(datetime(2017, 3, 12, 2, 30, tzinfo=NYC)))
+        2017-03-12 03:30:00-04:00
+
+        >>> KIR = tz.gettz('Pacific/Kiritimati')
+        >>> print(tz.resolve_imaginary(datetime(1995, 1, 1, 12, 30, tzinfo=KIR)))
+        1995-01-02 12:30:00+14:00
+
+    As a note, :func:`datetime.astimezone` is guaranteed to produce a valid,
+    existing datetime, so a round-trip to and from UTC is sufficient to get
+    an extant datetime, however, this generally "falls back" to an earlier time
+    rather than falling forward to the STD side (though no guarantees are made
+    about this behavior).
+
+    :param dt:
+        A :class:`datetime.datetime` which may or may not exist.
+
+    :return:
+        Returns an existing :class:`datetime.datetime`. If ``dt`` was not
+        imaginary, the datetime returned is guaranteed to be the same object
+        passed to the function.
+
+    .. versionadded:: 2.7.0
+    """
+    if dt.tzinfo is not None and not datetime_exists(dt):
+
+        curr_offset = (dt + datetime.timedelta(hours=24)).utcoffset()
+        old_offset = (dt - datetime.timedelta(hours=24)).utcoffset()
+
+        dt += curr_offset - old_offset
+
+    return dt
+
+
+def _datetime_to_timestamp(dt):
+    """
+    Convert a :class:`datetime.datetime` object to an epoch timestamp in
+    seconds since January 1, 1970, ignoring the time zone.
+    """
+    return (dt.replace(tzinfo=None) - EPOCH).total_seconds()
+
+
+if sys.version_info >= (3, 6):
+    def _get_supported_offset(second_offset):
+        return second_offset
+else:
+    def _get_supported_offset(second_offset):
+        # For python pre-3.6, round to full-minutes if that's not the case.
+        # Python's datetime doesn't accept sub-minute timezones. Check
+        # http://python.org/sf/1447945 or https://bugs.python.org/issue5288
+        # for some information.
+        old_offset = second_offset
+        calculated_offset = 60 * ((second_offset + 30) // 60)
+        return calculated_offset
+
+
+try:
+    # Python 3.7 feature
+    from contextlib import nullcontext as _nullcontext
+except ImportError:
+    class _nullcontext(object):
+        """
+        Class for wrapping contexts so that they are passed through in a
+        with statement.
+        """
+        def __init__(self, context):
+            self.context = context
+
+        def __enter__(self):
+            return self.context
+
+        def __exit__(*args, **kwargs):
+            pass
+
+# vim:ts=4:sw=4:et
Index: latest/Lib/site-packages/psycopg2-2.8.6.dist-info/LICENSE
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/latest/Lib/site-packages/psycopg2-2.8.6.dist-info/LICENSE b/latest/Lib/site-packages/psycopg2-2.8.6.dist-info/LICENSE
new file mode 100644
--- /dev/null	(date 1616410449565)
+++ b/latest/Lib/site-packages/psycopg2-2.8.6.dist-info/LICENSE	(date 1616410449565)
@@ -0,0 +1,49 @@
+psycopg2 and the LGPL
+---------------------
+
+psycopg2 is free software: you can redistribute it and/or modify it
+under the terms of the GNU Lesser General Public License as published
+by the Free Software Foundation, either version 3 of the License, or
+(at your option) any later version.
+
+psycopg2 is distributed in the hope that it will be useful, but WITHOUT
+ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or
+FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public
+License for more details.
+
+In addition, as a special exception, the copyright holders give
+permission to link this program with the OpenSSL library (or with
+modified versions of OpenSSL that use the same license as OpenSSL),
+and distribute linked combinations including the two.
+
+You must obey the GNU Lesser General Public License in all respects for
+all of the code used other than OpenSSL. If you modify file(s) with this
+exception, you may extend this exception to your version of the file(s),
+but you are not obligated to do so. If you do not wish to do so, delete
+this exception statement from your version. If you delete this exception
+statement from all source files in the program, then also delete it here.
+
+You should have received a copy of the GNU Lesser General Public License
+along with psycopg2 (see the doc/ directory.)
+If not, see <https://www.gnu.org/licenses/>.
+
+
+Alternative licenses
+--------------------
+
+The following BSD-like license applies (at your option) to the files following
+the pattern ``psycopg/adapter*.{h,c}`` and ``psycopg/microprotocol*.{h,c}``:
+
+ Permission is granted to anyone to use this software for any purpose,
+ including commercial applications, and to alter it and redistribute it
+ freely, subject to the following restrictions:
+
+ 1. The origin of this software must not be misrepresented; you must not
+    claim that you wrote the original software. If you use this
+    software in a product, an acknowledgment in the product documentation
+    would be appreciated but is not required.
+
+ 2. Altered source versions must be plainly marked as such, and must not
+    be misrepresented as being the original software.
+
+ 3. This notice may not be removed or altered from any source distribution.
Index: venv/Lib/site-packages/dateutil/tz/win.py
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/venv/Lib/site-packages/dateutil/tz/win.py b/venv/Lib/site-packages/dateutil/tz/win.py
new file mode 100644
--- /dev/null	(date 1616410449737)
+++ b/venv/Lib/site-packages/dateutil/tz/win.py	(date 1616410449737)
@@ -0,0 +1,370 @@
+# -*- coding: utf-8 -*-
+"""
+This module provides an interface to the native time zone data on Windows,
+including :py:class:`datetime.tzinfo` implementations.
+
+Attempting to import this module on a non-Windows platform will raise an
+:py:obj:`ImportError`.
+"""
+# This code was originally contributed by Jeffrey Harris.
+import datetime
+import struct
+
+from six.moves import winreg
+from six import text_type
+
+try:
+    import ctypes
+    from ctypes import wintypes
+except ValueError:
+    # ValueError is raised on non-Windows systems for some horrible reason.
+    raise ImportError("Running tzwin on non-Windows system")
+
+from ._common import tzrangebase
+
+__all__ = ["tzwin", "tzwinlocal", "tzres"]
+
+ONEWEEK = datetime.timedelta(7)
+
+TZKEYNAMENT = r"SOFTWARE\Microsoft\Windows NT\CurrentVersion\Time Zones"
+TZKEYNAME9X = r"SOFTWARE\Microsoft\Windows\CurrentVersion\Time Zones"
+TZLOCALKEYNAME = r"SYSTEM\CurrentControlSet\Control\TimeZoneInformation"
+
+
+def _settzkeyname():
+    handle = winreg.ConnectRegistry(None, winreg.HKEY_LOCAL_MACHINE)
+    try:
+        winreg.OpenKey(handle, TZKEYNAMENT).Close()
+        TZKEYNAME = TZKEYNAMENT
+    except WindowsError:
+        TZKEYNAME = TZKEYNAME9X
+    handle.Close()
+    return TZKEYNAME
+
+
+TZKEYNAME = _settzkeyname()
+
+
+class tzres(object):
+    """
+    Class for accessing ``tzres.dll``, which contains timezone name related
+    resources.
+
+    .. versionadded:: 2.5.0
+    """
+    p_wchar = ctypes.POINTER(wintypes.WCHAR)        # Pointer to a wide char
+
+    def __init__(self, tzres_loc='tzres.dll'):
+        # Load the user32 DLL so we can load strings from tzres
+        user32 = ctypes.WinDLL('user32')
+
+        # Specify the LoadStringW function
+        user32.LoadStringW.argtypes = (wintypes.HINSTANCE,
+                                       wintypes.UINT,
+                                       wintypes.LPWSTR,
+                                       ctypes.c_int)
+
+        self.LoadStringW = user32.LoadStringW
+        self._tzres = ctypes.WinDLL(tzres_loc)
+        self.tzres_loc = tzres_loc
+
+    def load_name(self, offset):
+        """
+        Load a timezone name from a DLL offset (integer).
+
+        >>> from dateutil.tzwin import tzres
+        >>> tzr = tzres()
+        >>> print(tzr.load_name(112))
+        'Eastern Standard Time'
+
+        :param offset:
+            A positive integer value referring to a string from the tzres dll.
+
+        .. note::
+
+            Offsets found in the registry are generally of the form
+            ``@tzres.dll,-114``. The offset in this case is 114, not -114.
+
+        """
+        resource = self.p_wchar()
+        lpBuffer = ctypes.cast(ctypes.byref(resource), wintypes.LPWSTR)
+        nchar = self.LoadStringW(self._tzres._handle, offset, lpBuffer, 0)
+        return resource[:nchar]
+
+    def name_from_string(self, tzname_str):
+        """
+        Parse strings as returned from the Windows registry into the time zone
+        name as defined in the registry.
+
+        >>> from dateutil.tzwin import tzres
+        >>> tzr = tzres()
+        >>> print(tzr.name_from_string('@tzres.dll,-251'))
+        'Dateline Daylight Time'
+        >>> print(tzr.name_from_string('Eastern Standard Time'))
+        'Eastern Standard Time'
+
+        :param tzname_str:
+            A timezone name string as returned from a Windows registry key.
+
+        :return:
+            Returns the localized timezone string from tzres.dll if the string
+            is of the form `@tzres.dll,-offset`, else returns the input string.
+        """
+        if not tzname_str.startswith('@'):
+            return tzname_str
+
+        name_splt = tzname_str.split(',-')
+        try:
+            offset = int(name_splt[1])
+        except:
+            raise ValueError("Malformed timezone string.")
+
+        return self.load_name(offset)
+
+
+class tzwinbase(tzrangebase):
+    """tzinfo class based on win32's timezones available in the registry."""
+    def __init__(self):
+        raise NotImplementedError('tzwinbase is an abstract base class')
+
+    def __eq__(self, other):
+        # Compare on all relevant dimensions, including name.
+        if not isinstance(other, tzwinbase):
+            return NotImplemented
+
+        return  (self._std_offset == other._std_offset and
+                 self._dst_offset == other._dst_offset and
+                 self._stddayofweek == other._stddayofweek and
+                 self._dstdayofweek == other._dstdayofweek and
+                 self._stdweeknumber == other._stdweeknumber and
+                 self._dstweeknumber == other._dstweeknumber and
+                 self._stdhour == other._stdhour and
+                 self._dsthour == other._dsthour and
+                 self._stdminute == other._stdminute and
+                 self._dstminute == other._dstminute and
+                 self._std_abbr == other._std_abbr and
+                 self._dst_abbr == other._dst_abbr)
+
+    @staticmethod
+    def list():
+        """Return a list of all time zones known to the system."""
+        with winreg.ConnectRegistry(None, winreg.HKEY_LOCAL_MACHINE) as handle:
+            with winreg.OpenKey(handle, TZKEYNAME) as tzkey:
+                result = [winreg.EnumKey(tzkey, i)
+                          for i in range(winreg.QueryInfoKey(tzkey)[0])]
+        return result
+
+    def display(self):
+        """
+        Return the display name of the time zone.
+        """
+        return self._display
+
+    def transitions(self, year):
+        """
+        For a given year, get the DST on and off transition times, expressed
+        always on the standard time side. For zones with no transitions, this
+        function returns ``None``.
+
+        :param year:
+            The year whose transitions you would like to query.
+
+        :return:
+            Returns a :class:`tuple` of :class:`datetime.datetime` objects,
+            ``(dston, dstoff)`` for zones with an annual DST transition, or
+            ``None`` for fixed offset zones.
+        """
+
+        if not self.hasdst:
+            return None
+
+        dston = picknthweekday(year, self._dstmonth, self._dstdayofweek,
+                               self._dsthour, self._dstminute,
+                               self._dstweeknumber)
+
+        dstoff = picknthweekday(year, self._stdmonth, self._stddayofweek,
+                                self._stdhour, self._stdminute,
+                                self._stdweeknumber)
+
+        # Ambiguous dates default to the STD side
+        dstoff -= self._dst_base_offset
+
+        return dston, dstoff
+
+    def _get_hasdst(self):
+        return self._dstmonth != 0
+
+    @property
+    def _dst_base_offset(self):
+        return self._dst_base_offset_
+
+
+class tzwin(tzwinbase):
+    """
+    Time zone object created from the zone info in the Windows registry
+
+    These are similar to :py:class:`dateutil.tz.tzrange` objects in that
+    the time zone data is provided in the format of a single offset rule
+    for either 0 or 2 time zone transitions per year.
+
+    :param: name
+        The name of a Windows time zone key, e.g. "Eastern Standard Time".
+        The full list of keys can be retrieved with :func:`tzwin.list`.
+    """
+
+    def __init__(self, name):
+        self._name = name
+
+        with winreg.ConnectRegistry(None, winreg.HKEY_LOCAL_MACHINE) as handle:
+            tzkeyname = text_type("{kn}\\{name}").format(kn=TZKEYNAME, name=name)
+            with winreg.OpenKey(handle, tzkeyname) as tzkey:
+                keydict = valuestodict(tzkey)
+
+        self._std_abbr = keydict["Std"]
+        self._dst_abbr = keydict["Dlt"]
+
+        self._display = keydict["Display"]
+
+        # See http://ww_winreg.jsiinc.com/SUBA/tip0300/rh0398.htm
+        tup = struct.unpack("=3l16h", keydict["TZI"])
+        stdoffset = -tup[0]-tup[1]          # Bias + StandardBias * -1
+        dstoffset = stdoffset-tup[2]        # + DaylightBias * -1
+        self._std_offset = datetime.timedelta(minutes=stdoffset)
+        self._dst_offset = datetime.timedelta(minutes=dstoffset)
+
+        # for the meaning see the win32 TIME_ZONE_INFORMATION structure docs
+        # http://msdn.microsoft.com/en-us/library/windows/desktop/ms725481(v=vs.85).aspx
+        (self._stdmonth,
+         self._stddayofweek,   # Sunday = 0
+         self._stdweeknumber,  # Last = 5
+         self._stdhour,
+         self._stdminute) = tup[4:9]
+
+        (self._dstmonth,
+         self._dstdayofweek,   # Sunday = 0
+         self._dstweeknumber,  # Last = 5
+         self._dsthour,
+         self._dstminute) = tup[12:17]
+
+        self._dst_base_offset_ = self._dst_offset - self._std_offset
+        self.hasdst = self._get_hasdst()
+
+    def __repr__(self):
+        return "tzwin(%s)" % repr(self._name)
+
+    def __reduce__(self):
+        return (self.__class__, (self._name,))
+
+
+class tzwinlocal(tzwinbase):
+    """
+    Class representing the local time zone information in the Windows registry
+
+    While :class:`dateutil.tz.tzlocal` makes system calls (via the :mod:`time`
+    module) to retrieve time zone information, ``tzwinlocal`` retrieves the
+    rules directly from the Windows registry and creates an object like
+    :class:`dateutil.tz.tzwin`.
+
+    Because Windows does not have an equivalent of :func:`time.tzset`, on
+    Windows, :class:`dateutil.tz.tzlocal` instances will always reflect the
+    time zone settings *at the time that the process was started*, meaning
+    changes to the machine's time zone settings during the run of a program
+    on Windows will **not** be reflected by :class:`dateutil.tz.tzlocal`.
+    Because ``tzwinlocal`` reads the registry directly, it is unaffected by
+    this issue.
+    """
+    def __init__(self):
+        with winreg.ConnectRegistry(None, winreg.HKEY_LOCAL_MACHINE) as handle:
+            with winreg.OpenKey(handle, TZLOCALKEYNAME) as tzlocalkey:
+                keydict = valuestodict(tzlocalkey)
+
+            self._std_abbr = keydict["StandardName"]
+            self._dst_abbr = keydict["DaylightName"]
+
+            try:
+                tzkeyname = text_type('{kn}\\{sn}').format(kn=TZKEYNAME,
+                                                          sn=self._std_abbr)
+                with winreg.OpenKey(handle, tzkeyname) as tzkey:
+                    _keydict = valuestodict(tzkey)
+                    self._display = _keydict["Display"]
+            except OSError:
+                self._display = None
+
+        stdoffset = -keydict["Bias"]-keydict["StandardBias"]
+        dstoffset = stdoffset-keydict["DaylightBias"]
+
+        self._std_offset = datetime.timedelta(minutes=stdoffset)
+        self._dst_offset = datetime.timedelta(minutes=dstoffset)
+
+        # For reasons unclear, in this particular key, the day of week has been
+        # moved to the END of the SYSTEMTIME structure.
+        tup = struct.unpack("=8h", keydict["StandardStart"])
+
+        (self._stdmonth,
+         self._stdweeknumber,  # Last = 5
+         self._stdhour,
+         self._stdminute) = tup[1:5]
+
+        self._stddayofweek = tup[7]
+
+        tup = struct.unpack("=8h", keydict["DaylightStart"])
+
+        (self._dstmonth,
+         self._dstweeknumber,  # Last = 5
+         self._dsthour,
+         self._dstminute) = tup[1:5]
+
+        self._dstdayofweek = tup[7]
+
+        self._dst_base_offset_ = self._dst_offset - self._std_offset
+        self.hasdst = self._get_hasdst()
+
+    def __repr__(self):
+        return "tzwinlocal()"
+
+    def __str__(self):
+        # str will return the standard name, not the daylight name.
+        return "tzwinlocal(%s)" % repr(self._std_abbr)
+
+    def __reduce__(self):
+        return (self.__class__, ())
+
+
+def picknthweekday(year, month, dayofweek, hour, minute, whichweek):
+    """ dayofweek == 0 means Sunday, whichweek 5 means last instance """
+    first = datetime.datetime(year, month, 1, hour, minute)
+
+    # This will work if dayofweek is ISO weekday (1-7) or Microsoft-style (0-6),
+    # Because 7 % 7 = 0
+    weekdayone = first.replace(day=((dayofweek - first.isoweekday()) % 7) + 1)
+    wd = weekdayone + ((whichweek - 1) * ONEWEEK)
+    if (wd.month != month):
+        wd -= ONEWEEK
+
+    return wd
+
+
+def valuestodict(key):
+    """Convert a registry key's values to a dictionary."""
+    dout = {}
+    size = winreg.QueryInfoKey(key)[1]
+    tz_res = None
+
+    for i in range(size):
+        key_name, value, dtype = winreg.EnumValue(key, i)
+        if dtype == winreg.REG_DWORD or dtype == winreg.REG_DWORD_LITTLE_ENDIAN:
+            # If it's a DWORD (32-bit integer), it's stored as unsigned - convert
+            # that to a proper signed integer
+            if value & (1 << 31):
+                value = value - (1 << 32)
+        elif dtype == winreg.REG_SZ:
+            # If it's a reference to the tzres DLL, load the actual string
+            if value.startswith('@tzres'):
+                tz_res = tz_res or tzres()
+                value = tz_res.name_from_string(value)
+
+            value = value.rstrip('\x00')    # Remove trailing nulls
+
+        dout[key_name] = value
+
+    return dout
Index: latest/Lib/site-packages/psycopg2-2.8.6.dist-info/METADATA
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/latest/Lib/site-packages/psycopg2-2.8.6.dist-info/METADATA b/latest/Lib/site-packages/psycopg2-2.8.6.dist-info/METADATA
new file mode 100644
--- /dev/null	(date 1616410449753)
+++ b/latest/Lib/site-packages/psycopg2-2.8.6.dist-info/METADATA	(date 1616410449753)
@@ -0,0 +1,111 @@
+Metadata-Version: 2.1
+Name: psycopg2
+Version: 2.8.6
+Summary: psycopg2 - Python-PostgreSQL Database Adapter
+Home-page: https://psycopg.org/
+Author: Federico Di Gregorio
+Author-email: fog@initd.org
+Maintainer: Daniele Varrazzo
+Maintainer-email: daniele.varrazzo@gmail.org
+License: LGPL with exceptions
+Project-URL: Homepage, https://psycopg.org/
+Project-URL: Documentation, https://www.psycopg.org/docs/
+Project-URL: Code, https://github.com/psycopg/psycopg2
+Project-URL: Issue Tracker, https://github.com/psycopg/psycopg2/issues
+Project-URL: Download, https://pypi.org/project/psycopg2/
+Platform: any
+Classifier: Development Status :: 5 - Production/Stable
+Classifier: Intended Audience :: Developers
+Classifier: License :: OSI Approved :: GNU Library or Lesser General Public License (LGPL)
+Classifier: Programming Language :: Python
+Classifier: Programming Language :: Python :: 2
+Classifier: Programming Language :: Python :: 2.7
+Classifier: Programming Language :: Python :: 3
+Classifier: Programming Language :: Python :: 3.4
+Classifier: Programming Language :: Python :: 3.5
+Classifier: Programming Language :: Python :: 3.6
+Classifier: Programming Language :: Python :: 3.7
+Classifier: Programming Language :: Python :: 3.8
+Classifier: Programming Language :: Python :: Implementation :: CPython
+Classifier: Programming Language :: C
+Classifier: Programming Language :: SQL
+Classifier: Topic :: Database
+Classifier: Topic :: Database :: Front-Ends
+Classifier: Topic :: Software Development
+Classifier: Topic :: Software Development :: Libraries :: Python Modules
+Classifier: Operating System :: Microsoft :: Windows
+Classifier: Operating System :: Unix
+Requires-Python: >=2.7,!=3.0.*,!=3.1.*,!=3.2.*,!=3.3.*
+
+Psycopg is the most popular PostgreSQL database adapter for the Python
+programming language.  Its main features are the complete implementation of
+the Python DB API 2.0 specification and the thread safety (several threads can
+share the same connection).  It was designed for heavily multi-threaded
+applications that create and destroy lots of cursors and make a large number
+of concurrent "INSERT"s or "UPDATE"s.
+
+Psycopg 2 is mostly implemented in C as a libpq wrapper, resulting in being
+both efficient and secure.  It features client-side and server-side cursors,
+asynchronous communication and notifications, "COPY TO/COPY FROM" support.
+Many Python types are supported out-of-the-box and adapted to matching
+PostgreSQL data types; adaptation can be extended and customized thanks to a
+flexible objects adaptation system.
+
+Psycopg 2 is both Unicode and Python 3 friendly.
+
+
+Documentation
+-------------
+
+Documentation is included in the ``doc`` directory and is `available online`__.
+
+.. __: https://www.psycopg.org/docs/
+
+For any other resource (source code repository, bug tracker, mailing list)
+please check the `project homepage`__.
+
+.. __: https://psycopg.org/
+
+
+Installation
+------------
+
+Building Psycopg requires a few prerequisites (a C compiler, some development
+packages): please check the install_ and the faq_ documents in the ``doc`` dir
+or online for the details.
+
+If prerequisites are met, you can install psycopg like any other Python
+package, using ``pip`` to download it from PyPI_::
+
+    $ pip install psycopg2
+
+or using ``setup.py`` if you have downloaded the source package locally::
+
+    $ python setup.py build
+    $ sudo python setup.py install
+
+You can also obtain a stand-alone package, not requiring a compiler or
+external libraries, by installing the `psycopg2-binary`_ package from PyPI::
+
+    $ pip install psycopg2-binary
+
+The binary package is a practical choice for development and testing but in
+production it is advised to use the package built from sources.
+
+.. _PyPI: https://pypi.org/project/psycopg2/
+.. _psycopg2-binary: https://pypi.org/project/psycopg2-binary/
+.. _install: https://www.psycopg.org/docs/install.html#install-from-source
+.. _faq: https://www.psycopg.org/docs/faq.html#faq-compile
+
+:Linux/OSX: |travis|
+:Windows: |appveyor|
+
+.. |travis| image:: https://travis-ci.org/psycopg/psycopg2.svg?branch=master
+    :target: https://travis-ci.org/psycopg/psycopg2
+    :alt: Linux and OSX build status
+
+.. |appveyor| image:: https://ci.appveyor.com/api/projects/status/github/psycopg/psycopg2?branch=master&svg=true
+    :target: https://ci.appveyor.com/project/psycopg/psycopg2/branch/master
+    :alt: Windows build status
+
+
Index: venv/Lib/site-packages/dateutil/tz/_common.py
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/venv/Lib/site-packages/dateutil/tz/_common.py b/venv/Lib/site-packages/dateutil/tz/_common.py
new file mode 100644
--- /dev/null	(date 1616410449808)
+++ b/venv/Lib/site-packages/dateutil/tz/_common.py	(date 1616410449808)
@@ -0,0 +1,419 @@
+from six import PY2
+
+from functools import wraps
+
+from datetime import datetime, timedelta, tzinfo
+
+
+ZERO = timedelta(0)
+
+__all__ = ['tzname_in_python2', 'enfold']
+
+
+def tzname_in_python2(namefunc):
+    """Change unicode output into bytestrings in Python 2
+
+    tzname() API changed in Python 3. It used to return bytes, but was changed
+    to unicode strings
+    """
+    if PY2:
+        @wraps(namefunc)
+        def adjust_encoding(*args, **kwargs):
+            name = namefunc(*args, **kwargs)
+            if name is not None:
+                name = name.encode()
+
+            return name
+
+        return adjust_encoding
+    else:
+        return namefunc
+
+
+# The following is adapted from Alexander Belopolsky's tz library
+# https://github.com/abalkin/tz
+if hasattr(datetime, 'fold'):
+    # This is the pre-python 3.6 fold situation
+    def enfold(dt, fold=1):
+        """
+        Provides a unified interface for assigning the ``fold`` attribute to
+        datetimes both before and after the implementation of PEP-495.
+
+        :param fold:
+            The value for the ``fold`` attribute in the returned datetime. This
+            should be either 0 or 1.
+
+        :return:
+            Returns an object for which ``getattr(dt, 'fold', 0)`` returns
+            ``fold`` for all versions of Python. In versions prior to
+            Python 3.6, this is a ``_DatetimeWithFold`` object, which is a
+            subclass of :py:class:`datetime.datetime` with the ``fold``
+            attribute added, if ``fold`` is 1.
+
+        .. versionadded:: 2.6.0
+        """
+        return dt.replace(fold=fold)
+
+else:
+    class _DatetimeWithFold(datetime):
+        """
+        This is a class designed to provide a PEP 495-compliant interface for
+        Python versions before 3.6. It is used only for dates in a fold, so
+        the ``fold`` attribute is fixed at ``1``.
+
+        .. versionadded:: 2.6.0
+        """
+        __slots__ = ()
+
+        def replace(self, *args, **kwargs):
+            """
+            Return a datetime with the same attributes, except for those
+            attributes given new values by whichever keyword arguments are
+            specified. Note that tzinfo=None can be specified to create a naive
+            datetime from an aware datetime with no conversion of date and time
+            data.
+
+            This is reimplemented in ``_DatetimeWithFold`` because pypy3 will
+            return a ``datetime.datetime`` even if ``fold`` is unchanged.
+            """
+            argnames = (
+                'year', 'month', 'day', 'hour', 'minute', 'second',
+                'microsecond', 'tzinfo'
+            )
+
+            for arg, argname in zip(args, argnames):
+                if argname in kwargs:
+                    raise TypeError('Duplicate argument: {}'.format(argname))
+
+                kwargs[argname] = arg
+
+            for argname in argnames:
+                if argname not in kwargs:
+                    kwargs[argname] = getattr(self, argname)
+
+            dt_class = self.__class__ if kwargs.get('fold', 1) else datetime
+
+            return dt_class(**kwargs)
+
+        @property
+        def fold(self):
+            return 1
+
+    def enfold(dt, fold=1):
+        """
+        Provides a unified interface for assigning the ``fold`` attribute to
+        datetimes both before and after the implementation of PEP-495.
+
+        :param fold:
+            The value for the ``fold`` attribute in the returned datetime. This
+            should be either 0 or 1.
+
+        :return:
+            Returns an object for which ``getattr(dt, 'fold', 0)`` returns
+            ``fold`` for all versions of Python. In versions prior to
+            Python 3.6, this is a ``_DatetimeWithFold`` object, which is a
+            subclass of :py:class:`datetime.datetime` with the ``fold``
+            attribute added, if ``fold`` is 1.
+
+        .. versionadded:: 2.6.0
+        """
+        if getattr(dt, 'fold', 0) == fold:
+            return dt
+
+        args = dt.timetuple()[:6]
+        args += (dt.microsecond, dt.tzinfo)
+
+        if fold:
+            return _DatetimeWithFold(*args)
+        else:
+            return datetime(*args)
+
+
+def _validate_fromutc_inputs(f):
+    """
+    The CPython version of ``fromutc`` checks that the input is a ``datetime``
+    object and that ``self`` is attached as its ``tzinfo``.
+    """
+    @wraps(f)
+    def fromutc(self, dt):
+        if not isinstance(dt, datetime):
+            raise TypeError("fromutc() requires a datetime argument")
+        if dt.tzinfo is not self:
+            raise ValueError("dt.tzinfo is not self")
+
+        return f(self, dt)
+
+    return fromutc
+
+
+class _tzinfo(tzinfo):
+    """
+    Base class for all ``dateutil`` ``tzinfo`` objects.
+    """
+
+    def is_ambiguous(self, dt):
+        """
+        Whether or not the "wall time" of a given datetime is ambiguous in this
+        zone.
+
+        :param dt:
+            A :py:class:`datetime.datetime`, naive or time zone aware.
+
+
+        :return:
+            Returns ``True`` if ambiguous, ``False`` otherwise.
+
+        .. versionadded:: 2.6.0
+        """
+
+        dt = dt.replace(tzinfo=self)
+
+        wall_0 = enfold(dt, fold=0)
+        wall_1 = enfold(dt, fold=1)
+
+        same_offset = wall_0.utcoffset() == wall_1.utcoffset()
+        same_dt = wall_0.replace(tzinfo=None) == wall_1.replace(tzinfo=None)
+
+        return same_dt and not same_offset
+
+    def _fold_status(self, dt_utc, dt_wall):
+        """
+        Determine the fold status of a "wall" datetime, given a representation
+        of the same datetime as a (naive) UTC datetime. This is calculated based
+        on the assumption that ``dt.utcoffset() - dt.dst()`` is constant for all
+        datetimes, and that this offset is the actual number of hours separating
+        ``dt_utc`` and ``dt_wall``.
+
+        :param dt_utc:
+            Representation of the datetime as UTC
+
+        :param dt_wall:
+            Representation of the datetime as "wall time". This parameter must
+            either have a `fold` attribute or have a fold-naive
+            :class:`datetime.tzinfo` attached, otherwise the calculation may
+            fail.
+        """
+        if self.is_ambiguous(dt_wall):
+            delta_wall = dt_wall - dt_utc
+            _fold = int(delta_wall == (dt_utc.utcoffset() - dt_utc.dst()))
+        else:
+            _fold = 0
+
+        return _fold
+
+    def _fold(self, dt):
+        return getattr(dt, 'fold', 0)
+
+    def _fromutc(self, dt):
+        """
+        Given a timezone-aware datetime in a given timezone, calculates a
+        timezone-aware datetime in a new timezone.
+
+        Since this is the one time that we *know* we have an unambiguous
+        datetime object, we take this opportunity to determine whether the
+        datetime is ambiguous and in a "fold" state (e.g. if it's the first
+        occurrence, chronologically, of the ambiguous datetime).
+
+        :param dt:
+            A timezone-aware :class:`datetime.datetime` object.
+        """
+
+        # Re-implement the algorithm from Python's datetime.py
+        dtoff = dt.utcoffset()
+        if dtoff is None:
+            raise ValueError("fromutc() requires a non-None utcoffset() "
+                             "result")
+
+        # The original datetime.py code assumes that `dst()` defaults to
+        # zero during ambiguous times. PEP 495 inverts this presumption, so
+        # for pre-PEP 495 versions of python, we need to tweak the algorithm.
+        dtdst = dt.dst()
+        if dtdst is None:
+            raise ValueError("fromutc() requires a non-None dst() result")
+        delta = dtoff - dtdst
+
+        dt += delta
+        # Set fold=1 so we can default to being in the fold for
+        # ambiguous dates.
+        dtdst = enfold(dt, fold=1).dst()
+        if dtdst is None:
+            raise ValueError("fromutc(): dt.dst gave inconsistent "
+                             "results; cannot convert")
+        return dt + dtdst
+
+    @_validate_fromutc_inputs
+    def fromutc(self, dt):
+        """
+        Given a timezone-aware datetime in a given timezone, calculates a
+        timezone-aware datetime in a new timezone.
+
+        Since this is the one time that we *know* we have an unambiguous
+        datetime object, we take this opportunity to determine whether the
+        datetime is ambiguous and in a "fold" state (e.g. if it's the first
+        occurrence, chronologically, of the ambiguous datetime).
+
+        :param dt:
+            A timezone-aware :class:`datetime.datetime` object.
+        """
+        dt_wall = self._fromutc(dt)
+
+        # Calculate the fold status given the two datetimes.
+        _fold = self._fold_status(dt, dt_wall)
+
+        # Set the default fold value for ambiguous dates
+        return enfold(dt_wall, fold=_fold)
+
+
+class tzrangebase(_tzinfo):
+    """
+    This is an abstract base class for time zones represented by an annual
+    transition into and out of DST. Child classes should implement the following
+    methods:
+
+        * ``__init__(self, *args, **kwargs)``
+        * ``transitions(self, year)`` - this is expected to return a tuple of
+          datetimes representing the DST on and off transitions in standard
+          time.
+
+    A fully initialized ``tzrangebase`` subclass should also provide the
+    following attributes:
+        * ``hasdst``: Boolean whether or not the zone uses DST.
+        * ``_dst_offset`` / ``_std_offset``: :class:`datetime.timedelta` objects
+          representing the respective UTC offsets.
+        * ``_dst_abbr`` / ``_std_abbr``: Strings representing the timezone short
+          abbreviations in DST and STD, respectively.
+        * ``_hasdst``: Whether or not the zone has DST.
+
+    .. versionadded:: 2.6.0
+    """
+    def __init__(self):
+        raise NotImplementedError('tzrangebase is an abstract base class')
+
+    def utcoffset(self, dt):
+        isdst = self._isdst(dt)
+
+        if isdst is None:
+            return None
+        elif isdst:
+            return self._dst_offset
+        else:
+            return self._std_offset
+
+    def dst(self, dt):
+        isdst = self._isdst(dt)
+
+        if isdst is None:
+            return None
+        elif isdst:
+            return self._dst_base_offset
+        else:
+            return ZERO
+
+    @tzname_in_python2
+    def tzname(self, dt):
+        if self._isdst(dt):
+            return self._dst_abbr
+        else:
+            return self._std_abbr
+
+    def fromutc(self, dt):
+        """ Given a datetime in UTC, return local time """
+        if not isinstance(dt, datetime):
+            raise TypeError("fromutc() requires a datetime argument")
+
+        if dt.tzinfo is not self:
+            raise ValueError("dt.tzinfo is not self")
+
+        # Get transitions - if there are none, fixed offset
+        transitions = self.transitions(dt.year)
+        if transitions is None:
+            return dt + self.utcoffset(dt)
+
+        # Get the transition times in UTC
+        dston, dstoff = transitions
+
+        dston -= self._std_offset
+        dstoff -= self._std_offset
+
+        utc_transitions = (dston, dstoff)
+        dt_utc = dt.replace(tzinfo=None)
+
+        isdst = self._naive_isdst(dt_utc, utc_transitions)
+
+        if isdst:
+            dt_wall = dt + self._dst_offset
+        else:
+            dt_wall = dt + self._std_offset
+
+        _fold = int(not isdst and self.is_ambiguous(dt_wall))
+
+        return enfold(dt_wall, fold=_fold)
+
+    def is_ambiguous(self, dt):
+        """
+        Whether or not the "wall time" of a given datetime is ambiguous in this
+        zone.
+
+        :param dt:
+            A :py:class:`datetime.datetime`, naive or time zone aware.
+
+
+        :return:
+            Returns ``True`` if ambiguous, ``False`` otherwise.
+
+        .. versionadded:: 2.6.0
+        """
+        if not self.hasdst:
+            return False
+
+        start, end = self.transitions(dt.year)
+
+        dt = dt.replace(tzinfo=None)
+        return (end <= dt < end + self._dst_base_offset)
+
+    def _isdst(self, dt):
+        if not self.hasdst:
+            return False
+        elif dt is None:
+            return None
+
+        transitions = self.transitions(dt.year)
+
+        if transitions is None:
+            return False
+
+        dt = dt.replace(tzinfo=None)
+
+        isdst = self._naive_isdst(dt, transitions)
+
+        # Handle ambiguous dates
+        if not isdst and self.is_ambiguous(dt):
+            return not self._fold(dt)
+        else:
+            return isdst
+
+    def _naive_isdst(self, dt, transitions):
+        dston, dstoff = transitions
+
+        dt = dt.replace(tzinfo=None)
+
+        if dston < dstoff:
+            isdst = dston <= dt < dstoff
+        else:
+            isdst = not dstoff <= dt < dston
+
+        return isdst
+
+    @property
+    def _dst_base_offset(self):
+        return self._dst_offset - self._std_offset
+
+    __hash__ = None
+
+    def __ne__(self, other):
+        return not (self == other)
+
+    def __repr__(self):
+        return "%s(...)" % self.__class__.__name__
+
+    __reduce__ = object.__reduce__
Index: latest/Lib/site-packages/psycopg2-2.8.6.dist-info/RECORD
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/latest/Lib/site-packages/psycopg2-2.8.6.dist-info/RECORD b/latest/Lib/site-packages/psycopg2-2.8.6.dist-info/RECORD
new file mode 100644
--- /dev/null	(date 1616410449816)
+++ b/latest/Lib/site-packages/psycopg2-2.8.6.dist-info/RECORD	(date 1616410449816)
@@ -0,0 +1,34 @@
+psycopg2-2.8.6.dist-info/INSTALLER,sha256=zuuue4knoyJ-UwPPXg8fezS7VCrXJQrAP7zeNuwvFQg,4
+psycopg2-2.8.6.dist-info/LICENSE,sha256=lhS4XfyacsWyyjMUTB1-HtOxwpdFnZ-yimpXYsLo1xs,2238
+psycopg2-2.8.6.dist-info/METADATA,sha256=htTa9QsaWzb-w-SRFJ9QVhgvA_61CejAgm6mNwAzTLA,4389
+psycopg2-2.8.6.dist-info/RECORD,,
+psycopg2-2.8.6.dist-info/REQUESTED,sha256=47DEQpj8HBSa-_TImW-5JCeuQeRkm5NMpJWZG3hSuFU,0
+psycopg2-2.8.6.dist-info/WHEEL,sha256=2Kg4PzfJLrLEnxRV1e1jZf0TVEjxVcXZXjp8WtjE4tI,105
+psycopg2-2.8.6.dist-info/top_level.txt,sha256=7dHGpLqQ3w-vGmGEVn-7uK90qU9fyrGdWWi7S-gTcnM,9
+psycopg2/__init__.py,sha256=f1RIT_o7T7LU9OYn1RAbbGvOZFv1S0y3250h6nuKoSQ,4916
+psycopg2/__pycache__/__init__.cpython-39.pyc,,
+psycopg2/__pycache__/_ipaddress.cpython-39.pyc,,
+psycopg2/__pycache__/_json.cpython-39.pyc,,
+psycopg2/__pycache__/_lru_cache.cpython-39.pyc,,
+psycopg2/__pycache__/_range.cpython-39.pyc,,
+psycopg2/__pycache__/compat.cpython-39.pyc,,
+psycopg2/__pycache__/errorcodes.cpython-39.pyc,,
+psycopg2/__pycache__/errors.cpython-39.pyc,,
+psycopg2/__pycache__/extensions.cpython-39.pyc,,
+psycopg2/__pycache__/extras.cpython-39.pyc,,
+psycopg2/__pycache__/pool.cpython-39.pyc,,
+psycopg2/__pycache__/sql.cpython-39.pyc,,
+psycopg2/__pycache__/tz.cpython-39.pyc,,
+psycopg2/_ipaddress.py,sha256=VTb0XXYHHhwdAgFwGt8mGQvPzcVCah2XVSNYlpW5AzI,2967
+psycopg2/_json.py,sha256=IRUpp3zIdrhw7cv5PdoXHsjEGHBeW9-vArKpxY9R7IU,7296
+psycopg2/_lru_cache.py,sha256=DhDTMD9aQsMcLYHyg8bAunlh62TKljZ6bLAlWd5tTrc,4261
+psycopg2/_psycopg.cp39-win_amd64.pyd,sha256=w81tneSq1KkgboGjXJAKqGhNU2gWgNl5dlxuZ7-YNEc,2399744
+psycopg2/_range.py,sha256=XsuiPZ-6mf9W8vxlBsp7zqwKOQPCac_vLVvEyPhthA4,17705
+psycopg2/compat.py,sha256=YAozNHFrE--nrjvV-g4kHPLbcmhOKVGVN84zo58VOqA,367
+psycopg2/errorcodes.py,sha256=MRcquTgL_7iTmk8x47MA6KM5Z1-MK0trPZc5KZCnxTQ,14273
+psycopg2/errors.py,sha256=iaaJeyL2pU9oMt9MsLaNlOPZipR0BXL0kOKABV2Tu_g,1420
+psycopg2/extensions.py,sha256=T99Lv2oAYC_pjSuYDNVj2xVmWz9gO_S4KmnUEbZcCHs,7122
+psycopg2/extras.py,sha256=pGt1UJdZkVaXDWjXz21kP7JEqEH0ER5FhemiOTmkXNw,44182
+psycopg2/pool.py,sha256=NdulUZrkF2h-Nv_hOX5RXUz6WeiL0WCnbIkxIgAMjPM,6319
+psycopg2/sql.py,sha256=RL1AGbpT5xzzVRNYxpeGbgMUojpkyqzwTZK1PNZUwWY,14903
+psycopg2/tz.py,sha256=_DahbM5JJtkiFzVyyhNWX2RbjDUTASd4xDWVGQAGP-c,4446
Index: venv/Lib/site-packages/dateutil/tz/_factories.py
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/venv/Lib/site-packages/dateutil/tz/_factories.py b/venv/Lib/site-packages/dateutil/tz/_factories.py
new file mode 100644
--- /dev/null	(date 1616410449844)
+++ b/venv/Lib/site-packages/dateutil/tz/_factories.py	(date 1616410449844)
@@ -0,0 +1,80 @@
+from datetime import timedelta
+import weakref
+from collections import OrderedDict
+
+from six.moves import _thread
+
+
+class _TzSingleton(type):
+    def __init__(cls, *args, **kwargs):
+        cls.__instance = None
+        super(_TzSingleton, cls).__init__(*args, **kwargs)
+
+    def __call__(cls):
+        if cls.__instance is None:
+            cls.__instance = super(_TzSingleton, cls).__call__()
+        return cls.__instance
+
+
+class _TzFactory(type):
+    def instance(cls, *args, **kwargs):
+        """Alternate constructor that returns a fresh instance"""
+        return type.__call__(cls, *args, **kwargs)
+
+
+class _TzOffsetFactory(_TzFactory):
+    def __init__(cls, *args, **kwargs):
+        cls.__instances = weakref.WeakValueDictionary()
+        cls.__strong_cache = OrderedDict()
+        cls.__strong_cache_size = 8
+
+        cls._cache_lock = _thread.allocate_lock()
+
+    def __call__(cls, name, offset):
+        if isinstance(offset, timedelta):
+            key = (name, offset.total_seconds())
+        else:
+            key = (name, offset)
+
+        instance = cls.__instances.get(key, None)
+        if instance is None:
+            instance = cls.__instances.setdefault(key,
+                                                  cls.instance(name, offset))
+
+        # This lock may not be necessary in Python 3. See GH issue #901
+        with cls._cache_lock:
+            cls.__strong_cache[key] = cls.__strong_cache.pop(key, instance)
+
+            # Remove an item if the strong cache is overpopulated
+            if len(cls.__strong_cache) > cls.__strong_cache_size:
+                cls.__strong_cache.popitem(last=False)
+
+        return instance
+
+
+class _TzStrFactory(_TzFactory):
+    def __init__(cls, *args, **kwargs):
+        cls.__instances = weakref.WeakValueDictionary()
+        cls.__strong_cache = OrderedDict()
+        cls.__strong_cache_size = 8
+
+        cls.__cache_lock = _thread.allocate_lock()
+
+    def __call__(cls, s, posix_offset=False):
+        key = (s, posix_offset)
+        instance = cls.__instances.get(key, None)
+
+        if instance is None:
+            instance = cls.__instances.setdefault(key,
+                cls.instance(s, posix_offset))
+
+        # This lock may not be necessary in Python 3. See GH issue #901
+        with cls.__cache_lock:
+            cls.__strong_cache[key] = cls.__strong_cache.pop(key, instance)
+
+            # Remove an item if the strong cache is overpopulated
+            if len(cls.__strong_cache) > cls.__strong_cache_size:
+                cls.__strong_cache.popitem(last=False)
+
+        return instance
+
Index: venv/Lib/site-packages/dateutil/tz/__init__.py
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/venv/Lib/site-packages/dateutil/tz/__init__.py b/venv/Lib/site-packages/dateutil/tz/__init__.py
new file mode 100644
--- /dev/null	(date 1616410450050)
+++ b/venv/Lib/site-packages/dateutil/tz/__init__.py	(date 1616410450050)
@@ -0,0 +1,12 @@
+# -*- coding: utf-8 -*-
+from .tz import *
+from .tz import __doc__
+
+__all__ = ["tzutc", "tzoffset", "tzlocal", "tzfile", "tzrange",
+           "tzstr", "tzical", "tzwin", "tzwinlocal", "gettz",
+           "enfold", "datetime_ambiguous", "datetime_exists",
+           "resolve_imaginary", "UTC", "DeprecatedTzFormatWarning"]
+
+
+class DeprecatedTzFormatWarning(Warning):
+    """Warning raised when time zones are parsed from deprecated formats."""
Index: latest/Lib/site-packages/psycopg2-2.8.6.dist-info/top_level.txt
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/latest/Lib/site-packages/psycopg2-2.8.6.dist-info/top_level.txt b/latest/Lib/site-packages/psycopg2-2.8.6.dist-info/top_level.txt
new file mode 100644
--- /dev/null	(date 1616410450128)
+++ b/latest/Lib/site-packages/psycopg2-2.8.6.dist-info/top_level.txt	(date 1616410450128)
@@ -0,0 +1,1 @@
+psycopg2
Index: latest/Lib/site-packages/psycopg2-2.8.6.dist-info/WHEEL
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/latest/Lib/site-packages/psycopg2-2.8.6.dist-info/WHEEL b/latest/Lib/site-packages/psycopg2-2.8.6.dist-info/WHEEL
new file mode 100644
--- /dev/null	(date 1616410450175)
+++ b/latest/Lib/site-packages/psycopg2-2.8.6.dist-info/WHEEL	(date 1616410450175)
@@ -0,0 +1,5 @@
+Wheel-Version: 1.0
+Generator: bdist_wheel (0.35.1)
+Root-Is-Purelib: false
+Tag: cp39-cp39-win_amd64
+
Index: venv/Lib/site-packages/dateutil/parser/isoparser.py
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/venv/Lib/site-packages/dateutil/parser/isoparser.py b/venv/Lib/site-packages/dateutil/parser/isoparser.py
new file mode 100644
--- /dev/null	(date 1616410450237)
+++ b/venv/Lib/site-packages/dateutil/parser/isoparser.py	(date 1616410450237)
@@ -0,0 +1,411 @@
+# -*- coding: utf-8 -*-
+"""
+This module offers a parser for ISO-8601 strings
+
+It is intended to support all valid date, time and datetime formats per the
+ISO-8601 specification.
+
+..versionadded:: 2.7.0
+"""
+from datetime import datetime, timedelta, time, date
+import calendar
+from dateutil import tz
+
+from functools import wraps
+
+import re
+import six
+
+__all__ = ["isoparse", "isoparser"]
+
+
+def _takes_ascii(f):
+    @wraps(f)
+    def func(self, str_in, *args, **kwargs):
+        # If it's a stream, read the whole thing
+        str_in = getattr(str_in, 'read', lambda: str_in)()
+
+        # If it's unicode, turn it into bytes, since ISO-8601 only covers ASCII
+        if isinstance(str_in, six.text_type):
+            # ASCII is the same in UTF-8
+            try:
+                str_in = str_in.encode('ascii')
+            except UnicodeEncodeError as e:
+                msg = 'ISO-8601 strings should contain only ASCII characters'
+                six.raise_from(ValueError(msg), e)
+
+        return f(self, str_in, *args, **kwargs)
+
+    return func
+
+
+class isoparser(object):
+    def __init__(self, sep=None):
+        """
+        :param sep:
+            A single character that separates date and time portions. If
+            ``None``, the parser will accept any single character.
+            For strict ISO-8601 adherence, pass ``'T'``.
+        """
+        if sep is not None:
+            if (len(sep) != 1 or ord(sep) >= 128 or sep in '0123456789'):
+                raise ValueError('Separator must be a single, non-numeric ' +
+                                 'ASCII character')
+
+            sep = sep.encode('ascii')
+
+        self._sep = sep
+
+    @_takes_ascii
+    def isoparse(self, dt_str):
+        """
+        Parse an ISO-8601 datetime string into a :class:`datetime.datetime`.
+
+        An ISO-8601 datetime string consists of a date portion, followed
+        optionally by a time portion - the date and time portions are separated
+        by a single character separator, which is ``T`` in the official
+        standard. Incomplete date formats (such as ``YYYY-MM``) may *not* be
+        combined with a time portion.
+
+        Supported date formats are:
+
+        Common:
+
+        - ``YYYY``
+        - ``YYYY-MM`` or ``YYYYMM``
+        - ``YYYY-MM-DD`` or ``YYYYMMDD``
+
+        Uncommon:
+
+        - ``YYYY-Www`` or ``YYYYWww`` - ISO week (day defaults to 0)
+        - ``YYYY-Www-D`` or ``YYYYWwwD`` - ISO week and day
+
+        The ISO week and day numbering follows the same logic as
+        :func:`datetime.date.isocalendar`.
+
+        Supported time formats are:
+
+        - ``hh``
+        - ``hh:mm`` or ``hhmm``
+        - ``hh:mm:ss`` or ``hhmmss``
+        - ``hh:mm:ss.ssssss`` (Up to 6 sub-second digits)
+
+        Midnight is a special case for `hh`, as the standard supports both
+        00:00 and 24:00 as a representation. The decimal separator can be
+        either a dot or a comma.
+
+
+        .. caution::
+
+            Support for fractional components other than seconds is part of the
+            ISO-8601 standard, but is not currently implemented in this parser.
+
+        Supported time zone offset formats are:
+
+        - `Z` (UTC)
+        - `±HH:MM`
+        - `±HHMM`
+        - `±HH`
+
+        Offsets will be represented as :class:`dateutil.tz.tzoffset` objects,
+        with the exception of UTC, which will be represented as
+        :class:`dateutil.tz.tzutc`. Time zone offsets equivalent to UTC (such
+        as `+00:00`) will also be represented as :class:`dateutil.tz.tzutc`.
+
+        :param dt_str:
+            A string or stream containing only an ISO-8601 datetime string
+
+        :return:
+            Returns a :class:`datetime.datetime` representing the string.
+            Unspecified components default to their lowest value.
+
+        .. warning::
+
+            As of version 2.7.0, the strictness of the parser should not be
+            considered a stable part of the contract. Any valid ISO-8601 string
+            that parses correctly with the default settings will continue to
+            parse correctly in future versions, but invalid strings that
+            currently fail (e.g. ``2017-01-01T00:00+00:00:00``) are not
+            guaranteed to continue failing in future versions if they encode
+            a valid date.
+
+        .. versionadded:: 2.7.0
+        """
+        components, pos = self._parse_isodate(dt_str)
+
+        if len(dt_str) > pos:
+            if self._sep is None or dt_str[pos:pos + 1] == self._sep:
+                components += self._parse_isotime(dt_str[pos + 1:])
+            else:
+                raise ValueError('String contains unknown ISO components')
+
+        if len(components) > 3 and components[3] == 24:
+            components[3] = 0
+            return datetime(*components) + timedelta(days=1)
+
+        return datetime(*components)
+
+    @_takes_ascii
+    def parse_isodate(self, datestr):
+        """
+        Parse the date portion of an ISO string.
+
+        :param datestr:
+            The string portion of an ISO string, without a separator
+
+        :return:
+            Returns a :class:`datetime.date` object
+        """
+        components, pos = self._parse_isodate(datestr)
+        if pos < len(datestr):
+            raise ValueError('String contains unknown ISO ' +
+                             'components: {}'.format(datestr))
+        return date(*components)
+
+    @_takes_ascii
+    def parse_isotime(self, timestr):
+        """
+        Parse the time portion of an ISO string.
+
+        :param timestr:
+            The time portion of an ISO string, without a separator
+
+        :return:
+            Returns a :class:`datetime.time` object
+        """
+        components = self._parse_isotime(timestr)
+        if components[0] == 24:
+            components[0] = 0
+        return time(*components)
+
+    @_takes_ascii
+    def parse_tzstr(self, tzstr, zero_as_utc=True):
+        """
+        Parse a valid ISO time zone string.
+
+        See :func:`isoparser.isoparse` for details on supported formats.
+
+        :param tzstr:
+            A string representing an ISO time zone offset
+
+        :param zero_as_utc:
+            Whether to return :class:`dateutil.tz.tzutc` for zero-offset zones
+
+        :return:
+            Returns :class:`dateutil.tz.tzoffset` for offsets and
+            :class:`dateutil.tz.tzutc` for ``Z`` and (if ``zero_as_utc`` is
+            specified) offsets equivalent to UTC.
+        """
+        return self._parse_tzstr(tzstr, zero_as_utc=zero_as_utc)
+
+    # Constants
+    _DATE_SEP = b'-'
+    _TIME_SEP = b':'
+    _FRACTION_REGEX = re.compile(b'[\\.,]([0-9]+)')
+
+    def _parse_isodate(self, dt_str):
+        try:
+            return self._parse_isodate_common(dt_str)
+        except ValueError:
+            return self._parse_isodate_uncommon(dt_str)
+
+    def _parse_isodate_common(self, dt_str):
+        len_str = len(dt_str)
+        components = [1, 1, 1]
+
+        if len_str < 4:
+            raise ValueError('ISO string too short')
+
+        # Year
+        components[0] = int(dt_str[0:4])
+        pos = 4
+        if pos >= len_str:
+            return components, pos
+
+        has_sep = dt_str[pos:pos + 1] == self._DATE_SEP
+        if has_sep:
+            pos += 1
+
+        # Month
+        if len_str - pos < 2:
+            raise ValueError('Invalid common month')
+
+        components[1] = int(dt_str[pos:pos + 2])
+        pos += 2
+
+        if pos >= len_str:
+            if has_sep:
+                return components, pos
+            else:
+                raise ValueError('Invalid ISO format')
+
+        if has_sep:
+            if dt_str[pos:pos + 1] != self._DATE_SEP:
+                raise ValueError('Invalid separator in ISO string')
+            pos += 1
+
+        # Day
+        if len_str - pos < 2:
+            raise ValueError('Invalid common day')
+        components[2] = int(dt_str[pos:pos + 2])
+        return components, pos + 2
+
+    def _parse_isodate_uncommon(self, dt_str):
+        if len(dt_str) < 4:
+            raise ValueError('ISO string too short')
+
+        # All ISO formats start with the year
+        year = int(dt_str[0:4])
+
+        has_sep = dt_str[4:5] == self._DATE_SEP
+
+        pos = 4 + has_sep       # Skip '-' if it's there
+        if dt_str[pos:pos + 1] == b'W':
+            # YYYY-?Www-?D?
+            pos += 1
+            weekno = int(dt_str[pos:pos + 2])
+            pos += 2
+
+            dayno = 1
+            if len(dt_str) > pos:
+                if (dt_str[pos:pos + 1] == self._DATE_SEP) != has_sep:
+                    raise ValueError('Inconsistent use of dash separator')
+
+                pos += has_sep
+
+                dayno = int(dt_str[pos:pos + 1])
+                pos += 1
+
+            base_date = self._calculate_weekdate(year, weekno, dayno)
+        else:
+            # YYYYDDD or YYYY-DDD
+            if len(dt_str) - pos < 3:
+                raise ValueError('Invalid ordinal day')
+
+            ordinal_day = int(dt_str[pos:pos + 3])
+            pos += 3
+
+            if ordinal_day < 1 or ordinal_day > (365 + calendar.isleap(year)):
+                raise ValueError('Invalid ordinal day' +
+                                 ' {} for year {}'.format(ordinal_day, year))
+
+            base_date = date(year, 1, 1) + timedelta(days=ordinal_day - 1)
+
+        components = [base_date.year, base_date.month, base_date.day]
+        return components, pos
+
+    def _calculate_weekdate(self, year, week, day):
+        """
+        Calculate the day of corresponding to the ISO year-week-day calendar.
+
+        This function is effectively the inverse of
+        :func:`datetime.date.isocalendar`.
+
+        :param year:
+            The year in the ISO calendar
+
+        :param week:
+            The week in the ISO calendar - range is [1, 53]
+
+        :param day:
+            The day in the ISO calendar - range is [1 (MON), 7 (SUN)]
+
+        :return:
+            Returns a :class:`datetime.date`
+        """
+        if not 0 < week < 54:
+            raise ValueError('Invalid week: {}'.format(week))
+
+        if not 0 < day < 8:     # Range is 1-7
+            raise ValueError('Invalid weekday: {}'.format(day))
+
+        # Get week 1 for the specific year:
+        jan_4 = date(year, 1, 4)   # Week 1 always has January 4th in it
+        week_1 = jan_4 - timedelta(days=jan_4.isocalendar()[2] - 1)
+
+        # Now add the specific number of weeks and days to get what we want
+        week_offset = (week - 1) * 7 + (day - 1)
+        return week_1 + timedelta(days=week_offset)
+
+    def _parse_isotime(self, timestr):
+        len_str = len(timestr)
+        components = [0, 0, 0, 0, None]
+        pos = 0
+        comp = -1
+
+        if len(timestr) < 2:
+            raise ValueError('ISO time too short')
+
+        has_sep = len_str >= 3 and timestr[2:3] == self._TIME_SEP
+
+        while pos < len_str and comp < 5:
+            comp += 1
+
+            if timestr[pos:pos + 1] in b'-+Zz':
+                # Detect time zone boundary
+                components[-1] = self._parse_tzstr(timestr[pos:])
+                pos = len_str
+                break
+
+            if comp < 3:
+                # Hour, minute, second
+                components[comp] = int(timestr[pos:pos + 2])
+                pos += 2
+                if (has_sep and pos < len_str and
+                        timestr[pos:pos + 1] == self._TIME_SEP):
+                    pos += 1
+
+            if comp == 3:
+                # Fraction of a second
+                frac = self._FRACTION_REGEX.match(timestr[pos:])
+                if not frac:
+                    continue
+
+                us_str = frac.group(1)[:6]  # Truncate to microseconds
+                components[comp] = int(us_str) * 10**(6 - len(us_str))
+                pos += len(frac.group())
+
+        if pos < len_str:
+            raise ValueError('Unused components in ISO string')
+
+        if components[0] == 24:
+            # Standard supports 00:00 and 24:00 as representations of midnight
+            if any(component != 0 for component in components[1:4]):
+                raise ValueError('Hour may only be 24 at 24:00:00.000')
+
+        return components
+
+    def _parse_tzstr(self, tzstr, zero_as_utc=True):
+        if tzstr == b'Z' or tzstr == b'z':
+            return tz.UTC
+
+        if len(tzstr) not in {3, 5, 6}:
+            raise ValueError('Time zone offset must be 1, 3, 5 or 6 characters')
+
+        if tzstr[0:1] == b'-':
+            mult = -1
+        elif tzstr[0:1] == b'+':
+            mult = 1
+        else:
+            raise ValueError('Time zone offset requires sign')
+
+        hours = int(tzstr[1:3])
+        if len(tzstr) == 3:
+            minutes = 0
+        else:
+            minutes = int(tzstr[(4 if tzstr[3:4] == self._TIME_SEP else 3):])
+
+        if zero_as_utc and hours == 0 and minutes == 0:
+            return tz.UTC
+        else:
+            if minutes > 59:
+                raise ValueError('Invalid minutes in time zone offset')
+
+            if hours > 23:
+                raise ValueError('Invalid hours in time zone offset')
+
+            return tz.tzoffset(None, mult * (hours * 60 + minutes) * 60)
+
+
+DEFAULT_ISOPARSER = isoparser()
+isoparse = DEFAULT_ISOPARSER.isoparse
Index: venv/Lib/site-packages/dateutil/parser/_parser.py
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/venv/Lib/site-packages/dateutil/parser/_parser.py b/venv/Lib/site-packages/dateutil/parser/_parser.py
new file mode 100644
--- /dev/null	(date 1616410450300)
+++ b/venv/Lib/site-packages/dateutil/parser/_parser.py	(date 1616410450300)
@@ -0,0 +1,1609 @@
+# -*- coding: utf-8 -*-
+"""
+This module offers a generic date/time string parser which is able to parse
+most known formats to represent a date and/or time.
+
+This module attempts to be forgiving with regards to unlikely input formats,
+returning a datetime object even for dates which are ambiguous. If an element
+of a date/time stamp is omitted, the following rules are applied:
+
+- If AM or PM is left unspecified, a 24-hour clock is assumed, however, an hour
+  on a 12-hour clock (``0 <= hour <= 12``) *must* be specified if AM or PM is
+  specified.
+- If a time zone is omitted, a timezone-naive datetime is returned.
+
+If any other elements are missing, they are taken from the
+:class:`datetime.datetime` object passed to the parameter ``default``. If this
+results in a day number exceeding the valid number of days per month, the
+value falls back to the end of the month.
+
+Additional resources about date/time string formats can be found below:
+
+- `A summary of the international standard date and time notation
+  <http://www.cl.cam.ac.uk/~mgk25/iso-time.html>`_
+- `W3C Date and Time Formats <http://www.w3.org/TR/NOTE-datetime>`_
+- `Time Formats (Planetary Rings Node) <https://pds-rings.seti.org:443/tools/time_formats.html>`_
+- `CPAN ParseDate module
+  <http://search.cpan.org/~muir/Time-modules-2013.0912/lib/Time/ParseDate.pm>`_
+- `Java SimpleDateFormat Class
+  <https://docs.oracle.com/javase/6/docs/api/java/text/SimpleDateFormat.html>`_
+"""
+from __future__ import unicode_literals
+
+import datetime
+import re
+import string
+import time
+import warnings
+
+from calendar import monthrange
+from io import StringIO
+
+import six
+from six import integer_types, text_type
+
+from decimal import Decimal
+
+from warnings import warn
+
+from .. import relativedelta
+from .. import tz
+
+__all__ = ["parse", "parserinfo", "ParserError"]
+
+
+# TODO: pandas.core.tools.datetimes imports this explicitly.  Might be worth
+# making public and/or figuring out if there is something we can
+# take off their plate.
+class _timelex(object):
+    # Fractional seconds are sometimes split by a comma
+    _split_decimal = re.compile("([.,])")
+
+    def __init__(self, instream):
+        if six.PY2:
+            # In Python 2, we can't duck type properly because unicode has
+            # a 'decode' function, and we'd be double-decoding
+            if isinstance(instream, (bytes, bytearray)):
+                instream = instream.decode()
+        else:
+            if getattr(instream, 'decode', None) is not None:
+                instream = instream.decode()
+
+        if isinstance(instream, text_type):
+            instream = StringIO(instream)
+        elif getattr(instream, 'read', None) is None:
+            raise TypeError('Parser must be a string or character stream, not '
+                            '{itype}'.format(itype=instream.__class__.__name__))
+
+        self.instream = instream
+        self.charstack = []
+        self.tokenstack = []
+        self.eof = False
+
+    def get_token(self):
+        """
+        This function breaks the time string into lexical units (tokens), which
+        can be parsed by the parser. Lexical units are demarcated by changes in
+        the character set, so any continuous string of letters is considered
+        one unit, any continuous string of numbers is considered one unit.
+
+        The main complication arises from the fact that dots ('.') can be used
+        both as separators (e.g. "Sep.20.2009") or decimal points (e.g.
+        "4:30:21.447"). As such, it is necessary to read the full context of
+        any dot-separated strings before breaking it into tokens; as such, this
+        function maintains a "token stack", for when the ambiguous context
+        demands that multiple tokens be parsed at once.
+        """
+        if self.tokenstack:
+            return self.tokenstack.pop(0)
+
+        seenletters = False
+        token = None
+        state = None
+
+        while not self.eof:
+            # We only realize that we've reached the end of a token when we
+            # find a character that's not part of the current token - since
+            # that character may be part of the next token, it's stored in the
+            # charstack.
+            if self.charstack:
+                nextchar = self.charstack.pop(0)
+            else:
+                nextchar = self.instream.read(1)
+                while nextchar == '\x00':
+                    nextchar = self.instream.read(1)
+
+            if not nextchar:
+                self.eof = True
+                break
+            elif not state:
+                # First character of the token - determines if we're starting
+                # to parse a word, a number or something else.
+                token = nextchar
+                if self.isword(nextchar):
+                    state = 'a'
+                elif self.isnum(nextchar):
+                    state = '0'
+                elif self.isspace(nextchar):
+                    token = ' '
+                    break  # emit token
+                else:
+                    break  # emit token
+            elif state == 'a':
+                # If we've already started reading a word, we keep reading
+                # letters until we find something that's not part of a word.
+                seenletters = True
+                if self.isword(nextchar):
+                    token += nextchar
+                elif nextchar == '.':
+                    token += nextchar
+                    state = 'a.'
+                else:
+                    self.charstack.append(nextchar)
+                    break  # emit token
+            elif state == '0':
+                # If we've already started reading a number, we keep reading
+                # numbers until we find something that doesn't fit.
+                if self.isnum(nextchar):
+                    token += nextchar
+                elif nextchar == '.' or (nextchar == ',' and len(token) >= 2):
+                    token += nextchar
+                    state = '0.'
+                else:
+                    self.charstack.append(nextchar)
+                    break  # emit token
+            elif state == 'a.':
+                # If we've seen some letters and a dot separator, continue
+                # parsing, and the tokens will be broken up later.
+                seenletters = True
+                if nextchar == '.' or self.isword(nextchar):
+                    token += nextchar
+                elif self.isnum(nextchar) and token[-1] == '.':
+                    token += nextchar
+                    state = '0.'
+                else:
+                    self.charstack.append(nextchar)
+                    break  # emit token
+            elif state == '0.':
+                # If we've seen at least one dot separator, keep going, we'll
+                # break up the tokens later.
+                if nextchar == '.' or self.isnum(nextchar):
+                    token += nextchar
+                elif self.isword(nextchar) and token[-1] == '.':
+                    token += nextchar
+                    state = 'a.'
+                else:
+                    self.charstack.append(nextchar)
+                    break  # emit token
+
+        if (state in ('a.', '0.') and (seenletters or token.count('.') > 1 or
+                                       token[-1] in '.,')):
+            l = self._split_decimal.split(token)
+            token = l[0]
+            for tok in l[1:]:
+                if tok:
+                    self.tokenstack.append(tok)
+
+        if state == '0.' and token.count('.') == 0:
+            token = token.replace(',', '.')
+
+        return token
+
+    def __iter__(self):
+        return self
+
+    def __next__(self):
+        token = self.get_token()
+        if token is None:
+            raise StopIteration
+
+        return token
+
+    def next(self):
+        return self.__next__()  # Python 2.x support
+
+    @classmethod
+    def split(cls, s):
+        return list(cls(s))
+
+    @classmethod
+    def isword(cls, nextchar):
+        """ Whether or not the next character is part of a word """
+        return nextchar.isalpha()
+
+    @classmethod
+    def isnum(cls, nextchar):
+        """ Whether the next character is part of a number """
+        return nextchar.isdigit()
+
+    @classmethod
+    def isspace(cls, nextchar):
+        """ Whether the next character is whitespace """
+        return nextchar.isspace()
+
+
+class _resultbase(object):
+
+    def __init__(self):
+        for attr in self.__slots__:
+            setattr(self, attr, None)
+
+    def _repr(self, classname):
+        l = []
+        for attr in self.__slots__:
+            value = getattr(self, attr)
+            if value is not None:
+                l.append("%s=%s" % (attr, repr(value)))
+        return "%s(%s)" % (classname, ", ".join(l))
+
+    def __len__(self):
+        return (sum(getattr(self, attr) is not None
+                    for attr in self.__slots__))
+
+    def __repr__(self):
+        return self._repr(self.__class__.__name__)
+
+
+class parserinfo(object):
+    """
+    Class which handles what inputs are accepted. Subclass this to customize
+    the language and acceptable values for each parameter.
+
+    :param dayfirst:
+        Whether to interpret the first value in an ambiguous 3-integer date
+        (e.g. 01/05/09) as the day (``True``) or month (``False``). If
+        ``yearfirst`` is set to ``True``, this distinguishes between YDM
+        and YMD. Default is ``False``.
+
+    :param yearfirst:
+        Whether to interpret the first value in an ambiguous 3-integer date
+        (e.g. 01/05/09) as the year. If ``True``, the first number is taken
+        to be the year, otherwise the last number is taken to be the year.
+        Default is ``False``.
+    """
+
+    # m from a.m/p.m, t from ISO T separator
+    JUMP = [" ", ".", ",", ";", "-", "/", "'",
+            "at", "on", "and", "ad", "m", "t", "of",
+            "st", "nd", "rd", "th"]
+
+    WEEKDAYS = [("Mon", "Monday"),
+                ("Tue", "Tuesday"),     # TODO: "Tues"
+                ("Wed", "Wednesday"),
+                ("Thu", "Thursday"),    # TODO: "Thurs"
+                ("Fri", "Friday"),
+                ("Sat", "Saturday"),
+                ("Sun", "Sunday")]
+    MONTHS = [("Jan", "January"),
+              ("Feb", "February"),      # TODO: "Febr"
+              ("Mar", "March"),
+              ("Apr", "April"),
+              ("May", "May"),
+              ("Jun", "June"),
+              ("Jul", "July"),
+              ("Aug", "August"),
+              ("Sep", "Sept", "September"),
+              ("Oct", "October"),
+              ("Nov", "November"),
+              ("Dec", "December")]
+    HMS = [("h", "hour", "hours"),
+           ("m", "minute", "minutes"),
+           ("s", "second", "seconds")]
+    AMPM = [("am", "a"),
+            ("pm", "p")]
+    UTCZONE = ["UTC", "GMT", "Z", "z"]
+    PERTAIN = ["of"]
+    TZOFFSET = {}
+    # TODO: ERA = ["AD", "BC", "CE", "BCE", "Stardate",
+    #              "Anno Domini", "Year of Our Lord"]
+
+    def __init__(self, dayfirst=False, yearfirst=False):
+        self._jump = self._convert(self.JUMP)
+        self._weekdays = self._convert(self.WEEKDAYS)
+        self._months = self._convert(self.MONTHS)
+        self._hms = self._convert(self.HMS)
+        self._ampm = self._convert(self.AMPM)
+        self._utczone = self._convert(self.UTCZONE)
+        self._pertain = self._convert(self.PERTAIN)
+
+        self.dayfirst = dayfirst
+        self.yearfirst = yearfirst
+
+        self._year = time.localtime().tm_year
+        self._century = self._year // 100 * 100
+
+    def _convert(self, lst):
+        dct = {}
+        for i, v in enumerate(lst):
+            if isinstance(v, tuple):
+                for v in v:
+                    dct[v.lower()] = i
+            else:
+                dct[v.lower()] = i
+        return dct
+
+    def jump(self, name):
+        return name.lower() in self._jump
+
+    def weekday(self, name):
+        try:
+            return self._weekdays[name.lower()]
+        except KeyError:
+            pass
+        return None
+
+    def month(self, name):
+        try:
+            return self._months[name.lower()] + 1
+        except KeyError:
+            pass
+        return None
+
+    def hms(self, name):
+        try:
+            return self._hms[name.lower()]
+        except KeyError:
+            return None
+
+    def ampm(self, name):
+        try:
+            return self._ampm[name.lower()]
+        except KeyError:
+            return None
+
+    def pertain(self, name):
+        return name.lower() in self._pertain
+
+    def utczone(self, name):
+        return name.lower() in self._utczone
+
+    def tzoffset(self, name):
+        if name in self._utczone:
+            return 0
+
+        return self.TZOFFSET.get(name)
+
+    def convertyear(self, year, century_specified=False):
+        """
+        Converts two-digit years to year within [-50, 49]
+        range of self._year (current local time)
+        """
+
+        # Function contract is that the year is always positive
+        assert year >= 0
+
+        if year < 100 and not century_specified:
+            # assume current century to start
+            year += self._century
+
+            if year >= self._year + 50:  # if too far in future
+                year -= 100
+            elif year < self._year - 50:  # if too far in past
+                year += 100
+
+        return year
+
+    def validate(self, res):
+        # move to info
+        if res.year is not None:
+            res.year = self.convertyear(res.year, res.century_specified)
+
+        if ((res.tzoffset == 0 and not res.tzname) or
+             (res.tzname == 'Z' or res.tzname == 'z')):
+            res.tzname = "UTC"
+            res.tzoffset = 0
+        elif res.tzoffset != 0 and res.tzname and self.utczone(res.tzname):
+            res.tzoffset = 0
+        return True
+
+
+class _ymd(list):
+    def __init__(self, *args, **kwargs):
+        super(self.__class__, self).__init__(*args, **kwargs)
+        self.century_specified = False
+        self.dstridx = None
+        self.mstridx = None
+        self.ystridx = None
+
+    @property
+    def has_year(self):
+        return self.ystridx is not None
+
+    @property
+    def has_month(self):
+        return self.mstridx is not None
+
+    @property
+    def has_day(self):
+        return self.dstridx is not None
+
+    def could_be_day(self, value):
+        if self.has_day:
+            return False
+        elif not self.has_month:
+            return 1 <= value <= 31
+        elif not self.has_year:
+            # Be permissive, assume leap year
+            month = self[self.mstridx]
+            return 1 <= value <= monthrange(2000, month)[1]
+        else:
+            month = self[self.mstridx]
+            year = self[self.ystridx]
+            return 1 <= value <= monthrange(year, month)[1]
+
+    def append(self, val, label=None):
+        if hasattr(val, '__len__'):
+            if val.isdigit() and len(val) > 2:
+                self.century_specified = True
+                if label not in [None, 'Y']:  # pragma: no cover
+                    raise ValueError(label)
+                label = 'Y'
+        elif val > 100:
+            self.century_specified = True
+            if label not in [None, 'Y']:  # pragma: no cover
+                raise ValueError(label)
+            label = 'Y'
+
+        super(self.__class__, self).append(int(val))
+
+        if label == 'M':
+            if self.has_month:
+                raise ValueError('Month is already set')
+            self.mstridx = len(self) - 1
+        elif label == 'D':
+            if self.has_day:
+                raise ValueError('Day is already set')
+            self.dstridx = len(self) - 1
+        elif label == 'Y':
+            if self.has_year:
+                raise ValueError('Year is already set')
+            self.ystridx = len(self) - 1
+
+    def _resolve_from_stridxs(self, strids):
+        """
+        Try to resolve the identities of year/month/day elements using
+        ystridx, mstridx, and dstridx, if enough of these are specified.
+        """
+        if len(self) == 3 and len(strids) == 2:
+            # we can back out the remaining stridx value
+            missing = [x for x in range(3) if x not in strids.values()]
+            key = [x for x in ['y', 'm', 'd'] if x not in strids]
+            assert len(missing) == len(key) == 1
+            key = key[0]
+            val = missing[0]
+            strids[key] = val
+
+        assert len(self) == len(strids)  # otherwise this should not be called
+        out = {key: self[strids[key]] for key in strids}
+        return (out.get('y'), out.get('m'), out.get('d'))
+
+    def resolve_ymd(self, yearfirst, dayfirst):
+        len_ymd = len(self)
+        year, month, day = (None, None, None)
+
+        strids = (('y', self.ystridx),
+                  ('m', self.mstridx),
+                  ('d', self.dstridx))
+
+        strids = {key: val for key, val in strids if val is not None}
+        if (len(self) == len(strids) > 0 or
+                (len(self) == 3 and len(strids) == 2)):
+            return self._resolve_from_stridxs(strids)
+
+        mstridx = self.mstridx
+
+        if len_ymd > 3:
+            raise ValueError("More than three YMD values")
+        elif len_ymd == 1 or (mstridx is not None and len_ymd == 2):
+            # One member, or two members with a month string
+            if mstridx is not None:
+                month = self[mstridx]
+                # since mstridx is 0 or 1, self[mstridx-1] always
+                # looks up the other element
+                other = self[mstridx - 1]
+            else:
+                other = self[0]
+
+            if len_ymd > 1 or mstridx is None:
+                if other > 31:
+                    year = other
+                else:
+                    day = other
+
+        elif len_ymd == 2:
+            # Two members with numbers
+            if self[0] > 31:
+                # 99-01
+                year, month = self
+            elif self[1] > 31:
+                # 01-99
+                month, year = self
+            elif dayfirst and self[1] <= 12:
+                # 13-01
+                day, month = self
+            else:
+                # 01-13
+                month, day = self
+
+        elif len_ymd == 3:
+            # Three members
+            if mstridx == 0:
+                if self[1] > 31:
+                    # Apr-2003-25
+                    month, year, day = self
+                else:
+                    month, day, year = self
+            elif mstridx == 1:
+                if self[0] > 31 or (yearfirst and self[2] <= 31):
+                    # 99-Jan-01
+                    year, month, day = self
+                else:
+                    # 01-Jan-01
+                    # Give precedence to day-first, since
+                    # two-digit years is usually hand-written.
+                    day, month, year = self
+
+            elif mstridx == 2:
+                # WTF!?
+                if self[1] > 31:
+                    # 01-99-Jan
+                    day, year, month = self
+                else:
+                    # 99-01-Jan
+                    year, day, month = self
+
+            else:
+                if (self[0] > 31 or
+                    self.ystridx == 0 or
+                        (yearfirst and self[1] <= 12 and self[2] <= 31)):
+                    # 99-01-01
+                    if dayfirst and self[2] <= 12:
+                        year, day, month = self
+                    else:
+                        year, month, day = self
+                elif self[0] > 12 or (dayfirst and self[1] <= 12):
+                    # 13-01-01
+                    day, month, year = self
+                else:
+                    # 01-13-01
+                    month, day, year = self
+
+        return year, month, day
+
+
+class parser(object):
+    def __init__(self, info=None):
+        self.info = info or parserinfo()
+
+    def parse(self, timestr, default=None,
+              ignoretz=False, tzinfos=None, **kwargs):
+        """
+        Parse the date/time string into a :class:`datetime.datetime` object.
+
+        :param timestr:
+            Any date/time string using the supported formats.
+
+        :param default:
+            The default datetime object, if this is a datetime object and not
+            ``None``, elements specified in ``timestr`` replace elements in the
+            default object.
+
+        :param ignoretz:
+            If set ``True``, time zones in parsed strings are ignored and a
+            naive :class:`datetime.datetime` object is returned.
+
+        :param tzinfos:
+            Additional time zone names / aliases which may be present in the
+            string. This argument maps time zone names (and optionally offsets
+            from those time zones) to time zones. This parameter can be a
+            dictionary with timezone aliases mapping time zone names to time
+            zones or a function taking two parameters (``tzname`` and
+            ``tzoffset``) and returning a time zone.
+
+            The timezones to which the names are mapped can be an integer
+            offset from UTC in seconds or a :class:`tzinfo` object.
+
+            .. doctest::
+               :options: +NORMALIZE_WHITESPACE
+
+                >>> from dateutil.parser import parse
+                >>> from dateutil.tz import gettz
+                >>> tzinfos = {"BRST": -7200, "CST": gettz("America/Chicago")}
+                >>> parse("2012-01-19 17:21:00 BRST", tzinfos=tzinfos)
+                datetime.datetime(2012, 1, 19, 17, 21, tzinfo=tzoffset(u'BRST', -7200))
+                >>> parse("2012-01-19 17:21:00 CST", tzinfos=tzinfos)
+                datetime.datetime(2012, 1, 19, 17, 21,
+                                  tzinfo=tzfile('/usr/share/zoneinfo/America/Chicago'))
+
+            This parameter is ignored if ``ignoretz`` is set.
+
+        :param \\*\\*kwargs:
+            Keyword arguments as passed to ``_parse()``.
+
+        :return:
+            Returns a :class:`datetime.datetime` object or, if the
+            ``fuzzy_with_tokens`` option is ``True``, returns a tuple, the
+            first element being a :class:`datetime.datetime` object, the second
+            a tuple containing the fuzzy tokens.
+
+        :raises ParserError:
+            Raised for invalid or unknown string format, if the provided
+            :class:`tzinfo` is not in a valid format, or if an invalid date
+            would be created.
+
+        :raises TypeError:
+            Raised for non-string or character stream input.
+
+        :raises OverflowError:
+            Raised if the parsed date exceeds the largest valid C integer on
+            your system.
+        """
+
+        if default is None:
+            default = datetime.datetime.now().replace(hour=0, minute=0,
+                                                      second=0, microsecond=0)
+
+        res, skipped_tokens = self._parse(timestr, **kwargs)
+
+        if res is None:
+            raise ParserError("Unknown string format: %s", timestr)
+
+        if len(res) == 0:
+            raise ParserError("String does not contain a date: %s", timestr)
+
+        try:
+            ret = self._build_naive(res, default)
+        except ValueError as e:
+            six.raise_from(ParserError(e.args[0] + ": %s", timestr), e)
+
+        if not ignoretz:
+            ret = self._build_tzaware(ret, res, tzinfos)
+
+        if kwargs.get('fuzzy_with_tokens', False):
+            return ret, skipped_tokens
+        else:
+            return ret
+
+    class _result(_resultbase):
+        __slots__ = ["year", "month", "day", "weekday",
+                     "hour", "minute", "second", "microsecond",
+                     "tzname", "tzoffset", "ampm","any_unused_tokens"]
+
+    def _parse(self, timestr, dayfirst=None, yearfirst=None, fuzzy=False,
+               fuzzy_with_tokens=False):
+        """
+        Private method which performs the heavy lifting of parsing, called from
+        ``parse()``, which passes on its ``kwargs`` to this function.
+
+        :param timestr:
+            The string to parse.
+
+        :param dayfirst:
+            Whether to interpret the first value in an ambiguous 3-integer date
+            (e.g. 01/05/09) as the day (``True``) or month (``False``). If
+            ``yearfirst`` is set to ``True``, this distinguishes between YDM
+            and YMD. If set to ``None``, this value is retrieved from the
+            current :class:`parserinfo` object (which itself defaults to
+            ``False``).
+
+        :param yearfirst:
+            Whether to interpret the first value in an ambiguous 3-integer date
+            (e.g. 01/05/09) as the year. If ``True``, the first number is taken
+            to be the year, otherwise the last number is taken to be the year.
+            If this is set to ``None``, the value is retrieved from the current
+            :class:`parserinfo` object (which itself defaults to ``False``).
+
+        :param fuzzy:
+            Whether to allow fuzzy parsing, allowing for string like "Today is
+            January 1, 2047 at 8:21:00AM".
+
+        :param fuzzy_with_tokens:
+            If ``True``, ``fuzzy`` is automatically set to True, and the parser
+            will return a tuple where the first element is the parsed
+            :class:`datetime.datetime` datetimestamp and the second element is
+            a tuple containing the portions of the string which were ignored:
+
+            .. doctest::
+
+                >>> from dateutil.parser import parse
+                >>> parse("Today is January 1, 2047 at 8:21:00AM", fuzzy_with_tokens=True)
+                (datetime.datetime(2047, 1, 1, 8, 21), (u'Today is ', u' ', u'at '))
+
+        """
+        if fuzzy_with_tokens:
+            fuzzy = True
+
+        info = self.info
+
+        if dayfirst is None:
+            dayfirst = info.dayfirst
+
+        if yearfirst is None:
+            yearfirst = info.yearfirst
+
+        res = self._result()
+        l = _timelex.split(timestr)         # Splits the timestr into tokens
+
+        skipped_idxs = []
+
+        # year/month/day list
+        ymd = _ymd()
+
+        len_l = len(l)
+        i = 0
+        try:
+            while i < len_l:
+
+                # Check if it's a number
+                value_repr = l[i]
+                try:
+                    value = float(value_repr)
+                except ValueError:
+                    value = None
+
+                if value is not None:
+                    # Numeric token
+                    i = self._parse_numeric_token(l, i, info, ymd, res, fuzzy)
+
+                # Check weekday
+                elif info.weekday(l[i]) is not None:
+                    value = info.weekday(l[i])
+                    res.weekday = value
+
+                # Check month name
+                elif info.month(l[i]) is not None:
+                    value = info.month(l[i])
+                    ymd.append(value, 'M')
+
+                    if i + 1 < len_l:
+                        if l[i + 1] in ('-', '/'):
+                            # Jan-01[-99]
+                            sep = l[i + 1]
+                            ymd.append(l[i + 2])
+
+                            if i + 3 < len_l and l[i + 3] == sep:
+                                # Jan-01-99
+                                ymd.append(l[i + 4])
+                                i += 2
+
+                            i += 2
+
+                        elif (i + 4 < len_l and l[i + 1] == l[i + 3] == ' ' and
+                              info.pertain(l[i + 2])):
+                            # Jan of 01
+                            # In this case, 01 is clearly year
+                            if l[i + 4].isdigit():
+                                # Convert it here to become unambiguous
+                                value = int(l[i + 4])
+                                year = str(info.convertyear(value))
+                                ymd.append(year, 'Y')
+                            else:
+                                # Wrong guess
+                                pass
+                                # TODO: not hit in tests
+                            i += 4
+
+                # Check am/pm
+                elif info.ampm(l[i]) is not None:
+                    value = info.ampm(l[i])
+                    val_is_ampm = self._ampm_valid(res.hour, res.ampm, fuzzy)
+
+                    if val_is_ampm:
+                        res.hour = self._adjust_ampm(res.hour, value)
+                        res.ampm = value
+
+                    elif fuzzy:
+                        skipped_idxs.append(i)
+
+                # Check for a timezone name
+                elif self._could_be_tzname(res.hour, res.tzname, res.tzoffset, l[i]):
+                    res.tzname = l[i]
+                    res.tzoffset = info.tzoffset(res.tzname)
+
+                    # Check for something like GMT+3, or BRST+3. Notice
+                    # that it doesn't mean "I am 3 hours after GMT", but
+                    # "my time +3 is GMT". If found, we reverse the
+                    # logic so that timezone parsing code will get it
+                    # right.
+                    if i + 1 < len_l and l[i + 1] in ('+', '-'):
+                        l[i + 1] = ('+', '-')[l[i + 1] == '+']
+                        res.tzoffset = None
+                        if info.utczone(res.tzname):
+                            # With something like GMT+3, the timezone
+                            # is *not* GMT.
+                            res.tzname = None
+
+                # Check for a numbered timezone
+                elif res.hour is not None and l[i] in ('+', '-'):
+                    signal = (-1, 1)[l[i] == '+']
+                    len_li = len(l[i + 1])
+
+                    # TODO: check that l[i + 1] is integer?
+                    if len_li == 4:
+                        # -0300
+                        hour_offset = int(l[i + 1][:2])
+                        min_offset = int(l[i + 1][2:])
+                    elif i + 2 < len_l and l[i + 2] == ':':
+                        # -03:00
+                        hour_offset = int(l[i + 1])
+                        min_offset = int(l[i + 3])  # TODO: Check that l[i+3] is minute-like?
+                        i += 2
+                    elif len_li <= 2:
+                        # -[0]3
+                        hour_offset = int(l[i + 1][:2])
+                        min_offset = 0
+                    else:
+                        raise ValueError(timestr)
+
+                    res.tzoffset = signal * (hour_offset * 3600 + min_offset * 60)
+
+                    # Look for a timezone name between parenthesis
+                    if (i + 5 < len_l and
+                            info.jump(l[i + 2]) and l[i + 3] == '(' and
+                            l[i + 5] == ')' and
+                            3 <= len(l[i + 4]) and
+                            self._could_be_tzname(res.hour, res.tzname,
+                                                  None, l[i + 4])):
+                        # -0300 (BRST)
+                        res.tzname = l[i + 4]
+                        i += 4
+
+                    i += 1
+
+                # Check jumps
+                elif not (info.jump(l[i]) or fuzzy):
+                    raise ValueError(timestr)
+
+                else:
+                    skipped_idxs.append(i)
+                i += 1
+
+            # Process year/month/day
+            year, month, day = ymd.resolve_ymd(yearfirst, dayfirst)
+
+            res.century_specified = ymd.century_specified
+            res.year = year
+            res.month = month
+            res.day = day
+
+        except (IndexError, ValueError):
+            return None, None
+
+        if not info.validate(res):
+            return None, None
+
+        if fuzzy_with_tokens:
+            skipped_tokens = self._recombine_skipped(l, skipped_idxs)
+            return res, tuple(skipped_tokens)
+        else:
+            return res, None
+
+    def _parse_numeric_token(self, tokens, idx, info, ymd, res, fuzzy):
+        # Token is a number
+        value_repr = tokens[idx]
+        try:
+            value = self._to_decimal(value_repr)
+        except Exception as e:
+            six.raise_from(ValueError('Unknown numeric token'), e)
+
+        len_li = len(value_repr)
+
+        len_l = len(tokens)
+
+        if (len(ymd) == 3 and len_li in (2, 4) and
+            res.hour is None and
+            (idx + 1 >= len_l or
+             (tokens[idx + 1] != ':' and
+              info.hms(tokens[idx + 1]) is None))):
+            # 19990101T23[59]
+            s = tokens[idx]
+            res.hour = int(s[:2])
+
+            if len_li == 4:
+                res.minute = int(s[2:])
+
+        elif len_li == 6 or (len_li > 6 and tokens[idx].find('.') == 6):
+            # YYMMDD or HHMMSS[.ss]
+            s = tokens[idx]
+
+            if not ymd and '.' not in tokens[idx]:
+                ymd.append(s[:2])
+                ymd.append(s[2:4])
+                ymd.append(s[4:])
+            else:
+                # 19990101T235959[.59]
+
+                # TODO: Check if res attributes already set.
+                res.hour = int(s[:2])
+                res.minute = int(s[2:4])
+                res.second, res.microsecond = self._parsems(s[4:])
+
+        elif len_li in (8, 12, 14):
+            # YYYYMMDD
+            s = tokens[idx]
+            ymd.append(s[:4], 'Y')
+            ymd.append(s[4:6])
+            ymd.append(s[6:8])
+
+            if len_li > 8:
+                res.hour = int(s[8:10])
+                res.minute = int(s[10:12])
+
+                if len_li > 12:
+                    res.second = int(s[12:])
+
+        elif self._find_hms_idx(idx, tokens, info, allow_jump=True) is not None:
+            # HH[ ]h or MM[ ]m or SS[.ss][ ]s
+            hms_idx = self._find_hms_idx(idx, tokens, info, allow_jump=True)
+            (idx, hms) = self._parse_hms(idx, tokens, info, hms_idx)
+            if hms is not None:
+                # TODO: checking that hour/minute/second are not
+                # already set?
+                self._assign_hms(res, value_repr, hms)
+
+        elif idx + 2 < len_l and tokens[idx + 1] == ':':
+            # HH:MM[:SS[.ss]]
+            res.hour = int(value)
+            value = self._to_decimal(tokens[idx + 2])  # TODO: try/except for this?
+            (res.minute, res.second) = self._parse_min_sec(value)
+
+            if idx + 4 < len_l and tokens[idx + 3] == ':':
+                res.second, res.microsecond = self._parsems(tokens[idx + 4])
+
+                idx += 2
+
+            idx += 2
+
+        elif idx + 1 < len_l and tokens[idx + 1] in ('-', '/', '.'):
+            sep = tokens[idx + 1]
+            ymd.append(value_repr)
+
+            if idx + 2 < len_l and not info.jump(tokens[idx + 2]):
+                if tokens[idx + 2].isdigit():
+                    # 01-01[-01]
+                    ymd.append(tokens[idx + 2])
+                else:
+                    # 01-Jan[-01]
+                    value = info.month(tokens[idx + 2])
+
+                    if value is not None:
+                        ymd.append(value, 'M')
+                    else:
+                        raise ValueError()
+
+                if idx + 3 < len_l and tokens[idx + 3] == sep:
+                    # We have three members
+                    value = info.month(tokens[idx + 4])
+
+                    if value is not None:
+                        ymd.append(value, 'M')
+                    else:
+                        ymd.append(tokens[idx + 4])
+                    idx += 2
+
+                idx += 1
+            idx += 1
+
+        elif idx + 1 >= len_l or info.jump(tokens[idx + 1]):
+            if idx + 2 < len_l and info.ampm(tokens[idx + 2]) is not None:
+                # 12 am
+                hour = int(value)
+                res.hour = self._adjust_ampm(hour, info.ampm(tokens[idx + 2]))
+                idx += 1
+            else:
+                # Year, month or day
+                ymd.append(value)
+            idx += 1
+
+        elif info.ampm(tokens[idx + 1]) is not None and (0 <= value < 24):
+            # 12am
+            hour = int(value)
+            res.hour = self._adjust_ampm(hour, info.ampm(tokens[idx + 1]))
+            idx += 1
+
+        elif ymd.could_be_day(value):
+            ymd.append(value)
+
+        elif not fuzzy:
+            raise ValueError()
+
+        return idx
+
+    def _find_hms_idx(self, idx, tokens, info, allow_jump):
+        len_l = len(tokens)
+
+        if idx+1 < len_l and info.hms(tokens[idx+1]) is not None:
+            # There is an "h", "m", or "s" label following this token.  We take
+            # assign the upcoming label to the current token.
+            # e.g. the "12" in 12h"
+            hms_idx = idx + 1
+
+        elif (allow_jump and idx+2 < len_l and tokens[idx+1] == ' ' and
+              info.hms(tokens[idx+2]) is not None):
+            # There is a space and then an "h", "m", or "s" label.
+            # e.g. the "12" in "12 h"
+            hms_idx = idx + 2
+
+        elif idx > 0 and info.hms(tokens[idx-1]) is not None:
+            # There is a "h", "m", or "s" preceding this token.  Since neither
+            # of the previous cases was hit, there is no label following this
+            # token, so we use the previous label.
+            # e.g. the "04" in "12h04"
+            hms_idx = idx-1
+
+        elif (1 < idx == len_l-1 and tokens[idx-1] == ' ' and
+              info.hms(tokens[idx-2]) is not None):
+            # If we are looking at the final token, we allow for a
+            # backward-looking check to skip over a space.
+            # TODO: Are we sure this is the right condition here?
+            hms_idx = idx - 2
+
+        else:
+            hms_idx = None
+
+        return hms_idx
+
+    def _assign_hms(self, res, value_repr, hms):
+        # See GH issue #427, fixing float rounding
+        value = self._to_decimal(value_repr)
+
+        if hms == 0:
+            # Hour
+            res.hour = int(value)
+            if value % 1:
+                res.minute = int(60*(value % 1))
+
+        elif hms == 1:
+            (res.minute, res.second) = self._parse_min_sec(value)
+
+        elif hms == 2:
+            (res.second, res.microsecond) = self._parsems(value_repr)
+
+    def _could_be_tzname(self, hour, tzname, tzoffset, token):
+        return (hour is not None and
+                tzname is None and
+                tzoffset is None and
+                len(token) <= 5 and
+                (all(x in string.ascii_uppercase for x in token)
+                 or token in self.info.UTCZONE))
+
+    def _ampm_valid(self, hour, ampm, fuzzy):
+        """
+        For fuzzy parsing, 'a' or 'am' (both valid English words)
+        may erroneously trigger the AM/PM flag. Deal with that
+        here.
+        """
+        val_is_ampm = True
+
+        # If there's already an AM/PM flag, this one isn't one.
+        if fuzzy and ampm is not None:
+            val_is_ampm = False
+
+        # If AM/PM is found and hour is not, raise a ValueError
+        if hour is None:
+            if fuzzy:
+                val_is_ampm = False
+            else:
+                raise ValueError('No hour specified with AM or PM flag.')
+        elif not 0 <= hour <= 12:
+            # If AM/PM is found, it's a 12 hour clock, so raise
+            # an error for invalid range
+            if fuzzy:
+                val_is_ampm = False
+            else:
+                raise ValueError('Invalid hour specified for 12-hour clock.')
+
+        return val_is_ampm
+
+    def _adjust_ampm(self, hour, ampm):
+        if hour < 12 and ampm == 1:
+            hour += 12
+        elif hour == 12 and ampm == 0:
+            hour = 0
+        return hour
+
+    def _parse_min_sec(self, value):
+        # TODO: Every usage of this function sets res.second to the return
+        # value. Are there any cases where second will be returned as None and
+        # we *don't* want to set res.second = None?
+        minute = int(value)
+        second = None
+
+        sec_remainder = value % 1
+        if sec_remainder:
+            second = int(60 * sec_remainder)
+        return (minute, second)
+
+    def _parse_hms(self, idx, tokens, info, hms_idx):
+        # TODO: Is this going to admit a lot of false-positives for when we
+        # just happen to have digits and "h", "m" or "s" characters in non-date
+        # text?  I guess hex hashes won't have that problem, but there's plenty
+        # of random junk out there.
+        if hms_idx is None:
+            hms = None
+            new_idx = idx
+        elif hms_idx > idx:
+            hms = info.hms(tokens[hms_idx])
+            new_idx = hms_idx
+        else:
+            # Looking backwards, increment one.
+            hms = info.hms(tokens[hms_idx]) + 1
+            new_idx = idx
+
+        return (new_idx, hms)
+
+    # ------------------------------------------------------------------
+    # Handling for individual tokens.  These are kept as methods instead
+    #  of functions for the sake of customizability via subclassing.
+
+    def _parsems(self, value):
+        """Parse a I[.F] seconds value into (seconds, microseconds)."""
+        if "." not in value:
+            return int(value), 0
+        else:
+            i, f = value.split(".")
+            return int(i), int(f.ljust(6, "0")[:6])
+
+    def _to_decimal(self, val):
+        try:
+            decimal_value = Decimal(val)
+            # See GH 662, edge case, infinite value should not be converted
+            #  via `_to_decimal`
+            if not decimal_value.is_finite():
+                raise ValueError("Converted decimal value is infinite or NaN")
+        except Exception as e:
+            msg = "Could not convert %s to decimal" % val
+            six.raise_from(ValueError(msg), e)
+        else:
+            return decimal_value
+
+    # ------------------------------------------------------------------
+    # Post-Parsing construction of datetime output.  These are kept as
+    #  methods instead of functions for the sake of customizability via
+    #  subclassing.
+
+    def _build_tzinfo(self, tzinfos, tzname, tzoffset):
+        if callable(tzinfos):
+            tzdata = tzinfos(tzname, tzoffset)
+        else:
+            tzdata = tzinfos.get(tzname)
+        # handle case where tzinfo is paased an options that returns None
+        # eg tzinfos = {'BRST' : None}
+        if isinstance(tzdata, datetime.tzinfo) or tzdata is None:
+            tzinfo = tzdata
+        elif isinstance(tzdata, text_type):
+            tzinfo = tz.tzstr(tzdata)
+        elif isinstance(tzdata, integer_types):
+            tzinfo = tz.tzoffset(tzname, tzdata)
+        else:
+            raise TypeError("Offset must be tzinfo subclass, tz string, "
+                            "or int offset.")
+        return tzinfo
+
+    def _build_tzaware(self, naive, res, tzinfos):
+        if (callable(tzinfos) or (tzinfos and res.tzname in tzinfos)):
+            tzinfo = self._build_tzinfo(tzinfos, res.tzname, res.tzoffset)
+            aware = naive.replace(tzinfo=tzinfo)
+            aware = self._assign_tzname(aware, res.tzname)
+
+        elif res.tzname and res.tzname in time.tzname:
+            aware = naive.replace(tzinfo=tz.tzlocal())
+
+            # Handle ambiguous local datetime
+            aware = self._assign_tzname(aware, res.tzname)
+
+            # This is mostly relevant for winter GMT zones parsed in the UK
+            if (aware.tzname() != res.tzname and
+                    res.tzname in self.info.UTCZONE):
+                aware = aware.replace(tzinfo=tz.UTC)
+
+        elif res.tzoffset == 0:
+            aware = naive.replace(tzinfo=tz.UTC)
+
+        elif res.tzoffset:
+            aware = naive.replace(tzinfo=tz.tzoffset(res.tzname, res.tzoffset))
+
+        elif not res.tzname and not res.tzoffset:
+            # i.e. no timezone information was found.
+            aware = naive
+
+        elif res.tzname:
+            # tz-like string was parsed but we don't know what to do
+            # with it
+            warnings.warn("tzname {tzname} identified but not understood.  "
+                          "Pass `tzinfos` argument in order to correctly "
+                          "return a timezone-aware datetime.  In a future "
+                          "version, this will raise an "
+                          "exception.".format(tzname=res.tzname),
+                          category=UnknownTimezoneWarning)
+            aware = naive
+
+        return aware
+
+    def _build_naive(self, res, default):
+        repl = {}
+        for attr in ("year", "month", "day", "hour",
+                     "minute", "second", "microsecond"):
+            value = getattr(res, attr)
+            if value is not None:
+                repl[attr] = value
+
+        if 'day' not in repl:
+            # If the default day exceeds the last day of the month, fall back
+            # to the end of the month.
+            cyear = default.year if res.year is None else res.year
+            cmonth = default.month if res.month is None else res.month
+            cday = default.day if res.day is None else res.day
+
+            if cday > monthrange(cyear, cmonth)[1]:
+                repl['day'] = monthrange(cyear, cmonth)[1]
+
+        naive = default.replace(**repl)
+
+        if res.weekday is not None and not res.day:
+            naive = naive + relativedelta.relativedelta(weekday=res.weekday)
+
+        return naive
+
+    def _assign_tzname(self, dt, tzname):
+        if dt.tzname() != tzname:
+            new_dt = tz.enfold(dt, fold=1)
+            if new_dt.tzname() == tzname:
+                return new_dt
+
+        return dt
+
+    def _recombine_skipped(self, tokens, skipped_idxs):
+        """
+        >>> tokens = ["foo", " ", "bar", " ", "19June2000", "baz"]
+        >>> skipped_idxs = [0, 1, 2, 5]
+        >>> _recombine_skipped(tokens, skipped_idxs)
+        ["foo bar", "baz"]
+        """
+        skipped_tokens = []
+        for i, idx in enumerate(sorted(skipped_idxs)):
+            if i > 0 and idx - 1 == skipped_idxs[i - 1]:
+                skipped_tokens[-1] = skipped_tokens[-1] + tokens[idx]
+            else:
+                skipped_tokens.append(tokens[idx])
+
+        return skipped_tokens
+
+
+DEFAULTPARSER = parser()
+
+
+def parse(timestr, parserinfo=None, **kwargs):
+    """
+
+    Parse a string in one of the supported formats, using the
+    ``parserinfo`` parameters.
+
+    :param timestr:
+        A string containing a date/time stamp.
+
+    :param parserinfo:
+        A :class:`parserinfo` object containing parameters for the parser.
+        If ``None``, the default arguments to the :class:`parserinfo`
+        constructor are used.
+
+    The ``**kwargs`` parameter takes the following keyword arguments:
+
+    :param default:
+        The default datetime object, if this is a datetime object and not
+        ``None``, elements specified in ``timestr`` replace elements in the
+        default object.
+
+    :param ignoretz:
+        If set ``True``, time zones in parsed strings are ignored and a naive
+        :class:`datetime` object is returned.
+
+    :param tzinfos:
+        Additional time zone names / aliases which may be present in the
+        string. This argument maps time zone names (and optionally offsets
+        from those time zones) to time zones. This parameter can be a
+        dictionary with timezone aliases mapping time zone names to time
+        zones or a function taking two parameters (``tzname`` and
+        ``tzoffset``) and returning a time zone.
+
+        The timezones to which the names are mapped can be an integer
+        offset from UTC in seconds or a :class:`tzinfo` object.
+
+        .. doctest::
+           :options: +NORMALIZE_WHITESPACE
+
+            >>> from dateutil.parser import parse
+            >>> from dateutil.tz import gettz
+            >>> tzinfos = {"BRST": -7200, "CST": gettz("America/Chicago")}
+            >>> parse("2012-01-19 17:21:00 BRST", tzinfos=tzinfos)
+            datetime.datetime(2012, 1, 19, 17, 21, tzinfo=tzoffset(u'BRST', -7200))
+            >>> parse("2012-01-19 17:21:00 CST", tzinfos=tzinfos)
+            datetime.datetime(2012, 1, 19, 17, 21,
+                              tzinfo=tzfile('/usr/share/zoneinfo/America/Chicago'))
+
+        This parameter is ignored if ``ignoretz`` is set.
+
+    :param dayfirst:
+        Whether to interpret the first value in an ambiguous 3-integer date
+        (e.g. 01/05/09) as the day (``True``) or month (``False``). If
+        ``yearfirst`` is set to ``True``, this distinguishes between YDM and
+        YMD. If set to ``None``, this value is retrieved from the current
+        :class:`parserinfo` object (which itself defaults to ``False``).
+
+    :param yearfirst:
+        Whether to interpret the first value in an ambiguous 3-integer date
+        (e.g. 01/05/09) as the year. If ``True``, the first number is taken to
+        be the year, otherwise the last number is taken to be the year. If
+        this is set to ``None``, the value is retrieved from the current
+        :class:`parserinfo` object (which itself defaults to ``False``).
+
+    :param fuzzy:
+        Whether to allow fuzzy parsing, allowing for string like "Today is
+        January 1, 2047 at 8:21:00AM".
+
+    :param fuzzy_with_tokens:
+        If ``True``, ``fuzzy`` is automatically set to True, and the parser
+        will return a tuple where the first element is the parsed
+        :class:`datetime.datetime` datetimestamp and the second element is
+        a tuple containing the portions of the string which were ignored:
+
+        .. doctest::
+
+            >>> from dateutil.parser import parse
+            >>> parse("Today is January 1, 2047 at 8:21:00AM", fuzzy_with_tokens=True)
+            (datetime.datetime(2047, 1, 1, 8, 21), (u'Today is ', u' ', u'at '))
+
+    :return:
+        Returns a :class:`datetime.datetime` object or, if the
+        ``fuzzy_with_tokens`` option is ``True``, returns a tuple, the
+        first element being a :class:`datetime.datetime` object, the second
+        a tuple containing the fuzzy tokens.
+
+    :raises ValueError:
+        Raised for invalid or unknown string format, if the provided
+        :class:`tzinfo` is not in a valid format, or if an invalid date
+        would be created.
+
+    :raises OverflowError:
+        Raised if the parsed date exceeds the largest valid C integer on
+        your system.
+    """
+    if parserinfo:
+        return parser(parserinfo).parse(timestr, **kwargs)
+    else:
+        return DEFAULTPARSER.parse(timestr, **kwargs)
+
+
+class _tzparser(object):
+
+    class _result(_resultbase):
+
+        __slots__ = ["stdabbr", "stdoffset", "dstabbr", "dstoffset",
+                     "start", "end"]
+
+        class _attr(_resultbase):
+            __slots__ = ["month", "week", "weekday",
+                         "yday", "jyday", "day", "time"]
+
+        def __repr__(self):
+            return self._repr("")
+
+        def __init__(self):
+            _resultbase.__init__(self)
+            self.start = self._attr()
+            self.end = self._attr()
+
+    def parse(self, tzstr):
+        res = self._result()
+        l = [x for x in re.split(r'([,:.]|[a-zA-Z]+|[0-9]+)',tzstr) if x]
+        used_idxs = list()
+        try:
+
+            len_l = len(l)
+
+            i = 0
+            while i < len_l:
+                # BRST+3[BRDT[+2]]
+                j = i
+                while j < len_l and not [x for x in l[j]
+                                         if x in "0123456789:,-+"]:
+                    j += 1
+                if j != i:
+                    if not res.stdabbr:
+                        offattr = "stdoffset"
+                        res.stdabbr = "".join(l[i:j])
+                    else:
+                        offattr = "dstoffset"
+                        res.dstabbr = "".join(l[i:j])
+
+                    for ii in range(j):
+                        used_idxs.append(ii)
+                    i = j
+                    if (i < len_l and (l[i] in ('+', '-') or l[i][0] in
+                                       "0123456789")):
+                        if l[i] in ('+', '-'):
+                            # Yes, that's right.  See the TZ variable
+                            # documentation.
+                            signal = (1, -1)[l[i] == '+']
+                            used_idxs.append(i)
+                            i += 1
+                        else:
+                            signal = -1
+                        len_li = len(l[i])
+                        if len_li == 4:
+                            # -0300
+                            setattr(res, offattr, (int(l[i][:2]) * 3600 +
+                                                   int(l[i][2:]) * 60) * signal)
+                        elif i + 1 < len_l and l[i + 1] == ':':
+                            # -03:00
+                            setattr(res, offattr,
+                                    (int(l[i]) * 3600 +
+                                     int(l[i + 2]) * 60) * signal)
+                            used_idxs.append(i)
+                            i += 2
+                        elif len_li <= 2:
+                            # -[0]3
+                            setattr(res, offattr,
+                                    int(l[i][:2]) * 3600 * signal)
+                        else:
+                            return None
+                        used_idxs.append(i)
+                        i += 1
+                    if res.dstabbr:
+                        break
+                else:
+                    break
+
+
+            if i < len_l:
+                for j in range(i, len_l):
+                    if l[j] == ';':
+                        l[j] = ','
+
+                assert l[i] == ','
+
+                i += 1
+
+            if i >= len_l:
+                pass
+            elif (8 <= l.count(',') <= 9 and
+                  not [y for x in l[i:] if x != ','
+                       for y in x if y not in "0123456789+-"]):
+                # GMT0BST,3,0,30,3600,10,0,26,7200[,3600]
+                for x in (res.start, res.end):
+                    x.month = int(l[i])
+                    used_idxs.append(i)
+                    i += 2
+                    if l[i] == '-':
+                        value = int(l[i + 1]) * -1
+                        used_idxs.append(i)
+                        i += 1
+                    else:
+                        value = int(l[i])
+                    used_idxs.append(i)
+                    i += 2
+                    if value:
+                        x.week = value
+                        x.weekday = (int(l[i]) - 1) % 7
+                    else:
+                        x.day = int(l[i])
+                    used_idxs.append(i)
+                    i += 2
+                    x.time = int(l[i])
+                    used_idxs.append(i)
+                    i += 2
+                if i < len_l:
+                    if l[i] in ('-', '+'):
+                        signal = (-1, 1)[l[i] == "+"]
+                        used_idxs.append(i)
+                        i += 1
+                    else:
+                        signal = 1
+                    used_idxs.append(i)
+                    res.dstoffset = (res.stdoffset + int(l[i]) * signal)
+
+                # This was a made-up format that is not in normal use
+                warn(('Parsed time zone "%s"' % tzstr) +
+                     'is in a non-standard dateutil-specific format, which ' +
+                     'is now deprecated; support for parsing this format ' +
+                     'will be removed in future versions. It is recommended ' +
+                     'that you switch to a standard format like the GNU ' +
+                     'TZ variable format.', tz.DeprecatedTzFormatWarning)
+            elif (l.count(',') == 2 and l[i:].count('/') <= 2 and
+                  not [y for x in l[i:] if x not in (',', '/', 'J', 'M',
+                                                     '.', '-', ':')
+                       for y in x if y not in "0123456789"]):
+                for x in (res.start, res.end):
+                    if l[i] == 'J':
+                        # non-leap year day (1 based)
+                        used_idxs.append(i)
+                        i += 1
+                        x.jyday = int(l[i])
+                    elif l[i] == 'M':
+                        # month[-.]week[-.]weekday
+                        used_idxs.append(i)
+                        i += 1
+                        x.month = int(l[i])
+                        used_idxs.append(i)
+                        i += 1
+                        assert l[i] in ('-', '.')
+                        used_idxs.append(i)
+                        i += 1
+                        x.week = int(l[i])
+                        if x.week == 5:
+                            x.week = -1
+                        used_idxs.append(i)
+                        i += 1
+                        assert l[i] in ('-', '.')
+                        used_idxs.append(i)
+                        i += 1
+                        x.weekday = (int(l[i]) - 1) % 7
+                    else:
+                        # year day (zero based)
+                        x.yday = int(l[i]) + 1
+
+                    used_idxs.append(i)
+                    i += 1
+
+                    if i < len_l and l[i] == '/':
+                        used_idxs.append(i)
+                        i += 1
+                        # start time
+                        len_li = len(l[i])
+                        if len_li == 4:
+                            # -0300
+                            x.time = (int(l[i][:2]) * 3600 +
+                                      int(l[i][2:]) * 60)
+                        elif i + 1 < len_l and l[i + 1] == ':':
+                            # -03:00
+                            x.time = int(l[i]) * 3600 + int(l[i + 2]) * 60
+                            used_idxs.append(i)
+                            i += 2
+                            if i + 1 < len_l and l[i + 1] == ':':
+                                used_idxs.append(i)
+                                i += 2
+                                x.time += int(l[i])
+                        elif len_li <= 2:
+                            # -[0]3
+                            x.time = (int(l[i][:2]) * 3600)
+                        else:
+                            return None
+                        used_idxs.append(i)
+                        i += 1
+
+                    assert i == len_l or l[i] == ','
+
+                    i += 1
+
+                assert i >= len_l
+
+        except (IndexError, ValueError, AssertionError):
+            return None
+
+        unused_idxs = set(range(len_l)).difference(used_idxs)
+        res.any_unused_tokens = not {l[n] for n in unused_idxs}.issubset({",",":"})
+        return res
+
+
+DEFAULTTZPARSER = _tzparser()
+
+
+def _parsetz(tzstr):
+    return DEFAULTTZPARSER.parse(tzstr)
+
+
+class ParserError(ValueError):
+    """Error class for representing failure to parse a datetime string."""
+    def __str__(self):
+        try:
+            return self.args[0] % self.args[1:]
+        except (TypeError, IndexError):
+            return super(ParserError, self).__str__()
+
+        def __repr__(self):
+            return "%s(%s)" % (self.__class__.__name__, str(self))
+
+
+class UnknownTimezoneWarning(RuntimeWarning):
+    """Raised when the parser finds a timezone it cannot parse into a tzinfo"""
+# vim:ts=4:sw=4:et
Index: venv/Lib/site-packages/dateutil/parser/__init__.py
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/venv/Lib/site-packages/dateutil/parser/__init__.py b/venv/Lib/site-packages/dateutil/parser/__init__.py
new file mode 100644
--- /dev/null	(date 1616410450331)
+++ b/venv/Lib/site-packages/dateutil/parser/__init__.py	(date 1616410450331)
@@ -0,0 +1,61 @@
+# -*- coding: utf-8 -*-
+from ._parser import parse, parser, parserinfo, ParserError
+from ._parser import DEFAULTPARSER, DEFAULTTZPARSER
+from ._parser import UnknownTimezoneWarning
+
+from ._parser import __doc__
+
+from .isoparser import isoparser, isoparse
+
+__all__ = ['parse', 'parser', 'parserinfo',
+           'isoparse', 'isoparser',
+           'ParserError',
+           'UnknownTimezoneWarning']
+
+
+###
+# Deprecate portions of the private interface so that downstream code that
+# is improperly relying on it is given *some* notice.
+
+
+def __deprecated_private_func(f):
+    from functools import wraps
+    import warnings
+
+    msg = ('{name} is a private function and may break without warning, '
+           'it will be moved and or renamed in future versions.')
+    msg = msg.format(name=f.__name__)
+
+    @wraps(f)
+    def deprecated_func(*args, **kwargs):
+        warnings.warn(msg, DeprecationWarning)
+        return f(*args, **kwargs)
+
+    return deprecated_func
+
+def __deprecate_private_class(c):
+    import warnings
+
+    msg = ('{name} is a private class and may break without warning, '
+           'it will be moved and or renamed in future versions.')
+    msg = msg.format(name=c.__name__)
+
+    class private_class(c):
+        __doc__ = c.__doc__
+
+        def __init__(self, *args, **kwargs):
+            warnings.warn(msg, DeprecationWarning)
+            super(private_class, self).__init__(*args, **kwargs)
+
+    private_class.__name__ = c.__name__
+
+    return private_class
+
+
+from ._parser import _timelex, _resultbase
+from ._parser import _tzparser, _parsetz
+
+_timelex = __deprecate_private_class(_timelex)
+_tzparser = __deprecate_private_class(_tzparser)
+_resultbase = __deprecate_private_class(_resultbase)
+_parsetz = __deprecated_private_func(_parsetz)
Index: venv/Lib/site-packages/dateutil/zoneinfo/dateutil-zoneinfo.tar.gz
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/venv/Lib/site-packages/dateutil/zoneinfo/dateutil-zoneinfo.tar.gz b/venv/Lib/site-packages/dateutil/zoneinfo/dateutil-zoneinfo.tar.gz
new file mode 100644
--- /dev/null	(date 1616410450362)
+++ b/venv/Lib/site-packages/dateutil/zoneinfo/dateutil-zoneinfo.tar.gz	(date 1616410450362)
@@ -0,0 +1,1042 @@
+��\�]�dateutil-zoneinfo.tar �]@��Ċm�]'V�,}��"�U��EĂ#"bߨј3�D�����1�l��}��l�h,������|�h�{�����®�gggv�sϽ�73͂��7�V_z�7��||=�}
+�=�>�����<�}}~�~^^^����))�o�
+�(Rl�D���ȸ�%���?�
+uS�V�od|x����n	�-c�Ŗ��x�0T+�"�D���m`\Z�	�bM��xu@M��ȁ�1}jD���ؽFL?��!��=���~���x�~��kĄǆ��M��x�K<��]�~���nQ1}"�W�-z<"j�~�=����6�g����+��3�{w��>>�~ݍQ�Q^�=|�"<����Gz=|��}#�"##���
+�~�#�#zt���������#�������@�a��6D�G�z�|���Oz�����K?m��h�����uÖş�l͐~���q��^ܴ�Qq1��o��X���}w@̋��q�}~�v���~j���������7�f@�����9��7>"2>2���a���Ⱦ	/�����~q���{xDo��}oPx\��p.e�^���>_����7x�y�V�
+�>��w��:�Dy���\�Y�l���=�28�&��Uo�&������[�G�����t���ߚ���h��i�Jo�Q����U�ߟy7 f֘v�m��\�-Xg�^`�'��ϫ�4�PϤ�u\�_�2��W�R����EO��d?i.� ���<�b'M�w�(�ɦ�\:I/5}�^z� �̰�ҧ��V�Fz٦�z���z�j��
+%��9ꕲTR+�)��_(b������j��~T��9�V��G����Ƙ�G�M5���zv٤{�Mս���}Z
+�}KYu?�N���D�j<�Px�Q����^�dm���@����jݱ�z�$��M�?��� ��DoXa���eY���F��Cu����]�7>7Vo�����j�������,.��\3gʜ%k��ٲ�ȚM��r>wϕ���}�C�Y.�w=��z�s�N���zS]rI���B{��A*��u#�K1I*�H�^|����g�MϿ/j�,LjƏ��h�O�ң�T��+�у��E�%q���� ��ҭ�:�vF�3F�5F�7 �#�#�#��b���H������d�d���?�㓑c���H������1��q�ȱ�����1��q�ȱ�����1��q��H������1��q�ȱ�xg�g�R�3r�32���F�#srE�`dn02?�#��F�
+#�H�ad� �;��F�#󈑹��|bdN12��[��/F�#󌑹��|cd�12��=F��8��<dd.22����8/��g�{�Imbc�2
+���������WR<������ٗ�w�������3d���e��e�����;rp��o?o���OF����_δ���^cé���i��X����;t�y^s�e~�5�*9��4ұ��ݲ��ǎ%��;�~�iNy��s�K��w,;�Zͻv-���|pN��P`&�ᦹ�G*u�z�y,G��LS-�/�s��q�����S��ӫ�o����S��;=�Z~.ctd��H����@)G�aj�.��~W5��'�\�Mj�ym�y,S��潗�\l|�Z�T���E�^r�
+��4O�����K��������ܡ��^�~Qu�Zݛ"7>7Wn�|��t�WZ�Ok͗��Z����	������Z���Z��aM��6E�km�����5h���0��ڇ��+�3g����$��{�/�3�.Ꮊ�';cr���ts����-���_�;��fiF�oU�7=|����]��J.
+Дc��(D)؁����(0)�QX�(0��L ��I���`dr02A�DF&
+#���	�Ȥad�02y�@�L"F&#�	H�bdR12��\�L0F&#����Ȅ�Ťcd���	Q`�����LHF&%#���	$���&���"+
+l",
+l"��-�s���&��o�;4QX/����,
+�����z�,
+�Ų(���ϱ ��C"��B��b�Ȃ�Ȣ���$
+�`,�@1�HI�Р&�b���[mZ_�k���:&6:\�����������3���)�9葝�uz��w�~�\�����\}��kR��B��'���fr͜%k�l�$)��4=o���_D+��V$z�I��K�M**I�U*�,i݌���/?{�s =���r���z.#����G3���J<�+}�W�h ��Eo^חa��V7��`h�Mһ���������/m����/�.���G����;XI?��z��˱{��{�;O}O?�,���ų��	7�g[T���^�B��=/vwM���ij����z駞W�J���H�o�$^�"��}��������?Q�k�ފ��ʎn��k��d��vw����H� puлLK�-M�1-�5��Χ���aB6��ۘM����fu���_jA� n�6�6\7m�m�$p۴Y�i��m��ۦM�ț��7#o.F�d���y�i�1�&�fd�M�ț��7)#oVF޴pɴy�i�%�f�K~}�ڍ�dL�x3o�Z�{�����w��;C����L�,,����mj=��z����C
+�釃�JG�~����t,k�z��-��K��'�V�N��QO9;XO/��3��_�Cu{G�a�T�l�d�A���u�J�z��ҥ����L󬩷�����Υ��5���z������~��8�a��S�=j+e������x����z������N�.�\\��]����#������X����4�s����z�W/�ț��6�7��н�M��
+m>toh"��fD�M�<B�H���6+�	mZ���y3�ff�M�ț��79�
+mvF���;���wh ��n@ޡ]�|C�H���w����=�;���wh7!�Юb�݅�C��"�m|�]�N��"څ�B���5�J7Zx���q3����Z���H���<};��痡�����|;���3s�ŉ�iM��Ӟl�N�~M��c�:sd�:k�:��-L���uN�����~�r���-�苳�P�4Q_��}����jҸ,����UjYuuܻ�sfu�WS59o���t����buS�z}s�B}ˬn�W����?��������۾��]�,�V�A�Vs����Ru����.ꎛ���lw}��V���s���M��O���|�����eo��ޭ_����-�v:Z�q:��V�����Ou��rxg�z��w��е���ʑ��(G��V�嘧���r��X�Ԇ��Uclg��}?9�����C\��l� ۹VUl���]��e���cۥ��Ԝŕԇ9��W)WN\S~�yF���>��b�r��ʍ��(�������(�"V�n���~
+�d��=��s���z��ݻ�ȖkI)��R��s��.ǻ[��(F9��V 𡵠��P���NiE\�hEnoъ��l+vЦ�v�Vb�f����r����4�̰�e�O��V��l�0�\� �|5?�B�Jr�\E�JY�Jw|4��ʇkU�fӪ���U�wY���	�Ƙ]�G�&��c������F���Q�i5E�-5C��J�����%>֌��倇	Z�́r�����iu6��ꎭ�՛VR3E���	�4ʢ�(!7�pI
+|,����	����~�Vc`�5��ͯu��.w\���鰛�ٖO���u�m���{eK��r��+Z�z��.��e>�#�,ע��բKiZt�T���8-&e���t��{a'�϶�r�w�h�Z��z��Ա�r���帨"� ��r|�}y`>IN�(�%�g��<w�D�w���ǵ!I�{7j�>�F�|�6b�<m�đ���Q��7�?u��G�Z;�-�_��n�d����xϿ.�����}gz����<ߎ[����Y?�b:�쿶���W?v1]��*%� �jX�$��,���J��ɪ$���J�ɪ$���J"��DJ�%�Xb,�c�$�3$��x2��2��2��2��2��2��2��2��2��2��IhYlYpYtYxY|�;%fdfd!��%1fdAfdQfdafdq�@��N�7��d�F/�H����
+<%�8�D���Hb�Ȃ$Qgda��3��I���I���łwN�wN�/�V�rc��R"c�c���X��8%�qJp� ��)I��S���d7N	n���p㏁�<��)� )���S"��d7N	n��
+�8%�qJ.p�`��)�`��
+#'FN8�����_J<�����	����C�c���@��}���rr���Q,��E׉#'+FNX��S�b������	cÔ�9�al��ƈ)��uGIM�k�#~[c�q�#���q�,ƈ�d1F�'�1�J@N|b�8Pc�>�#� �D�1bJ�b���&ƈ/91�1�]�#ޤ�1�e�#>.�1�5�#�(�1�)�#�!�1�D��@��ǚ#��q�&ƈe1F�^c��41F\Sc��51F\Rc��41F��ㄋ1bJ�b���&ƈ��1%�W#����cĔğ#�d����I��;#'wFN����9�3r�g䄏aJ����9�3�`d��F��� �#�F6�l� 0�I`d���f��
+
+Y2
+�l�<0����2�I�H0�� ��`dS$c��悑
+#�F6�l6�p`�+�t�>��F5��Tk�]÷��óZ3O�rK���Oxl�t���zz��4��*���͘�9?�uq�՟-���?O�ӏ/�f�[��ܠi��L�l���fGn�fII8#��D޳���wN��o���������6Zv�jRN;�u�|���h���S�㙾֎_N�S�H�7�X/�0�ze��ՂS��_���-�']���ơ��>d�tsMm�V���KK?լ%�^��s�R�f�rm�f-�̏��Uk�r����q��Z�v�����b'[�;�Zb�
+�6���B�"�0��C�
+m����ͪ�qW��ٳfs͔�'|a��9�^���n�n7�)�dG>����*>ȫ�"����Z�fi�%0��d���f��
+�ŬWf{2�_��z�S�-��-Q^�9��GeK��,X� �n%@GR�ʍ� I*5�Th$
+��HP��D�"#�@EFR����BTdk�,�"�"�ٮ_k�"K�2����	*&�TJ$+�bZ-��i�� �A�D2#*�A@�TL$9��HvP1���b"�A�T����l�?��܀,O�"�j�i����ZEE$�d��/a��h���VH�"���$e�"%��H�2�5Q�� dTDQFE��QF���T�F����kA����d}��[��������2�7e��t]����"�CW���7K�����f�Ԫ����@��饿l�����)#���
+��������M+<Z���\�R�R�VW�=[��~�$gr��w�G��waT��S<�i���<���p���0&A_xP8Y��@��p��e���<�1��h����F��
+'FN�6�Xe�XxC���Ƃ�
+��F��l���1��[����^��U�}�<}^��e��5=�?Kڃo3�^d�����6kc6�mlIm�痭s"�hs�d��9�y.���K;P�'�@xQ�G�v��c�~��ڃ�	҃{凩�G��ɏSjJO��KJҧ%d�qO�L�ˮ��[3�Ӳ�Y��j�g��>��r�vk�e+e7}�5�s����WRn�h-φ�R�E6Y�l��o�(9��H�@L�`�`�Ph#�p@e�Hew�h� k�nr�L���oU�J��a-y �V����W^����cUJ�o���Z��S�\��Ry��
+��K}+W��I��|�Uv��*��Z�r%L��e�V�j�>����VV�њ�#�g��k@a�wp����շR���u�꟭�l,qW2^�%<<.��v]�ur�T;�M��q�T�ëZ�i#%S��Z�1Ӭ
+Z$i�=�[zLւv���*W&�B��U
+]=^n|�$5�>_kz���ٰqZ�uu�-:�h�)��e�&Z��L��%�kam�[�����n���PMn_���~k�Ó�R�y����R�1�.[�K]{�����-Y�9��q�ݫ��"�c�=r�E7�F^KТ+U�F�i��d�k�YVS�u���vrG�oB��B���-!����>������^�o1E��PK0��&�9�%�ؚ��+m�됙�����[���
+O�i�5R�iI�/��5��l�u�t����%6���Z���u.<�8_Sô�5���9���ӫ�P2��Y̘�h��~#6��F��?�23K��@b(��f��
+$�b����}b-#3���$32��Ɍ�fF0�o�j�}*�&�n�1����t|ab;#3ӄ��@b>�و�@R L&@?�)�&�h��EۄU�6R��H�n#�@�m�8ޕ��6R��BEۄUm�ʢm��6[�6a���Q����F��v�
+L�J�6au��#���#���#���#���#Ł�#Ձ�#�A��
+�(�l�B@R"�ۮ��bEB��T	�6R&��H��n!�a�B���
+�6R+��H�D���Y�D���Y�D��.~+�h��2+�h�m�2+�h���2+�h���2+�h�M��ϊ'�mñ�ʇv��m6RA )!�l��@RD��H�n#eD����6RH�RI��H)QO���+&�m��h��r"K�zIA�f#����Fj
+$EE��T�6RV��H]�n#�E��T����j�v).�m��h����F�v[n��d^mNVc���dU.mNVg��H��n#�F�-A�9Y��nk+�ʪ�v���+�7�m�D��U�D��xF��U�E�9Y��n�)��*�v��WV{T%]E��[���mZ��2/��<kx���Լc����a���
+^/�O������gdT�k��'�l�Q��3���N��-9g>r�:��3��3�<�s�y�ڝ��8�՝�̟�,Pz��`�Pg�'Q��ƪ�F[��b)�=�Rܥ�����?䲔W�R�~�R::����aQ]��e]e)k��,��Y>��
+5\,35pV�}�R�ly�������duV���r�j��[����R���^�,���,��wX���8��,���5q��}`�+\��w{����N�����o:k����UK�Z8���-ux:�8`1unn��u��Am�%��KÒ�-A�-A�4z��|�gșږУ���[J[��u6�IB>������r;�QO�--U,�9��M�,a�q�)s��6�<gۧK��c��_e鰭���W[:�x��ya��ˇі��Nvv�j��w���j����������s����%�^Ng�MKϣל1��Yz�������g�Jg_�%v�G�~�WՒd���3�4�2 `�3^��,6˙ ��$��9�i�$�p�������9lNw���E�#F5�������"d�䚮�L�����҆<��ug���My臟Y}����ҳ�?{��J��lP���c�o8���BH�#J�%��`D�0�D	Q��(QF��#J�%���U�DQ��h#J�}`@�B@��(Q	F��#J��%Z���`D�^0�D1Q��(Q
+F��#J��%�����D?t��0�DCQ�"�(�F�(	#J��%j=��DQQ�)�(QF��
+#J��%�u�D_R�0�(�F��#Jt�%JÈ�aD��0�DoQ�8�(�F��#Jt�%�È�a@��@�?�I`D���R #zT�W���b��4��N��%F�dF��F�"�+K��I�W������%�T�W����~eI�%Y�%i�](ή�#J2#JR#Jr#J�#J�#J�#J�J�q_�! I�(��}I�`D���l�4���<���D���L���T���\���d���l���t���|����!;������I�Y�`DI�`DI�`DI�`DI�`DI�`DI�`DI�`DI���eϭ6�V�����[��Vk�aZ~�Z3����:���O��w|��������}<3�z��li8=�u��IkV��l9����=W^��i����r�-댋z�w]dI.�~��[�������/�����\�s��S�|�����c���K�_�~�����o�OO�.Bun�1"u[�,��XRS����������M��?����Ͽ�g}��W�]��cr�H�q���|��B;�^�p�ï9E�3���[�^5|6�ꕸ'���q�'q�{q�'q�{�S�1'qm�%#s�?q�'qH<���U�"���Ȝ���[J����_J���cJ\���gJ����kJ����oJǔ�9��.���MEVF��Qd���u�w㷩����
+�_j��,��E&�D��x�����������/)������
+�{�7��������||~{����o��_ӳ�˚���'i���_��u���[��uQ=��%d)�햾��V����K�h�ұIk��#�h�B[i�V�.T��.7�/�o)�V�&���d�#_9PH��._]yW���|}�q9�s�-��=rn�$[�
++伋�+�g��|�5%��r��8�`�6r��0�p��\���R�lk�X��J�L�Z�[>�g�h%�����Vz�=[��'5%����ۛ��ms+�z�����P*4�$W,�_�Te�\��5[e7�\��>[�+��[Vڪ�U�����j��1b���Q�3z��5������Ϊ�Vj��y�j�ٌ��d�x����\s�#���r��:��u?|`�7�����EZ�[l�=��z�lA
+�j���o�ߛ��f��B���4>_@k2}���^Z�a�ؚ�k���<�f�RCkY���U���.Y���������!�텚J��7��[K*��;�{�t:�V�<Ʃt�2U����������[��O�����AZ��sl����kclѕji�{�l1�Ji1�Bl�.>�zO�T�8J�}���O�~m++�N��_N%��7�Bה�����9l	F��p�G[b�9Z�=����hCf��
+=�
+1�6<9D�u�m�U4�gʜ%�[�/ޟ>�ܔ�ghR�O?�������Y�s��i�3��=��_z�_N��]r�?D0F&��CDC%��ȄC�F��4."�Ӹ���{^B��D�yf��8��!R�<3DL�g��)���R5I$Qq�$�H��yf��8j����&��8jr�8z�I,�e�Ŵ�I61-k�,�e-WĴ�I����)bZ� YLˊSĴ�6�����iY����姈iY�51-��"�e��b,bZVML�*lӲ�kbZ�=���uR̽'qӲ6���$bZ�	q$�����I̽'�Ӳf��Y$bZ�UӲ��Ĵ����&�e�GA���iY�l�,.bZ�83����U^Ӳ�̂#�e�UĴ�TML�2b�HL�*��iY�d1-�"�e�Ŵ��61-k�,�e=��iY�bZ�)����HӲ��Ĵ��51-�fӲ�b��	�D	���	�����&�e�GA���iYM�Q�$rbZV
+q$����%�� I�Ĵ�[bz����uHL�"Ӳn��Y$�bZ�Aq$�����VI�(�eMGA�H�iY��Q�$�bZ�'�(HM1-k�8
+��SL�� �g]�r���iYQ61-����E�*�e=GAN�r���iY�XZ1-��"�e9�Q�$�bZ�7�(H_1-k���E",�e���,c1-k���E�,�e�GA�|e�Ӳ_Y�Ŵ�61-�\��h���f������q�2��������_���?}��ݺ�Y���ץ���u��jkYx����ϒ�x,����|<ٟ>��N~�ֺ��؇Fy�������&ɡ��YC�
+���bm��Fn�����S����R��b�y�E�e��֪O�Ժ~-��b��r_k[m��N:��/���޹Y�p�=kG�,���>�΋6�]�6�v?S����j����#�I�C��]=��ʑu�IQ�-Zt��R��Z�Ǉ���^��K�We��l;h�;)U�]��گ�NM;�ڿ�%9.j�u@�r|�Nցŗ�	�R�ļ�����7jKC�l)�WZ6��6|I���ȉg�����.�_�������%6�MϴI���g��&������	�kS��l�S�ٶh�s��R )����oy�_�'������#p 
+_��NW����U�"�w9��/~��(Y�]h����r`�Qp�Q������"�� 5<�����CL�2?� �ܜvv����d�/"B�-~��_4^�]&|Q��L��P�w�0�ED�!"��-ig���e&�D$�������L*�""|ѤԴ�C��2��AD�/�x)����̤�"�AË/I;;.���� ���EDH�""%|�h�����U@R��7����4G��wN4����#c#�^�Y����������q��7%�w�Ҏ@�W��$˶�>�mn:w\9mޗi�s�����r�L���N �ήz�'����V�I�[��V��9U7^|B��S�y'��ֺo��+Y�l��������4U7��[��@m�b�5�G?���kPÖj��Q����j��$����c�R�sw�&��$��f�V��/���H�I�yTo^�ڪ��u�ְ���6ʏֶՆ��=���>W�;WX;��v�O�v:�U�h9I�I�:^#�+�Zb�H����C�H��Ge?��LzT�V��R���[>֞���1
+[{�^��^y��g�V����_���o��cǫ�;'��������:����=��H��&z�p�����/Iz����v�_~S1��u�ăz�a1\���zjn���͆$���Y~^ip�va�G��%���3�������N$F1��ÅR(�p��?a$a���:���u��
+�PS�a�*��8���xQ��q*�Cf���`�cVX�����F�_a����:�#9��uc֡�*�C����:�#9΅uC5��:�#9�uG0r�� ���<�A��|�A�ȼ�A����A��<�A��|�a�UXq�_掰ⲿ�!aʪ�:�b��$���ęW�:��1��uG02τuG02߄u��y�RXB柰�2�u�d�a�*�����Ka���Oa�%d�
+� ,!�UX�pIX�꺰�:�_a�%d� ,��g>�_�s���[Ә��_������y�t���o��{C������7����Oo\)�)���C���K�����v;l�M/<���H��j�U�E�Tы��f)�{�^b�yK�5C�R��8K�S-3�EQ�o��p�m�O-���Y�'�^�����i�����Ż������i���2층U̚gG��t0.���$)Wg�(<7'�,N�-�h�����^�K�
+��q]��m \�!Q�{��xm m��5ɉ7ƭ��d��W��0~E
+�V��qؼ��Eh�a܊6ƭh�a�j�����V�!1nE�V�A1n�#�'oX�[�ƅ	�
+D&�64�ml���0�Fw���^	�ͺ5�+�OdLl���������3������gSX�����q�Ͳ����ӱ%����.��9�wӡ$����l�R�ܨjg���ڥ��85Oz��W���c�^�Og�+����$JA7�2�4\������'�j�5&���#��'��q��������e��1����Ϝ��[���8��Ѻ�ԣ�:������$��R����S���M��sl�%���(�8�d��r�i�.��G0�#��'�9��?�ū��W]�&�]}��������?ԭ��ڵ���
+��OW���x����:��oH�/�F=\����k�d����C�gɱ�c�Mk��|G�u|�3�=Zͳa�3�Ѻ�Y�3��H=��g��`�`�*�B������E*�ԋ��l)���^<SN�˿�Y%g�=g�>����]r1/��g%�s�ѿ|&̸r#���Sз���7ҷb�o��ߎ��!#KF����m�3�f�o��ߞ�� #o�Q�%P��@1XVM�[���e����: .<��������3d\�)����?�Q��.���iz7��*��_��,}"����c߇QNǢ���c,���PF&Y�v:�v,h9�}�1����ҍ�'�T�ď��'��H�6(����3k�Z������~��C����-�-��|�ߕ..��y)�kj��RjjG�a�;�?Nr�����m���@�bgA%����xg�J:Kn��,5����2���ʨ���B�:�v��,�t1��h�T��+��x䢣ҏ���vWs�CW-U�qT��6��Q}Z��F�Ef�������ϐ)N�ڱfo����O��>���\`�Ϝ���E5���p꾳��Zky'K�6��m����Qj�a���~j}�<K��J�!-Ԇ��KA���j-5��_��B.�QCw�o��7Yr_j:!���B��㦩-��Z�]���	U[�l��5���)8�ڶZn��O#��U��
+�v��S�&����5����e�>���R��W�.���{��u�J]��%S��:�ը���ѥ����=�Uc��X{�6���/�����}g�5v���/2֪�-��o���@P��tJ����P㾚p�SJ�sRM�[@|}�:d�i��Y갩��×���H�m91BuyN�2��H%�-��W�q��b�b�T��F��,ށ)�G(�khkƴ�g9$.����ŕ�$N=�J\�8��$�p�$�
+��ej�c�H�L\$i��l-�
+��'����=�b�l1qc��C q���(._�`�y�6'q��%~���2OqXq�_qXq�O�-+ ���8�੸�7
+sH|F�%N#���9��Ȝ�8n�9��(�-G�:ڣ�w�G��h��#��h���%
+@{�t �ю��c��Gs��hYYYY#Y'Y+�` �`d�`d�`d�@j ��4iگ�#h�����Jz�1h� �
+ƠI[��/��Y�!��`��cФ7�&���M��ڃ1�a�]� �A���a-�4�ƠI�0M��1h�& �Ơ���:�@Z���
+�D�,�)�na����cФah3����f&=�4i����e�61�ˬqbZ8(�:1-kƠ	�ڇ1h�?�A�b�tcФ��&=�tqT�"ƠI1M��1h�H1�e�J1�ˬ�bڈe�N1���*Ơ���Z*Ơ�b�5cФ��&m�4�+,i,ƞIg���{&���b�tcФ��&��4i��~ˬ�b�K���Uu�P1�ߧ����_������q������5x�v�?},��OoJ��#��^��>�S�̟�g㜐���M�D�A�VӔ�MtJ��������^(�]IHq?9#���)U��M���RmV[c���)5��=����7=ͽR����^7R|*L�-X.�/�"�ߝ�)��N%���C6�ܐ7�֒O��?o�RgBJrݡ	!��>2�:/J���#�A�)��k����	9����yH����M�����l��ƭ
+i>���E��s���M����s;�u��!ae*��>��V���F��v?L4���AH��
+;���t��(��G?�t;��u`��n�˒-햦�7�J�nt�DT�2�(^ %2�gɑ�C���1F��������iJ���$��y���������W��u�<Dm���	��oP�UJ|�c���
+� �1!uCʠ���w�M����!K�B�μg�����֪�#b����ftɔ��:�k�S`�FaO#wG���F_�^_��g)�1��7����Ç��'�l�(c�ȑ�Kц^Ez-u�P�)��s�Dυ�Α"Α��"HQ	'G�	'G�	'G
+'GQ
+'G�
+'G�
+'G��@Q'G�'G�'G'GQG�������������Ȇ��膓����(���H���h�����������ȇ��臓#���Ԉ	pj��<1N�X�F̀S#v��C�Ԉ%pj�85b�1N�X�F́z{�ԈAph�" 1����F��S#V����Ԉ]pj�085b�1
+N���F��S#�����Ԉ}�(b ��HL�c#6©#�Ԉ�pj�L85b'�1N�X
+�FL�S#�©c�Ԉ�pj�\85b/�1N�X�dAL��Ԉь�j85b6��N��F,�S#�é��Ԉ�pj�zFkˮX~;�<�GyM��GW(�Ϗ)���������֏�4����ww�by|�J|��%��������	za�C�b�ľ3���.3����ayR]>?ٳ->����?��������ތ�S�m���#
+���w:>���|���~ڧ��~��vX?c�i��s
+˳:wǲ�I^|~v�O��9��~n�X?/�������~���X^p�m,���_��Z|~Ѫ�X�x^*�/�h
+�/[�������-�~E��XN
+=���Q����������b��\��~̓�X��Z?�_w:�������-���
+++��_�:��'w��Mog���&b�����U�X�7����?����OX�m�!X�]6w����r��zy��������N|>es>�ciA��9�s���A0������ۍ��[ay_K	�w����{yc�����`�h�?����sˇS�|�h|��������X|�q�?��X�?9!֟�˧c'a�L�z���-��-Y���5�ح6ޭ[ݻ���6ޫ[�����O��^~ބU�?������#=�?//ϗ�3�����߳S�4L{-�om�>��4c���̸��Y�]e[�w�����y�+Y�m���5+.m�SI�~�HҎ����VTve�`۵��m��=ʞ	�m{7�P���jsL���o�j;��2���;m�"?�د	�o;Zl�r�Bk۱��('�ʉピ���Nm蠜�룜�3����sT;��S�v���{B9ߠ��B�M�ŷ�.����,�\.����Gʕ���~�yF�zd���b�r}��v�9�>���f�1ʭ�ݔۭm����W�x���\��r�@۽2Y�{���?��<8�n{��j{�)Hy~:�k������E�R����y,���;X�qݪR�
+�Rp31���U��R��y2�^�(�I\K��&�%G{��i��q�g��wq�a�ŕ�2��4������Aׁܴ��1�A{�ݠ(��EF7(0�A�ڏ��ݠ���v)Bp�]��rP�`���H��
+� EF9(z�(G,sa��"	�M堈�(EF9(�0�AхQ�0�rP�a��"
+�mݠ�c�R���I}�N��'Q��I�8yE##G$#G%#G&#G'#G(#G)#G*#G+��G�k�Q�)rq-?�^\Ï"X\������F/3:��s�ݛ���������3�:��g� J{]���mg3O�Γv5�x�vF;�����G�7H2P3�h����jx%��|"O���K$���s���ɧ�K>3����uw�η����l�㹄%��=�/t۾�b���K�-�t/4�r��^>V5��ӾLΝ|���M��|=����A������o�[�|�]��m���S���w�UƟ�r�[a��^�p��Y,��w�\h`|x���G{�&?�R���3�-�&�Mv�ea���ɮ].-���br����Y�]��*^t�6��1G��?o7�]\���"c�m��M0���g!_��%S��t��N{�	JRoȟj�0�G���Q�?�>hH~��v�LOe!}�}�������)��+26�[d`ڿ������i?#ӾF��-����~8 Yd��)��)��)��)D.�����b���b���b���b��H���K��B�8B�XB�xB��B��B��B��B�C�8C�XC�xC��C��C��C��C�R"S,"S<"SL�*����.�&��'�n�K�q�ȱ�����1��q�G���N����
+�c1�b;�9�1���Rs\��N��n��n���1�(�������A1=�/�<��2��zs�A>�C1ط�g?����@��.I���s�oO���!N�p����nx���o������7r�{g���e�7���������xye����/�s=�[i�1yxZ�e�iG�(��l3�}k�9}�m���6�;_*���DNW�M��k�l�_��E���6ea�j����Km�R�\֕���(�vP��\YalKgPVNv�V�Mm��V�֘k�ֆvT�d�z�[r�[�
+���6�8d��l<vS�t���9���e��W��U��J(_'NU��X���`廖�l[���m5�V��?b�~"�mg��Ω�]�Kk�����������>����+,��%�y���l;�T�~�v��c���N�H�ʑ'��c5&*��O�xU�O�ګ����̚+b|��ݶ�Blg{�+�ZU���l�r�.�Y�\*QYI-fK}�S����r��5��ӭ��_�S��~`���J����6}�p�fx�
+�S���O��[�OI7���s�����SC��oߨ��۔̕�+Y���9j*��)�.�Tr�}�)O7���sUq[.�A�=�-OR~%o�36���|-���e[�9���o�
+��Q+lܦqݣ-�P+zn�V��{Z�o'i%~�B.�t�\���r�	�\fvoY�'��v3�l�0�\��\���\�q�b��r�*յJw|��ny�ʇkU.�Ԫ���U�qP���	�Ƣ��G�&�0~������F���Q�i5E�-5C��J�����%>֌��倇	Z�́r�����iu6��ꎭ�՛VR3E���	�4ʢ�(!7�pI
+|,7ʲC.��|������7En|n��d�b��f'�͗��Z����	������Z���Z���km�4��V����k��j$�?�_�p�]��'��a7��-��e�U����r���ʖn����W�����]vk=�|&G�Y�Ee_�E�Ҵ�ԩZ��qZL�`���0���NZ�m�����b����,��c}��-k�qQE���������|���QHK��ʉy�j�����׏kC��C�nԆ}��6|�m��y�ȉ#�Wo��rK�'3g}�Mt���;_��,��6�C	\r�E���P
+Z��^mА{O...|��b�]��^�.9v1�l��A9�O���G2�AX�R�b�$��e�����$�8�&I,#�,#K-#�-�$��eH��������2��R��r��R�$ɸ�(�2.5JҌK��<�R�$Ѹ�(�4N�IR��x�\���$ٸ�(�6���%���	dǥFI�q�Q�s\j�$�%Yǹ^H�q�Q�w\j�$�%��iBI�1HMr��i�|1H���$�G��R �)
+`p�R�)`p�R�)-`p�R��Z�"�"�4�9�
+��)]�V�c��
+��)u ���WN!�;hM��AkJ+h�Sj��]yqК�Z�j�2�t��9���)�eN�-sJ?h�S
+ 5�! �"��)�eN)	-sJKh�SjB˜�Z攢�2�4��9�*��)]�0hMi�AkJ_/ZS{aК���֔�^���9�8��)͡N��pJwh��W���,����"��i�pJ�h�S:d�ᠴ�ȩ���#Z�-ŕ`8M2r�d�t��)���&#�NFN�@J���F9�2r:e���i��S+#�WFN���f9�2r�e���i��S/#�_ �`FN�@JŌ��9%3rZf����陑S4�/�iFNՌ��9e3r�f�����H)���8�R9#�sFN錜�9�3rzg���i��S=#�{FN����1#�R?��(�3�@D6 HV��� �,#�F��l�"0�M`d���v��-#�F���d�B0�� ��`d;<�?�����Ed-�^0��`d���V���#[F��l=�~0�ad��V���0uj���ĕ�Ț0�=ad���6���
+#�F�,�!���օ��#[F�1���Iig�/$�\D���m
+��
+#�F�8�ls��0��ad�Øa{�+ۃ�=��*}k<<3���_��7x�����^<Q]��;�S����k߾���x�K��f��/=�9�|;��������4�H�|�����y\���d��2�x��x8���=�_}Ϟ5�p�ҿ<���A^6�����1����L2^��x-e�lg6�yfkai]�,-/���q���~�S���z�h��̗��K�f�o�mϚk��͵��ZFs-����\�{�k^��"8g�'�ٞ��~鵽�[P�`5>}�o?�����̨�ӵ�G�OÑi�ss����gʃ���n8wnOu�ڵܲ��ʎ=Kp�|.�e�T�K�O��Wrn�\9lq�x��~um_�ھ������I�U}p��I�[;H�W�5�z��,�����w��w�I��fU���Szp?@��c룓[���GY�l��>�N�fV�]�/[3�젺���2��Q�T�#e
+̧g�uؚ�|���z�-K��5��z��_[s��T�L�#�]�C��ݭ���T�ߦ�T ��Z���P�^�XAk�Gz�!R1u�^��Pk�j�%�H֒�U��,����zk�U�zT}+|�TvHg�\CE*߽�Z�Bkk��ߪ�����K���_��ZE�W�Y�Z��j�%��ߜ�kLX`��pz�rx����j|����ӧ���[o���m��������>s@�dK���暩�[j���\;e���G�uv����l�4�Y�� G�������8��������Sq6r�2����Y����w6�`���	K��͎���;��{`n=��l�t����M���̯>x�'�t�gi(����#d3s��,�A8�y�8��U�=���͖���@�m�N��(@q�����?8��9z�᜾� qޟ� $N� ^� n� ~� �� �� �� �� Π ޠ � �� � �K���' q
+5 �
+5 q5 �5 qǤ1�pQ�ub+߰��s��;�
+�=ll�j� j�!j�"F������f^������������&�s�2_�v��������jd�/j�0j�1j�bhcJ�g��(��Q+�Q+�Q+�Q+�Q+��gΣV ޣV �V ��Vh��:�Z�� ��j���. I�@��
+����$�z�Z�4���ij��
+�!�HGP+���V =A�@��Ⱥ$mA�@�$�A�@:�Z����
+j��
+�;�H{P+���V 
+B�@:�Z�����ij�% i#��4
+��j�*�
+�W�H���[@�.��_@�0 ����#-�;��8�����^�����?������{v��i�q���ݿ��<��yU|SJ�(G������B;7���.i�=��}�w9�jݱ�{�|��Q�]K�ݧ�M��4t�?����d-��/ƚm]�x<���I��x��9�4���e�V{�A�9\ճ�̖�Y|ڳ��5g+bʮ�7g�;��&�3��L9�1�\���sۛ��l�iϻj�Y>͔��G������}f/�i��pš�"�z8�f�b/V�����z���%�u6�<��(��������2*&�����~�Le[:�5?o*_��Q��6S�B�9*9k��������gƛ�]㨺�����)��3��kLMtx��0utxF7qx�������1u0��:l��J2�=^o6���0^<�x��Qs�ZG�������:�u?\c�7-�a���j�k�=�\��9��"s��}s�j����&������h��xG�;Zr:̟�lnY�����c��%���|i{x���w����ێ����;����sG�y���st�˖���=�:��49,�>5���b�^}�9"���G�����̑�ꚣ+����(昬�1�2�{]�n�=���Ͼs��	�#v�VG�6g�_8��~��7�1��G|�ގ�'ߚ����7'�eN�2�<�^S�1��j���hb�,�Gt�n9����?�x���eK���U)�Xe�k�l�����R�g��fo�vM�����y�~a��^�;���C��؇�=1��X$&±��H8Vb%��	gJ�3%�b�*��tb*"�U8������@b.�"�N��H,�S$&�)2�1|A���ߜ�
+�H�]�&8Eb9�"1���H��C$���p��~�U���p��p��p��p��
+p����|��Bt�wc��N��N���}��&�r�!�z IA�IE�II�IM�IQ�IU�IY�I]�Ia�Ie�Ii�ˉ�_���)���)�� I}�I��U&�� %�S$5�S$E�S$U�S$e�S$uB�"��S$��S$��S$��S$�]��f�UNH�%��b������r ���*k@V5�U��2���*�9DW���Hj�n1)𔸚+��Ot�O
+'H*(��w�>�!�Ƥ���*�kLʈ�1�#�Ƥ�p���Ȅ��@RKt�I1�����rI=�5&EטT]cRRt�IM�5&EEטT]cRVt�I]�5'�B�*��q��
+	�-�Ƥ�@R]t�+������[L
+$Fט�]cRct�I��5&UF�x��
+	�3�Ƥ���
+>�R�kLj��1)6���#+7���#+8p��#+9��3Y��5!��ʎ�1�;���Y�w������^5�������{������'����_�W�����/)���o����b�cb#c���������?���o�������w�]�=��7[�k4�>47����yְ��fK��I]m[9��iU}ɱ��j_S�Ǽ6`�i�k�c}���秙�w�oخ�w��5��s�q�ԇ�C%v$�nc?�0��xmӓ�����c��N%�4�3�B�\�x�3+U���ma�*�Nʖs�)��7��?)`����$��wL9^7��|Ԕ�]�!ό
+��=W䱇��B>6�tO0��79�]��I���o��p�1	5��I��GI�G�P<4�,v�P�(�+���P��={��
+�w��W�fsR���U��J���]{�Qo'՘����="�`g�l��e�1y�9j�151��lh�˝l��z8�(�5we7\�j�����֎�����6�Yx�^��rC�w��M�w&�����{iR`�'��&&y�2�V���}l
+���r3���������&�RRӕ5MͶe347�����<��฽�0-�U՟M�;�%��<fj���n�U{�")��w���Щ_����.���]Ǉ&u�j��TM
+�1ٻ��N�(X����FR��2ۣ��2D�~�}��fWS�~������+W��n�;�cCl�E�~C������w��W�����I�Y��o�4�Bo{�cҠ���'�'
+��a�a�;����3��a1�ads9��.�.�f{��Y��F
+�=�ӧ��d�@��]�5�+��a�����g�К�
+�������U����Z,���y�9j�U�E#�bqs����&���&닪�9��`�c�#.c.�s���*�y�9a�m�#~��$���.�뢺܁�3��{T��}T����Q5�`��j$=@�H����tU#i�(�sc�5H:�
+EZ��H��I3P5�n�j$�@�H����4U#��F�T��'/T��+/T��/�W��3�W��7/T��;/T��?/T��C/T��G/T��K/T��O�I���S�I�P5�^���;,�n��q�Y�D��.�Y�D��ˬgHs�i�I�P5����HG
+�jl�e�9T��uW �C�H�$�C�Hڇ���U#i �F�AT����IQ5�&�j$]��i#�H�gH#1�@:�j��RT�*�Y3���_ �DUI����4U%�(�ʕ�
+C���*ISQU����$mEUI����4U%�,�+i-#�-�4�#�.��U$�/�H�`T��è"I�QE��Ϛ�*2F�?k3��P��Ѩ"�E��Vc��5�4U�M��ݨ"���g
+G�R�?k9��I"�Y�QE����$mG�Q�?k<�Ț"�Y�a����g�G�@�?k?��"�9���<�*�r�H��")'��%�s���jӚ�>��]�Z� �2��B�|�^��)�> >2.t����/�����_������ϟ�bB�k��
+�M�f������������{$4i�g����Lڻ��ݼk�x^b���s�1����?��ˢx�O� ��Ȧw3<o������/���˾֯�=���k�~�^'�������=�_� �0��m������x*��c"�c����ߞ�ןJ�/���eI{��|��֛Kl��?c�v��af�;�Y_�6ϙQ�4װ�0oH[��eZ���JZX{�i�)���%g��iX��]\Ow�?ql"IFB�u���C�_H?$�0N��[G��,�֘�3�m�ױ��YX��s]���!9��8.�%��~�o{���?��y6��T���N��s�����9�o���_�5��j7~�F�!���u�`úO?�+Y��J7�r�a�DѸ��f��/cN�&�MO^�m:��uK�=�-��r����ǚ{c����Vp޶mD�a��ow�3
+;'H�]ٰ;���K~�!/p�-�t�׍Ͷ����=����%�����������f���q��Ѧ�� _�l.�}V<1;ʬe>-�L2�Jo)�s5�m���%��G5�����K�Nk���_>�K��.7���U���7_o�g�>b�x��p��~bI���tKk��/-�ݽ��_f���k�_�S_���z>�Pת�*ȯ>������k��Ě��Z����a����-��������j��M�y'��-�ߔ��`��ג�p����O$t�E��;�5���7iwOsi��ܴ�	͵�=���2���f��Eb�m����lb����Z���[
+>���4�ɀ�Z�>/�u^�y����(� z:��{-�_��&v,x��9L�����C4�s4��Gk�IW�~��4��ߚ<�k���s�
+
+��'5�C�������.�~��bόI�^3�ޱ����ω�|O��Z0Ms�����)v�����a_s��g���#�?-�?����#��yVd��g�i�<��?r����4�G����JD�"�#Ǌ��'�?����H^DdG
+���5�G��#h�\��?r����l���E�GN�-�?��H�g�?������{�WT�)�<�_�u�PI^�wK)��L>��!��|��}zl�2��)�a}�'�~X�X�F����@0���@p���@����@����@0��ٺ
+�H��@0����
+Y�'�G�~�H�~�I�~�J���d��L���d��N���d��P��eY�R����N�S�Hp���@���_ٺ
+:K)β�ֲ�޲�����������������wP<f����Hp����1�g���h֡Jp���Y�H�e��Y�Hp���@����@��@0����H����@��@0���@p���@����@��@0���@p���@����@��@0�=�Ep���ٳ\��Hj {����L��-R�n�l��h]��
+��1�X�!��:��k ��u��z�:pI�`#�X�������%RCЉ[_C'��|t��:qѱI�
+:qu3:q��l��ѱI���ؤ���J��w��N�T3:q����}'���":qS�1�G�_"5��K�.1��&�/����%R���D��H�b���^1_��,�+���|�jx���/�/���%Rǘ�Dj�H=c��i�_"u��K��1��7�/���%R瘯Dj:q�cZ�Љ��}?Z�Љ����N�4vLk!:q��cZщۃ�ڈN�h��i�D'n7vLk%�H�|����ʝ�'�ʝ�;�ʝ��X�w�X���W�/���%Rg�F�E3���;u�cߟ�^6���|%'t0�:��%R�ѩ����&3��e�/����%R�+w�+u�z]�S��X�S���ʝ���ʝ���ʝ�h�;ugk�;uW��;u_+w�+w��+w�v+w��b�NݎZ�N��Z�N]�ן:u1_��]�U���|��S���N]�ן:u1_���|��S���c�n���\Ñ|ٿ��{~��u�����q��~���_��4���������������W����c�93g��d��v���#"C��j��tuL���縃�D���C�aa��]�g���ҏ8������ȷ;�7\/,Z(_�HE�i��I��9L>�)�J�!��Όh!��t�΅v��?�_�p�.�h�_"�ͥ�%��s��+�w�ŻwrW�~��L\!����Р�\Z;�+-���^�pe�0�^^W�<�W�ڍ�9TN��5�I�r���rMs�\�X,;����>�o��u���L��͓����)r�MK	�y�p��	I&�%��(�YB	_	�w��x��"7�]ƹV��]o���NՑ����ͷ]����-���{dɭ_'���7
+�����
+�c(�_�=��Ȗ�_�$|b�ܱ@��2�ʝ����Ѳa������Nn,��ZW(�<��pT���F����	'8B��F�����[�F������Iݷ�=3ޗ{E,�{Ǿ({g�!�������>A-x���=,�R�}�������§���7����d�ǥ�{��ܒ���#�"˪�Q9R�YwR��]�oԇ�8Ej�"}x�NR{��GĮ"5w�.�o�cf�I��Vȣ�I�N3��R\�sr�G)~o9�������<��ii܂0R;+�	)H�<�'F9�Z�C�p��ȕ�d���6�ғˋ唠RJ�>9�e����NN+yNz>s�����4-}��bNG)}�y����o�`���߯`+��
+��Z��yK=�.~��O��&լ����E��Ȉ=c}��f�l$(��T�z���9�L-Ԁ�+�+�=� L�aj� 	��!jo������C��A��e�e�H��o���HPi2�_��7L������z�P�옢[� �`wj�_�tg���
+t�8��j�;���V� ��V� �5��}�`P{}d����A�j��A�qP{]9��ldG��A�sP{��H��=�zP{e2�^��W$C�퓡�l2��:�����P{_pP{Sd����������֙��	��A�rP{l�i��L��������1ET6Tej� +�^��wY��+�������-�^��w�������+��>����������P{I�^����C�jO�����P{e��hj�_��Ka��"7Ԟ���+����rP{G�1Es��;��Rd��cb�!<��+Ez�=\W��P{�����p]i��ː��HP{�qP{t��w9��j�j�G��[(C������d�=��7�����C�ڻ%A����cZM��r$�=wj� �y��@�mԡ�NqP{�t������:��*jo���]��K���V�P{�$���2�^	j�9j���ׇ�
+��Q��;-A�qP{:�^j�$;��jo����J+��~jo����J+��+�pP{����A�a�Ҋ���J+��v\U���9���=M�/�?4 O|$�/0�?���߷J��I�ߋ�ɧ̜yҒ͗EuV����3.{���|�㊙��+ۥ���<�P��������+�C������}$}��[\[������b�牒5�K[�x��i|1{���>���a���ѣ��Y�;RN-]���	}ӹ���[�]�>?�5+_�ݹI�bΧ�m�����w��/�;"R���#�]�mw�4��]�<�ҞWu	��]�`����vh��������ȷs�؎8O�?�b<Z��T�D�XX4[:��%�(w�tbv��e�K'�O�{K��ډgF4��z:��B����.x4�/6��]�u]�t��v�\�~��F�x���⵬��d�x}�z������ҭ�i������w��J%�j?4�.�֎�JK,��ݴ2{W�^^s�<�M���B����f�ԪO��Ǥr��xO�i��Z���a�X[�&��W���r�Q�)��^��Y�9����2�k^��w�h
+g�鏧��'B�F��5�0O�q�zZϺ�K+O�i�bݵz]������d�����|�>�}ݷR���D!��[Θ'�|Jo=6K{2`�ަ�\���*ݣ�dͣ|���8X�,Z)���Y�;K�X)ze&H��E����a�����&��~�a���B1����+vvp҃�Ղ�]ӻ��\�{���X��=��c��=5'_z��Q�1�S�g�t�W�;R��1�;E
+	�-��\��z��B^�Üzja���>ŭ���gK���i��[���%������)��An
+���yb�ݛRT��b����}�f�y]�._�
+]Q�+zM��A6w�6"v�>2��&���bf�Gy-�FǇ��N�R\��W<T��h(���.%Ժ)&�u�ƞ;$�[�U��6!�M��U�%.ץ9�I����P��]O�HӒ�OH)AĔ�mR�K����\J+*>���􂽻8-=^z1�]L&M_ĉ���_Ϥ���ox��/m�x���A�!)�l95R�C6��`0�t5�
+��<	R�2�(��*	�`��!�	 �`��"�	0�@��#��@2�F@��(%aa�p��G�'�	x�`� (��DvL���LY0L ��TY0L���\Y0L ��dY0L���l�H ����/[؟�/�	 �`��0�	�`��1�	 3�O@R?�Spf�0h�f�0j��%�K�`X
+� �`	|�K`�
+����^���Ȏ)����;����-�xI�%0N�%+��`	<#��`	�a	4�`	8���tXm����'��uX�@�(����P�؀E?I�`�~�����7���K���`�ORH �b�ORP � O�`)t�`)Dk�,X��X
+]��')8��t�i񁥀��!��"�{X�ӌ��%X
+iq�����)X
+i����L���E?IႥ�2�$�B�K���R�a)��`)xb�OR�`)��a)x���uX
+uEX
+��b��,�I
+,�o%X
+�DX
+�Ka�K�r҂Ka�Ka�Ka�Ka2��r,J%,��,��,�YX��NX
+	,�@�B_	���K!^G�\*�R�a)��:�rEX
+N:,���I����Ka�K!S��pU�� k��%X
+�4X
+�J����ޑ`)Ĉ�R`%�
+Ka5�R�a)�+�lX
+�uX
+�5X
+�%X
+F��8	�B+�B�K��K�[��pN���V)��o�J ��BX	��Rhч��Z��P��RxM���A��0^���P���_���^��0N���@��.�RH��@�,���a���V!��%X
+�DX
+]uX
+�5X
+n:,�
+2�+%�0_)����V!�0_)ဥ��J�,�WJ@`)`�R"K�X
+a,�*b򛈉#�r@��8����S&&�$L|��������������?��_�#~��[-3'KY��AV�U����^��,Ϩŭ���2`��j�y���j�����۹=��)ȅ]�C�O�B�FLSy�]y�qy�
+�֥
+�֗�*���%yk,���yk;��uy�m���� o�� om�#o�����䑷�����P��nS��.W���� o�W��f��[���[M<���<�[��㑷^�Y�juT��^Q��~� o�*�[�VB�G�!7w�^�H��sA��l�O�����J�����i�����#�'(��<�{_e`Juy���9��Y�@�
+�-G���[�Os�]����]�l����H�:�?�;�������q�<�+1�fɣ�>UF�'ȱN�(q�}��%��K��kQ�	k�*c�]��-ϯO�L~b��%F5�9HY��'%�'��������JJЧrJ�q%��95�%�$E~>s���"OKYy1���>"N���M�s�
+UT�W)��R��Bq��fϱ��	��'8��s����,�,�	L2Ø�$���d�1�If�d�1�If�d���<[3��@&,�,d#��LX��X9ku� �N�R����J�l�R9<�T��c�O� vl�)ĎM?e�*_9|���
+��A���S6����
+���M?e�m�J� A��� vl�)l�W�+����I�r6����
+�P*g�۔���r�r6��R9�W*g�|�lp_94���|�l� P�l�*_)$�T9��T��U*g�V�r6�6v�"�"�;|���k�@��E3��
+��pD~�"��"����2�<vX�h"��(�!�k�@�;b�/����� �	)"������N_A��EI�|D~�"��"� ��c�5�� ��a��(�<vX�h
+"��(���a?��+�<vX�(�l;�Q���kuA��E_y�W�� ��A�1_)*��c�Rt��|�(
+"���;�ڑ|�s�w��+����1D��. �
+���c��s�O^U��G�������M),�7���V�+��Ic����ԍ�.
+��l~���3���H�;|elQ�U#�~l뷺��k�\�����
+?����{[?>3����K
+?���7Y[gZ��~�nU��O�|������}�ą�������9�|��m���鷥A��-�_����'���/73||�Z��ؐ�b��	ږvm��EO�޿z���vu�^�;�aΗM��3��������|}�v�p�� <�W�j��`��L��kk?�y������^�K��K�#ט�5t�;�+��(�r|�SQn������d9��c:��j9���̳e���7�u���aޅ����o�]�Uh���P��s��+�>�+ޭگ~�k���բ/QM��,�ܘ���f�˭����#F[n?���w���ݨ�xXJk畖��߽�6����~/�v^y����Ky��j��ɫ>u��1颩�x�RӼ�T�������T[��R��cr�޲8�Lu5�R�țyN��������h����p���x�_�	��F��y�a�썃��5iw��Ҫ��)9-��n�\�oiv�nr�������&�u�,-�.6	S��j9cTl���n�+|2`ޭ6}�3m����h��G��ɞ�O��,JNn�֙�Q�Z�ze%wʮ��lx�|�O|�-ߤ�b�B]n��(6�m�@�7c;�*��l͙�s����}�L���n�&�鞵5�ǖ�3O�Y����>g��3�{f��1:�w�!6�;$9$��ؐ�So�zu:Z}+̉?���V�+7��]lI�w�Al�����7:�"�Y��tw����4�Y�%rp�)�n�%*`�)�L���.ϲ��]>/o�\���)y�3T���C�Fľd��%O_b��e�5�2:>��4��j�+�ķ-3����$�*2%��c{�f���}��¼	)��Y�y��/ڥ9jޤ�=��ė�&;��'G��%�mI	�aJ)�ؒ�2ڔ���%�$��|�dy��a��>��bNS���M���>��'}�U�g_�ϼ;�.ߵ�{Eŷ̄+\Q
+�	(���y�_�c���t�Z#�)�	�	M�OhBB�����
+܏�u���TY���{������ϕA񥿁H��4����H�`*S|W����1�W���2�Gp�)>��L���#�\%�eQ"�^6�e�"�`)f�"�b)<f�"�d)\f�"�f)|f�"�h)�f�"�j)�f�"�l%�f{��fQ"�o6g�"�q),g�"�s6Lg�"�u-lg�"�w-�g�"�y-�g�"�{-�g�"�}-�g���gϚ��FR�\�T���9��"GR�R&��)eR#X�H��I�`�#�l$5�u���FR;9&[9N0!r�� r�0!r� r�1!rt� r|����"GRc9��96dߟ�<�z3�c�]ȇ�9���L�gy�U;"�\"ǭD��	��"ǗL�gX9ƚ9�� r|Ƅ�1Ă�qT"G"��<D�����!rlcG�X;����#�i,r�hG��M"�=vD�M�/X�T�1�����b�	N��8sLp*޲���d�S!Y�T���b�NEb���v8��T��p*���T���T8���hd�3�w����m;��F&D�v;�Y�m�3��[9�M������l�S���b�	Ϭ��bT,��u��TH�T̻�B<�b�-8����x;Nœg�T$'é�uNET2��ֱp*���TԌ�S�ʎi��Sx��W�p*\n����Ӻ
+���X<�ZxNŚ3�so��x��
+���	g9nM�SqNŒd8>g�T�H�S�?N��d8�X8!�p*��S1���Ng�TD߂S���SэSN ���A,����p*�Lp*�,xf��	N����~vLy��l"�"�����8��9��T�˃S�k�S1%N�j�S1$N�Kv8]��T,����2���a�Sd�S1�����"�S.��Âȱ����N������ca�
+;���<D��������|��N�Z;���<8�������|��N�+�6p*0_)ǁS��J��
+�Y��<�i��H��_W?C��M����1ǌN�;-���������߀Ά*��O���V��ު.����"�m��4���|]8,\�(��7��
+���h�~��M�����k>V�r�'f��h�SՓ	�r*=Z=6P93��z��_9j�?>����U�pÏ���&\:��_>W.\Yw�/ޭ	W��e����-��9E��۔��6���������O�����PK�-�h0F-������,ܽ0�/��	��L|yN�P��=�-���Z���ZWxlR;�F��Zs��R�g��pE�-\V���*��^�Q�*u�,�ޑ���m�ZS�`�'��\��lEx<m2�DB��(z0�)4�ҙo�(���4��"�VP\o���N5Q�4V�o�Aq_W��XzLR:-glUZE9	����&���9��y���>��(/V=e޳h����(�C�:�cA��9O�-*��STü^�O�ۂ��'��d�P-%�#J���tv��j�A�]�.w��]w�	ݎ}�w���=�|�?5�T}��7ycb��3c��+"W���쭪!����B��k|h�!�i<��P�Sܟ�8[�wx�>m��c?%b�Tռ��2�{�:0�W�uS#�P"˚�Q���]��u޲�M�./���(�m��gh³���ۅ��i�^��̚��򲩣�*�N�Ը�h%�8C������&84W֚Ա�*�q���n���PabV9��)Hs4~R`]!)q;?ٹXH�X�'W�QS�lJJ�e5�e����WM+�P���R_��Q���U_�1)�#&���W���Y�����h��J��[��[�Ɉ�T{3)�fR���c�>�c��r�Qz���YA��VΝ۲��"S�=�C_�C_���[ ���
+�<��	������Rt���V��?V���P�o)P�SU�kI���V��*h����_���P�x4�v����g|��1E'��r��u�	x��u]ƾ?E-��"�z�umS���+P��T��W���zu=F���࡮_����P�qԵ�����0�b�|�B����" S��ࡲ> y1ED�k�����S���F^L��z/u=W���⡮?����P׊ u=���N���Pב� :����)�p����_E@} �U��������>���VvL���(u}M�������/@]g�� 4Ե�C]�S��G�P��T��t�z�
+u-*P�ST��R�����u�̎)�� J����� �S�G�� u}���.������B]�C]��P�o�Pׅ*���:W��~]��VU��	� ��5��Ju=� �b��?u��B]�U���P����*� :)P��*� x} �T��� �� �H�����~ Rq��x��r�zu�	P�y����uu]�B]�W��m*��T�z�
+u�~ R���
+� �b��9�H傺�P������Pס�u9�> �WZ՘��|��
+�X��^�~�
+�WZ�1_iՃ��|����VA�k�WZ
+��'���_�����A��|_�
+��<.&y�sqSc&���ϧ��/�����#����v����e�yn?��n���7L�g!>z�^c�����-�
+{N�����Mu��I��1���.黂扻}�ѿl���^��r�F��t����O���F�����~��v�vB4�8��T�h���%��h�r|M�\�;K91[����d�(�Tz_�tX�|f��rֳ�|.���������m���t����x��_Y��&�3��[^��?j9����??�ɧ��^��&J/��a!�(,�#��s}����\�J�����B8r�X�F.�ȅc��x,\#��k�"�p�\H�����5rA�H.*�ȅ�gm��Bc���_������A�s���@�U������R�ϔA�g)����������A��*���2迗��V��Ã����>��oÁ��<��+�@��
+�V�p��?zʸĉ������_�~~U�<J�p���_����ǺdKkUͯg]�쀼gv;+p�_�㝢Pez���*��c V��#�;��bF,�92�H���3�ވ����us
+��,�	@F��6��}pd�p��C�
+�/�|m1J�+Jqk���y��w��@�kg�\��89)ʃN�3U�G��Q�x����j�o�5��~�[����������T����]�����~�����?�_���P��=J����p?᭷�ÙJN�1\ν�M����E��h���W����/�4�x������R���Zd��֢f���|�x�&����j+`2�|y�X�x5�tM#��+��e��kk�Շf�ԛ��|�ﲍ�7V���$N7�^�F�:���MT�^Qa�~��w�u?�ߨ?�k�a�ה���93������0C����N�3���`#9#̐"g����0c��fL�3Č)r��1E��}��b�/9c,�%g��r�Z g�������E6�3�T9�,�};4ӳ�X?9����ة��a���;ߐ3MGz�ۜ�t��gݑ��P�'�|��?1)q�s1���~���_���oGB��q�9
+�����U6]o+l.�
+R�����M��M}��w���������6������k��۶(�N}^)�.�|�_�S-]}I�{�D({=Qi��,��~��P=T�o��r�0�U��JkKu���Q|��g�67�o�A9S�.'	].VS��]W�'rʯ"�O��N.��u]��uZ��|ȇ�C�Ԇ�XԆn��
+�
+jC[��8�L���-Ԇ��/��� �6��
+o�
+m�1=��
+f�!
+N9��
+�j�g�"g���,��@�4jC"�� g��+����ׇ�}Ԇaj�fvL�O�١W���0'�\�����r��H�s`ȕb�Z�����+F��SU[���O��~T��7������
+��$�?�'�OZ�� L˹gT7]�7l.J�}b8z��P����pS�p������"����Z��pkh��5G�m��;��Ւ
+%_�JXKW��w��2���������ߩ-� ��Om9#�Ъn����[[���6�oX��R�h�������]7x��������8_��m��k�N�������*� �|����C�_���P���d�(�0�{N�|{�5(��ˉӆ�s:���*���=v�5<�_W��[n0v:���Yb����{�vC�;����A��X
+m8���|�T���p���h���<O�y�5\����d�{[0�g tQ�5⚩��=
+�����u
+Q_�
+�����2!��>��W��aE�u�s6�!��_y'�z�E��E�C�?"�/��{��50i=j`��hTQ�
+��ɨ}�nA
+,5����F�����"5�=j�;�wj�50ր莾Xrw��PXQKT�Z������5�;�"��C
+D�A�B��<�>r7�JHE�]��%Rrw��ܡ,
+!w)ɝ�Tĉ�}zǲT�ܵ,!w.KE���Rr3P!w1KEȝ�Rr7�T���,!w5ɝ�Rrw����ɻ��ɯ�����"�GM���&�G*B�~����R2X*BfKE�l`U�	R!:+�x��lԐ
+�Y�F2S��$���"dưT�����H���a���T��"���!����"dF1�JfKE��bhFf/"����_!������
+�Y�R2󐊈������w�����=�����!q����������V���g�������9
+��9��[7]�e�\���h��ƣWj�^�n�7���X��É㫍ZdOíEN��k�7ܶ%���h-��X�e���Q����e�{�����׭ͿZltO=km���	~ǭ-gL5��{��Ѷ��5��7�D2��������M~́z��)j��`Դ!h�#�k�4�N���i���#g5�
+5-ހ��ڈ�vŀ��ڈ��� ��Ɇ�6ހ��dDM�hEM�jDM+0��i6x~���i���i�[Q�Q��ZQ�z�Pӎ[QӦQ�[Q�vQ�~#��ʙ����������G��?�W���~~~N�	M���85a�sU��{�
+���\���}�}���?���O�xt��?�ԍ����U��#��c���N&�����߷���@�Z�3�X���(�X��v����&[k������Z�g��Om�Û#mu�K�:k��o�u�=�zG.�lkm�7�14X�w���쏍���1<��Q�$�s�dl�e����@�K�Dk�:�F�����7zY��j��x��|����i-k��U!����=j��f��c/O�3����������ǂG�]���[�g�qk�K��!�kǂ7T�̥�N�U�����yf�'^5�N�U�B_2�j�x�}o���1�=!�og�r�{�뗎�nǾ�[�Z{l�$<�Զ>����1�g�gj��o��c�U��?������<i�Z$��0�9=/�e�4�).�]����p�>m���ơj��W������S��Ana��(N�,�`�
+8�F�5,��eW{Ct�Ia��z�aE;��W
+��F��Ff���+֘Y��Q^�ZGǿ��:Y�q��j\���x�05~o�5�����6�:���:n�d���������zBbTg�4�0)��!)1_��|א�\�Ě���R�5�Ū�������>�����=Y�����bN��>b�u�� �Z�Ǫը���k�v��9ng	e��E�5�U��>�c_��kg�h��Z����֔��D>��3�0���F��}��'<�Qi���w�9���os�fk�=���~�k<��	�ā�ʽĽ��<��ݣ�x�����짓yIG:7�H�'��#��t�s��t����Yd޲��]���KG:��H�1�\�#��t�s��t^ӑ�m:��MG:��H�9�\�#��t�s��t�ӑ�}:���F�l$8@G�t�x�����.0%D��)!�PB{�1�	����#���̠#�
+���`#���ac����<aʊ`
+SVW��G���{_X� ��=�3�ݛW��
+s��Б�s��0W�חb���R,b��#��Lb�חbs�\_�Q��K���X�<�\_�Yt���\=�]l$�Ŵ�06c��26<c��4��\c��6��|c��8���c��:���c��<���c�`	�1W�` 	2W�`!	2w�`"s�.�����)>ґb$)Nґb%)^ґb&)nґb')~ґb(	�ґb)	�ґb*	�ґb+)�ґb,)�ґb-)�ґb.)�ґb/)�ґb0	ӑb1	ӑb2	.ӑb3)>ӑb4)Nӑb5)^3' �]�W6yv�S�|�;h�����v��H���;�U�ь��MIN�������?���\���d��%�p>���Xz`��<g��bu��[4�\��@c�� �c��j�ȯ9��V��_��Oc�Û���%�:k/�����ڑ�zG��l[��o:bl��n���bl8{����HXln=���nn�%���S4��z�ִN/�k��6���f[�S~V����۝��6��Xz�*��[�8bm�il=�������6}솶��F���
+ul���
+�E�m�/�:��u,x�ꕙe�=��>�f�7�����w�������x$�jX;;D��Z����=f�����۱���V[�-_�R۞~���Xb뙱��+⨭w��`��m!���!7�C�VB�Ü^5�eg��5�]�����Lk��u����F�g3/�c�}�m`JG� �!�Ȩ��Ȳ.�� �u6�hi�d��
+2F�_3]�jV��0<���ln�aDl�qd�|�^j����:ʫ�6:~�5�)�:�W���=�X���dKp�bMXk{��u܂���A�	)�����Ĩ�4��0)�Ø�Xd�ܸ�19�fH�hcK	*���p����ZSs/��JT��{l/�_�NK_k{1'֚>b�m��g�>���)ZD�̴�Li!�뱯��u#VP\XAi�^7ef��P&)"���^����)��$�-+��#@���+3���d�4��2��A�� �m �h���/Ŀ1 �� �% d҂������c�ߒ���o7��o1��o6�������?��n�1���f�m ��� �$t���m �~V_���Ŀ�
+��b} �G� ��F���)P���
+ �د��	p��/F�_�6j
+" �{m ��YA��l �Ӭ �sm �#� ��A����	Ѐ�����'�c
+: ���|@�q})���A��@�q})(����Rp���� ��K�
+��s��l \ ��  ����
+@�����
+�&b}l ��!�' ���
+�?����
+�?��_� ��@ �~� �AF�k��	 ���7���A��
+ �EF���R��:+��
+���?��?� (�� � �]  ���7����0��@�GA�]
+ ��lA�!�)�2�O���P�NA���A�s!  ���Vv
+� ���A���@�X�و?�z�������L���CR����|���1 ���/���QU��O��Q�2Z�)��\����tS��wQ�K��kr�mߜ���pu+-��߽`��?�[jm�������y�_�-6ZK-�_�Ҧ��WcK0�_��Շ��F�ґ��X4s
+�`��~m�{��_x������3�����Ν�������r�;���oW�v���(/����ά//}lO2���;������G�U��p8/�V�m�V�g�>�7�â��G7�s�N���p�dF�Yٽ9kz7}����){ZOy}hWi����F7��5�Z�Ҧf��M�4iK�ܖ�ۥ�Ϝ�f�;�/��t����6kwi{�܎�}g�Dn��}w�k�
+Lz��x9�$N�ک���=T��j����^0�&w�xY?4�wXث�g��#��rG�����
+�1�d��h�||�"��'f'IZ�0�dB�t*��|:,P:3��|vHw�\hw�|gw���;w�	�_"g���S��s��+�w�ŻwrW�8)]��d}�������+���+�[#gI�G̔o?� ��~N.i���C�>ri�x��$��{!L/��q��:��9���N:�ȉ�6�^}�5"��I5b��5�W�Z�b���/9��!��?��]N��;R]m�\�Uw�M��oz[o��m"ђ�����4�ҟH�"�,Hw"R�Uo��J$Xg�i�2"��J�7\�f'�Jn�K��ێK��
+�K����DR-�Z
+�N��V�ɀ"���m�7�4C�(�/{:��=�����B�����$�̩r��`�;=Z6�k+�ħ)T[��p�/I]�@�o��n\P�zйr��ݯ���5"q>ֻg��=���?5�H~�}I7&��oJ�"�ɽc�`�9$x�r�3"Y&�����e�@$���w�B����R��4��F�1|�l^�4�{y��[� �r���RdY59* G�:��Y��]Tblԇ�8E��"}x�N")��GĮ"Rb�.�o�cf�I��Vȣ�I�N3��R\�sr�G)~o9�������<��ii܂0n��
+}BJnb�I=1ʉH����k����';�'���\^,���R��ɩ.3���urZ�s�����}�i�S�s:J�#���՗~S�c�R�/���ڃ�Zo��j��J��&+��$_���F�:�߽��v^��Mjxos��N�=.22�X�
+2�Q�~n?H #�e��c��%�ύ`&��-�DQ���G8��P��[8�������)	����������������Ʋ�ܲ�t!�Z���[���\���]���^��$�_��$�`��$�a��J��u�<f#�d��$�e6lfKI|fKI�f���f���f���f���fKM�fKM�fKM�fKMgKMgKM,gKM<g#�t��$�u6lgd��{e���w��R����!KM�ձ��g���ұ��Xr��,5�A�R��u,5�P�R����&�d,5�$a��a2������dKMJXj�;�uKMvg?��,5�Ύi�J�;��KO����NKO�䰏�I	+�k2�q�!a���2V�_)a��2V��%a���2V�O��>�s2�'{E�J�}d�4��4�s �a:V���|�d����&���,R��%9�K��K���,IR��%Ij�p��������\�N�,�y2,I�Kr�K�m���,�d�$�w�u�dK2H�%���t�aI�r�$;��Gk",ɦ�HF�8Z�Ij$�"I�dV$���"��`E6�`E.eǴvܪ�����D����9CG�~V�hVd�+2D�9_�9J�9U�,����aE��`E�p�"kK�"�6Z�Ê�ʡ�	V�;�u���6��kvLk4�ȏ�1�հ"�bǴfÊ�tX�6V���e2��D	Vd�+r�+�3V�V���V��HV�BVd	Vd�+� ��&Ê|\�كS +�;�| Vd5Vd�+ҝC�AV$��	̊$\V�"V�NV��:��U���:���2��4	V�
+V�0	V�LVd	V�s2����>2��j�Ȏ��
+X�a��Q�+�;��V$�+�!̊�|�|=�9X���1�&�"WH�A�'Ê�)��\'Ê|N���Jy�H�W�_`E�aEV��ǰ�{��&����o����	1��	�+������s��W���,����n�H�=��磌/�h�tty��^�A��-,׫�:�{�H!��Ő���P��Zh�kz�SO-,{�ާ���w�l��a�>m��c+1bx�d^PC��[8�8ȭ�98O��{S�
+�P�:�@����,;���嫵�+
+�aE�i�36����F�.�Gf�����R̬q�(����p1�)U��㊇J�
+���ݥ�Z7ń����s��q����]�&����
+����4g�6)@ӓj�����iZr�	)%h��R�MJuISs�Ki%C��3_�^�w���K/渋�#¤�8�-+^�Wr���N�C�_BQ���n�����˃P�#QH
+���T{���ad�
+��2����|v�3XEn{���P
+h��C�A��T z
+4�L	С�:�Pk
+th�:dA��I�C�DСp	t��:�-��A���)�F2�@�>A�����i:�Z*�A�^�@�6�C�5С�:�P
+th�:4NZ ����C��Ad*�
+
+"St�;h���C���!t��:t]r�A�
+�1���C4�!MZ��m
+"St�h�ҠC�@���Z.�
+A�^�@����C�萻:&��e��#�r@H�����򿸤߯�����_�?>U�=J����W��]�.-�|YTgr�������NI�_������2�qՠ���g���>�W���>|�-�âY�G7%���mm�@��̾ZV��nM���- }�G̞�'��(n�,m��/~�펔SK75;"m:w@�R�{}�����g�ӷf�k�;7�_��T��x_ߖ���=�E}GD��3v���ۢ��&}٠���5B�+"~�d���w���K���w��)g���ڡ������w�u;�T;���~D{Y;Z��t��͖��yI,�'��+j���Ʉg�S����v�
+��C:i�B���y�G�b�ڥZ��K�j���WoԊwoЯ~Q ^�: �K6��笗nL_(�L\ ��&~�*�~z�x�{�T�n��C��Ri�h��Ģ߽�M+�w���5�~΅�O��Ǥr��xO�i��Z���a���fS��B����Q�)��^��Y�9����2�k^��w�h
+g�鏧��'B�F��5�0O�q�zZϺ�K+O�i�bݵz]������d�����|�>�}ݷR���D!��[Θ'�|Jo=6K{2`�ަ�\���*ݣ�dͣ|���8X�,Z)���Y�;K�X)ze&H��E����a�����&��~�a���B1����+vvp҃�Ղ�]ӻ��\�{���X��=��c��=5'_z��Q�1�S�g�t�W�;R���J#<��_z?�͙�\��2���G	c&���<�.��@�]�(q� J.�%�Q��SlD�s���E1�e='��|�#�-"��XGֳRC��2���z$YO���g��������_G��!� !��#"���t��8K�z�c���ztY�d>Y�C0Y�zY�w:��|
+Y�&Yϧ�b3�z>#�yۊ�F�3ۊ�F�3MB��ۊ�F�3DD�c��#8��K�D�t��3:D�q
+"o������Z��[�A��G0"�	"/N�ț-A�$B䍓 �bE��p	"�"�[��k'B�5���tҐ�x��zx
+YOvLk��n �9�!�)Б�lԐ�lБ���zH�z6��z�K�z��zH�z�Dd=���a"�������ds�� ���z�i�z���z�k�E���ĲR�X�C��MD��Dk�d*�v!�yGG�3SD��Dk��%ZӐ���#��!�ӑ��4d=�:����OYO=
+YO]Y�����XG�SWD��(!�)��\������|+!�Y'"��td=�Dd=�td=Y���:�����U�xH�DֳCB�3XCֳRB��YC�3KB�)"�I�����z�J�z\Dd=����Z��'LG�S("��#���� ã5Y2<Z����ב�dj�z���ڌ����z���Z����U�F��Q�Y~�������M1Sc�G��
+>>�\�����Q����u�����-5{����d�3�G򞰠CoN6�����jVT��No���x�����3��z�3�����s&rc���+��%�:�5)�H��2��C�w���@X����_���UmL2��G�^��D�����ο����@B���s������s�ߣ���������GM���[���[���-�*��z|j���퓯=�yw΃��C����+]��_��W�z�yNg�����c�kU�꟫k�'�_���?���?��փ���x������O����X�ɯJ��Y����_����հw���=�������S�x0��y��-��2�����������O���~���s#�*ۮ��٪=Ԥ�l�N:���ς˟�tR���o	�褫
+Ϊ�����?8��ڪ��?��'N�������?�����7�|�ǤČM������7ǌN�0�����?�|�_�����͕��M�-Ί:�����;ʞٮ*������vy�r�|�r̦��E+��k>V�rg)'f��h�	��I9��W96P93�K9�鯜�ß| ��#�ɡ>�3���_Yw�/�}��:�-몢O��_���ܘ�M����rk�r���w��O����NQJ�-�h`QJkg�%/w/����q½<_�*T�n�s�<�j��㫧���N������YGu0\Q����U��BpԭJ]-K�wd/�d���ߔ�7X���;�o8[O��?��$4��;�E
+��t�x
+.�)M�����j�SM�����~P�ו�-�S��B�[�VQNB�G�'�	m�|ηu�/x���=ʋUOG��,ڧ��4�N�X��xe�S;e��w��0������;�I�/4Y�TK	��}/(��� ��|�yW����|��eB�c_�ݭ.j�-�O�)U�~�MޘX���X���U{Ǿ�{�jH�%�f���Z�Asχe/����.�V���O�����O�>U5/���L�An����7�Ȳ�jT�A%�lW��~���r����+ʅaE����l�B~D�vadf/��1��+��l����J��25.4Z�+�P�=�)�{Ǩ	͕��&u�
+e܂8a|�?!%T��U�'Fy
+���XWHJ��Ov.�#V��uԔ ��RtYMuY����U�J2��3���c�i�s�sLJ�����E핿n_QE�ܶ�w�M�����.���:�̄a�	�2�e~�.�͕��k�ڐE�T,�� �j�"����
+�U��E�e��Q�`b� ��
+�&�GִRA�����i����-YS���IR�5�U�5
+T�5y��"��>��R�A��#AdM�1�A֤��"��l�H���*����5�+�ݦ���S��r]��(�}EA�m����e<�n-
+�n3xdU/�cx��8���#�
+�U��Uy
+�BdcYA7dU�dU*���y@����Ao���
+��/�V�A�
+�`/�`�
+� ��y�� �`.�@`L�a$	0�0"��y��̃A��Q�y��<�g?�")3��<�A�yP��<8��<� �<�ʎ)��<8��<��qa`c��0��1E`���"1̃u*̃t��0��� {S��y�=�)R�<Hf��aD	0.(0��1Ep6����a`c���< ���#�A�
+��M�A�
+�`�� W�y��@UaLP`0^�al`��a,`��ad�0�*0�0�)0��0:)0��1�0��0n(�⚫0*0�
+0������<̃r���&�<X��<�.�<H�a�0�+0l*̃�
+̃e*̃h�A�
+��`��,������<�P`ı�G+̃P�A9�,�V,fb����X�y���*����<���<X��<ث�<�P``��
+� �V:��U���ϑ|9����.������M���� ���D���J�����{n�����7�����@U�����U�+zm���ּ[���:���Ȓ��H;hP�C}?J^'��c�}_G��ǧ���O��L��0���������7T���^�~����b�F��M�]��?���E�gߪ��%�?؁����N���8ͽ�1�p��}��k�(�.���{۟��
+�?�1`�9KP����/��_}�-��?���-���7���O�<��7����u�w-��~@y"<�o�W�8���4~�Pi��^���\��t�Ҵ@U\w�U�}��w�����%��
+�b�^�ķ>�o�/�o�=��c ��̓o[υ���[���_iw���y���~���a}��q�E�띣J��=�w��!v�����7i=��c�?p��o|�o*xo:��%�x��n��uko��1��}�H�ǖ��S3{*O��ǴVzft�{=SS�یns^	�}���WJh�|��s|�c���o��>���}���+l���);e{((K� j)PH���Ͷ@!@����R
+�}���Vx��8�W�8�D��bPQE+��5��8�pE(��s
+���R)���I��N�������sϽ���+C�~�H��e�S��aYY��[��cn7Fd�#c2��!qƨ+��;��p�M�U��u�1��ʸ���}��w7V��2a�7��e�(�������<�L��m#��}JZ�g�)u6�#���ԓ9F���ƴ}I��5����Tf����z|��=���-�Rf��L�R�
+k��
+�Q��ئ�wmj��9
+0������#���ʍ�l6
+�{Ÿ陇�ys5��9�G��k���٧�<l��&�:�԰�*8�P�7?��'�yẂr��d�p>������L ��H��]
+�A@�&�&>���ǔ��`�O�]��$�q~�X��Ib�'�m��$�q~�X���� F����@�O9?IL���b��'k�k���w�L��;9G�����w�TFb+�񈱜�#�r�����;b/71��w�b���9Gl��1��w�j���9G���1��w�r���9oGlg$��z���9G���) ��H8GJ��;R�ߑ"���*p���A��c�BH��rF(�����bH��2~?�C�w��
+"��d~
+%��]wF(����,������H��%���pގ����#)��H}I�8G*��;R"�ߑq����w�J��#e�����H�8G*��;R*�QH�xdI��y;R-FR.�ۑz1��q��T��w�d��#5��)��H�8G���;R7�ߑ�q��T��w�t��#���)��H��P>�ۑ�1�����#%���!��H9G���;RF�ߑ:r����w����#����%��H19oG������v�������#e$%���)��HQ9G���;RV�ߑ�r����w���үB��������5�^�۵)��s�V����������і����ϩ�y
+yJ����+�'=������60���?���"D[�����q�IU���P�鈌����r�ҲfgL�j�%�'��XL���������EPwa�??�eeX�������z[�x~�GU�?��_�5��C����0G�E�s������0?�5���Os��a|�O��e �������Hk����L������a������H����-����ԇ�|x߅�xo�������������|��۪��G�G���-����&GV�]�d�H��~��(㿵�����&GU�]�T�(��~��h������?�`rt��G��������7�[��!���$�S�w��1�c,��!�c�����~��%:�[�w����c-��!������_?����ܭ������f�����g�?��W������U��#ʚ���?/ڷu:��?�+�'=���?���U��#���Ok�������່�a⿵ ���g�������{��
+��G�o ?����ߚ��C�����|�N��*����~�k�����L������U����3�[�?~���|`rd��G��
+p��ծ������ǉk��|����-�����7�[�??�G�Q�w����-�����7�[�??��L���������C�G�������Z�U�w��Q�C��~��h㿕��C�'�`rt��G����!�c�����o~��I�S�w��1�C��~��X㿵���_����
+����j- �C�w�3��X�����0�[��w�j- �?�Wj�V���p�������|�Ͽ��"�c���X�?���������ʜe�����I����3�VF>��R2����sX��ڿ�/s�c��Ÿ�F&źTi�I
+����5������;n��?WV>�^����^�ѽ�����p�l���3����[�'>����N���������tTl���n��T�S�^}f�FJ����@�Vߺ�ڎ�F��w�U�1�>��=���|k��?ڡ4���n�i����g��}w)�����*�g�؛��4MH�_�-F�2$�ެ�H�y�f�բ�_G�[���y������뎹۬�ذ�w����%�������(WE}e�zЋ�5M߳w\��q��JH�&)���sw�5�]���e�jt�7��X��K���{��g�Yˈ
+m��܈�k�
+�������ۉ�(�_/����M�������(��w�y�o�3{���'�~ö��������8`�1�]���ە�]�	
+2���+샎U?��=��iFb�=�����v��w1�����#�z��F}m$��r��z��Yw{r�J� ���]ʸGK��oP�/�ٯ߲B����}�ʹ��X�NYt�1)�랜>�Hm�;-n��vd�;=����c�;�v+#��x���e���i�̢ eF~�=km��=:Į-�)3���s�_Qr���
+{T�+��Ώ���_��4{ؘ�e�{��
++׺o�=�(�w����xcބ\��{;� [�� ���-y�R<��:�X_~�$ٴ���ݕt*�E�C�2��P@�
+bA. ��h@�
+�A: �d���F$�oHD��@R�%bAN �H$���DV i� .���@�"Af 
+�� 6���@��Av �H���@� B� � A B� �� B$�
+F ��D� B<� D!BL�� ABT� ��Bd� ��a$�Bx� B��# 	QB��' 
+�b�HB�Hb�`1�h!\�$^@"��!f@��f��
+qB��9�H�I�<F= ��q[�� !�@!b� !�@#��@!�@%b	�`2�h!��$�@(#�(B
+��!�@�*�
+��!�@�,B��!��e�W/#�/�H"�!�@2��0!��KN���n�Ĉ.�]��º�u�3�G�82)&�������wc��ں{a������o-�o��of;~l�r��d[��1����m��ݔ�5Ad=Z*�Jm�f�T��l��Hin�t�赜'�ڎb��ߢ���W���:%�|X��[m���e��
+7�&��V��n!��岹idR�&c��"\�\�-��A�Y��z�J�j�z���1Z���c�����z�!����=�����z�QeJ�ioS�_�z�3Ե��w4�K��	̡�|���Pu��wiz��[�.�G�]����zX�%<�
+="n�9��D���cjwTb[�@]q}�ۉ���R���f�z�^��.������վc�]���o���z�>��������lS�B�+}BIh0����ʠ#N�:3�|8^O,Xd��[6>�p-���{6F�W�G�I���'�42FG���������S�*cK�Q�g*�?A]�N��-���{N��r:uqEFʢE���g���zj�eFZ�`=�H�����H62j7�3��nL;xT��|��YԐ��nJ�Z������d�mf�I%'�9�>Q�-�啞0�c����s�-��ly٘{,_�a�j����z��[��
+���&���
+���{yȐ�K���c}�=�dӖH�K�����
+���u��A��������g��f6������6��c���m���)����S���
+��������[����s�b��'r��/�����Q���S��?���_m���&��C��j���"������(���l��S��q6���*��Cl��;(�����������k��uu��u��_�����w���[)����k�����m���+������U|G�3,��sl������#�x���t�����G����
+���������+t��S�5F��"��.�_�u��2������R���&�_�u"��2�� ���q�I���� P����OB%���~,��O��'���X�ﴉ���?^�����[��a������������C���Љ�o$��O�g��$|��*����������'l��w*�����?����n�_d��_���������_&��S���~N�����I@��w7������Q��7���麗�7m����X��Q�W���O����2�
+_!������'���!�?_�/|� ���B������/1�,����?u�?2)����k�������~�����X{�R]�]���tۉ�̒�	���;����lek��{���ʬ6�+���)����/�Z�#zmG�V�o�z]�Y��ӏ��X���-���1xg�
+7�m6z�n�
+yf��ydF��g�&�k6M�%{�¼2�ق�y��͵_7�[�?��w\o�u��z�^���5{~#��Wk�F�n�%�]Խ�2�i�������������fH�z�㡁f�-��wM�BW�ֻ��u�7Vw,�FKϧn���L��!-*�;u�ok1���;�܌=XJ��?�����}�칶D��N���b�������}�M�7�a�j�6��}�����o���t���>�F��	�o��3���
+}ȇC�Ă��Ѝm���t��˴�={�#f}��j�'��PK*	�GGj�?kM���f�6t�q��n�^s��ר������8us�M5�=e�\mR���������^Zڑ�zzp-}� =�v���tg}��O���l�3�;Q7���݀��W͙Q_Q������=��y�G���G���w�9�js������ݰr�~��AZ��Y�M���y����m��i���\���X����!�$���Խ�����3�|�J�C]����;���5������'���l��;���;���7CA$���)��+�������z���/5��G��A����Q��?b��L��T��1�������m����&�?���g�?��?�&�?��/�Q@p��-l��c��@v���5�����@|��D~���4��{u��/k����������������&��)���~
+������'��������������O��������������_���Ϸ������O���?����n���&�_�uƃ2���������?ů!B���4��˸�$�_�u&��2��@��_ ���J�����I����'���K���6��a��������������&��:]��e���^�'����~:����I�����O�'�_���&��^S��k6��7������o��E�?W���.��:M��B��$������'��?H|?	���κ��O5��	�yT���l��������X���W�����������Bx���+��X��:]��TM����,�_�
+a�?F��	t`�ݵ������IQ���[�������V����^h�V߿C}�6Sc����?�l�����dww���V��� ��2�mE��h���l�Y]+Uk�'��.�Z���V��Z�o͵�ʣjݧ����B���V��G�xӵ���=y���7��xq�y��x��qf��}MB�+���]R�l�.Dm^�٢Z=��ׁZ��GԠ�k�����^���f�:՞o3�޼Tm7��~�Z�UQ��W��wM���������W���Q���Ǵ��b|��,�:�JRCWfh]�G�]�
+�K��a��fx�q5".���W�
+�dF�oQcj70c[������v�E_���3{|���s�Z�ͺ���"���|��g�����-�������k�W~�ƌ���u��Р�/a}�9�H{��kC>t��ӵ�۩��'j��5��=�j#fTG5֒FmW�N|�����:��Ffr��}ɯ5ǖ��{t�y]���6��o��MH]aN\9ԧ&>��,��N
+]�MNOTS���⺪iG�i�����=��ZߨO�֦�@�������Qߌ� 3k�._��RS[��73�g�d���6}��6חW����\�/ު�i6G���m�q�
++o�n��S-����T�Z�7!A��M���e���^<��:�X_~�$ٴ
+��e�����5��_���m�����S;�����'���{���w7�������L@܈���������5���H)�ߧ���D|?T���lU��2S��BU�������}���5��|��o1��O��O3������Ǚ��;������������3�������������5��GT���5����������S���L��KU��L��k}��_3��������~
+���j��G���?������_���OR��gh���U���5���T�����!,��L��{U���L��[T��2������q�G��{����>��2�����qI���� L��e\���/���J����$X��o�O�%�?����'��&�ߩ������o���O����P��w���T��7�OB�Hb'�����F��[���'��O��.S���>��L���>��+L��C}������OW��/���'�����'��?N|?	������I@����������n��?��d���ů!���7���_!���_�O�+�_�
+���U|?	���G4���T���W���+�Y��&����r�k��S���I�����?�g�?,*���W������$�\U"�b�
+���?���������pk����!C"�b���w������K��Y��C���戩ػ�}[���[�i9�S�V6�c���c�wxd��(�������L�*����£��è�]�f����Hɲڿ��?k��윔�4�h��ȰSퟒ;=�������̔��xx�9��EY������U�{��1O���N#�[m5�$&���6;x��`Z���C��`S5���H�U9B{���@�7�b����r�����r��?,*����������p��^�����|�'��MG#/����>����q����={7���;��Q�@���}�;|I�oW�y��9���7��C���c�;;����~<p����c��k9J�z��՛w:Z�����;�c�x����G�z���O���꘯=W���ݡ�u��Jt���{"jM�G�&9"�m�G��8�ߝ���uOl��n�|�辤����2O���^����=�t�nIs�wsϧn�Z�y�T++�Y�^�S_@����lu�w�:��q^W!�(W���,W�+�Uf�+
+��f�+�U��q��h Z�� �5�h Z��Z�L�u���ЄZ�M����@k�b@�-D�т@�"#�$��H-��V�e�h] Z�/Z��P�����Łhu Z��"�� "�h ""��
+ "X9�ؓ{���?�zY������'2�a������J��Ν�7#'-�����s����U��/�o�ע{��{�c�#�Ϸx�S�z���}��7y_���g�u������G��n��yys3�w��ևr���Uǫ󊼯}�٦�pn+��x�o��
+�Z����9������/z�I,s��9���y����^u߮���]�L�������<�.��=��.Ǐ��v��9�j���ő��O�p�>�(�#�Y��A�:We��/��JY�f�`滃�6r%�ClG!��]�N����ox��'nv]O������{^L��'�V�7�Ԭq�Ou~�YV�f$��W��b	C��P�D��½D}������"����~�e�7�<�f-D+�R�-�����[P�1R��z@� �DKњ@�(�
+D�Ѻ@�0��H-
+Dk3R���@�<#�>�HQ D$ 
+�e(")*��d�kD#E{��4���#Z��Pİ���aOC��ųO�����D4����"���2]@D#E��H�D�ugy�> "����H"Oy���H�/��B���S�Rf��L�p��
+���k�o������9��wn>�p~P�{�TLm���V�}%����k;[��?��e����������."���O��g��N��������r��s�?��Qg��T�9��?�Nj��9t��/*��������������5�~������=���������\����ߟ��
+�5m��>��?���s�?##�����������c��>�t������WDe��)��{{%��=����)�z}?��)�)�������WU�Y}�����2qDF�������9~��3�a������sɍ�wlpw����Wr��j��r�ZY�@}ζkȟ� jl(�$p~� �4t!B�r
+�f������}CU��ã�����WB��<���UO����O���o���s������ߙ�H촾�\pq���ְ�~?�����e��S�I��.��v�����03p"�����?
+�'ƥdf��gW����k����W���3�?{|�r�E��S�������r��""�������L�̻��@T`�?"��[��UX��;��0���E�����/�����?��������f]�7+2�o��n��W����<}�;�t����.����-;p	��S(�LS8V���B�r
+�n�?dVF�E��â���#������}I��'�i�?������%�]#<�G�	�#=��KvVp�U��"��Md�7������}�rU�(�~����zy
+FF
+H ���"8GI��P�\:�Ҭɳf\�7~��?���+��/����g�����t�j��]����� Ο�	<ju���NP��4���;��������ʝ:+%�������~������6
+����.N�ߺ۬^����d����cVo����gM��c�������GDFY�����Ǳ}8�����]�����j� �CA���
+(��`ۦ�x ����_f��M�:%���;+krFvV�?"&����ì�?���)w�
+���5;�q�.1=���y�������
+�:.
+u6�Q�To�����F-s^~�vO���Φ�%�+��^Y����㺳١Ɏ����x�sG�-�ޠgZzZ��t�^2��F_�k�M��l7�����d�U�=W��ἦi�'������v�^�������?����{��Q��:�K�#�2gX�TG��.ވF�z"co�w�W|����'�����[wx�}���}�ZO��w9{����5���^r��ϸ����}g~�����"����{�9����/��xy�p����[{8�<Q�M\��1t�~�0����J�Çf:F�|Α]�:��8G5t8F+�:G�0�3�\�L�W�آ��q�+��6-��_������x'��87ޫN<�H��;��.��n���m68Қ}�M+[�H�Vϙ��\���G�/_瘶�]��5�=���9g�6֓u�Rg��m�Z���V��Awys��<ys��9�Gy��R��C1�9E>��6���y�q��hg��㦥͜󴅎�9�Oυ֨���4�C�������ϔ=���O��/�X����E<�#����@D? �@0���e(��� X3�`�%@0� �Fb
+��=@0�$ ���`��]@0��5d2L���
+��x�X�H�����;���k&򸆘�`$���,��N 
+K�`*le$��ZFb������`0,��@�F�j4�yƜ���,b8���r �ہ`<�g$��x����,��Y���@(� �2 �@(*�R �@(+5���z0�� �"@(	j�� �*@(��� �2@(
+j�� �:@(��H
+�
+1~"g9B��P$ T	eB��P( T
+�B��P, T�B��c&B�M��EBՀP6 �
+�B�P:g�ڝ9���)�둽#y��91��%�����sbD�H<	<���eLϞ�R��u��odX�u�OU��Z�w��ʟ7��[Y�Z_���ccԷn+�w��VۙR�����k�,+�;/-�����p#L�y}~T�hk©�t��\�1tw%��s����kq�����_���IF��@|U �.��ʁ�?ܨ�'�O���O����_��F���73mV^F�����ڿ_�Ԍ*�������a�����_���Ӄ���w��{�S��[�W{�C
+<����;{78B��f��^��z��������{�%�m��I�g�	��׉񧯿�?=�:1��Y6���f�(&x4Jq��Q�
+�zeԂ�Ѩ[F-��o�@�x�� �ܩQGe�ݩ����b���Դ��܋�������D��Y�����ח��f�m�\[�u�o�����w�����ͷ�Tw���O5=,}��{�7E�qL�
+�W����1�;*�-��������G���]f������'���![�%��>̷9��1�.x@�7�c�O�I��nc������򌸫��q��Rj��v�*��]S\8J��r3���Ч�3�ͩgs��/sxJ�>"s�9�o]=i��(����7�cl;���kɾ����
+�q޻��>�������ڄņm�=�45#ǖ2��9)!�6y��L
+�����fN�l�����f�ב�ԓ��;�Ч�[cN_wL�|}�6�=z��Oh�3_Ե�����>��L���v�l˻6Q���![~�3��|ۜF��9{Rls�
+5ox����w��L�oz�9��;w��t�P��ԬV�����x�߇����?�2�	h"��t$�����d@t>�� !Dq�
+��P8qwF!%��B��mZ@	/N�,�f,�j,�n,�r@��3��3��3� #�!�4�"�4�#�4�$�4�%�4��$
+�k��$
+���UNR�rҐB�����,��"|9YH!�Ha��B
+eF
+gNRHsҐ��ڜ4���n�B��	
+sNR�sҐ���4��gzS�sҐ��DN
+8YHT`$:pҐ(�IC�'
+��4$zpcE8i���9LN]8iH��a��AN}8YH�F�,$*1�8iH���NiWP����]A1N�%�
+�qҐ���A���8iWP���D?NY�[H����ǥ]AI�=259iH��!Q����H����4�E��@�@�E4=��� '��8���?�����I)�ٹ������<������������50���ܫ>+�u�g
+m_�.����
+�O��*j��wY����ejGoW���ò��-�V��c��:<S�Յ�0[Az��N�|�	�mx���#}+�s�o&s�Y�ߐ�\�[�+}S�s�з���N�?-3mF�����~!�a����������]��߯�A���w��Z��_���3��~�u�j�/9�ϸ!�j�?���_ё��/���r�u��	yV���s�{��V���d%?2���hCW�c����2<���R��w�$?Yۧ>������+�?V\���7U���v�3O,T׎�p�g�Tu]t��g���Wܿ�9��s�����m���B������7��}/��>y�G!���$�����eb���=�z�TO�:�]��mv���N}�N��m�K�m��t�m���xc��7�������?����Z��[G�vh�'מ��Z{S��Y�L��?b\Ȱ�3��=�H>���x ���
+E*�"R2��2e�/4�����J��@\t .</�D ��a��`�� �A�Q�:S�0R� �@@4
+Dc�`���F��h< �F�!�19�G
+�H��*5,#5.w���ܱR#�24jh^�F���Ш�y5:/C���eh�������Q�24
+^�F����( )(x�#�HA���(P8�H�D� 4h$#�x1��s7�����)Y�CG�Lʼ�k ~u�u��?:���U��5���*��Wު�za����\��)Bנ(�g����?[UH�ʐ3��}���uF�T��|�qB�n����VUʽ�����zV���v��z����N�8:#7�2j�~u�sN�gx�U��/���O�����Fc�C=���s�P�Ǟ��{�q�m��w�tǾ��v|�o�ӗ����
+d�7��C�Ξcû;�"�x��{��Z���8K��WO�7t��󙧍����������v�>�5:�K�>9����V��TAlG�șl��4�k����,9��bY��.9���	�sJN�/��k�H�Cr_y%'�@{��;$'��)9�������Y+��IN���h�kw�v\CF���h├�_e]S�	|摜@����
+�ƒ���t�yr��9���B\��t+o�w����WI����p�����������S3/��&��:V�uu�r���Lu�@����)\B��ĉ,H�:�c��`$.>�ć����P���Q����3r+)��k����8w��hk�����;n+ʟ����x���M
+�����`��v�����
+Y��v��,���ɶ��c��ۻ�J�)ek�H8Z*�Jm�f�T��l��Hin�t�赜'�ڎb���m���W���:%�|X��[m���e[�-F�M�m��t+�}��/��r��4���J��q��	�*Wt�]�Ai�n�޼n�ҢZ����k����A;���~��^w�h�z�n�o���y��nT��~�۶���+Wz�vM�W����-��#$0�R���x(�����.M]y��e���tñ4��9������Ϳ��q�7۔��[ܮ'��l	�+��8m�|���x=�`�1tco}��õܮ�9��_Mj$����T����>���Jr�Om��*cK���=j*�?a�`�r��Ŷ	��)WN���EFʢE���g���zj�eFZ�`=�H�����H62j7�3��nL;xT��|��Y��6#����ִe�n�hKv�fF�Tr����6�D��ܖWz�ȏ}V�/�g�i�L���ec�|�����w'��n1n*�ϛ�f̿7Hg�X�z����ꧬli#)���]�#m�w��r���[4CW�P^j5��.)�B���T��P�{�-��z�� �qF�(�a�!T�$���n�l<L j�0�����(o|E4卯@U�CA�-���������@�
+s�M4�
+Q��!DgF�4�f$jAo (�qՁ�;n�<��
+����A��� @�n��̒, !
+@�#I2�T�i��JB2xشZj%!2l�ZIH2��9�
+���0�� !/�$1�jI�@j�� $�Bz��Y*�����
+���B��Bڀ�7F�8 d���8H֍��!{@H��!�@H!r�$rG��H��<2�D!��$�@�%n�L d7H'�$�
+R
+��!�@�*�
+��2��!��$�@�-#I.���!��A���a� �@�1n�d d7H3��X*|�L3�T!׌$�@�6�
+�|!�@�8Rή��%���D��Ft	�z�0����������܉}3r�r/��?w�oxxT���s7���_�Z�˗�ʌI9��i��̽��?���_�k�����+��ޗ?�z��;�3�z?t��p���c���dr�iv��_�5�m��5�^��ԮU�v���G���a.�@2�:��r�o����\,ъS}mO���P��ٝ���ֿ��B���)�*�|'�נ�9�5h� ���2�y�B��/���B^������X������q9� �"��£����1���~3�;�v���ȋ]��>�����y��cmޫ���ܶ�3���>�k�}���Zz;Mwz:{_u�N����~�����}�3��u����Gd�$'��kuF��V]Q�%�==�l������*g�>w�w:��<}�r������������@�	O\�eθ�q�޿+nu�޿�jϐ��-�����Kp;\��:���<#&�r���x���8��{�ct����ovp$W;�L~2�1��>��;�+�����w���U:o���*�NG�TH��g��B42RD�k��d��d�L��H�n�ԉ_��� PD,�f�Zv���)z�5S��P�k�Hf�|j�\�hv�Ռ��ȵ˞Èpv��OE"��2E=�e�|v��얉얉얉	�[�-#�-��f�K&v0C�%7�=����=r�1�O�K�a�����[&�[&&�[&6�[&F�[&V�[&f����a��˞�`�db#1��2���21O�rx����Xx1j�~���&Ϫ�]��72�꿬�_���w,/�j���=�?P������jD\�9b��ɌzͦF������������w5�_1{�-�{m��콤X��f:��z���
+{X�
+�@8`�vm�)z�UZܱ[l	5�j	��l�>�A\g�-�<%��g+_�_#��~���=�F�[g׍�p�w}ňi���~�2���K6<ڣr~����?�y���'��S�{U�t�׸��y[�<�L����b��3+:]kV��2)�k.���ǵ���Lʣ
+$�!��h�,���	��JNm�xL&��F��e؀�bE/��օ��������{������)�U���Ȱs������E��򊗥��K[w�S�⮻[s������s[��������&��4<�$9������g�I-�rJT瞧N�b
+�� ��8��������#�����)9��`��/���E�����������y��M�ʪ�
+�_]����������?����L�]�v2pj��,
+^��#IHX�� �7�T�����cY�_�k���)U3�w����/k������I������m��8�s�VnhV�Ȫ�)g5��N��/��.<�-��:N�t�O����*��/��M����'㗓�i�������o��s�#­��E�Ǖ�Ǜ��������s�hqɶ������;[�1�Чk؆�i���8h�e���n��J#i��m��?�;�ac��Hn�FO��d���v}�w�q����'_T��0T��x�2���f�JʼDۤ�I��	]m�!��ލmS.S��V��ҿ�gL=��-c�Uƴ}�ۦ?[��|}�>�ύ��7��3�ihW�3��Gə2W�����w�u���P�α���2��8ۜ=��ܯz�nxa�r㻭m��0nZ�Mć��<`�ig�_Ou��OYكw�|�p9�����g�޿�v�|��|����x>�D�d�y�-�&Ɋ_*����I6<�_#z%�\�l�A�dã���Y��WJ5 E5n�l ��3`�@D9#E:�΍CD��@D? �@06�F �
+�� ؁K�)@�70��� � ��`l�Q@�
+f�.gb,c$��6Fb��
+��}���@�70��~�Ɵ��~�����lrY�Sr&e�ʩ��N <3�W���Z��T��fO��
+`*��Q������_�j�����0qDFeL �����k�w����N^h����ϯHl��6~>�u����W�\�+|j���E!�_QC^�����E���G����~�z����8T�|����:&���u���k��������@|UƊ}��k��?'-7/�r��:�s��ߎpk�ߟ�j���>��`m�=�����~�'�*��ϴ������^6v�^�cxϓ��Q슭�pE�?+#eR���}n�O�����S��|�Ǎ��,�?.�u������]�>���Z�q�2k�ǥ���Z�q�8W���?���������𘘳�?�*˛X���R�f��Lϝ�����?���(G�u�{U��Z�w�˟+�	��\M"�M�a\q�^���;�+��b4�t��|��h��]F�_R��zFi��*���Ҧ�fŞ���?Yi7$Ii�s�rU�h��`��͔������"��]m�|p��q[m��sǌΏ��]����-�kދ�#�i�񟡎�ժ�ϟ�ee_ꢹ�U�5��:�����?�p�-.��D��>���p������ q���J@\) �#]1 �W����*�c�+Ɏ��&;���X課c�+�_��.;��@\ev*t�����T�3�U�]yv,t�ٱP�c�V`�B-���Z��;j~jƋ�:��kW����s������������J��S~g{\��-�+������.��Y��N���<�\�����Ʊ+����3r�MƎR�&$ٯ��\mo�n�Ѽn3{�jQF��#�-\i���j�F�u��mVl��;������nt{�i{�����_=�E嚦�ك;�T�K��Cu%��]w�C��N[ֹ;�g��\��^5�Λ�v,�g���mϽʈ�˳G��eD��G�n�Ԏ���Tb��������{|�������k�?��K���<�7ř���w��F�a[��S�j��v0���.{\��Jܮ
+���J���AG�*�\���4#���ЍC�a�g�]˻�{�u��W��A=�I��6�JZ�GG�o����=��Q%y[�}l�.eܣ���7(����oY�LH}�>q�\EM,v�,�ǘ�uON�m�6x؝7�H;�����H�1ŝQ����t�{��2c��4{fQ�2#?Ξ��T�bז������9ٯ(�M���=���u��z���/�s�=l�ٲ�=��㆕k�7�b̻�}Sa�1oB�{��
+)��Q�f�Z��৬�!�2��Dݬ!L���#�J4��ps~�
+���tI�1tw�u�~����pe<�ǿi���	do�1��	ޔ�x���7d_�������˾p����0���;�
+;��R1����&C�;�;�;�jR1^��8 C�;��R1���X-C���<�b�cA�cA�c1H*��Cv�b|d�(C��<�b�dAeA<e�^*��W�ϥR1�r�#W*��_�u���!�s�R1>s��8�H���	��9��T����,C�;����/�9B���i :���R1=��i#��>HI8B�9�	΁�Vp��s ��!��i�@H?8B�9��m�F��}��0��p���s �1�!���~
+�Bs�� ��B���! �=B�I���&F�' 4��t
+�B���, t�B���0 t-Bπ�4F�5 ����
+�c$�B��; 4�B���?&��@�?ĺ������b�����{��q��?�1���O��t/�L��K|��[�[���_�|0��C�!�_Q��mo+5�`�������=��^C�[�޽�ɧ��-��?Y|��[9۽?C3���4a���	=ܟ�D����l��ypw��_G(�j��l�|q��~x�ʑ�}�/��H�jm�ۜ�Y9��������7�^��1�����>�?t]��������:���n���|�R�;�~r{�RZg/[�Q��b���RmN={���)���!*_�dM�����/@���c��g�,�"Yv�o����W�H�D^��ї�:"�t����vh1 Z
+�����hAFjE�����5y�Z�g�Uy�Z�g�uy�Z�V���hm Z�V��h} "��� �H`�h ""��
+ "�� "B�� "�h"bxf���g)rxf��G���)wD$�"E��s�]�ҙ��Q:iv9J'^��t��r���S@�q��&�q\�BQD��#��J�?a������S9�q���11��chJ~ʴl���(ퟗ����/�G���M̘<5#��v&���t�g��Ȫ�����LX�Y��Y�223S������:#;��
+�+��^��?%+%5�kb������,�����9��Ҵ�*h���s��â������yC��3����配��
+O��n:�r�Pl8���ӵ�����O��4˹�D������O�mt���9���e�w5op~��]?4��=6<�u����_�����v�����m���]��|�m�^d������[]��������+t����w��_��j����n�.�F��!sj�S�ɜǑ���R�z�.5�SlR�:�+5�.�ԼR�J�Ej^�pI���"�y�唚�0�ԼwJ��F�ԼsJ�k�"�y��)5��Kj^�{��5�%5���R��e�Լ6�J�k;�Լ������<�Cט��:��]k�����;�9���u����@\���6�|�n�d�*��̉#S2�SR�s.��;""���h����_���5��|��~�^_����ݰ�׾�M.fzY�S*h��P�����[�y�#xM'}K}K}K}$�7~쥳F��?+7
+f�_���
+KL��19�k��i)C�s��,�WZ�_K�w�д��(�����s����OU��g�4-���������u����w]�#ж�hz�z�����Px�r7ܴVi��3v徻�Ƌ
+�ess�����y��V���,+��ǋ4Q{�>2Q��Ț��&j�ˆr�
+��MH��t0���$BJ�� $YBZ���Uj��ϧ<��^�J���1)s+�����x��ȮSr�B�R3R�R,�_�ퟒ�vC����?GFY�??��u����ez��F	�N��������{b�q���co���������h�(~���ɾ�����+�<�՜`�ޛ���ak������f?��s|�1��õ%�����;�������G��n{s��]����Ɋ���~u�מ��������[��>�����A���<=���c�jd�?G��/�3E���%lg�2���%�dF���H����eF��
+������Ȍ�X��5uȌP�]f��wȌP�ƕ��	v�JuȌPk��teeFh�]f�v��WYf�j9dF�&�|t�eF�_b���ˌ�X4���m��h	Fj
+�|�"��*l��e�bQ�Ţb�Vb�E-��Z�7� ���N������29mb���_�#a�?<����*��f��;ʟ7я��\Yx���}��n;�r�O=R�[�Gݟ몡~��t�t�r���v<�c_��U��m����W=�l��GˊxǪ
+7�5zr�O�/����1���v/�<����ؠ��	-}WĖ]�᤯Y����u>�8�jq�Dm��W�{�j��[]��y�6�q�g}��z�Q���O[]tU�F�Ճn)��齾��iE��Ԑ�����j�C!E���U;����:������z����������î����︢�[���=��Ze�ؖo����v♢���Q�s�O�9����W�>$9�U�.���7l��?u�k@ש��Q�����^����� �(a�ߠ#M�?x�:��pWb���ЍM\���Q]�|�޳�:b�n�Ƞ�jҨ\I'>SGG=��Y�/�uaQ�k��Ɩ�_4��m����/x�w��	ER�&�t����)��wM
+�M���Ǖ�`���֕vd��\ݕ����Q�3W�ӊ:�����;�2���hF~C_��mE٣L��䉢�Q;}9ً�r�>��6�(��=5?�6W~�zuN�i�9[�Q��a�l���]\�ƪ7*�yz��W|��gY�?;i����G>�/�7���/�7���k�G�Â'�仕O9 _8�G�9+�Gܑ$\U�p�<�	��8�D|�$�s.I2�W%ɴ�%I�{TI2�qI�i�*I�eE�d�J�)�H�L�|�dJ.�$��$��I���O�LAE�djɯ�IN2/%�Ԓ?���q��x�I&�*'����d�*5(�[I2=¯�_q�5(�cI2�.�$�F�$�n)�$ӽ>I2�I�i�*I�8�ܗx.I��"I2�U%�t�Դ�%���%I�^�$�]�d�Z I��� I�V>I2y�5�i#�$��)�$ӫ>I2��!I��"I2�f��I2=�J�i�K�LUI2�tI�i�*I�(�$���I�Ijz�3�d�(�$��$��I��FU�L�.I2]�J���K�L}�5�H�Lm�54I�L�UI2����O@h#�Z�Hz�f�[@h����c@hz���k@h���1���u��w@h#������@� Z���@�"��>�����Wh%c���ɸE�
+�B?��P t-BO�1_B�H���k�5�����75eR�|Ư�����s�����?��G�oo�_�����*��-�����甈^���˕�V)��s���ؖˌ�})J��F���+=>N6z>>�赹��{a_��A�sJ{��nJ�kk�S[*���1��I�ښoq�?Q�<�$Tߪ$��]��#��g��y�e#��;��O�6�ee)�;n1������f���4�����j��b���a$7�VI��e���:(�6~k\�A�2��X����ʄ��(����?PRn:dL��2�����6�)i��1���`��2���WSO�����%��\gd�>S�q[/#��J��6��0J�9���3�J%7���7�GeVc��ߵ��oP�4���S��2�ˏ�<�+7���(���g2��}Ԙ�|������*�z�w���3�+��- ༢U��ʿ����ֈ�}��G��,G;G��$�v��G�ϯ�.q���,G۝lG�։������Ѷ��`!;Yb"ld'K�d$V��%f2;��C��K��S��[��c��k��s��{������Y
+��@���,1��X�N��������W� ����������������������ђ��%`GKJ���Ԁ�,)��N������`GK*�����-�;ZRv���hI9�ђz��%aGK*���-�	;YR��HU�\�,��.�dIaIe�ђҰ�%�aGK�Î�T�-);ZRv��@�r�*�7�cxo�ר.���᧎a��G�ٹU���;g���h���*���︽]��|��yw�z�Â-+3��a�[�~��{/�}u�{k^��]�n�׼�Ҹ�����������j�v�����X��m��3>�}�mv�?�z�S���a�g�����{w�7�?
+>����>�q����ܶ}oq^�'g�o����a񾕱��3���k��i������$�����k��?�5���5�w~���j��}��qp�����~�u��/_���ڗ��U���KV%=�/��dߜ������MN��ϵ�?t�|�ä���LO��Q�x��EǏ
+��<��dwg��퍊J�ʞ8Zd[a��*�6{���fVa��Ò�7gd�UX�~��WE�_r�����4-(	�p8������N�C�o,�x���N[�/輫cf��>]����:�m���/3��{���eFĵ)��lfTp@It��̘Z��Ķ��=���ۉ�w��������^�G���>�vf�V�w���~æ�O���uH���3~3�$.4�p�.�$������+t��Ã�X0��+2�\���j�k��S��Y/��O����S�����)+{c<��w�����(z�w����xN���Q��O�5�^4H~��t�H�����c��
+(ߎ��~t����@I�mϫ$�>�I�X �`!Z@���!b@b��!j@��H�ȝ��?��B������+{I�����+{I������Đ+zII��7/Y*{g�Ke��d��/�
+��2�/��-����r~
+���^O��m�[*{�߇�2��rE/	*#��T�n�-���o��^7���Je�K��!�Rٻ*Y*{�/��7'Keoj�T�NN���k㥲w`�T�N�A�
+�.�T���$�R�Z$��}R�ۨH*|�kl�VH2�
+�x!��ɗK��=2e�D&_f�ɗ�Kd�%��L����K�a�|��@&_:�ɗd��a�|��@&_:f��K��|��)�/m�5: �|�U"CբL�|iS"C�g3e�%�D���2e����z��˶��}X&_�(��j�a�|y�@�������2T�=,�/��PuT�L�L+��jL�L�)�ɗ�2�2�D&_���Z"�/W�ɗ~��L�L,�ɗ+2e�o�5��ǘ|�:�С[3?~9��I�J��4+g����_����9��+2ڪ���_l
+W���ai��J/N3/��<#�l2���iB�yE���+C��څ���1[T����:Pk�����a���w�����ڬ^���mfۛ���F0�O[�*�5��Aw��i���1�\��8�R����P��ӖEZ�]Ij�����h����ci35,=��9�F�%��#��Q�����-jL�fl�=�؃_��N�����{f��W�z��R�Y��^R��y`�ϙ���w�|�߰eZ��u@�|m�����o֘q�}q�n7��%��4i���bmȇN5�`�6tc;u��D͵��:�gWmĬ��Ƞ�ZҨ�j҉o��QW�=�˼��v����d�&��0'��S��RMW'�.�&�'��
+�hiq]մ#����j���ZF�oԌ�[k�~�N_���|��oF~���v�/{T��-����3s�W�r��b�
+���+�Dˏ]��o��4�����6��8����j7���K�n*l�Λ��Ϳצ\�Dj����,+{Ʌn����a��P����/�`���d`y�r>q*���jgī��4Slv�Olv�)6��Olv�F�ͦX����>¯׌�b���b�kb��U�f����^ǯ�b���b��b����f�f�;�'6�qSlv��:'�f���~L����H��������fG�b�kR��L��n��>��{����?q!��4�X��L.��K�Aĝ]�D2r�u���ִU�ꫫ�j��ը�m]�U�����}۪���sN��ontw?�g'�����=��{��C4;Z'����hv{�h�<L�>B�N[D�?Ԉf�Չf�Јf���f��l�D4{�F4{�D4{��h�"�h��L4;S"�N�N�D�GS��&��n���0J9N-5��$��&3����f��1x�%��'�>e&�]W"����6�4�����F�׉F?��~O'���^����� ��h&�X"c&�%��#:�|��D��O �+�i��F0�������ԉF�׈F��D��ӈFk:��%��Ot��S�N3_B4z1�i�S�Fg�f��h�03����03��D�h���ht4?h~Ǎ#^�z���Z�����lt��,���a�OHJɐ*��O�������OO�dI*���P ������?E���
+w;���3߹z��g��Q�,s����Ϝ���ለ`�l�[�!9�����j�]�Z\�a_�Q�AoS4�������OA��~&N���4��,������Yu�n��T��Z(c�߆�`g�oE�?dSV�+��l|��G��W�'�2a�#ו
+�k��8�Í ?f����/^��k_F"�
+������e_��}9���� g�ٿ���Ҫ�qw�o����Pa�_������S�r��!�{V���C�}���Q�?醊�va�$���?T�o�÷�z�F��ٷ^}��P�%ȉ���OK�u�%����`�����'Y�ӭc��/���Yn����C��Kx�Ki_ ������:)%͚��R��?�����@���(��p]m����ڋ���qq�����sj�s���w��l>����$�?q��P��
+�$�{��G�B�]٥
+>
+�\�"�\��R���sa�*0�C�?�P0&"�X?H�d��QI��~>kb�@E���X���
+fa���C���i��S�N,�&�<ղ�oX���{~���C����!����\Y��B+�$Y��m��������NN�*
+�s�'$0�����������/��cIMHNL)��r��?c�����<��k����=��x����J�y��/}+�~*_�>5��r��G�R�3;�'����G5���NE�q?>�����N_l��a��3{/�?�:��}��~n�v��s꿬���O�`u��-��]��*M���R�����TU���L�$W���I5�uR�w�n���݋���>�k�6d�}h��ZE�壎k�W�Z�������dL���3�\�)�3�]<n\R�^���x慻o����X��"���9>I�0,��Z�|sO�:�Z"��)E��Q�e�,Qσf2�<�hgTG;��t�y��Qσ�:�<�8�uI��Q'8�uD��Q�9�y�N;�4�v&y�3�ʇ���K2�ʇ������D"R�0�^(�ʇ$�,�2h` U��a=� `��A,��3���S�`��g�U,�'&�3�3&#5����1������������+��>��V\����M�����Uү)���=_���<���V��������K�\��h�ʡh���z~N{��Mw�[��&�_�JS~�*O�%U�Ԕ���j�s����\��-G|�M�����r�ê�nϐkoz^'��_���}6	Nҝ����5����!����L/I	�,"`���"���Um�]����%�:?O���V��Ώ�i�|�N[�9�"���h��ȷ׉���	�� \�=�/$�cHDΈ���Q���������=�C��E��G��ɛ�j��DT'�N���$��OzPX��/6!)it�5�$��5�pk��1����[���F��Q��2���b���el.�G���� ���K�>�J1�S��߈Ჸ��Xgy@�������A��+.r�1G�������!;��oԇ�~�����9ۙϞ�������9��2�4��uyl�p)�}���YJ87^N�n&%��%[]]$�;�	�NJG3�[�O�l�|�q=%Ν��m�d�/̷����e>u���N�}]���J��'emyW�zi�4m���C������Q��YKkK�#�C����+{�y��<�_e���w,�P���0������ޝ%-�%�#���A,�_'��D&��W"�4U&�$HĒ��Ē��%u��%�W"��L&�t��C��bKUĒ�&���n* �X�	�X�R�X�v�X�4�X���:��OdbIS%bI��Ē�KĒ��Ē:[b�$�Ԍ�C'�#�PbIdbI'%bI����XR{�X�q<�KڦK"VH&����C4�$bŀlbI_�Ē�[b('�4^"�D�O,�X1 �X�`�X���p�M�3�W��_\Bf�׀��n��c�������?XH����s��<w	,��W�T��%P+Z��_WD�+���Q�Vŋ
+�6�[��&$''����x�������(�½���3~�6��k+��ǭ������z\¸�����B�����w��Z(�GW�΅r�	%�1`pb�m6@�>�p��c��9���El��.b�8ᢻq$�♓=p����UQ��`k�e��d�Zߍ�ߞ���Pa������p
+{�o��s�����˸��s�����o�i��	�n�*[�*��a���0�b��}���:����
+�5_�;�X���0vga���������pƮ,lH�e�,m������P��,��=�Ϣ=7�O��܃��l�Q����
+�B���>�_����G�w���F��ﲽ��։��w��t[���g�����7>� �el�U�+Cn������C=k<_h� �߰���O[ޣE�ܨ�߸����b�ɉ���Jӏ���=�4[�G6d6��^+�T������x�o�k
+צ�6޻��y�S|�R9�܏�vgb��[^S:�d�s�����f&*�AYk&ĵ��.��Z|Ǽ�\����ǿ�̅�nJ����,<�t]>�3�|�t��\��OU��g�~�+����_w�Q�ٌܬ��G1R���u����*���rL�|���.r�VE\l����VdV�z�*����c��Q�;�:�C�NrCv����`dD��f$d?r�F>6�WLd�áX�ϗ���S�&Z�x�EJBTo9�\����+'��X]���w:)N]�'.�'9j3�БO^�s)qMxi�>F��)I8Ƨ�[��A���N��=�dy,���lU�^ʔ��X�L?4DΞ��2#��<sT�2k����}9<i�a=�*X�V�qǿ��e`��ƹ�:@׆-�m6to�C0���P�0��°�m�0����-�`a���!�=X�`a����(�8� `�X�Z� �*`.� Ȁ؀�����b0[��F`b`fh�������@,� A� Cx q:bp��$�<5�g�$����f�aP%2�#���3ؒY��!�����"��*�C2��� ���t�/5�g�F� N:d�L:�5�gpG� O:����CVs�C�Q�x�H�l��+h�@:d�L:d�B:�*�Y���-�ɤ���]�B��� ҉�3�A:d0~��!y�!�\
+�}鐫� ���!ǨA<s3�C�1<s7�C�Rcx�vH�lUH�dʤCV*�C�ȤC�����I����[]1����&[�2�����B��P���-O��V�B�~n�E�J����?�����Z�\>��>�˫܃7�
+͙��۳������,��]�5h:�M.u���aP�i����_y-AѠ���Q"�]�B�r?#{��sc�<�(e�(�������R���,�
+��D%�Y��!��i�s�۽F���_/�$������5P��4����|�3&dL-��(~�W�/���-51!9ݚ\?�y��r�%�\�PP��m����r�7��^X��
+Dfv/hl�|�6|~N����v<�����T-�RVMC��m�*o[��nJ�n5l��Y��_���J�w��tU�����:��w�?g��i-_�5~�s<c���׳��khkh�1��'���b�Ҩ���q%�Ҹ}}����j��m��Z�M?q�y���6[��͐�Qh>{��E\��ӆVƫB�^��48&x�{�������=k��=��;#�o٪v����w�J����6��O����?�&�����ַ�����m!�=�P�z���
+�~3t��Mx��oaj���M�.Ju����S��ۜ�m��}���/�E��Q##��"=.D�.5D��&D�O3D�_%�:7�����>�l1ٯ�}7��1W����%�2�l=���8�{��g<a����0ī�0dG;ah�qðU����#�FnYe�F��o0ǜU-�_����R�8�ﮪ	Q���sϫ��Ѷ�=�յ���N�:�Gw���iB���aR� !Y�eH����
+��	�)CZ�<!��:Cz��jf藶��?�,Ֆ��[u��m�V|�N?�n˞��:#'�6s�lu��P#^���o}V%[��k>9n�t�ce(��o���Z����]�̖8�쉟�C���DF�D��DF����[o��{`�M4��^��R��
+Hɮ�\�v������@ws�R��w �pE����OQ4 	@	�	�	 �iUE���~��� X��:E��`�`�`�`�`�7�� �I�H�5�4�5�4�IHTh���@�؈� |���UZmim�ՖVx� %2s$���D�(�Dލ��H"�6�D�*�D��@��@�mI�<�$���GU�Ȓ�$�V�$�36��+U���6��O�$�EId�@�-6��O�18���I��m$�{�18Zmi+�D�
+��	�D��@�-mT�ț��I����gT����H"��D^f#��F%�<�F��@y��$�6�$�4I�UI����$��l$�_SI"��D���D��DNTi���F9����jK{�$�	I�I����H"�cp�$��H"�H"�2�Dv$��H"�UI"�f#���Jy��$���DN��D~^%�m#����jK{I�8<�J9M�Ֆv�ȃ�,���$���18[��Idj}�-s�$����D�S%���H"��D~�F�#�$r��$�+*I�8I��*Idt�U*U��Y����Y�g畢��MA��?���C�>V��{3��1v�T�R���������R.��OJ�5-Ӛ��P���o��1��o��A!N�W����D�u����x=�nUú���}��Eݲ����א���h�pᾏ��h���'h����7��R�+�:�Ww5��wDMm�T�𫚻=Q��i�V�'u~�8�����=�������1�C͹�Y��1wKn�)?ݥĪJ�w]���a��5�g�
+xl�ǼX�h�w��-8�����(�-5�n�eK
+x����0�sӖ��vC��>�JTϯ�V�>���XU#�N�b��H�?��X��XO�I��Ԝ��%��Mճ�3;ױ���%�5�?�9wx����I�V�	%������	p�V�������%ݟ��[�3v���]��XI�^���H�� :������>���U��XG#��E���<�s�e���G%�w�����*2�0V�Rj1�c魌��xEo��=�f���{e���O�z�ݙH������H�+�ȏ����f���H���\@Zu)0jcg$�w'6�!��z�Y����5-���,����@M��y��P�q���<AsU���"��T��.�kR�:)�w '�Ǒ��Iy�r�<�<s�<B$RW8R�����ȓHy\�Iy�Hy|'���*��Ñ�X)������H'屟#��N��=���lR ������X/���Iy�(��#��"��Hy�Iy��Hydr�<X]"�1�#�qF"�щ#��D�Ó#�qZwf�:�G��x�}�?E[\���)Y���V��O�`X.t�/���jIJ`�z�Ċp�C�O7��f�)�,p���K��2Z�L�����[��1ؙ�[����G��$5�k��9�|=��	F*�=a�e�l���$�|j�j�L�^����+�{@�X�7�߇�}'r�b~�[{��	�
+��I����n����O����U��-�e-��3馯�}�K�yҴï�cg3_��u:8>-�c���.z-ij�����[�8�h� ��ۺ���eb�r�����o ������ � `_6��#�y��,�X����?,�x�ph�I`���Zv2(`'��vR`'F��l<�D�N򚓺�oe�bt+��������V����B������qֱN����/�����!A�7���LNt����?%!u��
+�_���!A!F��+��c�`M)���������w꿊��ڱê��?�s�Dk9WM�M��r�
+GB�G~�,|���ݦ���y
+��幆cG_��@����Ue��/�Q��v��ҧ;�����߼d�;[M��3lM?{V������fT
+�_ٚ϶
+-j«-OH��!��_j䩂�[��;�М����N
+/�2<��@
+K�m�u�A�J�s���Ԁ�p�� �
+,ֵ���*�Fh�u�
+,\/�ld�-�n��ȮZv�0Ñ]C�pd�3ٵ�Gv=�%����]W�pm�
+��X��]c��:��k��]o�8̮9���'��.��Hw�=@���X�`�~��{��m�{�����G`�>��{�X�gh�}�,ܿ"�\R�u`�@�����O�$f�O���o��!!����Ö�j�U��G�=OWO7�x��X��%���)b=�#Z�
+�E�s�v�ۇ�>�E�>Į�w����rd����;�mA�Z����nX�㮭�u�������z7���耱D�������s��;��\����e���=;7�p~`���y��s��$�{e��.�3Ҹr�������O�T�4k�����t'�K���ZS�+���o�ɉL�[���4��5�:9��?�� c�S�U���h]�.LjϽ�+�^L��~PC涂���|�ޫ�
+\
+,l�sX��쵿�I��Ѥ];X�B��ٗ�-��������?�2)%5�4(�]�`�����'�+��8Vm<b.ʡ��\�ߪȏo�D[{E��Y���\��rI7���ns�%u����"E�͑��X�:��V�Rԥ'��*
+��C	\��H�_^"�9�W�ɞ*��(H�F��ŏH��:�2�+
+�l&�:(�^q��9R�^����!; �s�>����ܥ��9۹�[�����F���c>�-�Jc|_��&�����	Q���s��D�fR�^���E���A�p�4qq4��U�>)�=�������I�铍�p�)���{��~����srf��Rf�Wr��<)k˻��K�i+^���%e�̐g�t�f�,�ZZ[r�T*ς�WMTÞ��F��.�������[�K<a�
+m��V<`a ��AXL��؀BA�
+26�P��������2�0�в�ph��X�`a���#X�`aP���	'��
+P�l������
+Vx��EKM#p�����`a�2X���
+5X�`ap��9X�h�`-�`a�e�,  ,�  � x  �(�� �� ,� ����  ���, -X X X X X X �X���������4Kz�%�b��`#���IȲ�M��n�`����K��'$ǧL� ��cH������t�����2ɚ��P��?(0(�6�������oܛ���3n�������%_��������ü�W����{�7ԏ|����O�^?��u�_��͍�ƪ�'+Ƴ����w/GQ�s�r�(��k0%e�=�$���p����h�/.u]+�ܺ��ۺ�+��bJC	_��>���2��
+��&��=�f.ʩ�l%����GsWL��j�/�ۻ����o����S����H���o�y�}z�e�ω��쩧�,�������/�&'>����-Hڤ�VC��\d�Y��0C�푇4xI������-
+�?'?0J��n�{&i���b�lM�,3��c�c���z�O0�Х�>�rb���ċA���;u뾆�o�߽$'��!Mz��j)e�4o�4y�a.u�D)��f.�G�����\��Uϼ<�˪�[�:b���O� ���U=����5��Ov�g=�_g�r)<��rc�򺓅��)~bյ�p�z 
+du}(A�_ȡ.�0 �-�.�00����,�
+PdAb�0P�u�.�0`� E��.]d��F]�a #b�Y�Ȃޢ.�0��-�.�0��Y)x
+YP4M�0���A��
+|�0���0 ��H]�Ȃ�Q�p ��w�K8 Y�s�% �,��Y�<*�`A4�
+� h�����/ d?@h/S�p �#4S��1P!��
+� �����/ 2dAh׹Jp�U�ǌ��U����I���P��m�?B�s�� �?��`���
+����������a{�z`]녅���V+�l�wMQfK���.���{�`��d�_���/��
+?{�ܬJh�p6��S(�xͪ�Y��p6-����Դ�Z�"Wx��>��5�صC`+Pw���?,����O-���N�߁AA�����R-I���4�?�~'��G�G`�p��o���K���X�ºL�m}�^�X�!�{G��SL-�t�������MG�^�6
+�vx�l��_-��u���.۝ibo�e��a��wE�����&��~����boG@j�)0��4�n2z�q�j
+�v��d�=��~G�<��������=l�>���x{��Į�{�M)��nsƚ�����#M~���oS��8�|��Q�������EG�s���/O�le���'��X��o��(�x��?��8 �s��&�����6��}#��5�}��c���C�p��>����s��#�,s��"�G�Ow�^`7�,-�����N�&����G�	Q�L	纈�m~3%�1��jߘ��T'��d���ˑ����LΑ��}{ʠi�2�d�vGj�t{Z�7��F��󷉙��L����,���-�ũ��������L�3{�3r*�f��g-��TX�L���B�l��m��pu��[��	�8��� C�����F+|SL�·�A+|/�i��M��e�i��i��
+��
+�j���$��-i����V�&���j���V��h���a�Rl�7��a�Rl��A�-��b[u�z�a0Slk��b[�۲�i��=��=a���>�b[�v�mm)���N���"Ŷƚ(��%Rl+�D��a"Ŷ�M�����V������vZ����j��I"��2�
+_?�V���h���8��WO����@D+|o�1����x�":��> ��g������p��h�2�`�N4x��hp��h�R�hp?��i"�`��"��z&�����I4؀� P���DZ��d"���v����V���c /��evZ��� <�N4�
+���vZ��&
+�f"�J$<�D4x�H4���h0m*�
+�+ �h�/�@[�@�.|��Ź>W!�_J���ҡw�����?!���ʓ�U+|���Ϙ�#_�(�șk~僣��P��
+-My6v|���iK��ִM�os����f�c[��3m_��cG��vJ����1��y����Z��
+G9>?�۾��f�)��9�gԾ6}�80(G;hx���%����p�l��8�����}�����o���[F��-��]�ǭ�≙��'��ߏ�l����TT3��G<��]��~�8S�v�����O���|�qn�j����/k���WV��a�8k��k�S����(��o����1�~}̗�Z�y�|�zo��K���Ӿ�+�:hWw�q����
+V��~������4e�VY��*�_�U�}bu�zs
+~��ƽhvӳĚ�s�Ë����ڛ2u����eCu����Q��Q�?��� ���04��h۫�G�&b��Ǵ�.W�����?&z��57��c��]�����DC�E���b�A_k-'�t�2n�Z�z�Ѧ�Rͻ]��;�=��[��'w���G�-#�;�o�仢k�c�k%��l�-<>�?��TGR`T�+A�%�]�,J
+�v�Jh�l�W:�=����W�6�l���ٝ7ǝ�����CϚR���6gPR�~���C�"��dGF4J���%-ʷ�#j���^?J�u�������}�1�#�}7����j_�]���< �8г�9v�bl��8��b�.��ǐ�'���/9���C���1g�6r�(Ǩ���&�9�
+�e�Hq��S汉]�x�	愨�b¹>�D��b����j?��wx�S��wВ�:阔Y[K^�Ñ2Hפ������Ԕ����~��{͙�O�����YĬ-/��^�#N[1�<��cb�̡�9�8s���YK.�.w�A�T�\�|l���������g��	�,܄��q����s)����(^簲'�!̟d���'��1�$��-a���2�\XpS`�U�w\Ven+�2ׅC���̅a�P����+C��6�d.
+-sk��y�|S0��8��<�Q��Wx�,�<�������-s��s���cvPs��fj��.Rs̑fj�'Rs̮fj�*Rs��fj��X�昕�\&5�l�����c��1�Pl���(5����;4j�����c�֨9���cn��?�X��f����K[1��������V��bi+�~��s�������]{�1�c,m�\2���Q�:Z|��Q�MRc�q �'5������q�A$5�H}���R_��i�a����i�!�A�
+-6q�b�`�:9h���F�
+�Zlh����q���Zlh��� .6�� -�� ��05���,L��/j��犤���HU�t��ި��~����R�Tu�k6����r��^b&U�� U=2�Tu�$R�]�IU�J"U�<�T��$R՝���v$��nv�T��$R�.WHU/J"U}�
+�j�,��WHU?�T��+���ϒ�ޞM�:�,��7�IU��%U�T6��AI��'d��I"U�'�Tu�$R�/i�����f���@R�lZ#U��A�z��Tu�H�z��Tu}�TuW3���ER��ͤ��1L��? uͦAR�/��f�!��R�lZ$U���T��Tu��T�j�T�(���j��T�fR�#ER�O�IUwIUO0��nN�M���D��aZ%U��k6����T$U�A#UM��a�%U��A���	S/�j�'L���7h��'��f�1��H]�^aj&UMx�)�T5��jRՄW��IU?n&U휺�b�ƺݜ����OOHMM�Z
+�q�?���_+��OŨ������N����u��p�����}�X'��X��5>!��������c���WE��a�y&��W����͂oMo]���������/\x{�39��T7�������~����-�,Q�n��c�5U�x��OFW���
+�޵��c�Н͚��z�U=L���W�g�������=^;�=/�k{��\��Ec�s���ss�����q���J~���u�r�3�� C��O�Uvv��.n��;����W���W��m����#������?�ꌶ�����]{��.�U���jk�-Vh�eh��{���ֺW����0�w�:��c��ǭ��v�����O[�>��{���{�戨��=�Yo1�י��ꉎ��f{��ю����v�w�~y��ϛ�n���q���$N�%��j �6��+8�ؼ�
+�6�T��}]ٓޫ���gՂ��1��;UIdb��]�b�\�e��ri���gN��sQbjN(-��'(���>g aO&6���@�l`6���
+,,�0��� ��.d`a�ad�
+6����]6�0��Fv����.��e�#�l bd�
+F���aPbD�
+L�08Ѳ��]6H��@E�+F>ـE�-F@��E�/F0� F�1F(�@�%fx�����d-�`a��e�#�l�cD�
+v�l�c�
+z�l�c�
+~�@2 `�� #�����/ #���0��1p`D��"��T�#�,h`("��9 #�<d �	��9r4&�hP�њQ~ �E��x �[w<�Q�m4�? �(��
+�|ak�� B��U�c #��H�*�a��|��w�~p����P:I��S�+��[�-��HKZzBj�s�/e���0Ւ^����]����%-͒Q:�q��_����������B@/�t��~Y��]����&]j;E��N�t��P��!z��ǵ+�:�Ww5��s<����$_w�\�4E�+K��*�RUQ3S]�O��
+K5���n�k��>�\S�+�:���nO�jo���y�I�_6N�� AdjO��5J�?��� �Goر���OMݣ���Q�sz�J5͍/�IM��3{�=+5��+�׻_J�V�k6drz��/�[:����Vkeܮ����֦��w�4�;���6H��]%�;���2_�?���*=�>��7��$��a�OL�R/�����ߙ������-�Ww=��-��/zǼ�N;���B[{^�Yֺ,tH]���L)�nsf���[$��[�~�RdD�9��7�(��Z����h�nZ��$�׹�Z�H}��1���[�������U�������=�J��v�c�~���1��PG�S���>4�Mm�����Ok#漧�ܒ���_��^�W3�l�,�'���.��&Ƙ�ݳ��(?s¹aR�w]s�0�Z�W��/i©手;�I_]�&ez��k�k)��ui�{�d����,��|��������2C�3s?��<��Y[^��^f��b�4�P�9{f�4#��<sT�4k)g��R��g�ޤ52�Ŋ`� �iȒ(�a��r�I��0E���0�r�j��0D����5�i�SNCS�r<u�i(�(�!_�����4h:�4�)��D9
+_�
+���r>��`����D9�̔�0W��W5�qH�(�a�F9O��0N#e��S�CO�r�t�qh�Q���1ǁA�r|̔�p��h�)�᜙r�J���r��(��]<�S���Q�:E��j��]'E�F9oPM0�(�a�D�f�F9�$�q�(�a�D9�f�q�J��l���xn���:�8\6S�<Z�(�wf����)J��LQrw��7�vD�Z(J��F9{u�qX�Q���DQrY�(9�|�CQr���T�
+�E�3�&sG��(�n���T��'R`I:�8��H�Q��)0����"F�^p_���$�q8e���T��3R`�RM0��(ǁ����(ǁ����(�a�N9Ok���N9I�8,�)ǡ�F9$�q�h����8Ę)�!�j�1�H9è&s���F5����/�r�
+�L�q��Q���N9�5�q ����+�S�q��p���@x�J9�Wp���@xwK9�Wp���@x�K9�x���a7�f�t���O�2zhJ��
+��� ��]��������dM,��A�������oN�Wn��j��?c��9/H�|�yץhq�S�D�6�4��s��ڢ�\T�t3e�ϵ𝿑>Df/��.ŁȮ��M���� ����A���ts����YN���Y�l����I��z(�_ʤ���������[�?:�ʓ��(|�C)�������(�.����Lތ5qK�.O�*e�ʓثX�;���W��p�ohw��$G
+����;?�n�{M���?L��͎ڛ��uH�m6�]�������Y_��ej=Sl��bz��,z��aoT��ظ�h{�������MN��y�k�6���浮��l�O6CfG���ݶqM��NZ�
+�{}nh������m�w~������'����dh�e��a�36�+���'��f>�
+/�6�D��`�zBX�f��~����B=�Bl+t�����S7��o�1��m�Λ7�(�ծ˗L)g�ns޷u������F���n���������>��~����C�?V�̲�d����8��o�\U\f������
+�Vc�8[���������/��ݳZu�2|r��d�DȿI3�N(�^�����X����y���0;�e3c_63�e3cw��;�-�U�ú�����in�/x<wc�������Q]���u5E��BZ�,R}�XL\D�3T�rC&.1t�r���.Jq9�m]��e�%�r	��$S��I�v�L��D2e��d�a�ں�&�B[�$Sh�"��d�L�d��D2�,�L����'�2���\�	g�	P�0o�r�y�+�+�\��Fr��@re7�� �r�@r�@r�sɕc���<ɕ<Jpc���Q��d ��U%����J��J���ʓ*��Frņ��4$W��c�8$W��+��H���c�@h�"���7"��
+�W"��	��;�\Yn �rF%����*ɕe6�+kT�+�m$W�$W�H�lH�L3�\Y%�\a ��Jr%�Fr�5���0ɕ�*ɕ0�J0�Gr%���B	��]_�YW��uU��
+�k��e�,r���K�q_�܅�*P������)��+H�O�!0�3�wO�L�&�E$��s������#,S�-~�p�C��b�� ��N�W>��{BF�e|���Э��s��<����~����7:)�lv�m�<��/�$�^PK�x�w�R�wzw��`��N\~NG��MO�D��.��JS��'7��X)U�+r5S��*�ʮ�2*5x�\�wy7�U���R�ux+SO*�7�dJ���˞d
+�	���	L9����F1�Ѓo�ч)���G�H�Q
+7�q%o���6J�5d�}Օ��,{�{Fi�r�l�l�7��Vn1��o9����{�a��Na��������J�3��ɿ�t�/ɾ+�*�� ��LT��d��9|@ZC90j4��l����C\��M�`���1�0�i�y��o73�t��o��³J����R�6g�ܽ����ϐ#��W"#Fˑ���|��^�G��bLz�뜉1�UJ��#�Bo�RxV�z_ςۋ�����C��}Ǝ>ԟЅ�z�^�c}�a�2F�ޯ�:�R<�a��*�Tj�I�%F�<j�P�؟d�
+�Rn�
+xp�B��S
+��RH�Bډ��AG�b�!��?u>m��R̠�L1�F��Ћ1�`<�6��)f@��3�
+��l�l�(f�B1���l<�hC> �b��S̀6���m�O@1�H�bn#�D��3P��6䃇��Mڐ��b�!<�
+hC>x�|�Q��8O�ڐ��b�!<
+�
+hC>x��� C�I�X�\�b�!<�
+hC>x�І|�@��I��Q��6�G���?8�P��N��y��Xm�OE�ڐ�b�!<�
+��+�^+��(V�B�ڐ�bX==�
+Fq+X�S��BV��(V0B�X���,-m>X�en/�0u��#�O�bP�����N�_���E�C�wh��ޡ��=׾کa��{�}�ء;4a���|�C�uh����%5+��̱����;����e��c$��Sd�����2��6��.�F~�(��d��G#�?�R�g#�ߏR��#���_"��+9��?��?`^�����l�%)aR��g�'����N�_����9l����������N����e���^�a���&X�-���r�	q�(O��cG
+���xZZ{1Y�8.��~�>sN�`s��yw��|��G��7��|�uҕ�V��K���UZ�ч��^�W�����W�n�"�aU���Xoe@f%y���;�{9�J%θS���?��$������;����ṫ�w�Ǐܲ�y�
+���7w(����1�딱�V9�}���[N8��$z�ʉ{�(V�:���NʄS䉋�I���+w����7᥅���ʧ�l`����o1�yJf�:93����H�ڲU�z)S��b�2��9{�ʌ�N��Q	ʬ��2�?h�Sťd��Iz�7d~�
+z����yC�;����k���[��k��E�F
+�,��0j���A�FϽ�5��k�HC^�qo��5��D>ӊ
+�E>�F)Z6R�װ�z缆�
+�.2��B�� ���0����*�k�'~�F6��o�'^s��
+��k����'^��#^��'^��#^��'^C� 	�k���k�)�k�2�E
+���oB����aH!^S��
+C�2���}��5y�58I�k�q�kH� �����,&~�O:PF��B�f��8�5�2��!�>�5�C ��k�5�n�!1%�?��ђl�T:����
+1�P�7�2u��Y��4���������Ĳ��A����B�����j��Y~�y�� ��^��	�Km��ˮW�Ts��=D��͏�o+���l��ZNE��ZN�R˩2���U��Y͵�Y��k�{Ҁ�����<���l�5JaՒ�8k6�Y����e ,�Y��+#"��eQY����ƽ~7~.,��4���3@�j��S �a��;�L��"2��)��V�@fg32K�Fӭ��MD��5�����&��s����<���T��R�cʾ� ���
+	r��
+�-*���sU���Ү��}c:lh��?�ZcU��|�=�o}��/����� �q��Ն������T�K�5�c�7��Ȫ�@��~z���!w��������dkV���a��wK�NKI�8�_��?%5�ג�+�Z��&��������?8������W+�q���Bh����W5��h����b��{M�{bӏכ��]'6[�����"���)&��@�n��@�n��@�n��@�n��@�n��@�n��@��P��:�k �����#M~���o���.J�ťr�k�;UūT�~�
+0~A�%]j�8p��3Έ�
+�^Q�gP�|l��K����h ���D�
+�	����c
+E+։�x�a Q�b���hEQE�hEQE�hEQE�hEQE�hEQE�hEQE�hEQE�[�C����k7F+``R� �Dуa�Ô
+ҒP�Nu_r��|������q�JkI����� g�ϲ��)���M-�*�������[��*������%$�O)������
+r������ilf��?O�Ω3XϹ�W�t����'�#�����n���/��6%
+G�Z�r���}Ӥ�v�����[�$�w{����K�;�.}�_���/�UM�;[�t���Om���&���f�p�!����AB;�&\��`����9tQ�C1�^��
+爙i�<)C�/������-;w�p�h�5 �,\�p=��5����k�MA����Bv�p��]'��Z�Nv�вk�;:�u���!�f�O�]C���:"����ר4��E!���B�,�K�sE�a��e$�0�:����|[��}r��r��U
+_7~�!���� {Q��R.��R'�ڒ%{���a	rp�J�K���۴S/n��
+���&V�����?:�֝�n�-5!ْV��4ޖ�g������/<�����q��c���W�O�\�M�����|wJgӺn�c�ɾ�E��^��M+':�o����9WG�7}j��L6}����@� ����MW���򟿬|��Υ~��d��J�h�� {C{�j�~�j���Z�C��_����L5��Uݎ�f���y��Gߘܟr����Tg�:��w�^��"�q������XfoP�y�a�����U�j#�{��F�����6�j����jӵ]L^���B��0���<���E�<�e��M�Z�r��n�\�d�>�Rh��v��'��y����W��?e�}b��ؒ	v�1cUA�o���������A��&c�!�=�R���1��.t��������n{���ػLX#t}j��4�s������o��=_�G�{V��_g��UR��.2E�RI�y!��a��k�S�N��n'S�NW�������kT��a{�lE��w���jl�C��!���k�ڇ��Si�ԥ�K�JEOfU�V�OWׂ��������c\��&d́�E9��!�@$�F$�@B�g�lq2Ŭ�^,j�b�6n�f�,p�0���@�,x�0�q���Յ
+~� $$F�1 ,�-X Zܢ���[� �/�AB@�Sf`�����@�1 <�w�c Z$�0L`P`T`X`\```d`h`l`p`t`x`|`�`�h/P{ #ڽ�@�k��V���k�(pHQ�0���a`E�� ���NGj��ŵ`\+` Fˀ�k��
+ ,��
+>�� n\+x��c �q��	j�`ǵx����V���k��V� �0' Xp`�!����9����� N,8
+��,��� N,8�ؙ���	�@pm�9\�`��&�3A�
+Xp*h�c�,8��d����,8��tp��ej��:�µ�p��9"�x�3	-sJ���S�@}h�S��3)�,��L�e�`��{�w�����������J����v]l��T�L�j��
+_�5�u����/�jj/ȵ���=C���y��[�s��t��tqz=kWh�� :�kر���OcΣE�Ԩ��q�FR�r��y����rӏ�J^�~'7[�U2d���^)�t�k9�#��q?׺�+z��q��f���{e���O�z�ݙH�Yó�j�T�ƶ����ޤ�ܲ�����.*�>��������R��2���S��߃ʹ$_��(O
+\�� ��i@�N{ :��|��٩���20'd`R�����Y�����A��X�2/7d^�1ia��A��5�$�ָ,S��Q��5��)[c+$)ļR�l�ek|�S��~��5^�)[�=��5fSpY���S��z��5"u��p�D�,��P�y����T�������'Z�GG''%��y�7(�����YQ���p�����g��?���/���9��C���9ٱJ�J%������0W��/u�/��1<"���Eȝ,θ�
+c�6b�1�F�)��,;ɲ�,Wh��@���_�	c��J)��n������w��(��-w-�31'�N��s�d�t!H� 7�p$t�p����w����mj8��@�]�k8v�%A�
+4�wI��[�Q�������l��w.}��p�m�z��K���Մ+�7����g��ol�lF�����l�Т�.[�!���dhrQm������w��9s
+��:�T����5,�����7e6�]�'5*�P��p����]�M̡��h�zM6�
+(c4�@�k(s�]-�=�R��Pe�6(c4�@�/	�1��p%)ct��2F����Q�h�2Fw(ct��p�)c��@�3l�P�G�®:2v呡��OŊ��2v'в������ 3`w�;�����:��ÝBF��V�_��1�.������
+S������nI��[�Z�&Z�ǎO�R
+E ��?
+�ZJRFzB9��;����?*\��@�l��q�����*���]g���q���Og����Ϛ2�{�%yl9����� ��ﲽ�)i�TkJ�|�}�0B����R�ә>�OI�Ocq�����-��+:�2&!���� ����e����2��I��/���ZR_������[�q��
+���q�����L�Y��z�'��)�\�������`��J1KA\;U
+�O��O(�����v����1���jIL)�����
+oMJ`��#��$��/���2:"e�5���������_���E����Q�@`�c�͗��v\^��T�������e�~���Y=+K�X�h��U�}bխz�
+DWۇ�j��Ŏyj�|�c��*מU+W-(ؒS���9.uq�y�XF�P9��3���(��/��]'ov8��sA�8'@N��
+-;?�p�h�y��sE��,�3Zv�`��)>�!FK��/5M��?e�h�HJ��?
+�_��DZ�ҝ�/e�?6%5!m�Դ���2���Ɛ������_���]_�/��/��xԋI6�jeo��O[�z�)�Vޣ<�����Z��~��x�sJ�?�=�^�7}����o�=�7$���G��[��[�E�:�=��6�<x���oAJ�Z+>*�v�*�7\R:������؜݊_������?�0���켙��76�7��_�Ň6Y�����2�N��;D	{c��ys'�˼nJ�垊i\K�ۜ�|�U���&|D����|���)Q-��Q�O�ѕ?棿���:��{��>_lUb�}����J�_r2/>����ʀ�e`H��'J�h_%������iЃ��#������6�W~��a�ˏ�p�5�W~��/y���e�eL����#�P�-�:�Q�UOIl�(���(㯦*�]S�	Gc��oW�vN�'=�YI~c �2��"�3������������?������@��O�Y��P�����+��7��_nV��}��X�oe��וY��R
+[gT�S)�R}��������*w}��-.���z��?����RX\���qc�6��0���h#,�j�0�Ѳ�
+F8X�`a����F<�o6�Q~����~��(�
+P~3$�4�D�T�d�t�e(Hh����BG�P��P�Ѕ�!,�-C1������(H�h��D"�޿�L��N��P��R��`�hb�j�r�z���������������C2t�����eHhG�
+��ԃ�� � X�`��� �X�`�;��X�`�[�e,x
+��9��� ,x��I��7,x��Y��w,x���Ap1o��y��u�2��X�@`��O�X�H�b^�(�`{&���w�c���	�`UX�O�n����J�)c'V���1����Z2-R���,�5}biuY�[�� ������o���o,����s���^��F5���9Q��7���R��S��JY5
+�'�U�X�mU��)պհ�
+g���j�_*5��jp�U����V����������|����e��u(�G��������C�
+�c
+
+;����<ZT��04�dT���7��]mr���s_+��'�6�u��f+�2;
+�gﶵ�k"��p���xUh��sC���vo���T�g
+>�G�vg$C�-[������X�>�>��7�IUxA��'ڄ�� [`�B���6�w��-ĵ��Y��c[�c�o�N��	���!Lm�v޼��E��v]��`J9�v��{�/���e��5jd�t[�ǅ(ߥ���ۄh�i�����^�Fz�����`�-&�5���a�~#���0[��Du@��m�g���b��W�'lq?��x��h'�?n���0<w�aĜ���-������
+昳�e�k�1�_�c����U5!*іp�y5�;ږ�']����Y߉S'��n��8MHr�3L�$$��)q!���arp#!5�aHk�'��[gH/xT��Җ�����ڲ�|�N���mڊ����m�3_Qg���f����Zjc3�K��{V-�>���iu�j���0��[�)����w&fKP�g�� �b�5z��WD,7���Ϊ���KQ�T��V��<���-@�t���^�3�.��Ah7Wj��A <��K �1@ɀ��JH� J
+T��c '*��c )X *X +X ,X -X .X /X 0F[���Qf10��b�F��@�2��7�+p�W�(���2��e�G��@�r��?�-� Pn1'�r�9Z�܍��Pn1��r�9�[�9��besh��@�Ŝ�\Z=��r�9�[�y��b�s"(��#�y�9�[̡��bN�s,(��sA��ɭ��
+�,�l�2�Cr�7<�Cr�<Drk�#"����!��z����Hn-�cpP(���B��,��2��2�9-��q��b��s`(��C���-��Pn1��r�95�[̱��b�
+�'�1'��
+�1g��9<�Y��e��s~(��D�Ŝ ʭ9T��!ʭx�c
+N�s�(��sD��$�-�$Qn1G�r�9K�税)8M�{��)8O��PSp�(��#E�Ŝ)�-�PQn1��r�9V�[̹��b�s�(�PSp�h��E�Ŝ.Z�xQf1狖9`�[�	��ZAuL��ܚIuL�)��EuL�s�JU��Y��k>���l���כ\�7�{G�7��匮�����-����&M-o����U��W���������6�_���7aʸ����$KɯM9�����ۚ�^Q������>c���r�B��������I���q����_��?:�'�W��o���l��������%?��C�m�'��Y��<��ո��-��1��b�9k�W6�ʻ�Rh��۟��=0�;0�$����q���n��?�ٸ�������|J���ϝ۹�?��n�}�;\K#�� n�qP�����6��������>��&�c�a�?F�m��վK�N��p�T�}�����)ST��rsT��J�% ��
+�K.X�$`ᲀ�K��]�p���e�
+,\.�p���e�,\>���%����]i�'6!���DK�T��]�ޖ�lt��+O��2����}zG��� ���?dD�qGP5��a�a)SM�IqO}# � <P4�W�`Y��hi:*���RYi���Zn�֢V�=[_��o���=30(�'̨�=g~od�{���ν眫y������v�vI�{�k�?~���������z��w-&_�Cv��'�E����
+��x��F.+g���5Ud���E�����7(�z��Ot��rq�?�ϒ:}5�����R�w�ػ��w;9��}�8��+��=���k4Fd��t����ۥ�aG����R�n�1��%)&�=��Ϥ����[�����k��߱�b���^���{\n1�w�4c���������=3���c�o�H���'��-
+���2A���f��+�����g�燼��8��>����3�ի-?��C��Vu��oS.|ŏ4�0���G�f�}��/�1���-~G��l��s�I�wM�OH[(M\g瓟�M�'u/�S3�ӂ���m��?&��u�Gz��_��������&e��>uz)g�;���$<��>�pB��.��5�*�Ͳ�_<�O�)2N���0d��pד��?���V������q��1�����9n��[����7�=��f�}��T5�j�+ocG�'�� b�A�N��;"v D�D�ؑ�31ۂ���
+;"v.D�`�����!bgC��:"v<D�|���"bGD�Έ�;%#M蘈�9����:)"vT��Y��2�N���!t^D���؉�##bgF����;6"vnD����əQCGg�;<C����B�GD@D#@DC@Dc@D�@D�`�
+���Ɓ���F�����Ƃ���
+�!"C0"D4$D4&D4(D4*D4,D4.D40D42D44D46D48�`t�hx��� �"�!"�1"�A"�Q"�a"�q"z�@Y`߫Y�v�s��-��f����+_�#J��z����Ή����P�,�����-�(�,�L�!�u������o�x��-������
+��|��4O�h��'Ch�}����e�ӓ�F���3JM̉r�1]�f�:��c�����!�:�-U?ʡ����_���~�[�Ah��1��KG�[V��k�sr���ۍ�\n?e�t�a�����R�f���]���o�GH�?yN��]��u������J���(������>"#C�Y�������a�xCxW9J����c��H1_�,������Ϯ�zm�I�c�(�~�.�Y>I��}Y�;�>���'��4߿�t!�<���z9��D)��C��ҠW��;l/
+^�PHz?�O��%y�?��d���W��°����	)#�)~F6�#�j(�n�_��y�������O����<~W�4!m�<q��O�*�d�?%�f$�i��BzbO>�ǱBFx#>�H/�\�7޼��0���|�S����~��No%�l>)厸(��*M3H�%w���l��?t���Saz�S��O�
+C
+��]k����g��'��a/~����mm�9	�-���C�j�t��� s��ׇ6�e[���	0t1�:a܌�h]�9ć]�-?=Ѝ�0&C�Aʂ��!�`B��:ASBDsbs{`R�hV�hZ�h^�hbeR#hj�hn�hr�hv�hz�h~�h��h��h��h��h��h�l�L�M͔!�*"�+"�,"�-"�."�/�����wf̼{0e�݃9#�I#�Y#�i3u	��L��K0s�`�Le����\ ��L�Ie�R�Q<������Tf�L*�o�T� �T�9�TfW�T�.�)�T�R�@�2)�@�2WJ�2He��L�@*s�D*��E:!�I��"��ʜN�P�^He��R�@3�2�R�@7�2�eR��%R�R�q<��,�Tf;�Tf2{�tD*��@*�k�Tf#*�
+�D*�7*�
+4E*�!�BmC�`��He��He��Ie>$��|U&��-��\*��"���*����Ie>%��L�IeR)T�9R�c�*���^T
+h�Tf�T�i�T�m2��_$R��dR�'%R�d�H��2�>�Ie�R�@��2?�R�@��2�^�6Ie��"}��${E%�I��tJ*s{|��j �А��'���?�S
+m q��Z�������ϵ���{I�׈(C��4�뿤[rj�P��������c�%��V�$��.��n���F�ڿєj�lNU�&��l�0��^�GE������i�O�̵�{E�G�\�LAVnNM}J�S��sr�Bz���dTi�ǧ��[j�������c�*�7�L��J�h�����F*��\�q�����
+��Z�i��Fj.n���>F�-����j|[j�L����[��
+����bK��o[�#wm��>g���6P�e�/��%裳��=��4�����;��Wi-\�m<�~M��m:&U�l�$m��M����!�L���:jC}�mJ�����O]�Z<9���,�\����D�-�� v�f�M�O[�&f��7#��W\�Ç�R1�㺍{͏��]�i�{ty��j~��R�06<�Q� 4:�bTH���؊����E#dKT}�v #C0HZA:��a�
+�.� Q� 4RZA��h����SK+H�4���RK+H�khI��
+R��V�&ii)AC+H����db���M+HT�D�������$���$y��o-Wd"F����[9����G��?=;;wFV�y� ���7����?Z���נ�Y�떻��p�y�+��i��Ĝ�n:&���汝ax�i� ����
+C�h
+�����������6/}g�e�Q3�������v#.��O9��g�wn�a�mux+ǟZ;Z`~���~�Z����+�Y{�2L�9'ê}<R�Ș���5���Ց��
+��Q�3bt@uL�0��c/|�ݶ�'��gw��h�cǳ\��~��Y~�G�}�.�
+�b�O�W��s�5��D1�wԉ�g�0�N=(x�w���s֤���g/�y��8�n����F���`����Vݭ)#�S�ihi�/����zt�/`�j�s�nl����:�N���Z��V�ĕY0<٭��I�_��f�Ŵ�'�鉃���[3»�GF[�
+E��۬S��E�zj�:�� ��Xu�f��0���	n��_�%w+'���>��_�`��8�����!O���v[g�9]��r���G���<h�w�m�	�������؀�R��IΙ�����o�B��>�p�Ug�"�W�mX�YP�OeJ��n������;��Ӷ��dR�ijR��)\*�ݟ.�F3 �KE��H�v���`�lU�1�S�/Qh4R���x8�S�`2�ls�l?���`>�lߦ��]؟a�DʖxФH��X��E�VI�Σ��`f�l3�x8�)۹T<̎��dG��?ER���ψ�l�8������
+r��=F�$e��#e�(�,{��J��>���QG���")�-������l�P�p0cR��P�p0gR��h8�5)ۅT<̛��sVR�w��lXI��Iٚ��l5")��T<̟�mw*4@ʶ!
+: eۍ��-��m�&eK�G#E��]Ǒ�=A�Á.H�R�v�
+R�v+)�")ۗ��l�")[*ڎtBʖ��#������H/�l�h;�)�QjR�
+8R�T�i��-mG�a��@Eۑ�H�R�v�#�@I�l_I�~LEÁ�H�R�v�)R�T�銔-mG�"eKE�o�
+��D'׆XMHH�q�Q��/Qe�#Ze�O�??��9P�u���Tk��C�
+�&X��Q�Fi���)!�&���M�[���ު�	s��	��y�!���A�h���@
+T��8��m�&t]6�	ݗ�`Bf3�Ѝ�&te6�	ݙ�;��L�A�f��6�w��0��0��9�'7���)t����}_�%��DzՔc���_����_�R�����sH�������g�m�>[��u�v�u�ܥփ��Y3X}�֣k��ǖD��tP�4W�gUt�͢}�x�	2O�4�JC���L2�4�ed��մ��� � 
+�U�c`��� �(�0�8�@�H�P�X،#��XŪ(�I�^G��#�K�k�r�+9�7���?2:J����W������0��\������E�+��bb�G�����������u��J����o��8�qP�����(�F)���VԴ������v�K�G�SD{��N(��
+�=k\�Eը���G��3(���ڿ�T,��f���o0���%R��{R�;nxlu\��nyP���~��mz�xw��u�V-md��]�z��Ak���֎<Tl�_�\�Π�;�[�.��E�'|�腀��^�ilІo�-z1��d,����M�-�|��E[t]��Km�,zeɰ���.A���[��6(����A���=�p����A;B�-����v��\Лێ.�u��E��mY�����*\�h�C����ۣ�}��މ)���������lT�+?�m�X�3��
+	T�cg� O���<��b?v�r������4����y�@ͅ�ɾV���<&�����V���}��\ �d3�>�}ؿ��X�ā����ʦu�?�:��w�:ʶ ZG��	��� � "� "� "� "ɰ=�h�l�p�tX� D$�@@�HB�HD�����������������������������!"�12CDBCDRc��@l�Hn�Hp�Hr�Ht����������� �����>�xԊG�x��@�?���z����I˵Xj��w��?��r�Fk��/O���c0�u#��N�=�)��u��SuV��O`���E�T�� �Fz��R�N��GT�QΉz�	D숊Tt�������@J|RM迼|�)+Ӕ����E��������3pG
+ǵzCHB��������<䨶��H\��}��|��iy֠
+=<oO��%R��Z�ȗ�,J�n�=R�d'Jm�%u���
+�n�V_��*P�X���.��"t>��e��B׭�n�G��O�z��,�̷	ڴ�B����βT�߱R�6S6��(�89��IrLX��q9��X�7;ʷ��%�z>^�cG���B��79@�;���/��zQ��ᐐ/��7
+���ʉ?�+�S,:���/�˃7="'^+$?�+�$��G��T�d��3����qb�R���8������yo��x/&}U�w>�LH���'1�T7�"9�?�S��cӞІl�ڑM�A[�i8hO6�m�ڕM�A۲i8h_6
+mL�pK$�_J$��%�_�ɯ�ɯD��W�D�D�+T"�U_"��*�a� �.��
+��=���
+�ɮs��'��]�hSO�3$�l��'��];�z��؏Hv͔Iv��M=�B�"�E�Kb�"�E�Kb?#�E�Kb#�E�Kb�#��	$��z�����J��%�?���%�_���%���*&�~J�k�L���dm.���dTk�dSS�D��p`/xػ{�2|{n���L���L�o�^Wn��������?�q��!�u([�ۊ�g�����l��T�=�zZKߐ$]"{�,|�d%����z?L�����d��*.�x��`�x���hQ=�u��{���6�M<�7��5*��7ȼ�-8� :�
+6�8�j�]Ӌ��^8u��0'���l��f�ϗ^�p��%ŝ\}Q�r@e�����>���ep�'�6��
+m��m�쌖iC��������1�������F;���"[�{���h�h��|{m
+�ɖo�Fi�v�QY�U��i;/���	�����w]��~�ٓMy5���U��m��4���'�-�����ϰ���=������U�������u0
+��|
+R��ӫ��i�g�N}6?ǜ�-���$��!j�*�	*�{|偋"(�ú��UaFiB/y �/W+��k���(>���Ԓ�s�7G,��?K�9��^����h]�����I�W�e��1�uc6�5 ���wb�.���ꓩa�S��[O�ל���zz}�~�����?����#߷��/T+�v7r�����e�~��?9.��I4��z=��.Z�`�}����ÝD��K+�����РPL�1�Y������dF�����j�8�@��2CEDcED�ED�ED�ex�ġ�賂iEL_�^70+��U��S�9/�4���_.�72B�����*��)W�������'�V�S�N�O=�Us�ע9��v��>���Rk�&����x\���k}r\��<.?�$��5Ր�V�u3��m-a�?��w�*����{drl�!�%��`��>�(��^]�R�A�����~�JB��Y�����?�1���L��_�6r})�X-��hP\���������� ���_T9��W�{R��w����n��Y�A��BE>���jm�s��9;�5=�kg%�ņ���&���`�ׅ/��w�_�W~�Ha�7��|`�_<�W���:yӺ��f�Pa����Y��B���˶���W�ռ�U�^�M�mk��mۥ/l�>e{���5;>�E����7����Z�ж{٫�=��4o.���,Ҽ=z�f_���wb�i��������m�Գ�����ϒ3��xrq��C�z�7K�rJT��$J�z��:9�/�a��җ^���9��]1�~Tiν�{���<� �
+��k��0�O�F���A���BO�:�+�
+˰���4� �,ʌ@�a�u� �A����"QA�{	��� �D��
+�e��D�3D������12L�����XT�Cd.*�f���� ௄�dT�Cd4*�Cd6*x�!2|�=F����K"�Q!������8��dL�<J`�*y���e2��ҹ��ԜR P���F)C.b�j�u��e`}O�Ρ����0���O]��SJ&�U���d��
+��FI|t���N�� 5�dI�����t���_��[��\�^�rB���o���W�o|����~���7�=#�Z���{�liO�T��	��̡�ۣ�}#�wb�I�;5���I�6���M��ۛ��|���͛[��-��m���j���%b���a;7�Hn�Q|1����#w��#`� �u4�ԝ`�n	#t ��1��@�ӗx�)�1�u�Q�[�n��[�s7��_�k�
+��7I:�=v��F���
+��/��c�wB
+�B,,��x���~���Tk��ŝ
+��u$��`,Lڃ���_�
+�I|0��/H$�a��D6C4(��$��C%��q��H�c��Ƥ=��`pLj�ёԮo'�m�Ij,��>*���M�HR{�HR{�HR�A���f����#���#�� GR�
+������ ��v4GR�GR�%GR��H4f�ځ�}�Q3�]R�c���Q���n�������F��Kx��F�ڛ$������Hm���7*�*�޼�S�fjH�W��
+��F)�?yR���N.�\�����l�Z�3'4��쵾���B�q`OJ'���4>���NǾM�_-�s��8�cO�ٯǩ?_�^��_�/<'|�� }����M���oSNp�����$9�S�^n��0��0d�h1�,�����N��_^)N���1Υ\I��Kle���^iU��0�=��A�2v�jH�-V+Fl��胝�}�U�1�Y��0��˥� �-#�=#�M#�]#�m#�}#��#��#��3�e�c� �SV��m�Ҕ���o����g��H����W�
+Z������ۯ�p\S��S��>���#�;�w8���F�������z��\������:nl(s\���[��X�ѴSu糺?ЇB?Fľ�t2�gEW*�Rѕ^V۴L�Bm�Nb����s�Sޮ����?�3�  M���-W�.���A��5���#꿕Y���E������͸�Xn�x��o���<�\\�Yc���	���������Ï��v��V/.�[�x@n�(O�ev���!��{��.)Zn߫�|k���s���Ińt;}�B���cF�	y�x����0�����{S`̛��|1���0�e���i���N���w�w��&����,o �Mn&��ە����c�GbB��0f�����C�^�1�
+����i�K/�ɏ΁��qqh�P�xר���Q���	bJR�8�E�8�[�8�v��f10���c~���kqܩ`L���'0�|��C��qN���7v�i�<�M��Z'f�~@��v���o�h>�%N�x���>Y�ޟ
+cAO1�����p�����������s�_�����)���b��5��C�-ˀ�7����*޻�1q�̧���&�����|uY�3D/(����?��ـ0���ER)D���a�T��� �f��[:�c�|ڰ�l�9��8�ӫe�AK������`�ue�c�P���)zK�	 �f�̺J��`�Ln��3�
+&�d6�=C0}&�����
+`�4@r�&��^,��~@&��'��N�In��In�InG�$�;�$�[�$�ݷ�B�p�Ba�!��G�3�G��d��(���n�
+ɨ�d�B� ���E��� ��i�d�]"��n"�n�H���H���H��+�HY$�Y�%�.��?s$�w�$��s$�?�Hv�B�F��I�d�
+�d�K"��9���E����`tG�{�H�{�H�{�H�;V$�'��#*$��J42J$�M�0H�Lv=��Ñ���#��G��u3F�$�ω$�_�Hv�Iv?̑춉$�׉$� J%ٝ&���IvIv'�$�S9��=E��	�na�!������
+H�$��'ETL�;@$�}�|_�e�ݯq$��$��q$�7�$���$�Iv?%��Vh�
+�].�府v����4��pe�?������5����?�,◟�e??J�l��[�֓3�O�m����Q}�SI�A��v�U�zހ��n���r\��eg�]璯4�\Y��k��|� o��c[٬r�ϑ,J,��5v���B��BX�� b�`E,�,�!X�� �bVE�J��2���b{�,���g��M�}�9mיm�������.!�Jm�$���$����h�/�XQ�)������IS6|hC�!�|�����-��~�5���q�m����Ǵ�g�߶�\�m��P�m�������I_�Y{�A[�m���\�<߁׬߯Yߥ�f���6p'mN7��缬y�@�f�'4��
+�l�ʹmY�ռ��n�Rݧ�GSݧ��}:;��>�tѽ�Ӭ���]���>�׼����c������q���K��(?Z}����Y���������djg۩A��t���������~ȋ��/ֱ}��Q͇=�9�@М���ٯZ��:��x�_�O�~g�tSs���a�g���ϳ�5_�b�2�j�Jd�����o�:k�m�bS|� v�Zg���U�;~��D_��7�'o��))�QR!�d�V�fqé�b���]�=��l%܂���~̃�a<���k(��m��9,�x��= ����V
+8�U�b���XE(�#��k�"�~
+U��F��*AG1�b����"T��*BQ��U��i��PZ�9����V
+�έ"p�[E(�+V�.t��X��Pȓ�+Y��%�� �d3��lF���h VT!
+���l ��V#�����f4�[���p �2�ey&���sY~	�.C�^�g�����<��\��F>FDNFD^fy)��,/��� G���i��\��R��Y>
+p�2��̨(3*�7Q��
+���N�8���tKN^�L/��
+:��P���5�`zv�9'��������h���'��\��k�R��v��]��=_UP�K�_�˺]n�dj/¾cv���RQ���EeJ#��uQ���r�Bf�tc��@W��ʪ`)�^��������뎒��W�7(/;}b��ɦ�Z���A���Zm�|SΤ�l����#��S
+,Y5�*����w��o�*���"��6��)ۜc�ɰ��j��uѺr�?��������h�@��e�\����gϐ�?9�?��F��1�I�&�ӵ޷#��J��/�����n�g��O{�}S왿IԦ�#�g�y���)I]�
+u��:wJ(�ʧ~P��� �k�2���o6���,�9�	u�;�)�x�
+]��I�(]g&LW��U��\~S�
+��ܹk�
+��mO�2�nH%�6�E�������U�.�{]��������N$���H��a�|�7E��7������?đ��<G��͑{x��!���W1��ӧ��SY���PV��u���'��`Ǎ��8�����庴W�[���aw�Y/\Ӻ
+�h�+�kP�jf�:u����Щ�Wz��Yv��	��(�Yr%�r��f���y����S�Ok�=�_d���N��͛�o��n�W\W��$�Á4.��»�<X��ȕ�
+��wi�2���4G��(�
+�z�����MN{��7�Q��-�5� T6��Ӗ�����*�ߓ��5�=�q�^�Ŋ��76zO���#q-�������Y�6��=a;�H�^|Pj�"_j�(]�e�HI��(��;Fj��Yj�+T��[}ɩ���Å��C���]����?�K�1w��3�&h��w�:�RY�J9r�L��Z��t��'�1a�B�����c����(�~�����x�m���;}�sB�� ���Vr���B|�E��CBB�$��($��+'���<�N�<���;��/��tx���h���Ԛ��sQ��-�����~ �X`p��F\R��#6�{�3����l�N~W�n�@Ҏ�[��ˏ��#�Z�H���=$<�jIx!
+mJ�C�Ӡ%�9o	�%	�%��	�t���H��g�D�3F"��Y"�*��/U$<�OФW��.<�Hx�HxHx�HxnHx����;e�Ke�+e�3e��L�s!�)��	��2	ϱ	ώ2	�^	�x��g��g��''��Hx��i��<{�����!���$���(���+��|W&�YL}���|���#2	ϵ	�\��dk��yc�
+�?��]����?ɜ7)�{�
+:��s-��le�����R0){�)������c��cs��l\�NWڿ��?7'͋�?2J���j��O��[`ɨ��7D��W��#
+���A��������s�l�I����+�['=[�����X%�l�s��9_���h,��eV����|��.|�����B�3�~�6|�����5���w�ɛ��Ͷ�M��f�/Z�K�PQ
+�m����?L5 ~N5 V-t��YD5 ��,W�`?��\�J��_8$�zrq��������Tk��C�
+�&X��Q�Fi���)!V���
+��M�y�����+�B	\�����q���{�@�CkV������1��`���j$�Q�������9���Y�$�H$�%�?@*��PQ��+� D�&4�lX� V�H�e� �@>T�� S��
+|�a���!�< %V���
+>9*��N��:�
+>��CS�	�
+>hE*�P$T���[� 6��@pn��X��ϭ�`U
+> )V)�
+�ҭd%&���d��J�'�@�,H�ɔuK TD����B���zq�e����{e:��dS�ŜVC�Q����*���ޠ�T�?��7<�8�ٮ+�xG^e��l�0y�������/Wއ�ŕ�p�Ž�� �=z<�o`y��0��|�@�q�����	��i��Gm��ck��v�u���
+�����I����>j3@���8Y|DR�w�P���R�|���VR�����X��C�ʊ�vc�j~���p`
+P��t��y��?���u����EJ��Hõ��5�1%C˨�*�%ߕ�`2j�9Q�2�
+��V`�̷�f�7���]}��}�Y\žPc���|���*Շ=FR`>
+�I�A�j
+@�7�`�	��M�0�o��| � y0߄'_I��&@$�H&�Ӣ/�
+C �J@.l��}�@2�H4��Ĳ�U$ŷQ|ŷ�~}e@�`@Q���D��X���^�R�/�l�7�>JY����Z���u���?��K+�9$?�:ǯ\xQXek%���F~����ڤP�`�Av[_s��~"�|�w��Ԡ�ӭ���T~�{��a����_���h�t��	�����?�l�}�)��Wv����;/�>��|W����!�͛.�w}\��oT-��3�B�?�Z�����?k�����>�6�����7�j�+b��+���>)6I�n��eN�
+o�е�+����ud�����ҭ�'�,^Qvb�Z�YV����#�y�������a��5��7�h��U�S�Jr_p��~�V������Q6-�]v��2���	�sl@�O�g�
+��70C`V�Y�!0"�C`Dd
+DdD�x ��,¾A`DdDdDdDdDd���0'X�!0
+S`�6�Y��H�C�a�"0s�}�|b�"�s����lĜE`$�,+1g�IqgQq��Y��F��I�?�9=�4�FB��"�<����-N�����7��ey���a�o��O���{��g���E׬Ն�bX��	��\�l�/�j�`�tcyuT8�������v�pg�Z��" %�����W,�U��S�^@%O��D%O6ĸ�<�^Q� B�)̯��'ΌS����Vf�Ʊ�=O�9���Rs=4�UN��
+z�����mw\߂&��7]�X(/����b�b��=eZ�"�5 1H���$������\^?���B��2��L���Q~�@_�b���;�/S�O;�b���W��_����.I�����va���7����w|]~s�zyת���e�{���
+�彙��G����މ���o{J>0�E���b����)ҡ�f���Y������#���2%覨W׷N����#T����������#86��r�7��1����n�F�0�k�W��)�vV����&<��<�V �K��������Ev[� �qO�I��S��?�"Q�Ͻ�{��D�9�R����n�e�p7�=������'P�OO�s�/J�I(�� !p��l(���)�g�L�?�˔��^�ԟ���<�#�Q�O�L�?��uC(���R�2��Њ��^����Y��b��<pe�T 
+������T eDY�!�%*cd��Ho^C)���Rsgx������N�i"Fu>B��j����Ss��&���>ZW���>Z����I���qc��~nF�m,���%���IA��)��3{ùa��`��Q�|�ᒱIrK��~��Y����M��-��[�6���<���Lc��|�ιv�9�N�"کVd;Պ��Z�a?�;��Q
+��o�=������ׅ_�k�
+��7I���v�V)�{����")~��X�:���]���@&���@Q��5X�A����{Yߴ¾�|F��,�˙����2�י/��|g��gv�e��c��̗`���2-%�e�R�M�	�e�i�l�|��F�e����dɗ��ɗ�k'_�Yws��|g�́v�e%�e��ɗq����/㨻	v�|�-�e�.(��e�Θ/S���Kx�e
+���lb�|+{�vI��ER|ŗ�XY��׮e�v�����[c�j�?j#A�����S�8a��t�e���E�Ո�7�,�<�?6���]��u��m�k����7�����p�ܺ���$e��&^�����
+ˣ���
+���a����oĕ�5��\#6����>��y�.7�Y%��:K���b߬*���;v,>�,z�R Rc����.�%@e	Pq�o�%@e��_�J�Yt��i�s���������C�ŔQPS-T������]��b�7�e��������fΨ��/����ӕ��������4t�ظ�f�_+�/��j�mE��=pq�7�|rps�ޤtc���:��օ�h_� �Al���;�U�
+K��]n~D����l�#������,��*+��\��5��[���֗)P��}��L�Q
+P��>&�v�ş:�}ږ�/�5ʷapK^َ���@n��/?�Q��P�ܑ	���������ў�M���+挃m��\��*9�`s����5v-9r�I����h��g܁�_�Ӭ8Ɋ�|͜d�7/˛�n�ޥ�s���6{���F����E(���׾�#�5Y�1�q!�~��J�MV}?J�1J<+5����8��m�Th<�AYýq�T+��Uz�~m.��U+�5P��u�
+��F����m���~�#u �^��ZX��#0
+���m㰈a`��<l���m	�K��d� `#Z
+e��D�������xw^�ݹ.o��F�:�$�:�~�;q��O�P�4����켧gJ�w�w����� JQ���n�j���
+Pe��t�����(��=�������V��b�W����?��y�QmՑ��l	�����Azxޞ��K$��˗(�o�D9}1��J,��U�ܱ�9�?\(����(��c���v�׷����y��gY(���aY��%KQ��H1aS������I�mo�H�����z���h�{�o��y�W>.�/���R���||�,���&�B࿊Ol�UJ�i�4��SҠ��Jw~Q(
+�t��tx���h��jV&�V�{y�w%? ��e�H�d��|��'�쵏��;�B��� =c����H���->�I6��jX&�q��%�a#���Q--�hpZ8���AK����\"��t&��K$5�Ij#%���I����3I-T"��HRs����BR3\ �Y�Tt�%�j�$9��j�y���d��<INg�ڃ<ING�t2���d5�l$9��jɄ��HrN�IrFI$9�x��!I�<INO�S͓�l�;'���AIr6`�;*���YIr�ɓ�<!��\œ��*���!��|�:2I�B�$�}IεI�\��^W���E��L_��?g"ր�ɭ����Ȉ������V���-�)��k&�j�"�J�_-�~�t�}9����yR��sܜ2�޵���5�]�?��[�	݊�ݟ�%���Y�o�i����;e�e���c�9l�lh-�Q�qrԿ�䘰B!���r셱�mov�o?�K��|�pǎ6B���>�9!nr��wn+�_�y!>��ܿ�!!!^��o��zWT�Xt�?�_̗ozDv��������!�Hn3>���*N��1��UW*�@��	r�;��	r�QA�����Q�,*E�iH����⾜�/������	����w	��7��m������2���2���2���2�{Q&}O�c#}_(���/�����p��{	�����m���R��RH߷�IߟH�_�I�H��RvP��{e���ʤ�	�Ò��/��D�H�c'fS�БK���vfE����o�:9�r�=0�Ge������]�W;���<ˆ������#���8�*F�V�t|��\Q���{��{̝�3�Q��1�f��?�%~b��T{��|��g�*�X��O6�JW���ND��;H�Ó+�s$��M�г��<��OEۆk\�
+��T���`�U�k�����ʅ���F�Ge��4JFi��4�s�e��}�{���47�����=H��V�0ŋ��"u���Om���fO����������x��Ͻ���ȹ���ܪi�����>R�������R�n?ڛ7�#�:fo��1��b˓K�з�vn�!���bz�a7��4nG�P; ��hb;q�9ը�j�Ǯ��^��?���\��O����'(�sL�i�ZGaJ�����<]�>��hKY� ˆ֒D���:nx�q\��z=z+���/B�����M�Mͅ�Z0�j�l���a��T-�S�`FLՂ)���̑��q�js�j�H�o�������hj�j�9R��8R��Kի���`���U�;�+u�%���Yn��߷�t�8���佰�RG�/����q]�R�K�A�t,C�J�r8�~njVfn�T��!����.Z�����w��?�qM�m��O��������5.m^����lG&���%"�Q�c�*�ס����~�5�zK9���98{D�$��}�����$ĕ,+�J��"ĽN������YBLm�N=�=>�f��)�Q��ɑr�Sv�9'�f^�����Y��?����e������c�^��j]5w�u5�U(��M:��U��K���?$y�����X�a�q��Pу��A?�:>�up�����˖.�3�����\B+�ɭ�˥�rl��k��i�bl3��X�M����F�NqMlu�Ǻ,Ö�V��bo���;>��(��P�7����-�RfWV� ���O Cb�����4��]��\�$>b#G���#��w%��RE�^� U�Q��v�����-���Dj��C����e�w�s���
+���.�:�ȶ�VU�XY�so>пP�O��*m��Ȓ<хo��A��7�~"4��D�#4�};�l�v�y�������ZrO-�N�Co��y��6t�g-N#s\�eeg�K��7�\a�G�����t����9Z�'��`,�,�!X"Z"Z	"Z
+{�`-̛��&X{����F�z�l�@�!hEL��%�l���1ZC�*&���H�O�I�o���je�Zqj���uɆJI��^���L��������i�3�
+�_c�?"{�)'wz^��_��җ���G(������7&l�Mk��[�n��o�1�ցp�ʪP����L�W=y��e��86h�8���V�Z6�-��:�}CT��.���8(U#��^���L�^�]_�)q��VfF�%7�3��je����2�{��_�n�Lz��4k�8��+��_�+_�����]>�O�˭�\�
+J��82S���	Z�ۊ',�����yO��8@I/-�������\�
+fB�k`�̕uTh(��������%T)H���~E{>xk�
+�8�J�M�S�g����'���c8%:C9*��#Mi�j�5����^��{A�9'#�f�ӕ�_j�|s�)�[��m�+��k����99��%R�ז��E��������Ü���A-X�6Y�-~���Y#����g�p~��j�>~_��dj������ӱo���U�A�P5���$9\n���J>�
+�gE�	>���i��]�qv�i�����Y������fbO�c���5f;l�ݰ6�v*J	A;b;j�-Uk�������v�{c;j�ͱ5��hGͭ���;j�@;DD[d�J.�2{��^x��ōƩJ̙���sA�g�D��\��A����o�9W?��p�z�q��;���E+��\�|��ޘ.�j�۵wxQ�W4�e������p>ܿ�%S�A�e�
+�]���N�=���x�L�rw+w�5u)�⼏����\��k����E���w|��p4
+n����W�vΤW��Ȟ���8���3 ,��V�1���?XS�`Q,	��J�,ͻ��%	��J]Qފ�ƺ�UfFe���������ɂ��NQ������Q��G��p�f��qܩ+���*���\�dO��Ȯp[l��T����6T�}�����25�}X�����?�d�3�����hm��0�f�rҔ����)Ò>�k�?*R���^��/�Zrge�L�����F�����V�<���76Q⸾��6�\��m;����ۜ��7��Y��k^���Rbwjh �Ԭ`G�z�@�Tӷ��4�������;6�	d���j�f��;�A^�9����y����N��򾛮�Xձ��۱��Z���h)W��G����JR��z�/%�F��n��T��o�l�Ŝ��=��A�S�j�0�R͓ͩ=k�5���6����H��͠����}�������(���R��<���<zq�����b��3��b�V�oI^�Ur�����
+�,'_�����H�� >��^i�-?�#�K#/��Q_ϗF�2?f�4v��������o��?��O(Z"M�����ihW~���Rj�`>�S����g~r���?�K�D��(���䧼~L��r��^��4��1�3�q)W���~ژ��%n	�������Z���s#���/͐b�R��{B�Y��{^��f���߻0D��@��̿%Z'��꫊���q�i�K9��0��t)��	�t)݈z�5;��}�Os�h�#"�Z��[�5B��j�
+z�9w��!b!b;1ڊy �^��6c��<h;��~��1�#�D�1�'�Dn�J�خ/Q��/�D>�J������f��7�D�͙'��<�"ZK��g�H&�%b?`��@ZK���<�N�����y"�7�I����0O�	�D��0O��D��0O�
+�D��0O��D�1O�'��D�hk�S��~Ũ��@�1�>����y"�ט'��y"��'��y"���'��y"��'��t�γ}1�\������-9��D��P܁��(�R�jj��*������C�*�-��܂�9g�9;;���?2����^��?/����Ԩ��G�'�f�)+?i\�Sd����l��s���GyFH�jc#��bu/،�ԇuB��XLI����؛�7Q:@����z'e|'�~����O#|?��2o
+G��"n�!�i���LS�l�~U�z������(�_�_P�UC�Q9�����CP��K�������k�5Z+�b����.�?Ѩ�#&N�K�z.;�� P�Wp AH�M?��8'��VD|uD|��.؀ ��u ����|;�&U��p �� �� ��'����-�2�������t�[�W3������M���O�+����x
+�7�[d�%�������нg����lo�f������恕{n��C�&kG\�qo�
+~6���+��v�/�C�c�����xc���q���m�|�]q]��w5�㐱+�0ɗ�e�~�� �N����%�G|��$�D���9� ��A�τ��?"~>D����9�"��E���>7"~vD���� ����߅s����j����IK�L*�����
+��?�E�y�������G�����š��\�4q�*���Y�t#
+�����w���C���0�=�
+��z���.
+�ʯ[2o�LP_����L��s=2��#���(�����8�Q��!�>�}�&�	���1�S9���j�u\h0xV�_���+yź������k�5*�� �/k�z� ��k���W��8��>��=Q����>����5��y�?�Q7i�|����dK_iȚ����}��M����aY�I��̲��|ç�1E�.?�$it믤ѳzHc�= ����}��tw������	-OI�_�����I��O��K�{_�ӇI�k��=�H���
+�$s֓Ҕ�{HY�gH��v#�l���ֿ]�5��[K����.I��N��[[���~��?~�/��
+�$~��4k�^��Ii����w�iN�=�}�1�}���.�˫~��_Ǵ�kvT���8�����&�>�-�Z[�!�"�Ch%Dl)Dl-F��b��j���B�!b2�Vd=Z�!�&"�(ChUDlY�к���ʈ�҈�ڈ����������B/@Ğ�z"���+�g0�ށ�=�!�D�)��[�� b�AĞ���{C�E�ؓBoB��z"�,�л��1�^��=�!�6D�q�����!b�c�����+z�׬'⨪�QU�F�n�=t�8#��gl�2�ހ�A�irA~�h����.2���o�����%���qc�ژ,���(�R��Z��t����KxH!���DS�I0e��y�������?G)��%���	z�8Il��صE��u����`�\��"�N��-8�}�����pյ�EU념���D<� � �e/\BU}��^p�;J�+���I�Z �|��,7������	�@?�/]�6�����ݫ��6��_+�+��h���w�V���f�N5嘲�A�G)�?{���/r��'��?zf�S�GT��᯹�����̭u��ZS�Qi�O9���G���o���P��~R��X(����9�O��r���'|�%�6ܥ�eni7�g@��;�W��(!@X�>.�sA�t���� }�p[�sʜ�ݣ"�E�S	��$<�FfH���6��p��
+�Ga��(����4�=	?+�?"~<D����c���x�G�?6c9��x��Gį�!|
+��U0���D�Z髩��W��w~7�V�
+���\��?07'7� ���_���Q��#F�9�4�d6+�_��gnfN^~n����!Zi��l��f�9�<�T+ W1�g�)��2�;���(�xį\O����8�l��)e�c��}׀�t���I^�j%�DAٰ����j��P�Wd9��#�$�+�n��TC	 �ٿA]V�GE*��[쿞C<7Es\��I;f_�������4?��pF�3���'����K�U[�S�;������2"�1��5%5�u+��V��"���5E�h�T1���M��7�B+�~u|�1�����W�������a�b�N7�x��+�� ��&ߔb�n�l�R`���GF���a�_����c��B�?vG��T���@�6��y��_�.�웊U!{��\��{�7b<J��[���<��3��)��-��\�	|4йZ{o�^�2KVk��j�-ZNXb����l
+X��{�^��o5h����5�W1�����
+7M�5)�_��?�T`)�<����r�?e��k����x�7]�[�<.7j��[��_+f�o���R�LD5p�(��ؖ�Z/�6ņ�d���e��/���/�*�����
+��\PS�?*�������J���ؿsV����
+�:����Yx~+�6ކ��rTUV����iK��FT�h �-��k��u]���ڠ##"z+�D���\����,O��!�\�?�^�����8���
+�������Y��o2G6�:s����"�<�p��g> �F�ɓ�ɩ1#�N���hyr�T!�'E��%A��,J0��"d�TOȶ�-L�~/��\� �����9/[���b���w�-7��뭔����<�(~4M���$y����=/�'�^#�.1	s&�g���W������|VD������y��,%�~�O�CLP�=�b�LXp��mu�Q��jQ�X�Y�!~��F�o�iD���G�o�yD�����%�5�EB� b� b� b!b+!bK!bk!b�!b�!b�!b�!b"b+"bK2C��D�e���-�����-�����-�����-����F�����/Y�a*�m����T&���T�����r�+��ז_�U�����_f�=h����|�����{��WE���
+��!�����:8��"�ci���U-㮰�b�o�J����'� ��a�p?�b÷��o
+ߞ���-޸��N�7�2r'�w��"�����m�l����tQ���pHP��;��
+��/]���^VG L�����T�s,��o���ͷ�O7-�@����ݕ|��s~��l�H��>�\��e�7����6@�7��*���A8�VT��o����lwmN�ic���i��Kėp#�+����QX�����!�f-*������t����ؿsGV�����Ҩ*�N��)TUQ�lþ0�XM�a{7�����2%�����w�DJ���
+��\j�9&�C������AN�����-��s-�y�f�v��u��S��f�����?r�J�r/�6w�rn��"���t7�]�n��zj����,���951�V��o�6�\��b�^c��8����a��y5����5MnY�tL��饙!�c4Ϳ}rYH;�-���e�����c��}��֪��e����d�^v���6M�em�?dk�*���o5��/�t��=MY
+	��&ܾ7�Y��2'ȸ),Z8{�3�#�}�ٟ����\���� �����y�3#��F���>?"~�{@��!|���0������� �w���"~W��}!�w���"~w���!�w��GD�.��Y°��;�xmo��o�n2�ʳ�����(W�_�ŉ��h��[g���_q�'e����?Ŕi�7{��u������+�_^��=a�͹��w�h?�:����#����
+���1j��-�&O���o�R�ë�ְJt�[��Ƈ�+�E%S���~�MB���P.�'@��]�w\��_����F_H�ǜ��~���x�e[��_|g�5외ѭ?������D`��	���yo[��B]>
+\�&��:6!b\ �P��G���� ����[Eķ��o�!�mD|����#0��QBN��x�^�%�o)Ȫ�׸�����|fA��;��c_�(S���?+�z����Z����/�M��P��G�?;ۜ�5�eP�����_��ۿj=wſ�����J����S�_m}��[L�fSO�F�?�`�F�뵘�cP��ۿo|�g�?R�/��������ߙ|��������;5�W�CF	�_)Y+��q��	u�X�/��o��/F����~�X��b�W�~K���%��'\�\�m{��>����p�z���嚴Y�5=�kz�A�y�@�E�B1�m�r�~1�g��.U����jA����@����-K_�4c�mţb�~˹���[���ut����w\x��\���\�z��Λ7q]��q]��'v;�ؽ�E����Ğ��K���Ǌ:�A���K��B4�n#FE�%F�ˉ1a͹�s����΋���'�~���ϸ;������6�癕\\�s\���%,��SW��{����s��y1�5��o�}0���@7���\ҺQ\�ҁܐ���]8�0B�� 3F���:�)ږ�M�8��q��Q?,����8��nq��-�m縻���/��M(��M,�q|�b�4�n��<.5&�K�4�K�Mn4M��$f�2\����h>n���Q�z����Z%N��%�߉��YQ��M�'gt�ˋ=��w>����M������Jn��ǸDn�ӸY�'q����8{���%��x�>�]bɾ�u����G�a�~f��#����g߄�x7<�f�c"(l���M�!��gL�!�
+�i���惈&Ċւ�ESBDsb/&��
+M�!�"�C03D456A
+��hvx����� h�x�)���$C0K<�4�@�DDef�����M�M�M4cD4eD4g<Ф�@��M�!�7h���yf����@���M�) i�1:P"�"R"�"R"�"RC�	6�T��)��=m��g�6��RH#x ���tj�D�<�Z�^�b�f�@�a��+RH;x ����RHCx �t�\�$D�%D�&D�'6� E!"M!"U1�BD�bs�R�"u!"}!"��4�RHgx �ၴ�RHox ��4�RHw�Hy�vE�CD�CD
+DDDD*DD:DDJDDZDDj���H<�&�@�dʡ%�+R&ÿ�]�:�@��)�Q<�J�N�R�V��|�Sk ^v�����_+�F<\�Zz�ɜV� ���
+��*�_�T�o,^�3��C)o��Px���EG����R[Ю��W��^�olW��}��~E�-����z��)
+��`Q�UUЇ_����U5�v@�p*��T�z�W5.|Xդ�zU��SUM/>�j3T����B�f�(*
+�I.
+]7�(쳞E�$�~�QQ��k�nY�]�3���x��]�5���_U�����0蔪��dUx��T��N�:�[��|(����Y��ˎu;�TQ��;�x���g~�J�dlQ�xS��ҫHG|Q�6E����t\QԿE1a�U1����}Iu��CE���L��oUw�����T}�yN�����o�KxT�����
+E	���S%��(J����o�Q
+��a՝f��>U��n�*y�PՐq��3"TF���a��E��z�h5E#4��F�}�F^��h��_���tјc����~�hܶ/Tw�?���Մ��Tש��e*�腪Ig�Rc�Ti��V��$�&7*,��1e�2�(��E�㽊��ս(�6E٫M]��?{WU��/*:��h. ��
+��l�,������\R�B@ �t\�y�Q�l2-3_����Tj>��TV�f7��Y���J��
+S��;�̰��8X�|�̌�ܙ�9��=��w�
+-?��ߔ��5S�?ꂢ8ͩ��렢$|��4�m�����ϬTL9����sS�7+��7O1�Յe3^�]����e>�S�P�Ȳ�����<�����*J'�t
+��݃�뾋�?��H���/R��
+�B�)ج�8�3�c�(0�)���8���� c��t*�8 %���(��$37�v�Q�RPp%���)(8��8�E��*(xLAq��I2�8`0If��d�Jq@&If��,�8 ����e,/�8�
+�f�Q�i�/((8��8`��‽(��)�H��;��I2��8`��‏�(x
+%� �f� �]Fq���‸2���(h_Fq@W� 4*�8 DAq�Q|�Aq��2�*(�^Aq��
+�>PP�RAq�:�o�Q0_Aq }n 3��pCq@N��� =кQ@�
+PDq �+@��c�(�u��8����� ZW�,�N�Qp��� ZW�0�^/�8���� ZW�4�h]�(�u��8�����1
+�2к�Q@�
+Hq �+@!��� �<A�
+�Hq�7e4SP@�
+PIq �+@&��� �к�R0WAq�YAq@�� eк�R@�
+[������1�oBtm��Z�>!�Pܺ��D$���'}�������&�7�|��6�8�]�������z���˻����<�ot:�y�tl���H��&���ߵ;S�A�/��.7 ���&��:���������W�ߦ��O��]O�\=���E������#�����~�?k鍊���[]����,��+�c �՛y 0�+���_1��Z���/���y�z@wm�/<|s�-�� �fU��Y�MzqN���Y���p|vq���_���1=��܌�D_��{�K���<������)��u2�{�S������e��4�%�?sB���٭�8�C��ȅ;h	߻����ۖ��Ӹ/��D.�E�s��gI���G����`��ސ�
+^����+����?�u�`���M-����q��#Q�g«���~!�6z������?�:�͑+)��_c�O�i�DCR�����$��
+$��ߢ���'�{Y�z`��]c�'3_�����̻Z��9|��c��OOD��x��=�{��1�c��� ��&�3(�x���� ��=W����U�2��x��?*(޻L�'���\��B(�s�2(�x���� ��=W�'���\��b(�s�2��x���I��_����V_�g���ɦ�)y^��Ss��^���o��Wc������*r���TO�WO�_� 4�*����Q���n�U^ܨR�9�2�׵���	�9 �j������?ԝ��%We���A��K�hg��}�����z=�凫�4��疍76k��od˶�K[�w�2�?��ܿ~a�1S;�L=>�eZ�a-�v�nY1��zU���z����� ��]� ���g�>��㳊���٪ ;!�&5!�v!���� y
+Ar[��7����TOk֒⛑$���8��e�/m�	��։��YH��b�w�����%�8��ݸ�F%�	������f��ƛ�K����kj������u����M���[��ν� w��Q������p��onW/�?�/?�����`e0�h��'|�z��;�g� ��@�ف���_`���Y�y0E�s��}yF_�їg����
+Ѿ|���ƀ4��U��.Z]��'�/��+��iA�m�ǽr�Xcy���
+�8��^An[�Ds�Ճr�v4����
+y������b��ז�F�bG�{�N��9;�*�ҩ��5��'�;C�W��~��������<��~4�<b��Ǟ2s��91����=GZD���fl��-�2��D��9:D)4'͆s'���f�_�{����{�F�Ͼ=�q+�8�7�/O��ޙ��rc�Sξ3_3�K1;�&,2'G-S������9S;�2����s�w���}^�������G83V.�|��s�\M��)�N^d�S���j�Pc[q�������ᷟ6��8��g�_;�Qm2߽�q����c���9v���{�l�q���B��N��i��d9'Ď)�
+���L(���1�o�9��1�`�9��P�7;��_i,,�3O��(Z���E1�B����:���O��Y�vyi�K�ɍW�O>�s�ѹ�����9����i�����D���">T<�\}�M�lӋ�TB��M~��ݎ�ݪ�#4��Ɵ�Z�)e��|ɹԕ8��'�-qȱ�S
+�K2�LrP.qȎf��\���1�5qȵ��!E�8�{f���!��,t�|���\��A��;6���`�!�) �d���rHf�!�i �d���L�8d>S!���d�C*�1�Jf>��	��+���Lr#>�"��L�8�z|&F�)|�FҌ���C.¿�G2�I��Qf�O:�C>VN��Irb9q�N␃ˉC�r�Ԕ�v�d&+�T��C��C���`��!O��C~%���L�!��d&��Hro9q��9�Cn,'is�\\N�a'q�i��!���!ǔ���$�PNr�Hr��8d�H2�L2T$��L��H��L�G�8�!3q��1@qȣN�ˉC�t�|��8�KN�+ˉC>�$9��8��N�y��!�:�C�1�${ �!9D$9���q�B��ӆu8o��N�s���¬쉞�y��O�%����u%�ۊ���/>w�{�8�u��7rOp+�ڞ��z{O0���Ixc>����b�E�Y�Mɾ��_��?F�3T���\p���w}ę��J�o��_��?�߇�u��~�s���,�.[߻���P�����?�y��7�\\t��������`���r7���)�6S��ܟ=��]�����q��=��z\�������N��R�b4���E�%�ud�c4����s�S|�����lo�L��_��������wT���ڲtK�r簏T;ߛd��z����wY�~��xc����x[���»�����U���T��sT��g�R�ϴ�տǖ�;�v��f���h�Py��`#j��Q50+Y��0fom��,^I��G*
+�&Y)0+�Q`v�����<��Q`3�${�`��J��*$��=�Q����	8�Pޠ�! �F��9���4;�pR��0����U�/:��s������-*�;�_��V�N�[��O�*̞Z7��������]�a�IM�yu�����:�{ns�o�]��	%E�ub���\m�=W�����#�=��3�q��^u�=������2N(��WXh��k.�������������M��k�������,�*���_������ߠ���v���U����4ذ��8.k��մ�.�-Wm�d�������p��.!�W���L4�L���kbjؿN����m�w���u_�6h����P�
+}��:�Ue�+�6g�X���R�ݕg�2��n]�#d�HG�yi�3z;T��c�9:e�����G�������[���
+�CO7�>Ƈ���{%c��o#ֿj�b�1r�BcԬ�ƞ%����f���x�C_����0h5��XGl� c쁶�^g���[�9��oa�[d��|ژ0��1q�gFc�cߙ'�6�T�]װ��5����?IƋ~
+�
+\S�O�3~Mk���þ
+����WmV�V$��#�HX��2(�ꀄ	�V
+$�HX1��j a�@�ꁄ	�V$�&HXQ��� aeA��d+V$�4J�ڈ�l�Aª���	�4 $h���
+ A#@�V���4$hH��LK@���d�4$h
+H���= A�@��M	ڄ(�4����iH�4\�'zd��5�NS�������x��5�R���6.�LjX<Un��߼�K��8�����Q��w'��J����,4[��t�����x���O���K��:<,�⯅����;
+yS����%k��5�!u�)B�� �5�$�}3�?�?���{��7��� E>�*G�7H=ge	�+eMVA��-A�&�;����9B̴'��^�c��!��d����{�>�-�/⟜)$�,��}��e�Iq���䔾=��M
+rj��r�O�rZ@����wy�J!��_��2���W\�_��=�P��°!��Z�C�}J~�_��fy䁇�Q'���j�G��+I�j{������#cɦ�!���]�	w_��5�{���^�i���s�!���r�;���)篜/��\�8�\�|�\T8Og���*��'�ɓ�x�$�^���V��c�0�����iw���F��SSa��w�wf<����� ��ɟ-�I�h ��>ݨ8�w�[=����1Gb'�U�v*�p�Ox -ZSR���_���AQ�IPV��� AiQ2�E�ʔ%S`��� A�A�2��	J
+�&Snt�L��m2%G���&Svt�L��m2�G��N�ʏn� �Mf�.�!��dƀ��Kf��1�@wɌ�%3t��H�]2CAwɌ���Kf4�.�ᠻdƃ��KfD�&�!�cB�
+�%3*t�̰�]2�Bw��%32t����]2cCw��%3:t:��@��	F�!3F�`�(�Q��DɌ$(H0R�`� �XA����	��A�0H0b�`�(�1��FɌ$6H0n�`� ��A���c	�$>H0~�   @�0 	����H �@@�� 	@�$ H 
+�  <@��	@�F��$ 
+��hXP2p	 @$ 
+H � 8 t�&�*���Ej�����(}O������{j�
+y	��������Zm��u�h_�����}]�[�
+Y�a�<G��`u����6�A�6g�P���m���������n�B��B��~:L�VP�.t�C��_�s��B��g����nMB��CO?#�^�7��{��ݷ����=V�#&�Q��rϒ��:���� h��]�J��yV��'4ù�Bl�3r��
+�~�/�޲F�o��r���y9a�*9q�?dcv��w�sB����	!�k���4^��%�vNR��i��	i�#���B�˷����^��]?v�6殑⚦�_ce6حq@�]�0n�A�F	�;z�}��5��<�z-�ֳoQQ��f))������DVSa�����DxBMI+��ԔDhe�$B'������Ȇ#�@6�O���l��%�
+�Dx��S
+J"<@l��%�!6�T��F�Le(�P Sa,�"�>�DH$V�Ԉ�eJ"� V�T��AĊ�j!+b�EI�zĊ���d��l��J�rȊ��Qa
+>�CV�T���˔DX%S�2%�dJ"<��TYSOdELE�15EV�T�SW�Le�
+1�E�TYS_dEL��15FV�T�j����3���M��h}�����KL�^��hb�1��Ɨ��+�_W��_(oX~��:p��r��l�GOڃ�����b�2Kj��T
+Yz��~��Ì�����qLw�SF��9���%��5��ԭ��R�>��9>��Y!ܼ\���}�G|�z�c�+|����YO�=K꬙�f�˲��Yo��C���b٠͔
+�ɱ��	�r��Bסּr��QBܪh!�
+��0�����`�>#���LF�c�W��.�{�F5o u=1�kH��sU����l�$- a�oR�V�J�j�u�S�e�ڔZ�Ũ��?e#o}�N)�Py�)v�ֳ(w��r�X��!Qʟr	�p���.Q�?%,"y��y�㔻`�^�-*y�s<yk��䭿��[ē�v��_��[����~�'oM9P ��/����[[eJ����)� �A)�)��Pʟr
+�(護RN�R�є�x�r
+�<�)� J�����e��tBdt@��h|���ߠ�������ߤJ�	���\��V���[:T7����Y��f�M�O�t�K�!c��,ɠM���K��c��aR��	|�R��*>nU(�F=>aNc>q�aޘ�#�w'��Ku�N~��F/�i�~����m�U_�z�j����V��0����O�œO(��'�$�	�%�	K��J��$�	�$���OÓO��'$��$�	*�|B(O>�O>�1O>�0O>�G�|'U�	uJ�.��'��ƛJ�������o������]���>��&W��m���W꠨_���Jaj�@�o���~̡�V�
+�m�z��L�2�nS�
+x{S?��sR�����L���e �+���?5���	�����>⒩�L ^5�����ia����ש�_˵AO�V4�o~��Zb�����D�����<P����*/�U�r�וtU�䑇� ?���ިx�K9���P�ι���rr�<���������������%c\�q��s�8��:�o������A���mw=)o�al��{|�����l�ÌᲪ U�8&V�.w�k+w��D�|N����$��j�¾�l	��<���DK�f��ǿ'q��fqQ�VYz�xڢ���ӌkg���8�������3-��r1�^�bN�����z}�����E�>���ŭ^��/>bI(�̒8-�3揶���/�q.)�cKr�[���\�f�r�\��e���$���1�
+_���sE�!����V�S�Wa�z�����ϛ�
+n��@�g���-b=[��$#a���y�0��lq�Kd�z���"�O�	�ce��p���-JX<��s2a�1����&`1뿣SjaQ���"Ƴ�E��7Y,2b<[h�x��hG��TXt�x�N���G���SP�v��a1e@y�Nk�@���NO�@��N%A�g��ϔ1~��J� 9�Nk�/P ��D A���	�@������T��1����bS^���_�S��������W}�w�e'��n���;W�{�|e�T�2���\�?O�T��U^ķC�����L�l��j��N����_��޴��*�gW���(��}M�V��8(���~��8G��hu�]��[���͔k�	4���.v�����Jm�z�.�%ҕ�p�q���¸�Y7�{`(�r-��F��m�%n՝��7zX��,��6��me�;+���%)�6.���YR�Np��߰�v��K=��V�5.m�fn�E\��K��]�X2�?�
+Z��ep����J-w��aR0�24�˰�^���-�{[��>o�@Ѹ^�k�1��R5�sxM�?�ϸ�ߩ�體��+xY�yɥ���"�n�Su�G��Fb�~�²�V������3e�2�_h��e~)�@3A�(K�^IY:T����@�(K@�Q�`(1H�j�% � ��,���� ���xR.jHY�b�L�Cg*��+�����'2H��(����*J���*_������@�A���2HPg��� A�2h��7HP�U�ꐚ�'D�}�O�����:���)���c�P��r�WP�{0�f?�@����Ԛ��8{;Hx�j��J/����?i�Ņ��/ٿV��q��N���R�Kv��e�>pn��V�E�ց+!\�ls�sK��ϬA��08��%��n�({�ҁ�����;��aW��;�if�~�޹���%⠽k�{�&o�C�P����a��6���������5u���+�#�QG͚��Y����^��F��/e�1i�^Gr�eƔ�����3���;R�?�H�?͑������8�_����5՘9?�1,��z��?��E��W�5h��A8�k�����|�5u�t?�jl��J�j?���nv���fU1��V�����Y��c"W�
+��[������?�����ϵ�e'�?�NԿ���;Q�;Q�f(A3��3���A;Q�=v��o�m�¢�����F*,�%ɴ�B���TX\����"5稩�8EM��\�L���X7�M�Ёi+�ˌ:ltP�0�H��b��;(t�F�i2�c:LpP�0�H�C
+>���i��B �k����(���W\Z�y���5���?|�������߆�?{��|����Aae�ziU�Pyu�CҚ�S�_��>[��t$�C��
+?|*H?�����ƅ���?ğ����2����#�H
+��_�<�W��/>O���(9��R�O�!�J|�����K���:�����;���w�'t�=!u�� ���̇�|/��.u�&��w7�"�����.T�1���em��1��$����h�!�/�#�_=F��z�`	����1�~)���	�H�]�
+)Iۥ�����WI��ߐ��Ii��%<t����CrƮ�|�|�<h]?�0I���w��!��И~°�����t�G�����0��m��ϾF�>!ݽ�a�ޏ�1�+�]��t�C;�qI¸���W����	c�Y
+�������Ǆ���|��������������h��wc��ew���JE9���s��w6�����&�O�%)�T��<9� ?���ln��7K��S�/�٧��w��g<�Xx��l���ӄ���W?��&��@�(��/Վ|��-P���&Y�M�� 	��$�H��`+(����A��$�Jf? ��@��[	�l
+$��Иm��	6���`1�y�c��&��1�D��)T ����(�?f�����"�c����,�?f�����"�c����0�>f����-�d����l�n:�l�X����.�xK���̵���=�=זRf���\[J�so)uor��������ۇ��d��C�v2��!w;m� ���Dlo�@lo�Dl���<!���Ll�L"�G�V�ۣc� g��ѱU�7�(�c� w(Q,�(��c�Q��v��tl�����*�%��ѱU�O �@N��	x���Y �@v��	p$`H�3��i �P2l	�0$�H�:��w �@��	�0$� H�B���H
+&�\Dɰ$�#J�.�	X	�$`&H�M���Ⱦo1����,uO��,v�G��0�ϛ��������?u0�������.�\���c��o�#��u��+U��{����\uV5+O�s��:+]��w�Z��c��?�~���!�_��;�3��
+�k@쁞_�:3����_��4 nU����g$�Q�L\r`�1��Ⱦ3��藲wd��TW�n�U�]|��f
+��t-�5����\��*�*o�c���bz�-0��V�u�BQ���a�����cXx"j����Z����#_PZn�"j�_PZ.v��/���5��Z�/��� ���"jA��E�����DԔ#��@D��HJ˝�ADm/>e�J���(Ե��})�/.-���V�G]��K����׹�o�����9'���4���yfJ�r��1:5&kk���σ���V��ˀ��&\��c��O2L(-)1y�����_����:c���Y��s��e�����?p�"�=%-�6���4�?�v�H�-�s�We�ﴡX�aV{
+�و���[ t�2�� �@�u�vv-(���t]�!\�4^ZS�4%\ڀ���FF���-BV���<�?w=�Z8�g�޵��SI���e���6,��C�ցs�6�9�6g��n�����J��dXۭ���,�������a�Ҫ*�v}��)���s���.�X�o�vk����e���ʰ�o�����𽫔ݷ?��X_��b�2r�}ʨY��=K2��x�fl�U[�d����t�F��������ͬ��]��_:���6T�޲��g��ʸ�'��?P&��X��d�Ҙ������~)��I�Z��NQ�$ͳ���L�\hM=^jM��[�v��<�����˚�k�2s~�uX����_w��s�O՛I?�Ff��a�<P���M����_������M"B�\��P�����C�� lm)�|���r�H��\�B�9N
+-�(�܌��N�e�H�e��B�x+��QV
+-;X)�TZ)��C	z��%�
+-�Z)�|�J��F+����Z~���r;J�-��d�C!��J��))Ĝ��Z�}J
+1G+����3^I��\|�1
+1Z)��j����B�F$��Q���?���
+�1�!��L1�d�H!�(A/)�\���5%��;�b.RR-`��jS�T�g�Z�(%�
+�T(�R-�'���jZ+�zY�0XI��`|���|��W	e댎���������/�o*��!`W���=�>�_G�����[��仰ۛ|i
+<��R��a�CG�=̫/Ҽ�#"�{xO�y/�4��1��=�v�~T����f=�;i�C��f=�tҬ�Q��S��G����Bt�R44=%�>���g�s�����/�Xf=dM,o1f��}�%[�%'Y���,�]�ZSB���k�w�Zb�o��2�6�H�r�נ������d#0�7^te#U�LY�\�Tc\}k��j�i�7�O��O���˥��{CG���k[��#���u�#���G0�(��u�`xL$�����I^�Q���#N����N����N���=��mݣ2DJ����F�cXm�J|��ޔ�<zS���M��7eZ�ޔizS�
+�M�F �1�@o�L^��i��%�=���mAo�4%���9�����=��t��0������j���ת��J�I���M����9����ۮQA���Eު�Dj����|�������[(AR�wk��w�۵(¶���YŅi��Tɉ?�U���\��/1�<\�&�5��k�ɵ��f3�Ww�8B��õ'�+.��2��BI��@��Rr8p�H=؅#�`�T���J�~���ǦS'Խ�2��i�����ZM����W��+��pՀ�<��ϱ�k?��Y<��vez�V�qWt~հ�Ef#Tti����ݥ����S�k����l�z����Ap�h�}(g�[��o�5׾�N��DӤ	���c�z��p���V�쿮��Ӝk�ò��6��������K\ajnY���xʲ��I\����b��??>�;9z�xjR��t��_�z��k�a����.�g����|�����ٷN���ȝ_Y"����\����=���r���ʱ�Ok�l`����a��k��=Q�e�Eq�wg��\.�(���M����&��~��Y�(��k'qʌ������O�~>��zRlWg�ãGDU�4��#A�Nq%\���]��,]����Z%[B�C��_G�a�Y��o�����#^�z,G�����{Θ.�'�GҌ�-��t	�zM.�~�`h�So�s�#>�H��g������>W�[=G�_��P�YH�z\2�'
+}�L�p�|�j>9r����<���'�Қ�/���z|��6B���y�?�.���G��w�*�{�5�~�Ds�ˤ�'#[�'�����GI4�^)��H����Ώ�;*O��g������
+<͡�X�9��I4�~�Ds�H4�~�Ds��H4�~$Os�{󓏷��M��8���?x�C/�8�~�9���%թ>����wUXr�o3�bV�;��%�!fM�c�Y�bV�;��e�N!f] ��@���K	�,$XH�<�`}(��+D�,$X#H�H�`� �2A�ubB��`�X�a�
+�$X,H�Z�`� �z�,�7�b�̒A�5����`���
+�$X8�C���c^�4U-��1/ʬ���1ʬ�R�P �	0G�_0�P�0ڊ�(J`�!�AZ��0��<(C
+̃2��<(C̃2�<(CtI0ah��C̃2T�<��yt�<(C��2(O�ڀ6Xud��yR�:�'eȃyR�>�'e�yR�B�'�Jw!C;� �0Oʐ	�#�N�'e�UǦ��	�
+�/�z�X(j!���v<za��}��(�$�H@4��j����tCo5�v<�a^VK;� �@�<@;� �@��	(�$�!H@D��� 1_��$ $H@I��� -Ab�<B;� 9Q2�	
+P$ )H@S��� U�lʐ$�+H@X��� i��0�	����.H@^��ӎ'@`��� �A�D	����E��"EW�E���E���sM�^��/�������_<�����G�W��yo�uz���u8��w1ئ�
+ܾ����j���ϸ�'آ_�-�����]���em^8&�fn��y��rHn�KV�m�����k����<�ٿV��_����b��\ߊe'�Y����"�Xg���c��_�X��5�|ɿ�;������\S��&�_u�����o�����m��-�A\��������q�J=Ǎ8�N���-��;��"�W�7L{�gZn�=����WO����4��7M4� z�u1�5����^��F�oL��7_9�}����#X 5�=Kn��w��V��=zP�}V��,,5�p^h1T����[���[u~Sh}�
+�M��B�Ss��C���Or��o�4/f���P��BaV��Y!M%��BaVHg�>Ƈ��I�Y��8�OkV�?��
+^h�=`R�:;��{k�����ָU��o��&��kM|���xogk�Y�����[�����]���$�W��ߚ��ke��o�i��T��ޡxh�2��ʌ]۬���)�[f\X���ʹ�9�Q됂l�И밌T�]mY����Mm!=$��%Ly����џ(�ؚ+Ǯ�Iy�C����V
+�>U���:>�u儱��Y�Qfǿl�W���b��|��5�|�5o�T�}�Y�׌��{�rbY��p�PeQn�8'Zy��q��{�('i�+KR�(K�s��=[Y';�Q���f5KەS���u�}�r��7�3�y������>8u����Yk�����h�k�f�qo�D��'=�]��v�0��@����DmT�qL��IPy,N1��|S},N���`X�bf�ũYTs 	&�$�H0d�D�Q03A&�L%3d�d�Q|B� 0b�)��9+�)��9+�)�T|���Ꭓ��Z1g�=��=g�5��=g������TLo��q{�\Q2��А�-Jf��b��.f�X�bf��.f�X�b��.f�X�bf��.f����yc���8���c���:���#9b&�E.f�(��c���?JX�:D�d`����$`����4`����D`����T 43��b�,r1�@ɠ$���`�����`���	��`���
+��`�����`�����`���
+��`������d� �\���Š�\k�Pp�$,r�іP�&,r�ҖP�(,r1��"�*,r1��"�,���9� ](|aq�AJ�ڻ ʰ�e��� iX�b��E��i��2���<�OWqߥ�(��RM�<Xa�j��^�������ގ��ch���4��^�wy��p���wOK=~�,�8U�x� �y�}�l�eo�,}o� T?�w�O&r�>z�y���	�k�sjW��O|�<y�(�Ԥ���>�,�����k���{��]H��6�����L/���~�b�c��]j��B�*�t��k喪�r�3%r�?����W.�<��~�����z��c���=�ɝUc�.w���\"N��g�J�?~$�9��|���F���?���"�sz�����������/h��%��}�Bt� ��7G�imb&��{���_���|�O���W��O)���r��
+%�C�r�1�������ugE�W����_$��(x�9�|������f��J��,��|�~Bƞ�d�|��w��#���-��;>F~��9��:��
+s��?�/`��k��=_K����5�Pƞ�1��=_qZ{�ڵ��{!��2�|�C�������s{�f�W����g��J~@����gd���m��=_������a��=_/u�����j {ج�珷�V@g�V�bv���%@8-�Ύ�\Hm�	8�[b�2��,3�	�L$�H05�`n����H0;�`zx�43�+)�;6~�Iґ��c0M:R�5��`��p��Θ�R�Y[���Y���y|�K
+g{��06�13���8j8��&��7f�(�i#�f捜��8r��AL9��)&���=r`f�ȁ��#f��� r`ȁ f����r`
+U90@r`ȁTT��2��A��9���Ar��ĹJP28A.� �0���Z�3xA.܅�7�H���nP2�A.�`�0���~�3B.�`�0�"����3HB�`	�0�&����_��Š
+%�+��?�Q� [ȅݍ_��3C.�`�0�2���oUo�b��\�����
+�����rauȁܡd�`%�>�ħ��
+ 9�'�pU����9���k)5\U4~͠���Ư1�pU��G
+W�_�����������u��*��S�UE��
+j��h�b�������`9����-�w�W$1]��u1]���`9����1rbw��e���Ư�&<_�+��S�L^#�`*,�b�?Z��Y����+��^�Ve󒓟X�a����G���Ip~�}Cyh���m���/g�l��kfcc�ѹ
+{t��3`��Ň��b�=����B��.��8dG�A�E������ً�kL�r����B����O�>F�����?{|q���_��V�<��w�c]��<�������
+���Ͽ�����i"���/t
+5��l&詋2AA�L�/t�g��]2���J�  7��|�!_f���37D��h\Rn޸̼�\��t15������J�'�2��d�T����Öc=s��UM�`r%��T&(�z&(�R�L\2����鏱K�(3�g.���
+��0g\zQ�9�1Zk0p*
+\W��.�g���?9˃�q��?�15���5>��#�Mf0�G9�soo�-��g֠�M���F[��$Xhއ�B�>�Yh��a��x�B�>�Xh��;��X�Ѭ�G8����Ѭ�L�f}��Y��t�����ଏ�n��>�����Ͷ����/\jK���=��A�1�{�a��_�8{���-�K_{J�8�]��؇�Y���}đ;-ն�\�>�1~L�Ûak� �	����#�C��AO-H�xA�G��.꣄�#܊�*|\9Z�>��qW��xW��Xc��=Z�ѩ�����=R�|\9R�&�V����Ǖ#5z�㊑l)�ͻGj�%���=R�--F�ly1reK��+[f�\�Rc�ʖ#W����eG(cK��+[~�\�
+`��� #W�
+)��Ǡ)>��A5*8��ԣnq�����ҒIޚ����j�����?���M]2�u�%X�-n߶a�'�V�&K��E�6�E\�3�4✳�LK�m�֥�B����ϋ�u��ަ*���qg����s�ol]">�u
+�n��d�-��AU��=������S��{׫p���T8x�Y�s�K�V�౓m��;m���6��-:��͠me3�og�
+֪b�����lKU�-��Ͼ_Uq+ϫ�7�J���*q�f�1�MUߙ����,W%M�dK�:[������?G��y�-��L[Z�{li��mm�/��2v�Ue��
+K�\Y����Un��^���ߟ�LobF�MWtQu������p���q�& LZE ���R�U�%��N�C��R��W�K�$,=J�����)�9�oeZ�o�m#��n#�g#�i#���F~�v��&�~�����F~����6�[l���o�Q����T���z�/��a�V�\S��z��rMfjF��5u���/�r�F��#��%� J����e����#ff�J�cj����&�7���ߘ��cj����*�7���Leѿ1��Ec�����/��$Zj���4��3�L�Q2���,Sm��2���,Sq��25Gh`�^�2��[{��|`��҂:����a���+-�Ϟ����^���|S��&�^5�����4��u%���;���������_	;��,�3���yܻ�}�q�7��g���o�qY�H�O���)pzw3��⁈�� ���k�3�	�G�����UI�7
+��p�8J�])%Ʈ���A�U��+��G�>����9`��O5���ޚ���9�;Z�����w%�Zln��bi���7��ˬ��f~��̂����.�֌`��A�HV�!�}s1���#��2��;����?��t�� {b����5���&��|����O7y��_�k�5����u	���?���FJ��8���
+#�q� ��z����]���,�	]��y����	���um��-d�'�J�s��V��1��w����[E\����<�}��%R��pc����6�1�6g�P���m�����H��p�c�4�s��A�W�y��
+4���A?#�^�7��{��4z�L3�e�	�Q���	��8H�ū��g��z�As@0�;,Ķ=#�~������r�-k�>���q+��񛟗f����C6f��}g>'�K�ON�`��f�)I���Qrj�d!�x��V����;RxH!��|���K�����JG)V{x��5a���%v����	�8 �I?��@��~�G�c�(B�c���|gm�'ʰ5�������FJꏵSR����O�)�o5RR��������wO���ъ�ӏQ�h��ij��8M���}�r�4��VN���U�J�I�6������Z9y��X+'OSk������A%�U(A�(�_%�J�_腘�QR�]|�FI�5%��ʔ��.SR�y����dJ�S{5�!%��(��LI}�@I�����J�Gɔ�O(��.PR�I����W�Կ]��>��[�T�3��&Dj�>��-�_l����W�������}�ߺ���	mCy��
+�������k�5��[��{��a�}m�&��������3�\�����f��њ~x��n���2�ͥ��>t�1�V��
+����O�^�*��p݈����������Xڄ
+��^So��	`?��Y�.����c*���ל����������`�cs�{ZÐv������Z���V�H.�oՙ����/ɝh*�*�V�����z����X�O�������T$������\@U��@�6�F�<0�H�"�2�W{!�?��	���!�c�4�����)��?�����>�\��N��R�_�3Ԝ�����m���%�]�[.���
+���Z�[Ε�(�8ۜyC<�Y�w\n�+Qޒa��@QV����~��V���J��6Zi?�'J���*ܜ��=AO+iO�T%�	��=A�J�T�d�=AC�ZqO����p��56��2�K���ن��[�X���^��2~�ʄ�+��S&�<,�Wr}gn��K��%MXjI�ǥ$=h��Υv,��s,i��Y�v�Y�bI9��/�9�6ˠ�z�����/��h\�֤1��j2�0�g���
+?�ϸ�_@B
+zc�٠��~.�S�{�I,�qu"i4�i6?���ˍ�-9��io,=���ʔ.�S@
+(]�Y�t�q��ŉ"��3��.v�]�BY�wI��r��I+���{��Z)]�޻��J�b��%�Q�ܻ������$+�0=��t�{�T%���{�F+)]�����t�kS=J��01�t�kSE�L1M�T���N|�I��=VJ��t�	%��?PR��c%��בdjKi��L})mL��A�)mLY<PgJ�s�6,�6�A�ޔ6N�Pڸ����J���*�Ⴉ�u�����������E�&���^���?�I��	�%�:�c�_l�TX4�T�=�W����zm���y��5q�~���egn;�a�AU��"k����/W�9��~�\{�u��!K����c�0��]Ub�8���S�{�>N{������{�ݚ�mmpBzZV���n�k���������W�{�X��\8G5k��gI�Z�5J�;ˮ-g���k��k�`7h;�
+��c����M��vR��r��guܪ&���ߪfS'.١6f��;�_�+�	�ړ�>�NIZc��_�N���=�������ݓ�
+���|�=cW�:s~�}X�՟���7P���̝�W�����_���Ww�]ŕnί6K��-+q��*�xEV�x+8�x4���8�����ډ㍲�h'���N���8^JP	�x���v�x����؉�m'�G8A]��}m$�7�$S�x����P�[�&�7GMo��8^��8�(5q�Yv�x�T�8�U#�י$S9�xF���z��:����}�L
+��1U$����8�15q�j�v�����{EM��];q�'���h�:�,q;ڿ�Kܮ�$Sa�v�������W����;��nNwsU��q�r�����Ӹ�҉bi�������_�����:����1�e����̜�|s� �#���kG��O�S�0����_�ó`cp#�7��il�v�X}�
+p �̵��- 7S
+���[sCUm.�ك�����*�qO	�h�p� ��qk{�$��z=�F*kz3ug����'��y���%�j}�����QoM�K�6�n�I-�6=Բ�T0���u�7?��o'���?��Q�aygq#�=�T���vq��&}���eg�)~�#90�K�� ���3&fd�j�q
+��x�t����fu��V�
+�vx+�
+��1�J��@�[C��Hx�(��	o%{� �-�doOqfo$�}D� ڰ��Pg$Wu<�\Ƹ��)����_b��A�s��fe��ߣ��i�`*⼵�Z�����h_�����=;�u�����w��:w��@�uv3��'���R�c�&~b.��{��i����J2��'u~�3��E����>�}����◛�'����e��_o������y𩧝�w�<�y�g�qO��6;��.��5ߕ�m:��5G����Å�k~�tۦ������'6�Qvb�Ǜ�k��<�M'��a��R���a��^��5�t�o]�-o54���{���ߏ�=�ո5�v߳�������e��u^�����A�5�
+l�?��5
+2���� �aL��Fݾ
+k43>�q�a�}/6�۵aM>{1���?�+�EQ�o�KF�~
+���q�_��t?������u$%sEʵZSpB����ڢd���l��0]��8���5:-��8j��9�`뎇벵	돧,0 	z�������%�	�� A7�O��H���' AW@������NLo�P_�; A@��=B�t	$�J�S8
+���B`����~���L�p�3��t
+G!0}�QL�p�;��t��3��QLq�C��t$�#�@`:���%�B`����~�	z
+u�@_��,.9�[��� AA��=	��J��%�i���^�d�
+���L�A���]Y��=�=�;��O��R���K�hCE��������#�1e�
+���Z����_�o����%��Ek��
+��ȭBc�ց��6���6g�7}�ڷ��vWg>x�Zl�������~^}���Ӣ*���q�gb�����}6�]"^�/�5yLm��zz�σ6���>��}�3b}��Ǌ1�ȅ�ΨY	Ξ%=��,�S36C�����(Q?���
+�Eù�blp#g�{�^�u�޲Q�o�3n�g�旜	��;�<�4f?��;s��/��L�0_L�z�3%I���9S;S�����Ŵ�}ā�Z��/���������#��ސB	��� ��<���^����g��V�������R��)�����f]�R��R����S0�AE��$*>o�"�s���T��SP-R��HE�"�}�" �	,2��"�{"7�T|Q�"������T��"�j']�T3ݡ"�#N*NsR0�IE�1N*f:���"`O'UN*f�T�%R��HE@%J�9�L���?��Rp#>]�" �G*��"�z'wR�)'׉T4;�8_�"��N*�"�TBc���RPO��1[�T�X}_0�6H��U���þaMB�F�~���&M����������a$���׍�?��.a�ɱ�ͭ?��,��I�P�"�����O�;7��n�dAۈ�a}k���+h,���Kcz����0��8��/d���¼��^����9�W�;����c�1*-�ǛKO[�j�w����^�*~SЋ��������(���,��]����A�_M��#��d�=t7p����B�����(�wHDL��	�F)��8����e�d�
+.$\��ڀ踯�~�گ<����Od���&��R�/Z]��/�t�)�g��\�Ay���;�oPG������ٞ�<����/�\�_:�0�3C��~�������>��m�_�����*�߳��1s~����v'&̮�?��=ѵ=������wj������
+��y@�}]�u��O����:u
+�����������]����u���?�Aϗ#.4F͚m�Y2٨��1j�.ph�':t�%�������V�0��u�2�h��uVm�圣��ƸUA��ͧ�	���|f4f0��y��/e�1i�^Gr�eƔ�����3���;R�?�H�?͑������8�_��ps�a��#��uU.�h����[j�~M���_mV��y��Wf�I���,4;�m$v0�H� �H�`����D�����b��4$��;d$v��A�@m$vp�A젅��A����i#���Fb��0;8� v��H�`����2#���b3��;�<� v0�$�dbt�3h���h7V��_[��x�
+���'zn�/w=���_��u�_s��kƍ��P�
+}��:�Ue�+�6g�X���R�ݕg�2��n]�#d�HG�yi�3z;T��c�9:e�����G�������[���
+�CO7�>Ƈ���{%c��o#ֿj����Fm�N� q�wa�q������@��p����:ѵ��PL]������ɹ�����>[fr�G������)������Ov���q��� �� ���A�?�AοJPr�8���p����?v��?o$��H��O�I�:���4����s����o�����_l*��g�E���z_�����z���k���rÊ&|����*���l�GOڃ�����b�2Kj��T
+Yz��~��Ì�����qLw�SF��9���%��5��ܭ�19�?H�%@;|V7/��~�w�~@�X�[�b���.D�Z&�,Y ��f
+��/���Gd]�U�ɗ�C�e�6S6�&��'�0Ƚ�f���}�G	q����7�B6B⒓�1���wV3ٽ�Ѯ�<s���%n0�\�����X��U}�?�k����<��n�avM��+A�O~�n���������n�����I;��P��)vr۳$rۥ��{%r�#$r�$r۽$r��%r��(aE�m���m���mC	+���2�m���Mn�+��6Mځ�'��M �m�m/�m/�m��m�,��~D&�m��m��䶋erۙ$���۾O �m��mg�c�r�Q��h��E趙&��>)��>����)��ӱ.=q��-,�8��.̭+�
+��@��L�9�E�>�����
+K�L��|��u�^S���h������/����]��mn�5�s�
+�ų�;�+�@�_�z�
+9�^�ߋ�7���9��@��F���tUίp�Nַ���;�+��N�Q^m�;�4O\��0��m�S�
+s��<u�U��k�]��w�g]��������}���߶.���$޵��x�O�Ѐ�W�}:��7���nm��� ��k��x!�e�b �цً�/���Ջ�;�S�/k�w�J<7���5:}%��-6���߃�_�>�B�To�5�J����Q��s����lX~�xc�?ǥnM��B�������?��|���_�f=��,�ū�Jy�X��-�.����C�J�!Y�A�(���b���¤^g��[�>�U|ܪP>��z|�|�ü1�G��,N�t�N�z���n�s\l��i���7�L��5��^]��殹r��m�.C���ԝ�q�R@_K��,��S@�r�z���<����)4��P)O) �D)�����(4V�P�D)�D�LY(4��P�D)��R@��T<��ByJ�P&J�)�#O) N�|
+���u��	���iS���L^�-{X��k}�������96�⿻��y����
+f꯸��*` a�P;;��Ъ	�K�i�V���ۭ�..��5� h�U����J5���,�b*�)*���_j����_��w�]���wȋ/;9�Ν'�~�$��B6@��{bN�' ���ʜ9�BM��<ym^\����|L'�L��v���3�"�@l�/9�N�Xqo�:��k�ySMY�����R��c|�ߴ�j����_��}E�w@Ѹ�ܼq�y��N�?�~���c9����kk�6���������I��-�8?ܴG���������bМ��s����\��Xz�^��޲��g�>.n�A.~�.a��,R{��3����ov���km������;��b�5����r"ζ���lĊ��6��Ñ؊bq��*�|�~R��}�g�ڣM��g��Ak|}�:�0����>�0
+���B�l�mp���;x��܁w�:�F��� �uR�}g}z��O4�
+����5������{���g���+�͎�\���LiCh�Nx�ڲ���z��R^}v̭�W�mq��4}���g�zpX������_3dp��o���
+sr=v��u�������$���f�^a�I,*ή+������u��߽���Y���ES=r�U�1������^��5�X�;�w��s�I�����[���������s��/��?̔'f{��������|���������﬿F�������Go�?E�������ƞ<��J�󏿡׻�s�.w�Tm�0����o���nʇ�����|^A�$�����������������w����k���}��)�*�G����6��m~����9��G����޲@n�n���Dn?/[�0c��*H�;���;e�˝���]z4�k�v��H�?��O��������0�c��r���	�?��O��g��8�f�ٟ0�����������j��rT�
+Y��t�h�^�z���oP��c��q^ �쮆�����mXOk���~Ư��w�>�+ �~�Nm�rbS햅:�7���Z�����3�V���>D� K�ފ-y�h5y���Vd�V3e�V%2y�l���p��U�L�*V&o���[f�VW9��ؕ;A�gx�7���to��O�X:ó�8�ٝ�q�;��<�gw��y���t��p�����>��=΃���BXe*F1�Q���MU߭O���|����g���R���Ui�<yU>�_e�����7�ά�>:F�?�ؔ]�[��n���^�]M��1����6�w�w}7���V%M�k���c��)�F�Πp�ps��V8+�y��%*9�U_�w&�
+�1��[�����57�|��>���E�{�������@��q�[X� ���?�Z������5������߸�o�:��*��-���.{���q�ղJ��2Z�LA��Bۄ�E@��"Cy��+.�VdE@��;��1���`�����9ORZ�B���&&��K��9�3�s�s�#�m�t��^�b/�2Q*ՏV��x�?���+��vFF�t�����������������2Ro�L�H���a���X�hcV������?�h�L0z�����`���?T#������cm���'��T*wN�uy�X��-g�C�"[��Nd�+�l��/"[�}Rd�7�l��"[�<��Ζ��α��8��{8��zGpl��0Q�٬��IT�i`�^�.�o�~��i��ί̒"����%�,�L֮��n��[#�j�{�5�^~`�7�����A�M��&�\ȫ=�3����8%j4�.�,�TX��Rj� Ê'qhYp���,b\Ŋ,�r��n'��ʽ��2�Y_��Y_}Rd��{}�F�W���o�,�r�������u'�^�XP�^W=�cA�{]�p�U�u�L#��U��GQ����HYP�j� ���	�KA���%3K j
+�@�,��)X��)�S��`	(@�Ѐ�%�"�)A����Q$�y����%<�Mx�_��̑݌�&�8ه���
+u�;'���[r2����o�J���1f��xn{
+Y� ���6}�-F��_�R��&����ʻ0���֢��o�`�n�z�8��������cR��\�޿гlP����5�w6.ʯ����쪗�F�R��<�aF��wR��n�����3%A�,!��c	�83K�5�,!��]�Tg	��:���(���BD�PAN���JK�
+@����������ӍIicMYٞ��������y�W�Y����#>X��Y�y��F����e�9j�X��uy�����ΡPC����"�'�Y>�k����,����9���o9n�r�38�ͱ�`,�r��(���hD�	����*�z	-k�	������w���a����w�e��(���P�,���je`��xじY��Z�b�U�9�,�5�X/B,��T���@���ɯ����=b����b��$�E��'?�Y�7�/�����S2�v'O��SҞw�@�By��'M`�Ԗc:������9ٞ[v���aE�?r�W�����~�ĝ��4G�2S�5ol1Ժ��\��UG�C]�![c���:K�淕��l 5��K�� ���?K��\�w�Dj��n�i��Y�R�'����[|�S�r�hE�O��v��?�~:�z�x��+���S��e��BRg>tD���DJ�ν%�����^kI�,-ioW��C����R����[�K�|�wZ�#�y�>�c|�7W������E��#WJݛ>�GEΔz
+�gJ�Ws�^�z�ב�R�J�Ϛ�R̡~|�)���Gf$�/�3c���)�~w�	(�o�2�2�v����z�\�4��A���o10������U��]����H��w���o+1��@b��'D:0���������O$��wK��o���_!1��g����N���u���g�:���x���Q<����������w��O��������-1��Tb��5!ҍ�����Mx���t��c�������<��?������?�3���g��}���}�>&P�����>&P������Cy��3%��s$�������+%���K���������V��j����N���g���?�&?��������?y�1;ْ���c���?�JUd��F-���o����Y���*��
+��]����-�>2�+{��k�Q���=�f�/�G_]m�8�������F���c�94M;+����f|7$"��_�@/�+��+��`�����w���.�<�K}~�~-�xx�{�)���B��o�����w�����H[~egq�Z=�w�Y\8[����v����p:C�5��=\�7���Y\G�H�"�����r/������F_���
++��Ѩd��c��V�.�����o��l�?̭v}o~l�9s륇�m^���v�Zs�l�YH�mVu����z�V��ގw���2��u��c谭���ٶ�N�5��[xC�Ԛ�.o�l�%�0t�R��-�!2����t�!*�G�BCt����[�_u�:���q�>k&9b�5��2:��z��wc��>�bl㴉|������.����w�4rw�M�=z7�׳��;X�ww�?�̓��6H����'���<�Z3��V3��]�w$�ܣ�s[�s�2B1�=��<���<w��y�Z��������
+�s�40����y��+:��>k`���`�{��y�����^�`�{��y�WA��fw䐨�s�50�m�c$��2:>%��s�o�&����Dc;����W1�)�.
+����)�HcV�x_��Ԛ�"�ar������녏2�����H�}������}ߙ��yX�Q���&��g��${��>������+�O�:����1t�k �A.��\\"^"^"^۝Il�Ͽ��<��ݍcӲ�F����~�����ߣ����~�����?t}�Y)����p�JH�`��l+Q���+̝�y(��k@�� { ���A5s�&fV
+�\����������?'Ô��}�elZzz��_%(���V��|��)��%P?�:V<�6.u*!��)ߗ�VN�?�B��u���t�[(�w�!�|��kL�c��=�*���ôE��j9�����wE��\�r��q���
+�u�zé��͏���z�Y��ޡܟcmbފ�7h�0�W��Z.��^,Y�.��~K��-����X��b�n��?��-�͕��<W�ٛ\�M�\�'>���s�#�sU�M��_�U�$W����=�����Z
+��ZB�:=�:+Ő/[�u�E��v��S��
+^{�S}Vl(u��5N��k���i��\�#��-ײ��+_�Tspx�H5���Ts�i"�d��Ts0h*-WkSi!��FoZ �{kVs��H5�[�Ts���H5�^���	;�9�xO��v�U�VsPz}m1����^��p���p}6>鞯<�ʫ�=K�*hSi�uY���}����kT\<�u�ϟ�U.uЬO�A�Ri��TBD:!"��V�H-
+��^T�Б};Ќ����>�r�c*�F�D=B�]P�h��T$:R�(����RHO| E�4�RHW| e��R��K�v�0e�Y�*R����)M��l;P���@oʶ�)�4�l;P���CY] R���@{ʶ�)���l;� e�A
+(�ޒ�[~]�˶��)@5X��UO*²�z
+P�mw�S�� ��S��컫�T�e�]��J,���)P�(� բ컻�T����z
+P5ʾ��)@�X��UO�ǲ�z
+PAʾ�R�T�e�]����ט\Q5)�~��U���\�����f��Oeyd���������Ur��o�w���_)�b�3�t���]_apO���-�(��Q�/g�F�;Zu���z<��?16ǒd��ߣ�w�J�)B����{���3�=�g�~�?m��������}i��pw�C�s}�}5��Ņ��U#s��=!���)�'���;5����	�W
+��9_#��T�J/�m+��d�)l��*5"�ֱA�����Yn9:\Wwv[�����[�/+t�I�BCS	]��7��}��5����4��mzc������O/Z\ە���m�V���>�x�����m��lk�ڨ�v	�6A���eS�t�Χ���NS�����IV�-���?XFh���+�:���CB�̍�F�2�X�.k����T�l�=��v�:���.��-��+��K=���$�>6D�gg�Y�A����W�\n��kl�n�s�O�l�]7�b�/��np�Ea��r�DN��k+�~�,���(��Yҕ.��ۛ˕��;i(��w�P?c���q�+s�m5�T�r���m����=�A)y�!PiBTAD� "eh���yP��y@��!��4�y��D�D�&�͗�V�@-D�͛�b4o�Ѽ	�F�&�͛�r4o�Ѽ	�G�&�͛��4oҼ	�H�p�
+)I�Y�l�&͛��4o�Ҽ	hJ�&�*͛��4o�Ҽ	hK�&�.Y�51G
+Ӽ	h��M�����4oJ�|	hM�%�6͗�ބ@q�7]f;	#�i޴��$���y��l'a�>͛����Q�5�м	T��M�4o��y�!�͗@=AEh��ۛU�";P�7�� �� ���-P�e*��j������D��"�j���Eꅈ*� �j�	�%B�s�?����&�����E���5*y��/��{5J�aӲ � �K2~���M�N�o˟���}����q���ԑzSz������j����ޕ�x�Si{��)��K�����K���l�7�����]~�����o��*��� ����Sz��_�,��Q*���/��������U����"�B��M/IQ���A����_��W/�w���{_X��Y���9�]��5��j��/3���|^�?�Ei@z��.��DKk���n)
+�&HC������"
+��?lï��'��������?�OL�����0�$o|�;)��F>q�!)��|r�5ғe>�R�IRʷ�I��-Rھ�Ҩ���o?.���gL�,e.��M�
+$�T
+?�'��dM>+�>�u�ϩ��c�U��:���U�&�����_=-M�-�>�E�����3kޒ��T�4k��V+0��?}��ߨ�(��^��w9���l�2��M�A^� 3�����@v4q�!�i�r$Y���I2�	��ʖ&� _����ir�	<Ț&� o����ir�	<Ȟ��GD "�4�>'���
+D�"ry��\AD� "g�7��D�"ry��\BD>��W��-D�"ry��\CD�!"��w��=D�"ryH��2G�|$N""/	��9��<ED�""_���i��n��m�/"xWF�Q��U�մڅ��
+���}��y��C���Py��������G�xW�}?���?~[����7�;�{��+3)͘�Σ�Q��O�J���?�(t�𴤍5yD�������a���������Um��3����}���Ϯ����`�Mq�m8�q����*�3� �+vP�(&Tk����'�W����
+�ᄜU*�����S��~���?Uj��������4g<{m�p�s[���ȯ)}�GŃ��k��y�p���O�rG�����~?"G��L�-iY�F�������#������D����i���ŝ�e�x�k�o����ڟ�ߔ�1���h���S��?�����a��Ouk�V%뻨 p`���}��<�J �A%�z{P�3L����h�'L���������?8�}�-)9��ə�����?A^��w��c�]����l����~[A�_���>���15�c�Q|�W����O��']���V�-��p�;VS[���
+��o���zQ�ӓ��&g�D��Q�6A�?���4-��+�v������-�;��J�Qqc]����mXX�����z�Y�ߏ��#��KZvZ�O�*mh������_���[MgL
+z�V�]�����=��4U�-��\��ܹS�.���� �-<��G�I|�o��6�y�ߗc����xSv��� ��Q��9��5�H��L��&�1�������>�>?��v��'�?�����(�l�?�f�3��=��!�jÔ��O�ʿ���7��VU���&�������z���s-4�s.����3C�������Jo�_(-�4KZ��oi��,%-����$�%ii���~�����I+}�_��f��_k-٦5��͘οg��޷,����Fe�����Ҧ��҇?���߶i7��§���s�U�w����:��9d4��KCiwx,������!����oJ��H��$�j���\�:��?<�?xg�xĲ�;���t4G�]5��X�ٗm��
+����$w\�<w���҉�_��:ΟlE�i��S���>+�����:��ˋu�>��}��5���ٹ_�y.��\V�ܯ�^�#��na��([�^lT;�RH���rZݷ7��._K��ٲ�����a���++�鮾yX�����~e���x0������F���M� ���/�^�*�^�{����
+�Z�_��W�%��Z�rRs�J|3k��e�j�2��oXkT��Z3��/���.��>��Zg�Bk�փ����*��_��?s���ė�tQ�p�E��E�Nq�&��+���(��o�h�����n�ߨ�-O6���]�����R륗�6����N9(���*	I����y�e=�꼅Wx���{��*���ۓ��W��ύ|��c��"��g�H����:o� EL�*u�WW�=�X�:�=/יީ3
+(U"���Ŗ���@ϲ����3�\yO=a�ɉ�_�i��~r�~J�(����x#H|'�T��y�{«�Jݖ�qpT<�!m=G�p�!;W�q��C$D�����!!XDjk
+V-#"ZGD�����$m���%"ZLD���h9i�F���`Aъ"�%EDk����˃UEDˊ�֕�σ�ED+�����-"Z\D���hy��"�FD+����1"ZdD�ʈh��:Ӻ}�Є`��R��FD���V�,7"Zo�sl<Њ�%GDkN�:!XvD��`�����GDkO��Z}ڕ,?"ZD� Ԧ� "zB����+ �g�]-�; ��@D/����߂�@D���^="z��!x��o���
+"zJ��wAD��^=
+"zD�8��u�� ����~���Q[?�D���Ha�#!�WBDτ��	="z)D�T����c!��BD�Eދ2���ы!�'CDo��
+�"z6D�n�����!��CDo���"z>D�~���"�'DDo���""zFD��!)P/����%"zLD����9�{��2xQB��Mѣ"�WEDϊ��=,"zYD��4 o�(w	��P>�@� 9��d���B#B�3��#���!4ث��nɖ��$_��Ra����?�����'��˭�Y�b�������`n�!�9N_����W�r�*~8�^���{��U�w�WMk�6���z�G��?�5[�v�j��]�G����:?�2�|�����z;v���54X�D�����p��F?q4���D��Ѵ���f�_w4o�lo���������_3��������Z��o��qC��[��=�� �7X�2ԡ���WEwt��k��sh�6}X�<Gx�!{��/�o��wس���d��a��b�x�cC�y�v�i���1�n��"����ۥ��k�Q���n��}b��W����O8z_�n�3�iÇJ}�������
+�b���]߿SCÀ���qu
+�7��o~c����M�cH�M�!�.8����}��ݎ��O����1�'�O$�p�\��b���F��L7$�t�'UeH�n�O�cHi�O9�֐V�}�j�0��^��W[;ҏ^�g����\��n�t�_^a�9fس��wd�m���al�t���������\���1�	�2<�Y[��g�����}��a�k?��yۘ���F���w��v�MO����4)J�I�5"R�MGD�#"�)��S���`hO�.P��]�?����� U�`ԁ�]P	
+rA-(�ՠ ԃ�\PBP
+vAU(�u�`T��]P
+vAu(���`T��]P#
+vA�(�u�`T��]P+
+rA�A�(�#5�`T��]P7
+vA�(���`T��]P?������`�:Fud��:F�d����Q=Y�{�~Ք�k�Օ��ڲ`�BǨ�,؍�cTc쎡�Guf�n�ZS��M�MA.�8!�9��ꄠ���S�jO�.�>����	�`� �`
+(�s@�.�
+v�,�9�@恂\0�`&(�SA悂]0�٠`L�`>(�B�.�
+v��P�愂]0)�Y�`L�`^(�Cf��\05�`n(��Cf��]0=���`L�`�(�SD�.�#
+v�$Q�f��]0M�y�`L!�)
+r�T�g��&��#��h�(�]��M��2}ESF�.�3
+r�ߤ�5|�Q���ж�mU-T~��,<���}�?M���!(��?��\/�5����Kw~����j�����C���{�F�sR���R�_>�j]X+�>a���-�l���]���7!_��7�8�W�[����F1�|�NQ|��Z�i��|����A�R���R�o�J-O֐Z�.-���s�!���G��Y��V����+��~�qͧq=7�cs�M�ߓ��!})���hL1P�% ��X�����Yr���V�% gK,��g	�5<K@.�YR�Yr2���% y����Y2�g	H-���y���ųd���j�% �J,YCb	�Ғ�����K	��I
+���-���_װ����#%[����	�л�?���r��/� ׫���x���������r5���
+,	zs�W���L����Ǆ8j�+�]�.x�/�n��EPf.$�v��^�+��p�i���0&[L�) ���O�����L����r}��R��!��f���g^ލ���b)v�����X�����rS��ɓ8y�W�8��1��ٚG�?O�Q���(���7�S���
+qoc��X�xOt +����RE�I�Ř2S�'-	��:Y�L��Ƥ�4�/�i��"��C���?_��
+V?|��\O��k�4����?OJ�����?[\0I���YG&��^�..�zI\�����q���:ne�mq�oq��o�֬Prk�#D۴jܺ��̂���Uq����Q9L�T�SqS�^��7�[���m��}�0C���\�y܎qOs��s;���vu�*����鰌�;d����q@gq�Om�_��~`����yH�<tnwxn$wx�P���yd�a�hNS���}��}�Z����ܱ���Ǖ���/�O=�}�kw��§-�©�;��ʾ'|vc�p��+¹S��ߛc;��y�s�m��m_ZپJ��]n��[K�7�:�����.��	ߖk!|{��p��`�37��� ���s���#��7�?�h�	?��#�����K�ۯ�m��$��'ۮU�خ&ڮ�o�0/���Ry�Ҕ0��n!VN�-V��%U��)����6�<O���=�;�L�O�-���3/��S��N�� ���|���3���N���څ��<��=�u�@����.M\|�U�\���- ���:�%�糺/������Q�Ud�_�EV�%���k7���-%���$���gDV�±��u�h=Y��[������/%��F������&p��KY�׫"���"���a"����!X[V��Id�_{8V���c�_"��z���
+����9V��α�����*���.��ZƱ���"���"�����Z���1��22��꿆2<���8��jf�_6'��:,�������q���9�³������d�_�_`�B���vq������V��C`�_�1o��^X�W�����X���6V��mc�_�6V�5��꿢m��+���Z�X�W��*gc�_a��j�<	��
+&D���~X�����:"�������	��k������k���������6V�%�X��d����X�W"C�F�0��hI�K�~)z&Zމ�Ă��%��h�x��-��f�3wr�N��y!s'G�:�%��?��<~�(�ش�^���+�'(U��-1�.I��{A�q���ԑ��&KJ�ѻ�W������#9����O��=���6׽�ƽ�����Ҧ�����qU�2B)���g���x |_�W�����������v��9=AQo��ﰢ�F���KX��/�(��]�|�����d���G���0m�����_��hx��D
+���v�ig�a������v�r�T�F�[k�no^�m������/�|VOw�ݶC�t����ڕ���>��V�]���IB�c��^�!��q[�QZ�bzg[�޵t�R���Cפg��i�s�f���f�?ҵ��	-���m��Jh�����컄�s䶱-�Z��v�tA��:~�M�q�N5t�Mb�iڧ�47#ua�{���6Յ�hmk������V���8:}��<f�#bqK}�a�
+����vx���xEY�?��]���a2�h�N��LC�����;3��[k､��ρ����C�Z�BS��^	
+��ۿ� xw��RY(�!�F#'�hA�%�q(��~�,_��M���J)\,�pA���S
+�L�[4!N)\:�pA��S�@�Z M��,���R�HJ�)(�Ġ��Rx@J�I(�D���Rx@J�i(�ġ��Rx@ B ��H�@&J��(����Rx@.J��(�$��t} ky�����Rx@<J��(�$""	����BR
+HI)< &�������R
+HJ)< *�������R
+�K)< /�����@bJ��	�̈HhB 5���ؔ�rS
+N)< y~��DǙ�*B�����'-i��v������R
+r�g/ʿkBZ�(�����c��P���ɩ,�b�g�~=��C�ڻ�R������9`ä��'�/Q?-.9qK���Zn�����J\�j����jp�<��}��yܻ�B��Ww�_�L	nm���'4����{���{����
+�r�wd�767,^����@n��'��9�m~r�}��ĭѳ��ft�>j�þ}T��[�7����&�w�m��<�ھ��Aܽ�K��+�^��}߉��~���căq�����a
+g/fO^)3a`�&�lS
+��f<�����"5[,�CH�<`	a(�G'")"+"--��E�!F�a�E!0Դ(�����ӢvBzZ�c�0P�(�@�@Dq�Hh�����hh��E��b�E# *Z4�E# 2Z4b�E# :Z4�#Ҍ�H����DJ3+�8@�4� �ҌDL33�8@Ԭ:Td�C���7sSn�����5�k�1���{���y�'o�?=%����<��U���UZ���}��˸���s���6��͋�w��y����r{:��Ӽ���i5,s.�;���\2!ƹT3ٹtS)�RfZ�}����5o��Yj���61ҧ���#'�_�ۜ%��pF�sV8z������Ҹa�:��26�\��nb�����Fr%eJ�
+�g�Rp�4~(]�Ǖ8��^"�PX�{]E@e<��`���^g�F$~��r׊o������A�\�x��P3B7Z%
+cG�Da�(@�1�U�0��JƒV��x�*QS
+`\i�(�-!�/9�<���,a�i$�7�~|�c�a�i�#�=�r��ՆGتG����A�2��e��"�儈�B�����M�� zP���a���!��JA)���?ٿ䯕��E�w3fG��F��0�V��yU��)9i>��RYd�W�:L���$���tgQ�_�pH�s���
+]����/�(���7�?*'ݏ�6L��ޔZV�1�G�W	�"�_+�����t�8�٦
+3��l���\�OI���ۢb��}@���]O�'��բ�N��Ў�����=�?5�������z��5 k�l]�""���/
+��6r����b�0�86-==����������7&�r�GC�3*'#!�'���)����=�d��G�,�J�=���*��G��7g���+��2&��%�/�&�H������M�7�s������{�{��2c�㋔γ���٫͝7�Zt7?��\f��̞g�o�s���
+���g�l�t���7_b��q9W���ٳ�E��F�ލ�p��s���\�3�s�k�ľ��~�V}�-V}�
+}�
+k���Y�v�: h�u@z�5.l�5nMCkܹ����ց5�[Nt(�[�:�u�uе��i���W)�T�W9��U�j:$�:�7�b���a��+o�k}�d-��#���RO̳Y��Ra�Q��	]v+�j�H��nM�>[�|���ɐpk��Ɋ�����-�i�c�S��s�fh:+2�VS����e����cx�ղ���r��5{�՚�~�bl|�ؗҭ�Z}�7�u��F�	�&+�>�������g��Q<sb�u��b��Ί"��dQ[`�|��]��%c
+�|���R�� �n���
+H�@�[� �)�
+I��D"2!"��TtA@,B "H2D$� ��p�H:D$>�|�H@B !"�Ȉ��DDR""1���HPD$)!�Ȋ��%�""q	���H`B 1!�Ȍ��&R��܄@pD$9!�N�GD��	���� ���������������� ��$��(��,��0��4��8��<��@�?��?T$BP&DT(¹��Q�A�Q�A�Q�Q�Q�A�Q�׳�D$|�]'*"!(#"*$"*%"*&!('"*(!()"**�Jv��{�@�'?����W�aؗ]�+�//4a�9uWW:?��'�x��5t<}?��S��_e��q�a��Y�G��Hv�/_�B��Z:���/����ft�ߏ�u�q���}�g:~�t�Z��7���o�����^$�W�]��elW�����\0��}�ʝtl�c��Nf׹X�>/®sɵat~i�It�l�^:^v�]�y&:�b���K
+�Vv��vy���ˮsu��������x��	��a�i�܅�m�&��{�%������O0=Z?�]��M:�!QAǛ�-a؞]燧y:�̳�ܲv#����9:�6u$���:����퓝t���;��N�?�����u�:2��ﺵ���,k����}��t��v�zu���J��C
+�gؗ]��+C��H�3t|t���&t���:>��]��jt�ī���d�V���:O�oIǧ"�u~���Ο���3�cx�]繩����Z=�ܼ�|p�	>E��}Nw������U����*U���2�/�z��Y���,�4ǼpQ�aeЏ敗2���W8YO�~�=��5�{��^Awv�ȷ�%�Jy�	S ��?��� �Zpmp�B�|D�W��W�����{O����Y�4-A���l�>���#����+�����3�]W^�Mo䮧r�SN�z�p����9V�y�����h��]3��)�8�2�'��=���Jy�������F�����j����ޕ�edr��8c�ј�s�+�&T����G�%�r���D��4��_����o�����	����)����]�i9����Z�-R��������Z��T�֞NG�c6�ry�=����x����GP^�/�;���g�ls����J�b����� 5�P�
+��0�*�ֻ|�]��.�z�o���ֻ'|�w�����λ_��=,��٦�|��k��Rk����mL0YL��~"�V����{-F
+�C�_�T�����{�R����Y	9���_�-���6L���/�����8	����Ckf����Gfe�G��of1$����W���J�U���޸�q���)L3d<�UǪ���Ro_�Y��?M>��S����`|����9	[�y�����"��B���O����\JYyÒ3�5����p>�b/ix���{)��Q��B_F��Q���sM�_Nӗs�r��U^_a����˺�+�d�f�+O�d����^5u��Z����{�k���H}��1�*?�^���P��}��^r������p�[��=\�R�wi8�zK���M@Y��V�D�!�fQֹ �����Pn�&�@q(q8qHqXqhȰ�� �!�0!�P!�pQJ��f�0t�R�ᣔ*!�Ta)�
+C��É�C��Ê�CK�'�!���������E����om��||g��3���P��|�ߛ�O5Z�M9���RV���:T��~��s���?�������w>%8��x/��>?L(�?�P��C
+ zF*rG(����c�����3�'��?��?3+՘e��S�wy����cL1eq~��m���ӫ�OK�${���C��S���U��2�9���Z#����)�cf�_����߫�O��H0f�����Ô�*9��������G��*�<���c������IVH�������9�~���J���߫������RY ����4Y�$���C���o���,��ߔbLJ�J�������zW����4����f����U�|�����;t���"�YG��<0,3�D`^�o_c����97ꊅn�U��Ǜ��&,�n��3��S�n`�@����	�c=������*��Q������E�he��O�_�\��<9�\��yC@� ��X��5���`M�q��X���l�G1	O�/ >د�;?�O��P�Ǉ���������o�1�NL5eg���A�*�����/ǘbL2夘r�@�J�	d�{S�z�%�Ԧ�i��/�>��ߛ�3�F�{j
+�}��0m��_&��>���\/Ε�	r��\�%�5��j�P"���33���5v�a�c\�����V��ę��nl�0/���G�'� g�
+�|ZFB������=�?��?��ߒf6��M�O�U�������F�,�Nf�����*��E��R��_|��+��F�ϕ���6����0ݱw��޳���w\��<t������kp���#�5��9j�>�㘥�o
+C��_8+�Xe��2��g�17Z��ٸSg�ֵ�M�;�u�in���-��3����վ[%K�(�
+�h�B�+;/�D�;i��E%/J#�c]���.*�R���dh���"���>�08l���Q""u���n60h�0p�0x������ "�@"�`Ҿ�0�x18����E��E����AFāF��F�G�AGāG��GD�8"yT0lG9d������jJ���ɾ���+��ﾶ���e�j�A(���Y��63�ڦ���=s�z�ɇ���^�㒨�|K�4�/j~:/��zW;�+�_���~�b����q���ڙ\�1OJ/gr]�=��Lz�k�d�[?%Y'��ޮ����|���s=Δ㣯W{�l.�:���{IY���OŘ羗��|�a��So��nk����܀F��8�\|�5�@�����%~07�|��qtᆾ�<Lc[��4�d}��*�`�g�6���LU׆�*�u��g�u�o��ϸ�j�F�d��r@DY �<�� D�"�僈2�9��Q^� 3D�"�凈2DD9�e������J�dKn��1��3!Ț�țdNn䎈�'w�GD "���=���D�"��D�	�p�B�=�OyCx�����/8$�D��C~���O�h�6� p
+ 
\ No newline at end of file
Index: venv/Lib/site-packages/dateutil/zoneinfo/rebuild.py
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/venv/Lib/site-packages/dateutil/zoneinfo/rebuild.py b/venv/Lib/site-packages/dateutil/zoneinfo/rebuild.py
new file mode 100644
--- /dev/null	(date 1616410450456)
+++ b/venv/Lib/site-packages/dateutil/zoneinfo/rebuild.py	(date 1616410450456)
@@ -0,0 +1,53 @@
+import logging
+import os
+import tempfile
+import shutil
+import json
+from subprocess import check_call
+from tarfile import TarFile
+
+from dateutil.zoneinfo import METADATA_FN, ZONEFILENAME
+
+
+def rebuild(filename, tag=None, format="gz", zonegroups=[], metadata=None):
+    """Rebuild the internal timezone info in dateutil/zoneinfo/zoneinfo*tar*
+
+    filename is the timezone tarball from ``ftp.iana.org/tz``.
+
+    """
+    tmpdir = tempfile.mkdtemp()
+    zonedir = os.path.join(tmpdir, "zoneinfo")
+    moduledir = os.path.dirname(__file__)
+    try:
+        with TarFile.open(filename) as tf:
+            for name in zonegroups:
+                tf.extract(name, tmpdir)
+            filepaths = [os.path.join(tmpdir, n) for n in zonegroups]
+            try:
+                check_call(["zic", "-d", zonedir] + filepaths)
+            except OSError as e:
+                _print_on_nosuchfile(e)
+                raise
+        # write metadata file
+        with open(os.path.join(zonedir, METADATA_FN), 'w') as f:
+            json.dump(metadata, f, indent=4, sort_keys=True)
+        target = os.path.join(moduledir, ZONEFILENAME)
+        with TarFile.open(target, "w:%s" % format) as tf:
+            for entry in os.listdir(zonedir):
+                entrypath = os.path.join(zonedir, entry)
+                tf.add(entrypath, entry)
+    finally:
+        shutil.rmtree(tmpdir)
+
+
+def _print_on_nosuchfile(e):
+    """Print helpful troubleshooting message
+
+    e is an exception raised by subprocess.check_call()
+
+    """
+    if e.errno == 2:
+        logging.error(
+            "Could not find zic. Perhaps you need to install "
+            "libc-bin or some other package that provides it, "
+            "or it's not in your PATH?")
Index: venv/Lib/site-packages/dateutil/zoneinfo/__init__.py
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/venv/Lib/site-packages/dateutil/zoneinfo/__init__.py b/venv/Lib/site-packages/dateutil/zoneinfo/__init__.py
new file mode 100644
--- /dev/null	(date 1616410450487)
+++ b/venv/Lib/site-packages/dateutil/zoneinfo/__init__.py	(date 1616410450487)
@@ -0,0 +1,167 @@
+# -*- coding: utf-8 -*-
+import warnings
+import json
+
+from tarfile import TarFile
+from pkgutil import get_data
+from io import BytesIO
+
+from dateutil.tz import tzfile as _tzfile
+
+__all__ = ["get_zonefile_instance", "gettz", "gettz_db_metadata"]
+
+ZONEFILENAME = "dateutil-zoneinfo.tar.gz"
+METADATA_FN = 'METADATA'
+
+
+class tzfile(_tzfile):
+    def __reduce__(self):
+        return (gettz, (self._filename,))
+
+
+def getzoneinfofile_stream():
+    try:
+        return BytesIO(get_data(__name__, ZONEFILENAME))
+    except IOError as e:  # TODO  switch to FileNotFoundError?
+        warnings.warn("I/O error({0}): {1}".format(e.errno, e.strerror))
+        return None
+
+
+class ZoneInfoFile(object):
+    def __init__(self, zonefile_stream=None):
+        if zonefile_stream is not None:
+            with TarFile.open(fileobj=zonefile_stream) as tf:
+                self.zones = {zf.name: tzfile(tf.extractfile(zf), filename=zf.name)
+                              for zf in tf.getmembers()
+                              if zf.isfile() and zf.name != METADATA_FN}
+                # deal with links: They'll point to their parent object. Less
+                # waste of memory
+                links = {zl.name: self.zones[zl.linkname]
+                         for zl in tf.getmembers() if
+                         zl.islnk() or zl.issym()}
+                self.zones.update(links)
+                try:
+                    metadata_json = tf.extractfile(tf.getmember(METADATA_FN))
+                    metadata_str = metadata_json.read().decode('UTF-8')
+                    self.metadata = json.loads(metadata_str)
+                except KeyError:
+                    # no metadata in tar file
+                    self.metadata = None
+        else:
+            self.zones = {}
+            self.metadata = None
+
+    def get(self, name, default=None):
+        """
+        Wrapper for :func:`ZoneInfoFile.zones.get`. This is a convenience method
+        for retrieving zones from the zone dictionary.
+
+        :param name:
+            The name of the zone to retrieve. (Generally IANA zone names)
+
+        :param default:
+            The value to return in the event of a missing key.
+
+        .. versionadded:: 2.6.0
+
+        """
+        return self.zones.get(name, default)
+
+
+# The current API has gettz as a module function, although in fact it taps into
+# a stateful class. So as a workaround for now, without changing the API, we
+# will create a new "global" class instance the first time a user requests a
+# timezone. Ugly, but adheres to the api.
+#
+# TODO: Remove after deprecation period.
+_CLASS_ZONE_INSTANCE = []
+
+
+def get_zonefile_instance(new_instance=False):
+    """
+    This is a convenience function which provides a :class:`ZoneInfoFile`
+    instance using the data provided by the ``dateutil`` package. By default, it
+    caches a single instance of the ZoneInfoFile object and returns that.
+
+    :param new_instance:
+        If ``True``, a new instance of :class:`ZoneInfoFile` is instantiated and
+        used as the cached instance for the next call. Otherwise, new instances
+        are created only as necessary.
+
+    :return:
+        Returns a :class:`ZoneInfoFile` object.
+
+    .. versionadded:: 2.6
+    """
+    if new_instance:
+        zif = None
+    else:
+        zif = getattr(get_zonefile_instance, '_cached_instance', None)
+
+    if zif is None:
+        zif = ZoneInfoFile(getzoneinfofile_stream())
+
+        get_zonefile_instance._cached_instance = zif
+
+    return zif
+
+
+def gettz(name):
+    """
+    This retrieves a time zone from the local zoneinfo tarball that is packaged
+    with dateutil.
+
+    :param name:
+        An IANA-style time zone name, as found in the zoneinfo file.
+
+    :return:
+        Returns a :class:`dateutil.tz.tzfile` time zone object.
+
+    .. warning::
+        It is generally inadvisable to use this function, and it is only
+        provided for API compatibility with earlier versions. This is *not*
+        equivalent to ``dateutil.tz.gettz()``, which selects an appropriate
+        time zone based on the inputs, favoring system zoneinfo. This is ONLY
+        for accessing the dateutil-specific zoneinfo (which may be out of
+        date compared to the system zoneinfo).
+
+    .. deprecated:: 2.6
+        If you need to use a specific zoneinfofile over the system zoneinfo,
+        instantiate a :class:`dateutil.zoneinfo.ZoneInfoFile` object and call
+        :func:`dateutil.zoneinfo.ZoneInfoFile.get(name)` instead.
+
+        Use :func:`get_zonefile_instance` to retrieve an instance of the
+        dateutil-provided zoneinfo.
+    """
+    warnings.warn("zoneinfo.gettz() will be removed in future versions, "
+                  "to use the dateutil-provided zoneinfo files, instantiate a "
+                  "ZoneInfoFile object and use ZoneInfoFile.zones.get() "
+                  "instead. See the documentation for details.",
+                  DeprecationWarning)
+
+    if len(_CLASS_ZONE_INSTANCE) == 0:
+        _CLASS_ZONE_INSTANCE.append(ZoneInfoFile(getzoneinfofile_stream()))
+    return _CLASS_ZONE_INSTANCE[0].zones.get(name)
+
+
+def gettz_db_metadata():
+    """ Get the zonefile metadata
+
+    See `zonefile_metadata`_
+
+    :returns:
+        A dictionary with the database metadata
+
+    .. deprecated:: 2.6
+        See deprecation warning in :func:`zoneinfo.gettz`. To get metadata,
+        query the attribute ``zoneinfo.ZoneInfoFile.metadata``.
+    """
+    warnings.warn("zoneinfo.gettz_db_metadata() will be removed in future "
+                  "versions, to use the dateutil-provided zoneinfo files, "
+                  "ZoneInfoFile object and query the 'metadata' attribute "
+                  "instead. See the documentation for details.",
+                  DeprecationWarning)
+
+    if len(_CLASS_ZONE_INSTANCE) == 0:
+        _CLASS_ZONE_INSTANCE.append(ZoneInfoFile(getzoneinfofile_stream()))
+    return _CLASS_ZONE_INSTANCE[0].metadata
Index: latest/Lib/site-packages/soupsieve/css_match.py
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/latest/Lib/site-packages/soupsieve/css_match.py b/latest/Lib/site-packages/soupsieve/css_match.py
new file mode 100644
--- /dev/null	(date 1616411341722)
+++ b/latest/Lib/site-packages/soupsieve/css_match.py	(date 1616411341722)
@@ -0,0 +1,1534 @@
+"""CSS matcher."""
+from datetime import datetime
+from . import util
+import re
+from .import css_types as ct
+import unicodedata
+from collections.abc import Sequence
+
+import bs4
+
+# Empty tag pattern (whitespace okay)
+RE_NOT_EMPTY = re.compile('[^ \t\r\n\f]')
+
+RE_NOT_WS = re.compile('[^ \t\r\n\f]+')
+
+# Relationships
+REL_PARENT = ' '
+REL_CLOSE_PARENT = '>'
+REL_SIBLING = '~'
+REL_CLOSE_SIBLING = '+'
+
+# Relationships for :has() (forward looking)
+REL_HAS_PARENT = ': '
+REL_HAS_CLOSE_PARENT = ':>'
+REL_HAS_SIBLING = ':~'
+REL_HAS_CLOSE_SIBLING = ':+'
+
+NS_XHTML = 'http://www.w3.org/1999/xhtml'
+NS_XML = 'http://www.w3.org/XML/1998/namespace'
+
+DIR_FLAGS = ct.SEL_DIR_LTR | ct.SEL_DIR_RTL
+RANGES = ct.SEL_IN_RANGE | ct.SEL_OUT_OF_RANGE
+
+DIR_MAP = {
+    'ltr': ct.SEL_DIR_LTR,
+    'rtl': ct.SEL_DIR_RTL,
+    'auto': 0
+}
+
+RE_NUM = re.compile(r"^(?P<value>-?(?:[0-9]{1,}(\.[0-9]+)?|\.[0-9]+))$")
+RE_TIME = re.compile(r'^(?P<hour>[0-9]{2}):(?P<minutes>[0-9]{2})$')
+RE_MONTH = re.compile(r'^(?P<year>[0-9]{4,})-(?P<month>[0-9]{2})$')
+RE_WEEK = re.compile(r'^(?P<year>[0-9]{4,})-W(?P<week>[0-9]{2})$')
+RE_DATE = re.compile(r'^(?P<year>[0-9]{4,})-(?P<month>[0-9]{2})-(?P<day>[0-9]{2})$')
+RE_DATETIME = re.compile(
+    r'^(?P<year>[0-9]{4,})-(?P<month>[0-9]{2})-(?P<day>[0-9]{2})T(?P<hour>[0-9]{2}):(?P<minutes>[0-9]{2})$'
+)
+RE_WILD_STRIP = re.compile(r'(?:(?:-\*-)(?:\*(?:-|$))*|-\*$)')
+
+MONTHS_30 = (4, 6, 9, 11)  # April, June, September, and November
+FEB = 2
+SHORT_MONTH = 30
+LONG_MONTH = 31
+FEB_MONTH = 28
+FEB_LEAP_MONTH = 29
+DAYS_IN_WEEK = 7
+
+
+class _FakeParent(object):
+    """
+    Fake parent class.
+
+    When we have a fragment with no `BeautifulSoup` document object,
+    we can't evaluate `nth` selectors properly.  Create a temporary
+    fake parent so we can traverse the root element as a child.
+    """
+
+    def __init__(self, element):
+        """Initialize."""
+
+        self.contents = [element]
+
+    def __len__(self):
+        """Length."""
+
+        return len(self.contents)
+
+
+class _DocumentNav(object):
+    """Navigate a Beautiful Soup document."""
+
+    @classmethod
+    def assert_valid_input(cls, tag):
+        """Check if valid input tag or document."""
+
+        # Fail on unexpected types.
+        if not cls.is_tag(tag):
+            raise TypeError("Expected a BeautifulSoup 'Tag', but instead recieved type {}".format(type(tag)))
+
+    @staticmethod
+    def is_doc(obj):
+        """Is `BeautifulSoup` object."""
+        return isinstance(obj, bs4.BeautifulSoup)
+
+    @staticmethod
+    def is_tag(obj):
+        """Is tag."""
+        return isinstance(obj, bs4.Tag)
+
+    @staticmethod
+    def is_declaration(obj):  # pragma: no cover
+        """Is declaration."""
+        return isinstance(obj, bs4.Declaration)
+
+    @staticmethod
+    def is_cdata(obj):
+        """Is CDATA."""
+        return isinstance(obj, bs4.CData)
+
+    @staticmethod
+    def is_processing_instruction(obj):  # pragma: no cover
+        """Is processing instruction."""
+        return isinstance(obj, bs4.ProcessingInstruction)
+
+    @staticmethod
+    def is_navigable_string(obj):
+        """Is navigable string."""
+        return isinstance(obj, bs4.NavigableString)
+
+    @staticmethod
+    def is_special_string(obj):
+        """Is special string."""
+        return isinstance(obj, (bs4.Comment, bs4.Declaration, bs4.CData, bs4.ProcessingInstruction, bs4.Doctype))
+
+    @classmethod
+    def is_content_string(cls, obj):
+        """Check if node is content string."""
+
+        return cls.is_navigable_string(obj) and not cls.is_special_string(obj)
+
+    @staticmethod
+    def create_fake_parent(el):
+        """Create fake parent for a given element."""
+
+        return _FakeParent(el)
+
+    @staticmethod
+    def is_xml_tree(el):
+        """Check if element (or document) is from a XML tree."""
+
+        return el._is_xml
+
+    def is_iframe(self, el):
+        """Check if element is an `iframe`."""
+
+        return ((el.name if self.is_xml_tree(el) else util.lower(el.name)) == 'iframe') and self.is_html_tag(el)
+
+    def is_root(self, el):
+        """
+        Return whether element is a root element.
+
+        We check that the element is the root of the tree (which we have already pre-calculated),
+        and we check if it is the root element under an `iframe`.
+        """
+
+        root = self.root and self.root is el
+        if not root:
+            parent = self.get_parent(el)
+            root = parent is not None and self.is_html and self.is_iframe(parent)
+        return root
+
+    def get_contents(self, el, no_iframe=False):
+        """Get contents or contents in reverse."""
+        if not no_iframe or not self.is_iframe(el):
+            for content in el.contents:
+                yield content
+
+    def get_children(self, el, start=None, reverse=False, tags=True, no_iframe=False):
+        """Get children."""
+
+        if not no_iframe or not self.is_iframe(el):
+            last = len(el.contents) - 1
+            if start is None:
+                index = last if reverse else 0
+            else:
+                index = start
+            end = -1 if reverse else last + 1
+            incr = -1 if reverse else 1
+
+            if 0 <= index <= last:
+                while index != end:
+                    node = el.contents[index]
+                    index += incr
+                    if not tags or self.is_tag(node):
+                        yield node
+
+    def get_descendants(self, el, tags=True, no_iframe=False):
+        """Get descendants."""
+
+        if not no_iframe or not self.is_iframe(el):
+            next_good = None
+            for child in el.descendants:
+
+                if next_good is not None:
+                    if child is not next_good:
+                        continue
+                    next_good = None
+
+                is_tag = self.is_tag(child)
+
+                if no_iframe and is_tag and self.is_iframe(child):
+                    if child.next_sibling is not None:
+                        next_good = child.next_sibling
+                    else:
+                        last_child = child
+                        while self.is_tag(last_child) and last_child.contents:
+                            last_child = last_child.contents[-1]
+                        next_good = last_child.next_element
+                    yield child
+                    if next_good is None:
+                        break
+                    # Coverage isn't seeing this even though it's executed
+                    continue  # pragma: no cover
+
+                if not tags or is_tag:
+                    yield child
+
+    def get_parent(self, el, no_iframe=False):
+        """Get parent."""
+
+        parent = el.parent
+        if no_iframe and parent is not None and self.is_iframe(parent):
+            parent = None
+        return parent
+
+    @staticmethod
+    def get_tag_name(el):
+        """Get tag."""
+
+        return el.name
+
+    @staticmethod
+    def get_prefix_name(el):
+        """Get prefix."""
+
+        return el.prefix
+
+    @staticmethod
+    def get_uri(el):
+        """Get namespace `URI`."""
+
+        return el.namespace
+
+    @classmethod
+    def get_next(cls, el, tags=True):
+        """Get next sibling tag."""
+
+        sibling = el.next_sibling
+        while tags and not cls.is_tag(sibling) and sibling is not None:
+            sibling = sibling.next_sibling
+        return sibling
+
+    @classmethod
+    def get_previous(cls, el, tags=True):
+        """Get previous sibling tag."""
+
+        sibling = el.previous_sibling
+        while tags and not cls.is_tag(sibling) and sibling is not None:
+            sibling = sibling.previous_sibling
+        return sibling
+
+    @staticmethod
+    def has_html_ns(el):
+        """
+        Check if element has an HTML namespace.
+
+        This is a bit different than whether a element is treated as having an HTML namespace,
+        like we do in the case of `is_html_tag`.
+        """
+
+        ns = getattr(el, 'namespace') if el else None
+        return ns and ns == NS_XHTML
+
+    @staticmethod
+    def split_namespace(el, attr_name):
+        """Return namespace and attribute name without the prefix."""
+
+        return getattr(attr_name, 'namespace', None), getattr(attr_name, 'name', None)
+
+    @classmethod
+    def normalize_value(cls, value):
+        """Normalize the value to be a string or list of strings."""
+
+        # Treat `None` as empty string.
+        if value is None:
+            return ''
+
+        # Pass through strings
+        if (isinstance(value, str)):
+            return value
+
+        # If it's a byte string, convert it to Unicode, treating it as UTF-8.
+        if isinstance(value, bytes):
+            return value.decode("utf8")
+
+        # BeautifulSoup supports sequences of attribute values, so make sure the children are strings.
+        if isinstance(value, Sequence):
+            new_value = []
+            for v in value:
+                if isinstance(v, Sequence):
+                    # This is most certainly a user error and will crash and burn later,
+                    # but to avoid excessive recursion, kick out now.
+                    new_value.append(v)
+                else:
+                    # Convert the child to a string
+                    new_value.append(cls.normalize_value(v))
+            return new_value
+
+        # Try and make anything else a string
+        return str(value)
+
+    @classmethod
+    def get_attribute_by_name(cls, el, name, default=None):
+        """Get attribute by name."""
+
+        value = default
+        if el._is_xml:
+            try:
+                value = cls.normalize_value(el.attrs[name])
+            except KeyError:
+                pass
+        else:
+            for k, v in el.attrs.items():
+                if util.lower(k) == name:
+                    value = cls.normalize_value(v)
+                    break
+        return value
+
+    @classmethod
+    def iter_attributes(cls, el):
+        """Iterate attributes."""
+
+        for k, v in el.attrs.items():
+            yield k, cls.normalize_value(v)
+
+    @classmethod
+    def get_classes(cls, el):
+        """Get classes."""
+
+        classes = cls.get_attribute_by_name(el, 'class', [])
+        if isinstance(classes, str):
+            classes = RE_NOT_WS.findall(classes)
+        return classes
+
+    def get_text(self, el, no_iframe=False):
+        """Get text."""
+
+        return ''.join(
+            [node for node in self.get_descendants(el, tags=False, no_iframe=no_iframe) if self.is_content_string(node)]
+        )
+
+    def get_own_text(self, el, no_iframe=False):
+        """Get Own Text."""
+
+        return [node for node in self.get_contents(el, no_iframe=no_iframe) if self.is_content_string(node)]
+
+
+class Inputs(object):
+    """Class for parsing and validating input items."""
+
+    @staticmethod
+    def validate_day(year, month, day):
+        """Validate day."""
+
+        max_days = LONG_MONTH
+        if month == FEB:
+            max_days = FEB_LEAP_MONTH if ((year % 4 == 0) and (year % 100 != 0)) or (year % 400 == 0) else FEB_MONTH
+        elif month in MONTHS_30:
+            max_days = SHORT_MONTH
+        return 1 <= day <= max_days
+
+    @staticmethod
+    def validate_week(year, week):
+        """Validate week."""
+
+        max_week = datetime.strptime("{}-{}-{}".format(12, 31, year), "%m-%d-%Y").isocalendar()[1]
+        if max_week == 1:
+            max_week = 53
+        return 1 <= week <= max_week
+
+    @staticmethod
+    def validate_month(month):
+        """Validate month."""
+
+        return 1 <= month <= 12
+
+    @staticmethod
+    def validate_year(year):
+        """Validate year."""
+
+        return 1 <= year
+
+    @staticmethod
+    def validate_hour(hour):
+        """Validate hour."""
+
+        return 0 <= hour <= 23
+
+    @staticmethod
+    def validate_minutes(minutes):
+        """Validate minutes."""
+
+        return 0 <= minutes <= 59
+
+    @classmethod
+    def parse_value(cls, itype, value):
+        """Parse the input value."""
+
+        parsed = None
+        if itype == "date":
+            m = RE_DATE.match(value)
+            if m:
+                year = int(m.group('year'), 10)
+                month = int(m.group('month'), 10)
+                day = int(m.group('day'), 10)
+                if cls.validate_year(year) and cls.validate_month(month) and cls.validate_day(year, month, day):
+                    parsed = (year, month, day)
+        elif itype == "month":
+            m = RE_MONTH.match(value)
+            if m:
+                year = int(m.group('year'), 10)
+                month = int(m.group('month'), 10)
+                if cls.validate_year(year) and cls.validate_month(month):
+                    parsed = (year, month)
+        elif itype == "week":
+            m = RE_WEEK.match(value)
+            if m:
+                year = int(m.group('year'), 10)
+                week = int(m.group('week'), 10)
+                if cls.validate_year(year) and cls.validate_week(year, week):
+                    parsed = (year, week)
+        elif itype == "time":
+            m = RE_TIME.match(value)
+            if m:
+                hour = int(m.group('hour'), 10)
+                minutes = int(m.group('minutes'), 10)
+                if cls.validate_hour(hour) and cls.validate_minutes(minutes):
+                    parsed = (hour, minutes)
+        elif itype == "datetime-local":
+            m = RE_DATETIME.match(value)
+            if m:
+                year = int(m.group('year'), 10)
+                month = int(m.group('month'), 10)
+                day = int(m.group('day'), 10)
+                hour = int(m.group('hour'), 10)
+                minutes = int(m.group('minutes'), 10)
+                if (
+                    cls.validate_year(year) and cls.validate_month(month) and cls.validate_day(year, month, day) and
+                    cls.validate_hour(hour) and cls.validate_minutes(minutes)
+                ):
+                    parsed = (year, month, day, hour, minutes)
+        elif itype in ("number", "range"):
+            m = RE_NUM.match(value)
+            if m:
+                parsed = float(m.group('value'))
+        return parsed
+
+
+class _Match(object):
+    """Perform CSS matching."""
+
+    def __init__(self, selectors, scope, namespaces, flags):
+        """Initialize."""
+
+        self.assert_valid_input(scope)
+        self.tag = scope
+        self.cached_meta_lang = []
+        self.cached_default_forms = []
+        self.cached_indeterminate_forms = []
+        self.selectors = selectors
+        self.namespaces = {} if namespaces is None else namespaces
+        self.flags = flags
+        self.iframe_restrict = False
+
+        # Find the root element for the whole tree
+        doc = scope
+        parent = self.get_parent(doc)
+        while parent:
+            doc = parent
+            parent = self.get_parent(doc)
+        root = None
+        if not self.is_doc(doc):
+            root = doc
+        else:
+            for child in self.get_children(doc):
+                root = child
+                break
+
+        self.root = root
+        self.scope = scope if scope is not doc else root
+        self.has_html_namespace = self.has_html_ns(root)
+
+        # A document can be both XML and HTML (XHTML)
+        self.is_xml = self.is_xml_tree(doc)
+        self.is_html = not self.is_xml or self.has_html_namespace
+
+    def supports_namespaces(self):
+        """Check if namespaces are supported in the HTML type."""
+
+        return self.is_xml or self.has_html_namespace
+
+    def get_tag_ns(self, el):
+        """Get tag namespace."""
+
+        if self.supports_namespaces():
+            namespace = ''
+            ns = self.get_uri(el)
+            if ns:
+                namespace = ns
+        else:
+            namespace = NS_XHTML
+        return namespace
+
+    def is_html_tag(self, el):
+        """Check if tag is in HTML namespace."""
+
+        return self.get_tag_ns(el) == NS_XHTML
+
+    def get_tag(self, el):
+        """Get tag."""
+
+        name = self.get_tag_name(el)
+        return util.lower(name) if name is not None and not self.is_xml else name
+
+    def get_prefix(self, el):
+        """Get prefix."""
+
+        prefix = self.get_prefix_name(el)
+        return util.lower(prefix) if prefix is not None and not self.is_xml else prefix
+
+    def find_bidi(self, el):
+        """Get directionality from element text."""
+
+        for node in self.get_children(el, tags=False):
+
+            # Analyze child text nodes
+            if self.is_tag(node):
+
+                # Avoid analyzing certain elements specified in the specification.
+                direction = DIR_MAP.get(util.lower(self.get_attribute_by_name(node, 'dir', '')), None)
+                if (
+                    self.get_tag(node) in ('bdi', 'script', 'style', 'textarea', 'iframe') or
+                    not self.is_html_tag(node) or
+                    direction is not None
+                ):
+                    continue  # pragma: no cover
+
+                # Check directionality of this node's text
+                value = self.find_bidi(node)
+                if value is not None:
+                    return value
+
+                # Direction could not be determined
+                continue  # pragma: no cover
+
+            # Skip `doctype` comments, etc.
+            if self.is_special_string(node):
+                continue
+
+            # Analyze text nodes for directionality.
+            for c in node:
+                bidi = unicodedata.bidirectional(c)
+                if bidi in ('AL', 'R', 'L'):
+                    return ct.SEL_DIR_LTR if bidi == 'L' else ct.SEL_DIR_RTL
+        return None
+
+    def extended_language_filter(self, lang_range, lang_tag):
+        """Filter the language tags."""
+
+        match = True
+        lang_range = RE_WILD_STRIP.sub('-', lang_range).lower()
+        ranges = lang_range.split('-')
+        subtags = lang_tag.lower().split('-')
+        length = len(ranges)
+        rindex = 0
+        sindex = 0
+        r = ranges[rindex]
+        s = subtags[sindex]
+
+        # Primary tag needs to match
+        if r != '*' and r != s:
+            match = False
+
+        rindex += 1
+        sindex += 1
+
+        # Match until we run out of ranges
+        while match and rindex < length:
+            r = ranges[rindex]
+            try:
+                s = subtags[sindex]
+            except IndexError:
+                # Ran out of subtags,
+                # but we still have ranges
+                match = False
+                continue
+
+            # Empty range
+            if not r:
+                match = False
+                continue
+
+            # Matched range
+            elif s == r:
+                rindex += 1
+
+            # Implicit wildcard cannot match
+            # singletons
+            elif len(s) == 1:
+                match = False
+                continue
+
+            # Implicitly matched, so grab next subtag
+            sindex += 1
+
+        return match
+
+    def match_attribute_name(self, el, attr, prefix):
+        """Match attribute name and return value if it exists."""
+
+        value = None
+        if self.supports_namespaces():
+            value = None
+            # If we have not defined namespaces, we can't very well find them, so don't bother trying.
+            if prefix:
+                ns = self.namespaces.get(prefix)
+                if ns is None and prefix != '*':
+                    return None
+            else:
+                ns = None
+
+            for k, v in self.iter_attributes(el):
+
+                # Get attribute parts
+                namespace, name = self.split_namespace(el, k)
+
+                # Can't match a prefix attribute as we haven't specified one to match
+                # Try to match it normally as a whole `p:a` as selector may be trying `p\:a`.
+                if ns is None:
+                    if (self.is_xml and attr == k) or (not self.is_xml and util.lower(attr) == util.lower(k)):
+                        value = v
+                        break
+                    # Coverage is not finding this even though it is executed.
+                    # Adding a print statement before this (and erasing coverage) causes coverage to find the line.
+                    # Ignore the false positive message.
+                    continue  # pragma: no cover
+
+                # We can't match our desired prefix attribute as the attribute doesn't have a prefix
+                if namespace is None or ns != namespace and prefix != '*':
+                    continue
+
+                # The attribute doesn't match.
+                if (util.lower(attr) != util.lower(name)) if not self.is_xml else (attr != name):
+                    continue
+
+                value = v
+                break
+        else:
+            for k, v in self.iter_attributes(el):
+                if util.lower(attr) != util.lower(k):
+                    continue
+                value = v
+                break
+        return value
+
+    def match_namespace(self, el, tag):
+        """Match the namespace of the element."""
+
+        match = True
+        namespace = self.get_tag_ns(el)
+        default_namespace = self.namespaces.get('')
+        tag_ns = '' if tag.prefix is None else self.namespaces.get(tag.prefix, None)
+        # We must match the default namespace if one is not provided
+        if tag.prefix is None and (default_namespace is not None and namespace != default_namespace):
+            match = False
+        # If we specified `|tag`, we must not have a namespace.
+        elif (tag.prefix is not None and tag.prefix == '' and namespace):
+            match = False
+        # Verify prefix matches
+        elif (
+            tag.prefix and
+            tag.prefix != '*' and (tag_ns is None or namespace != tag_ns)
+        ):
+            match = False
+        return match
+
+    def match_attributes(self, el, attributes):
+        """Match attributes."""
+
+        match = True
+        if attributes:
+            for a in attributes:
+                value = self.match_attribute_name(el, a.attribute, a.prefix)
+                pattern = a.xml_type_pattern if self.is_xml and a.xml_type_pattern else a.pattern
+                if isinstance(value, list):
+                    value = ' '.join(value)
+                if value is None:
+                    match = False
+                    break
+                elif pattern is None:
+                    continue
+                elif pattern.match(value) is None:
+                    match = False
+                    break
+        return match
+
+    def match_tagname(self, el, tag):
+        """Match tag name."""
+
+        name = (util.lower(tag.name) if not self.is_xml and tag.name is not None else tag.name)
+        return not (
+            name is not None and
+            name not in (self.get_tag(el), '*')
+        )
+
+    def match_tag(self, el, tag):
+        """Match the tag."""
+
+        match = True
+        if tag is not None:
+            # Verify namespace
+            if not self.match_namespace(el, tag):
+                match = False
+            if not self.match_tagname(el, tag):
+                match = False
+        return match
+
+    def match_past_relations(self, el, relation):
+        """Match past relationship."""
+
+        found = False
+        if relation[0].rel_type == REL_PARENT:
+            parent = self.get_parent(el, no_iframe=self.iframe_restrict)
+            while not found and parent:
+                found = self.match_selectors(parent, relation)
+                parent = self.get_parent(parent, no_iframe=self.iframe_restrict)
+        elif relation[0].rel_type == REL_CLOSE_PARENT:
+            parent = self.get_parent(el, no_iframe=self.iframe_restrict)
+            if parent:
+                found = self.match_selectors(parent, relation)
+        elif relation[0].rel_type == REL_SIBLING:
+            sibling = self.get_previous(el)
+            while not found and sibling:
+                found = self.match_selectors(sibling, relation)
+                sibling = self.get_previous(sibling)
+        elif relation[0].rel_type == REL_CLOSE_SIBLING:
+            sibling = self.get_previous(el)
+            if sibling and self.is_tag(sibling):
+                found = self.match_selectors(sibling, relation)
+        return found
+
+    def match_future_child(self, parent, relation, recursive=False):
+        """Match future child."""
+
+        match = False
+        children = self.get_descendants if recursive else self.get_children
+        for child in children(parent, no_iframe=self.iframe_restrict):
+            match = self.match_selectors(child, relation)
+            if match:
+                break
+        return match
+
+    def match_future_relations(self, el, relation):
+        """Match future relationship."""
+
+        found = False
+        if relation[0].rel_type == REL_HAS_PARENT:
+            found = self.match_future_child(el, relation, True)
+        elif relation[0].rel_type == REL_HAS_CLOSE_PARENT:
+            found = self.match_future_child(el, relation)
+        elif relation[0].rel_type == REL_HAS_SIBLING:
+            sibling = self.get_next(el)
+            while not found and sibling:
+                found = self.match_selectors(sibling, relation)
+                sibling = self.get_next(sibling)
+        elif relation[0].rel_type == REL_HAS_CLOSE_SIBLING:
+            sibling = self.get_next(el)
+            if sibling and self.is_tag(sibling):
+                found = self.match_selectors(sibling, relation)
+        return found
+
+    def match_relations(self, el, relation):
+        """Match relationship to other elements."""
+
+        found = False
+
+        if relation[0].rel_type.startswith(':'):
+            found = self.match_future_relations(el, relation)
+        else:
+            found = self.match_past_relations(el, relation)
+
+        return found
+
+    def match_id(self, el, ids):
+        """Match element's ID."""
+
+        found = True
+        for i in ids:
+            if i != self.get_attribute_by_name(el, 'id', ''):
+                found = False
+                break
+        return found
+
+    def match_classes(self, el, classes):
+        """Match element's classes."""
+
+        current_classes = self.get_classes(el)
+        found = True
+        for c in classes:
+            if c not in current_classes:
+                found = False
+                break
+        return found
+
+    def match_root(self, el):
+        """Match element as root."""
+
+        is_root = self.is_root(el)
+        if is_root:
+            sibling = self.get_previous(el, tags=False)
+            while is_root and sibling is not None:
+                if (
+                    self.is_tag(sibling) or (self.is_content_string(sibling) and sibling.strip()) or
+                    self.is_cdata(sibling)
+                ):
+                    is_root = False
+                else:
+                    sibling = self.get_previous(sibling, tags=False)
+        if is_root:
+            sibling = self.get_next(el, tags=False)
+            while is_root and sibling is not None:
+                if (
+                    self.is_tag(sibling) or (self.is_content_string(sibling) and sibling.strip()) or
+                    self.is_cdata(sibling)
+                ):
+                    is_root = False
+                else:
+                    sibling = self.get_next(sibling, tags=False)
+        return is_root
+
+    def match_scope(self, el):
+        """Match element as scope."""
+
+        return self.scope is el
+
+    def match_nth_tag_type(self, el, child):
+        """Match tag type for `nth` matches."""
+
+        return(
+            (self.get_tag(child) == self.get_tag(el)) and
+            (self.get_tag_ns(child) == self.get_tag_ns(el))
+        )
+
+    def match_nth(self, el, nth):
+        """Match `nth` elements."""
+
+        matched = True
+
+        for n in nth:
+            matched = False
+            if n.selectors and not self.match_selectors(el, n.selectors):
+                break
+            parent = self.get_parent(el)
+            if parent is None:
+                parent = self.create_fake_parent(el)
+            last = n.last
+            last_index = len(parent) - 1
+            index = last_index if last else 0
+            relative_index = 0
+            a = n.a
+            b = n.b
+            var = n.n
+            count = 0
+            count_incr = 1
+            factor = -1 if last else 1
+            idx = last_idx = a * count + b if var else a
+
+            # We can only adjust bounds within a variable index
+            if var:
+                # Abort if our nth index is out of bounds and only getting further out of bounds as we increment.
+                # Otherwise, increment to try to get in bounds.
+                adjust = None
+                while idx < 1 or idx > last_index:
+                    if idx < 0:
+                        diff_low = 0 - idx
+                        if adjust is not None and adjust == 1:
+                            break
+                        adjust = -1
+                        count += count_incr
+                        idx = last_idx = a * count + b if var else a
+                        diff = 0 - idx
+                        if diff >= diff_low:
+                            break
+                    else:
+                        diff_high = idx - last_index
+                        if adjust is not None and adjust == -1:
+                            break
+                        adjust = 1
+                        count += count_incr
+                        idx = last_idx = a * count + b if var else a
+                        diff = idx - last_index
+                        if diff >= diff_high:
+                            break
+                        diff_high = diff
+
+                # If a < 0, our count is working backwards, so floor the index by increasing the count.
+                # Find the count that yields the lowest, in bound value and use that.
+                # Lastly reverse count increment so that we'll increase our index.
+                lowest = count
+                if a < 0:
+                    while idx >= 1:
+                        lowest = count
+                        count += count_incr
+                        idx = last_idx = a * count + b if var else a
+                    count_incr = -1
+                count = lowest
+                idx = last_idx = a * count + b if var else a
+
+            # Evaluate elements while our calculated nth index is still in range
+            while 1 <= idx <= last_index + 1:
+                child = None
+                # Evaluate while our child index is still in range.
+                for child in self.get_children(parent, start=index, reverse=factor < 0, tags=False):
+                    index += factor
+                    if not self.is_tag(child):
+                        continue
+                    # Handle `of S` in `nth-child`
+                    if n.selectors and not self.match_selectors(child, n.selectors):
+                        continue
+                    # Handle `of-type`
+                    if n.of_type and not self.match_nth_tag_type(el, child):
+                        continue
+                    relative_index += 1
+                    if relative_index == idx:
+                        if child is el:
+                            matched = True
+                        else:
+                            break
+                    if child is el:
+                        break
+                if child is el:
+                    break
+                last_idx = idx
+                count += count_incr
+                if count < 0:
+                    # Count is counting down and has now ventured into invalid territory.
+                    break
+                idx = a * count + b if var else a
+                if last_idx == idx:
+                    break
+            if not matched:
+                break
+        return matched
+
+    def match_empty(self, el):
+        """Check if element is empty (if requested)."""
+
+        is_empty = True
+        for child in self.get_children(el, tags=False):
+            if self.is_tag(child):
+                is_empty = False
+                break
+            elif self.is_content_string(child) and RE_NOT_EMPTY.search(child):
+                is_empty = False
+                break
+        return is_empty
+
+    def match_subselectors(self, el, selectors):
+        """Match selectors."""
+
+        match = True
+        for sel in selectors:
+            if not self.match_selectors(el, sel):
+                match = False
+        return match
+
+    def match_contains(self, el, contains):
+        """Match element if it contains text."""
+
+        match = True
+        content = None
+        for contain_list in contains:
+            if content is None:
+                if contain_list.own:
+                    content = self.get_own_text(el, no_iframe=self.is_html)
+                else:
+                    content = self.get_text(el, no_iframe=self.is_html)
+            found = False
+            for text in contain_list.text:
+                if contain_list.own:
+                    for c in content:
+                        if text in c:
+                            found = True
+                            break
+                    if found:
+                        break
+                else:
+                    if text in content:
+                        found = True
+                        break
+            if not found:
+                match = False
+        return match
+
+    def match_default(self, el):
+        """Match default."""
+
+        match = False
+
+        # Find this input's form
+        form = None
+        parent = self.get_parent(el, no_iframe=True)
+        while parent and form is None:
+            if self.get_tag(parent) == 'form' and self.is_html_tag(parent):
+                form = parent
+            else:
+                parent = self.get_parent(parent, no_iframe=True)
+
+        # Look in form cache to see if we've already located its default button
+        found_form = False
+        for f, t in self.cached_default_forms:
+            if f is form:
+                found_form = True
+                if t is el:
+                    match = True
+                break
+
+        # We didn't have the form cached, so look for its default button
+        if not found_form:
+            for child in self.get_descendants(form, no_iframe=True):
+                name = self.get_tag(child)
+                # Can't do nested forms (haven't figured out why we never hit this)
+                if name == 'form':  # pragma: no cover
+                    break
+                if name in ('input', 'button'):
+                    v = self.get_attribute_by_name(child, 'type', '')
+                    if v and util.lower(v) == 'submit':
+                        self.cached_default_forms.append([form, child])
+                        if el is child:
+                            match = True
+                        break
+        return match
+
+    def match_indeterminate(self, el):
+        """Match default."""
+
+        match = False
+        name = self.get_attribute_by_name(el, 'name')
+
+        def get_parent_form(el):
+            """Find this input's form."""
+            form = None
+            parent = self.get_parent(el, no_iframe=True)
+            while form is None:
+                if self.get_tag(parent) == 'form' and self.is_html_tag(parent):
+                    form = parent
+                    break
+                last_parent = parent
+                parent = self.get_parent(parent, no_iframe=True)
+                if parent is None:
+                    form = last_parent
+                    break
+            return form
+
+        form = get_parent_form(el)
+
+        # Look in form cache to see if we've already evaluated that its fellow radio buttons are indeterminate
+        found_form = False
+        for f, n, i in self.cached_indeterminate_forms:
+            if f is form and n == name:
+                found_form = True
+                if i is True:
+                    match = True
+                break
+
+        # We didn't have the form cached, so validate that the radio button is indeterminate
+        if not found_form:
+            checked = False
+            for child in self.get_descendants(form, no_iframe=True):
+                if child is el:
+                    continue
+                tag_name = self.get_tag(child)
+                if tag_name == 'input':
+                    is_radio = False
+                    check = False
+                    has_name = False
+                    for k, v in self.iter_attributes(child):
+                        if util.lower(k) == 'type' and util.lower(v) == 'radio':
+                            is_radio = True
+                        elif util.lower(k) == 'name' and v == name:
+                            has_name = True
+                        elif util.lower(k) == 'checked':
+                            check = True
+                        if is_radio and check and has_name and get_parent_form(child) is form:
+                            checked = True
+                            break
+                if checked:
+                    break
+            if not checked:
+                match = True
+            self.cached_indeterminate_forms.append([form, name, match])
+
+        return match
+
+    def match_lang(self, el, langs):
+        """Match languages."""
+
+        match = False
+        has_ns = self.supports_namespaces()
+        root = self.root
+        has_html_namespace = self.has_html_namespace
+
+        # Walk parents looking for `lang` (HTML) or `xml:lang` XML property.
+        parent = el
+        found_lang = None
+        last = None
+        while not found_lang:
+            has_html_ns = self.has_html_ns(parent)
+            for k, v in self.iter_attributes(parent):
+                attr_ns, attr = self.split_namespace(parent, k)
+                if (
+                    ((not has_ns or has_html_ns) and (util.lower(k) if not self.is_xml else k) == 'lang') or
+                    (
+                        has_ns and not has_html_ns and attr_ns == NS_XML and
+                        (util.lower(attr) if not self.is_xml and attr is not None else attr) == 'lang'
+                    )
+                ):
+                    found_lang = v
+                    break
+            last = parent
+            parent = self.get_parent(parent, no_iframe=self.is_html)
+
+            if parent is None:
+                root = last
+                has_html_namespace = self.has_html_ns(root)
+                parent = last
+                break
+
+        # Use cached meta language.
+        if not found_lang and self.cached_meta_lang:
+            for cache in self.cached_meta_lang:
+                if root is cache[0]:
+                    found_lang = cache[1]
+
+        # If we couldn't find a language, and the document is HTML, look to meta to determine language.
+        if found_lang is None and (not self.is_xml or (has_html_namespace and root.name == 'html')):
+            # Find head
+            found = False
+            for tag in ('html', 'head'):
+                found = False
+                for child in self.get_children(parent, no_iframe=self.is_html):
+                    if self.get_tag(child) == tag and self.is_html_tag(child):
+                        found = True
+                        parent = child
+                        break
+                if not found:  # pragma: no cover
+                    break
+
+            # Search meta tags
+            if found:
+                for child in parent:
+                    if self.is_tag(child) and self.get_tag(child) == 'meta' and self.is_html_tag(parent):
+                        c_lang = False
+                        content = None
+                        for k, v in self.iter_attributes(child):
+                            if util.lower(k) == 'http-equiv' and util.lower(v) == 'content-language':
+                                c_lang = True
+                            if util.lower(k) == 'content':
+                                content = v
+                            if c_lang and content:
+                                found_lang = content
+                                self.cached_meta_lang.append((root, found_lang))
+                                break
+                    if found_lang:
+                        break
+                if not found_lang:
+                    self.cached_meta_lang.append((root, False))
+
+        # If we determined a language, compare.
+        if found_lang:
+            for patterns in langs:
+                match = False
+                for pattern in patterns:
+                    if self.extended_language_filter(pattern, found_lang):
+                        match = True
+                if not match:
+                    break
+
+        return match
+
+    def match_dir(self, el, directionality):
+        """Check directionality."""
+
+        # If we have to match both left and right, we can't match either.
+        if directionality & ct.SEL_DIR_LTR and directionality & ct.SEL_DIR_RTL:
+            return False
+
+        if el is None or not self.is_html_tag(el):
+            return False
+
+        # Element has defined direction of left to right or right to left
+        direction = DIR_MAP.get(util.lower(self.get_attribute_by_name(el, 'dir', '')), None)
+        if direction not in (None, 0):
+            return direction == directionality
+
+        # Element is the document element (the root) and no direction assigned, assume left to right.
+        is_root = self.is_root(el)
+        if is_root and direction is None:
+            return ct.SEL_DIR_LTR == directionality
+
+        # If `input[type=telephone]` and no direction is assigned, assume left to right.
+        name = self.get_tag(el)
+        is_input = name == 'input'
+        is_textarea = name == 'textarea'
+        is_bdi = name == 'bdi'
+        itype = util.lower(self.get_attribute_by_name(el, 'type', '')) if is_input else ''
+        if is_input and itype == 'tel' and direction is None:
+            return ct.SEL_DIR_LTR == directionality
+
+        # Auto handling for text inputs
+        if ((is_input and itype in ('text', 'search', 'tel', 'url', 'email')) or is_textarea) and direction == 0:
+            if is_textarea:
+                value = []
+                for node in self.get_contents(el, no_iframe=True):
+                    if self.is_content_string(node):
+                        value.append(node)
+                value = ''.join(value)
+            else:
+                value = self.get_attribute_by_name(el, 'value', '')
+            if value:
+                for c in value:
+                    bidi = unicodedata.bidirectional(c)
+                    if bidi in ('AL', 'R', 'L'):
+                        direction = ct.SEL_DIR_LTR if bidi == 'L' else ct.SEL_DIR_RTL
+                        return direction == directionality
+                # Assume left to right
+                return ct.SEL_DIR_LTR == directionality
+            elif is_root:
+                return ct.SEL_DIR_LTR == directionality
+            return self.match_dir(self.get_parent(el, no_iframe=True), directionality)
+
+        # Auto handling for `bdi` and other non text inputs.
+        if (is_bdi and direction is None) or direction == 0:
+            direction = self.find_bidi(el)
+            if direction is not None:
+                return direction == directionality
+            elif is_root:
+                return ct.SEL_DIR_LTR == directionality
+            return self.match_dir(self.get_parent(el, no_iframe=True), directionality)
+
+        # Match parents direction
+        return self.match_dir(self.get_parent(el, no_iframe=True), directionality)
+
+    def match_range(self, el, condition):
+        """
+        Match range.
+
+        Behavior is modeled after what we see in browsers. Browsers seem to evaluate
+        if the value is out of range, and if not, it is in range. So a missing value
+        will not evaluate out of range; therefore, value is in range. Personally, I
+        feel like this should evaluate as neither in or out of range.
+        """
+
+        out_of_range = False
+
+        itype = util.lower(self.get_attribute_by_name(el, 'type'))
+        mn = self.get_attribute_by_name(el, 'min', None)
+        if mn is not None:
+            mn = Inputs.parse_value(itype, mn)
+        mx = self.get_attribute_by_name(el, 'max', None)
+        if mx is not None:
+            mx = Inputs.parse_value(itype, mx)
+
+        # There is no valid min or max, so we cannot evaluate a range
+        if mn is None and mx is None:
+            return False
+
+        value = self.get_attribute_by_name(el, 'value', None)
+        if value is not None:
+            value = Inputs.parse_value(itype, value)
+        if value is not None:
+            if itype in ("date", "datetime-local", "month", "week", "number", "range"):
+                if mn is not None and value < mn:
+                    out_of_range = True
+                if not out_of_range and mx is not None and value > mx:
+                    out_of_range = True
+            elif itype == "time":
+                if mn is not None and mx is not None and mn > mx:
+                    # Time is periodic, so this is a reversed/discontinuous range
+                    if value < mn and value > mx:
+                        out_of_range = True
+                else:
+                    if mn is not None and value < mn:
+                        out_of_range = True
+                    if not out_of_range and mx is not None and value > mx:
+                        out_of_range = True
+
+        return not out_of_range if condition & ct.SEL_IN_RANGE else out_of_range
+
+    def match_defined(self, el):
+        """
+        Match defined.
+
+        `:defined` is related to custom elements in a browser.
+
+        - If the document is XML (not XHTML), all tags will match.
+        - Tags that are not custom (don't have a hyphen) are marked defined.
+        - If the tag has a prefix (without or without a namespace), it will not match.
+
+        This is of course requires the parser to provide us with the proper prefix and namespace info,
+        if it doesn't, there is nothing we can do.
+        """
+
+        name = self.get_tag(el)
+        return (
+            name.find('-') == -1 or
+            name.find(':') != -1 or
+            self.get_prefix(el) is not None
+        )
+
+    def match_placeholder_shown(self, el):
+        """
+        Match placeholder shown according to HTML spec.
+
+        - text area should be checked if they have content. A single newline does not count as content.
+
+        """
+
+        match = False
+        content = self.get_text(el)
+        if content in ('', '\n'):
+            match = True
+
+        return match
+
+    def match_selectors(self, el, selectors):
+        """Check if element matches one of the selectors."""
+
+        match = False
+        is_not = selectors.is_not
+        is_html = selectors.is_html
+
+        # Internal selector lists that use the HTML flag, will automatically get the `html` namespace.
+        if is_html:
+            namespaces = self.namespaces
+            iframe_restrict = self.iframe_restrict
+            self.namespaces = {'html': NS_XHTML}
+            self.iframe_restrict = True
+
+        if not is_html or self.is_html:
+            for selector in selectors:
+                match = is_not
+                # We have a un-matchable situation (like `:focus` as you can focus an element in this environment)
+                if isinstance(selector, ct.SelectorNull):
+                    continue
+                # Verify tag matches
+                if not self.match_tag(el, selector.tag):
+                    continue
+                # Verify tag is defined
+                if selector.flags & ct.SEL_DEFINED and not self.match_defined(el):
+                    continue
+                # Verify element is root
+                if selector.flags & ct.SEL_ROOT and not self.match_root(el):
+                    continue
+                # Verify element is scope
+                if selector.flags & ct.SEL_SCOPE and not self.match_scope(el):
+                    continue
+                # Verify element has placeholder shown
+                if selector.flags & ct.SEL_PLACEHOLDER_SHOWN and not self.match_placeholder_shown(el):
+                    continue
+                # Verify `nth` matches
+                if not self.match_nth(el, selector.nth):
+                    continue
+                if selector.flags & ct.SEL_EMPTY and not self.match_empty(el):
+                    continue
+                # Verify id matches
+                if selector.ids and not self.match_id(el, selector.ids):
+                    continue
+                # Verify classes match
+                if selector.classes and not self.match_classes(el, selector.classes):
+                    continue
+                # Verify attribute(s) match
+                if not self.match_attributes(el, selector.attributes):
+                    continue
+                # Verify ranges
+                if selector.flags & RANGES and not self.match_range(el, selector.flags & RANGES):
+                    continue
+                # Verify language patterns
+                if selector.lang and not self.match_lang(el, selector.lang):
+                    continue
+                # Verify pseudo selector patterns
+                if selector.selectors and not self.match_subselectors(el, selector.selectors):
+                    continue
+                # Verify relationship selectors
+                if selector.relation and not self.match_relations(el, selector.relation):
+                    continue
+                # Validate that the current default selector match corresponds to the first submit button in the form
+                if selector.flags & ct.SEL_DEFAULT and not self.match_default(el):
+                    continue
+                # Validate that the unset radio button is among radio buttons with the same name in a form that are
+                # also not set.
+                if selector.flags & ct.SEL_INDETERMINATE and not self.match_indeterminate(el):
+                    continue
+                # Validate element directionality
+                if selector.flags & DIR_FLAGS and not self.match_dir(el, selector.flags & DIR_FLAGS):
+                    continue
+                # Validate that the tag contains the specified text.
+                if not self.match_contains(el, selector.contains):
+                    continue
+                match = not is_not
+                break
+
+        # Restore actual namespaces being used for external selector lists
+        if is_html:
+            self.namespaces = namespaces
+            self.iframe_restrict = iframe_restrict
+
+        return match
+
+    def select(self, limit=0):
+        """Match all tags under the targeted tag."""
+
+        if limit < 1:
+            limit = None
+
+        for child in self.get_descendants(self.tag):
+            if self.match(child):
+                yield child
+                if limit is not None:
+                    limit -= 1
+                    if limit < 1:
+                        break
+
+    def closest(self):
+        """Match closest ancestor."""
+
+        current = self.tag
+        closest = None
+        while closest is None and current is not None:
+            if self.match(current):
+                closest = current
+            else:
+                current = self.get_parent(current)
+        return closest
+
+    def filter(self):  # noqa A001
+        """Filter tag's children."""
+
+        return [tag for tag in self.get_contents(self.tag) if not self.is_navigable_string(tag) and self.match(tag)]
+
+    def match(self, el):
+        """Match."""
+
+        return not self.is_doc(el) and self.is_tag(el) and self.match_selectors(el, self.selectors)
+
+
+class CSSMatch(_DocumentNav, _Match):
+    """The Beautiful Soup CSS match class."""
+
+
+class SoupSieve(ct.Immutable):
+    """Compiled Soup Sieve selector matching object."""
+
+    __slots__ = ("pattern", "selectors", "namespaces", "custom", "flags", "_hash")
+
+    def __init__(self, pattern, selectors, namespaces, custom, flags):
+        """Initialize."""
+
+        super(SoupSieve, self).__init__(
+            pattern=pattern,
+            selectors=selectors,
+            namespaces=namespaces,
+            custom=custom,
+            flags=flags
+        )
+
+    def match(self, tag):
+        """Match."""
+
+        return CSSMatch(self.selectors, tag, self.namespaces, self.flags).match(tag)
+
+    def closest(self, tag):
+        """Match closest ancestor."""
+
+        return CSSMatch(self.selectors, tag, self.namespaces, self.flags).closest()
+
+    def filter(self, iterable):  # noqa A001
+        """
+        Filter.
+
+        `CSSMatch` can cache certain searches for tags of the same document,
+        so if we are given a tag, all tags are from the same document,
+        and we can take advantage of the optimization.
+
+        Any other kind of iterable could have tags from different documents or detached tags,
+        so for those, we use a new `CSSMatch` for each item in the iterable.
+        """
+
+        if CSSMatch.is_tag(iterable):
+            return CSSMatch(self.selectors, iterable, self.namespaces, self.flags).filter()
+        else:
+            return [node for node in iterable if not CSSMatch.is_navigable_string(node) and self.match(node)]
+
+    def select_one(self, tag):
+        """Select a single tag."""
+
+        tags = self.select(tag, limit=1)
+        return tags[0] if tags else None
+
+    def select(self, tag, limit=0):
+        """Select the specified tags."""
+
+        return list(self.iselect(tag, limit))
+
+    def iselect(self, tag, limit=0):
+        """Iterate the specified tags."""
+
+        for el in CSSMatch(self.selectors, tag, self.namespaces, self.flags).select(limit):
+            yield el
+
+    def __repr__(self):  # pragma: no cover
+        """Representation."""
+
+        return "SoupSieve(pattern={!r}, namespaces={!r}, custom={!r}, flags={!r})".format(
+            self.pattern,
+            self.namespaces,
+            self.custom,
+            self.flags
+        )
+
+    __str__ = __repr__
+
+
+ct.pickle_register(SoupSieve)
Index: latest/Lib/site-packages/soupsieve/css_parser.py
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/latest/Lib/site-packages/soupsieve/css_parser.py b/latest/Lib/site-packages/soupsieve/css_parser.py
new file mode 100644
--- /dev/null	(date 1616411341744)
+++ b/latest/Lib/site-packages/soupsieve/css_parser.py	(date 1616411341744)
@@ -0,0 +1,1209 @@
+"""CSS selector parser."""
+import re
+from functools import lru_cache
+from . import util
+from . import css_match as cm
+from . import css_types as ct
+from .util import SelectorSyntaxError
+import warnings
+
+UNICODE_REPLACEMENT_CHAR = 0xFFFD
+
+# Simple pseudo classes that take no parameters
+PSEUDO_SIMPLE = {
+    ":any-link",
+    ":empty",
+    ":first-child",
+    ":first-of-type",
+    ":in-range",
+    ":out-of-range",
+    ":last-child",
+    ":last-of-type",
+    ":link",
+    ":only-child",
+    ":only-of-type",
+    ":root",
+    ':checked',
+    ':default',
+    ':disabled',
+    ':enabled',
+    ':indeterminate',
+    ':optional',
+    ':placeholder-shown',
+    ':read-only',
+    ':read-write',
+    ':required',
+    ':scope',
+    ':defined'
+}
+
+# Supported, simple pseudo classes that match nothing in the Soup Sieve environment
+PSEUDO_SIMPLE_NO_MATCH = {
+    ':active',
+    ':current',
+    ':focus',
+    ':focus-visible',
+    ':focus-within',
+    ':future',
+    ':host',
+    ':hover',
+    ':local-link',
+    ':past',
+    ':paused',
+    ':playing',
+    ':target',
+    ':target-within',
+    ':user-invalid',
+    ':visited'
+}
+
+# Complex pseudo classes that take selector lists
+PSEUDO_COMPLEX = {
+    ':contains',
+    ':-soup-contains',
+    ':-soup-contains-own',
+    ':has',
+    ':is',
+    ':matches',
+    ':not',
+    ':where'
+}
+
+PSEUDO_COMPLEX_NO_MATCH = {
+    ':current',
+    ':host',
+    ':host-context'
+}
+
+# Complex pseudo classes that take very specific parameters and are handled special
+PSEUDO_SPECIAL = {
+    ':dir',
+    ':lang',
+    ':nth-child',
+    ':nth-last-child',
+    ':nth-last-of-type',
+    ':nth-of-type'
+}
+
+PSEUDO_SUPPORTED = PSEUDO_SIMPLE | PSEUDO_SIMPLE_NO_MATCH | PSEUDO_COMPLEX | PSEUDO_COMPLEX_NO_MATCH | PSEUDO_SPECIAL
+
+# Sub-patterns parts
+# Whitespace
+NEWLINE = r'(?:\r\n|(?!\r\n)[\n\f\r])'
+WS = r'(?:[ \t]|{})'.format(NEWLINE)
+# Comments
+COMMENTS = r'(?:/\*[^*]*\*+(?:[^/*][^*]*\*+)*/)'
+# Whitespace with comments included
+WSC = r'(?:{ws}|{comments})'.format(ws=WS, comments=COMMENTS)
+# CSS escapes
+CSS_ESCAPES = r'(?:\\(?:[a-f0-9]{{1,6}}{ws}?|[^\r\n\f]|$))'.format(ws=WS)
+CSS_STRING_ESCAPES = r'(?:\\(?:[a-f0-9]{{1,6}}{ws}?|[^\r\n\f]|$|{nl}))'.format(ws=WS, nl=NEWLINE)
+# CSS Identifier
+IDENTIFIER = r'''
+(?:(?:-?(?:[^\x00-\x2f\x30-\x40\x5B-\x5E\x60\x7B-\x9f]|{esc})+|--)
+(?:[^\x00-\x2c\x2e\x2f\x3A-\x40\x5B-\x5E\x60\x7B-\x9f]|{esc})*)
+'''.format(esc=CSS_ESCAPES)
+# `nth` content
+NTH = r'(?:[-+])?(?:[0-9]+n?|n)(?:(?<=n){ws}*(?:[-+]){ws}*(?:[0-9]+))?'.format(ws=WSC)
+# Value: quoted string or identifier
+VALUE = r'''
+(?:"(?:\\(?:.|{nl})|[^\\"\r\n\f]+)*?"|'(?:\\(?:.|{nl})|[^\\'\r\n\f]+)*?'|{ident}+)
+'''.format(nl=NEWLINE, ident=IDENTIFIER)
+# Attribute value comparison. `!=` is handled special as it is non-standard.
+ATTR = r'''
+(?:{ws}*(?P<cmp>[!~^|*$]?=){ws}*(?P<value>{value})(?:{ws}+(?P<case>[is]))?)?{ws}*\]
+'''.format(ws=WSC, value=VALUE)
+
+# Selector patterns
+# IDs (`#id`)
+PAT_ID = r'\#{ident}'.format(ident=IDENTIFIER)
+# Classes (`.class`)
+PAT_CLASS = r'\.{ident}'.format(ident=IDENTIFIER)
+# Prefix:Tag (`prefix|tag`)
+PAT_TAG = r'(?P<tag_ns>(?:{ident}|\*)?\|)?(?P<tag_name>{ident}|\*)'.format(ident=IDENTIFIER)
+# Attributes (`[attr]`, `[attr=value]`, etc.)
+PAT_ATTR = r'''
+\[{ws}*(?P<attr_ns>(?:{ident}|\*)?\|)?(?P<attr_name>{ident}){attr}
+'''.format(ws=WSC, ident=IDENTIFIER, attr=ATTR)
+# Pseudo class (`:pseudo-class`, `:pseudo-class(`)
+PAT_PSEUDO_CLASS = r'(?P<name>:{ident})(?P<open>\({ws}*)?'.format(ws=WSC, ident=IDENTIFIER)
+# Pseudo class special patterns. Matches `:pseudo-class(` for special case pseudo classes.
+PAT_PSEUDO_CLASS_SPECIAL = r'(?P<name>:{ident})(?P<open>\({ws}*)'.format(ws=WSC, ident=IDENTIFIER)
+# Custom pseudo class (`:--custom-pseudo`)
+PAT_PSEUDO_CLASS_CUSTOM = r'(?P<name>:(?=--){ident})'.format(ident=IDENTIFIER)
+# Closing pseudo group (`)`)
+PAT_PSEUDO_CLOSE = r'{ws}*\)'.format(ws=WSC)
+# Pseudo element (`::pseudo-element`)
+PAT_PSEUDO_ELEMENT = r':{}'.format(PAT_PSEUDO_CLASS)
+# At rule (`@page`, etc.) (not supported)
+PAT_AT_RULE = r'@P{ident}'.format(ident=IDENTIFIER)
+# Pseudo class `nth-child` (`:nth-child(an+b [of S]?)`, `:first-child`, etc.)
+PAT_PSEUDO_NTH_CHILD = r'''
+(?P<pseudo_nth_child>{name}
+(?P<nth_child>{nth}|even|odd))(?:{wsc}*\)|(?P<of>{comments}*{ws}{wsc}*of{comments}*{ws}{wsc}*))
+'''.format(name=PAT_PSEUDO_CLASS_SPECIAL, wsc=WSC, comments=COMMENTS, ws=WS, nth=NTH)
+# Pseudo class `nth-of-type` (`:nth-of-type(an+b)`, `:first-of-type`, etc.)
+PAT_PSEUDO_NTH_TYPE = r'''
+(?P<pseudo_nth_type>{name}
+(?P<nth_type>{nth}|even|odd)){ws}*\)
+'''.format(name=PAT_PSEUDO_CLASS_SPECIAL, ws=WSC, nth=NTH)
+# Pseudo class language (`:lang("*-de", en)`)
+PAT_PSEUDO_LANG = r'{name}(?P<values>{value}(?:{ws}*,{ws}*{value})*){ws}*\)'.format(
+    name=PAT_PSEUDO_CLASS_SPECIAL, ws=WSC, value=VALUE
+)
+# Pseudo class direction (`:dir(ltr)`)
+PAT_PSEUDO_DIR = r'{name}(?P<dir>ltr|rtl){ws}*\)'.format(name=PAT_PSEUDO_CLASS_SPECIAL, ws=WSC)
+# Combining characters (`>`, `~`, ` `, `+`, `,`)
+PAT_COMBINE = r'{wsc}*?(?P<relation>[,+>~]|{ws}(?![,+>~])){wsc}*'.format(ws=WS, wsc=WSC)
+# Extra: Contains (`:contains(text)`)
+PAT_PSEUDO_CONTAINS = r'{name}(?P<values>{value}(?:{ws}*,{ws}*{value})*){ws}*\)'.format(
+    name=PAT_PSEUDO_CLASS_SPECIAL, ws=WSC, value=VALUE
+)
+
+# Regular expressions
+# CSS escape pattern
+RE_CSS_ESC = re.compile(r'(?:(\\[a-f0-9]{{1,6}}{ws}?)|(\\[^\r\n\f])|(\\$))'.format(ws=WSC), re.I)
+RE_CSS_STR_ESC = re.compile(
+    r'(?:(\\[a-f0-9]{{1,6}}{ws}?)|(\\[^\r\n\f])|(\\$)|(\\{nl}))'.format(ws=WS, nl=NEWLINE), re.I
+)
+# Pattern to break up `nth` specifiers
+RE_NTH = re.compile(
+    r'(?P<s1>[-+])?(?P<a>[0-9]+n?|n)(?:(?<=n){ws}*(?P<s2>[-+]){ws}*(?P<b>[0-9]+))?'.format(ws=WSC),
+    re.I
+)
+# Pattern to iterate multiple values.
+RE_VALUES = re.compile(r'(?:(?P<value>{value})|(?P<split>{ws}*,{ws}*))'.format(ws=WSC, value=VALUE), re.X)
+# Whitespace checks
+RE_WS = re.compile(WS)
+RE_WS_BEGIN = re.compile('^{}*'.format(WSC))
+RE_WS_END = re.compile('{}*$'.format(WSC))
+RE_CUSTOM = re.compile(r'^{}$'.format(PAT_PSEUDO_CLASS_CUSTOM), re.X)
+
+# Constants
+# List split token
+COMMA_COMBINATOR = ','
+# Relation token for descendant
+WS_COMBINATOR = " "
+
+# Parse flags
+FLG_PSEUDO = 0x01
+FLG_NOT = 0x02
+FLG_RELATIVE = 0x04
+FLG_DEFAULT = 0x08
+FLG_HTML = 0x10
+FLG_INDETERMINATE = 0x20
+FLG_OPEN = 0x40
+FLG_IN_RANGE = 0x80
+FLG_OUT_OF_RANGE = 0x100
+FLG_PLACEHOLDER_SHOWN = 0x200
+
+# Maximum cached patterns to store
+_MAXCACHE = 500
+
+
+@lru_cache(maxsize=_MAXCACHE)
+def _cached_css_compile(pattern, namespaces, custom, flags):
+    """Cached CSS compile."""
+
+    custom_selectors = process_custom(custom)
+    return cm.SoupSieve(
+        pattern,
+        CSSParser(pattern, custom=custom_selectors, flags=flags).process_selectors(),
+        namespaces,
+        custom,
+        flags
+    )
+
+
+def _purge_cache():
+    """Purge the cache."""
+
+    _cached_css_compile.cache_clear()
+
+
+def process_custom(custom):
+    """Process custom."""
+
+    custom_selectors = {}
+    if custom is not None:
+        for key, value in custom.items():
+            name = util.lower(key)
+            if RE_CUSTOM.match(name) is None:
+                raise SelectorSyntaxError("The name '{}' is not a valid custom pseudo-class name".format(name))
+            if name in custom_selectors:
+                raise KeyError("The custom selector '{}' has already been registered".format(name))
+            custom_selectors[css_unescape(name)] = value
+    return custom_selectors
+
+
+def css_unescape(content, string=False):
+    """
+    Unescape CSS value.
+
+    Strings allow for spanning the value on multiple strings by escaping a new line.
+    """
+
+    def replace(m):
+        """Replace with the appropriate substitute."""
+
+        if m.group(1):
+            codepoint = int(m.group(1)[1:], 16)
+            if codepoint == 0:
+                codepoint = UNICODE_REPLACEMENT_CHAR
+            value = chr(codepoint)
+        elif m.group(2):
+            value = m.group(2)[1:]
+        elif m.group(3):
+            value = '\ufffd'
+        else:
+            value = ''
+
+        return value
+
+    return (RE_CSS_ESC if not string else RE_CSS_STR_ESC).sub(replace, content)
+
+
+def escape(ident):
+    """Escape identifier."""
+
+    string = []
+    length = len(ident)
+    start_dash = length > 0 and ident[0] == '-'
+    if length == 1 and start_dash:
+        # Need to escape identifier that is a single `-` with no other characters
+        string.append('\\{}'.format(ident))
+    else:
+        for index, c in enumerate(ident):
+            codepoint = ord(c)
+            if codepoint == 0x00:
+                string.append('\ufffd')
+            elif (0x01 <= codepoint <= 0x1F) or codepoint == 0x7F:
+                string.append('\\{:x} '.format(codepoint))
+            elif (index == 0 or (start_dash and index == 1)) and (0x30 <= codepoint <= 0x39):
+                string.append('\\{:x} '.format(codepoint))
+            elif (
+                codepoint in (0x2D, 0x5F) or codepoint >= 0x80 or (0x30 <= codepoint <= 0x39) or
+                (0x30 <= codepoint <= 0x39) or (0x41 <= codepoint <= 0x5A) or (0x61 <= codepoint <= 0x7A)
+            ):
+                string.append(c)
+            else:
+                string.append('\\{}'.format(c))
+    return ''.join(string)
+
+
+class SelectorPattern(object):
+    """Selector pattern."""
+
+    def __init__(self, name, pattern):
+        """Initialize."""
+
+        self.name = name
+        self.re_pattern = re.compile(pattern, re.I | re.X | re.U)
+
+    def get_name(self):
+        """Get name."""
+
+        return self.name
+
+    def match(self, selector, index, flags):
+        """Match the selector."""
+
+        return self.re_pattern.match(selector, index)
+
+
+class SpecialPseudoPattern(SelectorPattern):
+    """Selector pattern."""
+
+    def __init__(self, patterns):
+        """Initialize."""
+
+        self.patterns = {}
+        for p in patterns:
+            name = p[0]
+            pattern = p[3](name, p[2])
+            for pseudo in p[1]:
+                self.patterns[pseudo] = pattern
+
+        self.matched_name = None
+        self.re_pseudo_name = re.compile(PAT_PSEUDO_CLASS_SPECIAL, re.I | re.X | re.U)
+
+    def get_name(self):
+        """Get name."""
+
+        return self.matched_name.get_name()
+
+    def match(self, selector, index, flags):
+        """Match the selector."""
+
+        pseudo = None
+        m = self.re_pseudo_name.match(selector, index)
+        if m:
+            name = util.lower(css_unescape(m.group('name')))
+            pattern = self.patterns.get(name)
+            if pattern:
+                pseudo = pattern.match(selector, index, flags)
+                if pseudo:
+                    self.matched_name = pattern
+
+        return pseudo
+
+
+class _Selector(object):
+    """
+    Intermediate selector class.
+
+    This stores selector data for a compound selector as we are acquiring them.
+    Once we are done collecting the data for a compound selector, we freeze
+    the data in an object that can be pickled and hashed.
+    """
+
+    def __init__(self, **kwargs):
+        """Initialize."""
+
+        self.tag = kwargs.get('tag', None)
+        self.ids = kwargs.get('ids', [])
+        self.classes = kwargs.get('classes', [])
+        self.attributes = kwargs.get('attributes', [])
+        self.nth = kwargs.get('nth', [])
+        self.selectors = kwargs.get('selectors', [])
+        self.relations = kwargs.get('relations', [])
+        self.rel_type = kwargs.get('rel_type', None)
+        self.contains = kwargs.get('contains', [])
+        self.lang = kwargs.get('lang', [])
+        self.flags = kwargs.get('flags', 0)
+        self.no_match = kwargs.get('no_match', False)
+
+    def _freeze_relations(self, relations):
+        """Freeze relation."""
+
+        if relations:
+            sel = relations[0]
+            sel.relations.extend(relations[1:])
+            return ct.SelectorList([sel.freeze()])
+        else:
+            return ct.SelectorList()
+
+    def freeze(self):
+        """Freeze self."""
+
+        if self.no_match:
+            return ct.SelectorNull()
+        else:
+            return ct.Selector(
+                self.tag,
+                tuple(self.ids),
+                tuple(self.classes),
+                tuple(self.attributes),
+                tuple(self.nth),
+                tuple(self.selectors),
+                self._freeze_relations(self.relations),
+                self.rel_type,
+                tuple(self.contains),
+                tuple(self.lang),
+                self.flags
+            )
+
+    def __str__(self):  # pragma: no cover
+        """String representation."""
+
+        return (
+            '_Selector(tag={!r}, ids={!r}, classes={!r}, attributes={!r}, nth={!r}, selectors={!r}, '
+            'relations={!r}, rel_type={!r}, contains={!r}, lang={!r}, flags={!r}, no_match={!r})'
+        ).format(
+            self.tag, self.ids, self.classes, self.attributes, self.nth, self.selectors,
+            self.relations, self.rel_type, self.contains, self.lang, self.flags, self.no_match
+        )
+
+    __repr__ = __str__
+
+
+class CSSParser(object):
+    """Parse CSS selectors."""
+
+    css_tokens = (
+        SelectorPattern("pseudo_close", PAT_PSEUDO_CLOSE),
+        SpecialPseudoPattern(
+            (
+                (
+                    "pseudo_contains",
+                    (':contains', ':-soup-contains', ':-soup-contains-own'),
+                    PAT_PSEUDO_CONTAINS,
+                    SelectorPattern
+                ),
+                ("pseudo_nth_child", (':nth-child', ':nth-last-child'), PAT_PSEUDO_NTH_CHILD, SelectorPattern),
+                ("pseudo_nth_type", (':nth-of-type', ':nth-last-of-type'), PAT_PSEUDO_NTH_TYPE, SelectorPattern),
+                ("pseudo_lang", (':lang',), PAT_PSEUDO_LANG, SelectorPattern),
+                ("pseudo_dir", (':dir',), PAT_PSEUDO_DIR, SelectorPattern)
+            )
+        ),
+        SelectorPattern("pseudo_class_custom", PAT_PSEUDO_CLASS_CUSTOM),
+        SelectorPattern("pseudo_class", PAT_PSEUDO_CLASS),
+        SelectorPattern("pseudo_element", PAT_PSEUDO_ELEMENT),
+        SelectorPattern("at_rule", PAT_AT_RULE),
+        SelectorPattern("id", PAT_ID),
+        SelectorPattern("class", PAT_CLASS),
+        SelectorPattern("tag", PAT_TAG),
+        SelectorPattern("attribute", PAT_ATTR),
+        SelectorPattern("combine", PAT_COMBINE)
+    )
+
+    def __init__(self, selector, custom=None, flags=0):
+        """Initialize."""
+
+        self.pattern = selector.replace('\x00', '\ufffd')
+        self.flags = flags
+        self.debug = self.flags & util.DEBUG
+        self.custom = {} if custom is None else custom
+
+    def parse_attribute_selector(self, sel, m, has_selector):
+        """Create attribute selector from the returned regex match."""
+
+        inverse = False
+        op = m.group('cmp')
+        case = util.lower(m.group('case')) if m.group('case') else None
+        ns = css_unescape(m.group('attr_ns')[:-1]) if m.group('attr_ns') else ''
+        attr = css_unescape(m.group('attr_name'))
+        is_type = False
+        pattern2 = None
+
+        if case:
+            flags = re.I if case == 'i' else 0
+        elif util.lower(attr) == 'type':
+            flags = re.I
+            is_type = True
+        else:
+            flags = 0
+
+        if op:
+            if m.group('value').startswith(('"', "'")):
+                value = css_unescape(m.group('value')[1:-1], True)
+            else:
+                value = css_unescape(m.group('value'))
+        else:
+            value = None
+        if not op:
+            # Attribute name
+            pattern = None
+        elif op.startswith('^'):
+            # Value start with
+            pattern = re.compile(r'^%s.*' % re.escape(value), flags)
+        elif op.startswith('$'):
+            # Value ends with
+            pattern = re.compile(r'.*?%s$' % re.escape(value), flags)
+        elif op.startswith('*'):
+            # Value contains
+            pattern = re.compile(r'.*?%s.*' % re.escape(value), flags)
+        elif op.startswith('~'):
+            # Value contains word within space separated list
+            # `~=` should match nothing if it is empty or contains whitespace,
+            # so if either of these cases is present, use `[^\s\S]` which cannot be matched.
+            value = r'[^\s\S]' if not value or RE_WS.search(value) else re.escape(value)
+            pattern = re.compile(r'.*?(?:(?<=^)|(?<=[ \t\r\n\f]))%s(?=(?:[ \t\r\n\f]|$)).*' % value, flags)
+        elif op.startswith('|'):
+            # Value starts with word in dash separated list
+            pattern = re.compile(r'^%s(?:-.*)?$' % re.escape(value), flags)
+        else:
+            # Value matches
+            pattern = re.compile(r'^%s$' % re.escape(value), flags)
+            if op.startswith('!'):
+                # Equivalent to `:not([attr=value])`
+                inverse = True
+        if is_type and pattern:
+            pattern2 = re.compile(pattern.pattern)
+
+        # Append the attribute selector
+        sel_attr = ct.SelectorAttribute(attr, ns, pattern, pattern2)
+        if inverse:
+            # If we are using `!=`, we need to nest the pattern under a `:not()`.
+            sub_sel = _Selector()
+            sub_sel.attributes.append(sel_attr)
+            not_list = ct.SelectorList([sub_sel.freeze()], True, False)
+            sel.selectors.append(not_list)
+        else:
+            sel.attributes.append(sel_attr)
+
+        has_selector = True
+        return has_selector
+
+    def parse_tag_pattern(self, sel, m, has_selector):
+        """Parse tag pattern from regex match."""
+
+        prefix = css_unescape(m.group('tag_ns')[:-1]) if m.group('tag_ns') else None
+        tag = css_unescape(m.group('tag_name'))
+        sel.tag = ct.SelectorTag(tag, prefix)
+        has_selector = True
+        return has_selector
+
+    def parse_pseudo_class_custom(self, sel, m, has_selector):
+        """
+        Parse custom pseudo class alias.
+
+        Compile custom selectors as we need them. When compiling a custom selector,
+        set it to `None` in the dictionary so we can avoid an infinite loop.
+        """
+
+        pseudo = util.lower(css_unescape(m.group('name')))
+        selector = self.custom.get(pseudo)
+        if selector is None:
+            raise SelectorSyntaxError(
+                "Undefined custom selector '{}' found at postion {}".format(pseudo, m.end(0)),
+                self.pattern,
+                m.end(0)
+            )
+
+        if not isinstance(selector, ct.SelectorList):
+            self.custom[pseudo] = None
+            selector = CSSParser(
+                selector, custom=self.custom, flags=self.flags
+            ).process_selectors(flags=FLG_PSEUDO)
+            self.custom[pseudo] = selector
+
+        sel.selectors.append(selector)
+        has_selector = True
+        return has_selector
+
+    def parse_pseudo_class(self, sel, m, has_selector, iselector, is_html):
+        """Parse pseudo class."""
+
+        complex_pseudo = False
+        pseudo = util.lower(css_unescape(m.group('name')))
+        if m.group('open'):
+            complex_pseudo = True
+        if complex_pseudo and pseudo in PSEUDO_COMPLEX:
+            has_selector = self.parse_pseudo_open(sel, pseudo, has_selector, iselector, m.end(0))
+        elif not complex_pseudo and pseudo in PSEUDO_SIMPLE:
+            if pseudo == ':root':
+                sel.flags |= ct.SEL_ROOT
+            elif pseudo == ':defined':
+                sel.flags |= ct.SEL_DEFINED
+                is_html = True
+            elif pseudo == ':scope':
+                sel.flags |= ct.SEL_SCOPE
+            elif pseudo == ':empty':
+                sel.flags |= ct.SEL_EMPTY
+            elif pseudo in (':link', ':any-link'):
+                sel.selectors.append(CSS_LINK)
+            elif pseudo == ':checked':
+                sel.selectors.append(CSS_CHECKED)
+            elif pseudo == ':default':
+                sel.selectors.append(CSS_DEFAULT)
+            elif pseudo == ':indeterminate':
+                sel.selectors.append(CSS_INDETERMINATE)
+            elif pseudo == ":disabled":
+                sel.selectors.append(CSS_DISABLED)
+            elif pseudo == ":enabled":
+                sel.selectors.append(CSS_ENABLED)
+            elif pseudo == ":required":
+                sel.selectors.append(CSS_REQUIRED)
+            elif pseudo == ":optional":
+                sel.selectors.append(CSS_OPTIONAL)
+            elif pseudo == ":read-only":
+                sel.selectors.append(CSS_READ_ONLY)
+            elif pseudo == ":read-write":
+                sel.selectors.append(CSS_READ_WRITE)
+            elif pseudo == ":in-range":
+                sel.selectors.append(CSS_IN_RANGE)
+            elif pseudo == ":out-of-range":
+                sel.selectors.append(CSS_OUT_OF_RANGE)
+            elif pseudo == ":placeholder-shown":
+                sel.selectors.append(CSS_PLACEHOLDER_SHOWN)
+            elif pseudo == ':first-child':
+                sel.nth.append(ct.SelectorNth(1, False, 0, False, False, ct.SelectorList()))
+            elif pseudo == ':last-child':
+                sel.nth.append(ct.SelectorNth(1, False, 0, False, True, ct.SelectorList()))
+            elif pseudo == ':first-of-type':
+                sel.nth.append(ct.SelectorNth(1, False, 0, True, False, ct.SelectorList()))
+            elif pseudo == ':last-of-type':
+                sel.nth.append(ct.SelectorNth(1, False, 0, True, True, ct.SelectorList()))
+            elif pseudo == ':only-child':
+                sel.nth.extend(
+                    [
+                        ct.SelectorNth(1, False, 0, False, False, ct.SelectorList()),
+                        ct.SelectorNth(1, False, 0, False, True, ct.SelectorList())
+                    ]
+                )
+            elif pseudo == ':only-of-type':
+                sel.nth.extend(
+                    [
+                        ct.SelectorNth(1, False, 0, True, False, ct.SelectorList()),
+                        ct.SelectorNth(1, False, 0, True, True, ct.SelectorList())
+                    ]
+                )
+            has_selector = True
+        elif complex_pseudo and pseudo in PSEUDO_COMPLEX_NO_MATCH:
+            self.parse_selectors(iselector, m.end(0), FLG_PSEUDO | FLG_OPEN)
+            sel.no_match = True
+            has_selector = True
+        elif not complex_pseudo and pseudo in PSEUDO_SIMPLE_NO_MATCH:
+            sel.no_match = True
+            has_selector = True
+        elif pseudo in PSEUDO_SUPPORTED:
+            raise SelectorSyntaxError(
+                "Invalid syntax for pseudo class '{}'".format(pseudo),
+                self.pattern,
+                m.start(0)
+            )
+        else:
+            raise NotImplementedError(
+                "'{}' pseudo-class is not implemented at this time".format(pseudo)
+            )
+
+        return has_selector, is_html
+
+    def parse_pseudo_nth(self, sel, m, has_selector, iselector):
+        """Parse `nth` pseudo."""
+
+        mdict = m.groupdict()
+        if mdict.get('pseudo_nth_child'):
+            postfix = '_child'
+        else:
+            postfix = '_type'
+        mdict['name'] = util.lower(css_unescape(mdict['name']))
+        content = util.lower(mdict.get('nth' + postfix))
+        if content == 'even':
+            # 2n
+            s1 = 2
+            s2 = 0
+            var = True
+        elif content == 'odd':
+            # 2n+1
+            s1 = 2
+            s2 = 1
+            var = True
+        else:
+            nth_parts = RE_NTH.match(content)
+            s1 = '-' if nth_parts.group('s1') and nth_parts.group('s1') == '-' else ''
+            a = nth_parts.group('a')
+            var = a.endswith('n')
+            if a.startswith('n'):
+                s1 += '1'
+            elif var:
+                s1 += a[:-1]
+            else:
+                s1 += a
+            s2 = '-' if nth_parts.group('s2') and nth_parts.group('s2') == '-' else ''
+            if nth_parts.group('b'):
+                s2 += nth_parts.group('b')
+            else:
+                s2 = '0'
+            s1 = int(s1, 10)
+            s2 = int(s2, 10)
+
+        pseudo_sel = mdict['name']
+        if postfix == '_child':
+            if m.group('of'):
+                # Parse the rest of `of S`.
+                nth_sel = self.parse_selectors(iselector, m.end(0), FLG_PSEUDO | FLG_OPEN)
+            else:
+                # Use default `*|*` for `of S`.
+                nth_sel = CSS_NTH_OF_S_DEFAULT
+            if pseudo_sel == ':nth-child':
+                sel.nth.append(ct.SelectorNth(s1, var, s2, False, False, nth_sel))
+            elif pseudo_sel == ':nth-last-child':
+                sel.nth.append(ct.SelectorNth(s1, var, s2, False, True, nth_sel))
+        else:
+            if pseudo_sel == ':nth-of-type':
+                sel.nth.append(ct.SelectorNth(s1, var, s2, True, False, ct.SelectorList()))
+            elif pseudo_sel == ':nth-last-of-type':
+                sel.nth.append(ct.SelectorNth(s1, var, s2, True, True, ct.SelectorList()))
+        has_selector = True
+        return has_selector
+
+    def parse_pseudo_open(self, sel, name, has_selector, iselector, index):
+        """Parse pseudo with opening bracket."""
+
+        flags = FLG_PSEUDO | FLG_OPEN
+        if name == ':not':
+            flags |= FLG_NOT
+        if name == ':has':
+            flags |= FLG_RELATIVE
+
+        sel.selectors.append(self.parse_selectors(iselector, index, flags))
+        has_selector = True
+        return has_selector
+
+    def parse_has_combinator(self, sel, m, has_selector, selectors, rel_type, index):
+        """Parse combinator tokens."""
+
+        combinator = m.group('relation').strip()
+        if not combinator:
+            combinator = WS_COMBINATOR
+        if combinator == COMMA_COMBINATOR:
+            if not has_selector:
+                # If we've not captured any selector parts, the comma is either at the beginning of the pattern
+                # or following another comma, both of which are unexpected. Commas must split selectors.
+                raise SelectorSyntaxError(
+                    "The combinator '{}' at postion {}, must have a selector before it".format(combinator, index),
+                    self.pattern,
+                    index
+                )
+            sel.rel_type = rel_type
+            selectors[-1].relations.append(sel)
+            rel_type = ":" + WS_COMBINATOR
+            selectors.append(_Selector())
+        else:
+            if has_selector:
+                # End the current selector and associate the leading combinator with this selector.
+                sel.rel_type = rel_type
+                selectors[-1].relations.append(sel)
+            elif rel_type[1:] != WS_COMBINATOR:
+                # It's impossible to have two whitespace combinators after each other as the patterns
+                # will gobble up trailing whitespace. It is also impossible to have a whitespace
+                # combinator after any other kind for the same reason. But we could have
+                # multiple non-whitespace combinators. So if the current combinator is not a whitespace,
+                # then we've hit the multiple combinator case, so we should fail.
+                raise SelectorSyntaxError(
+                    'The multiple combinators at position {}'.format(index),
+                    self.pattern,
+                    index
+                )
+            # Set the leading combinator for the next selector.
+            rel_type = ':' + combinator
+        sel = _Selector()
+
+        has_selector = False
+        return has_selector, sel, rel_type
+
+    def parse_combinator(self, sel, m, has_selector, selectors, relations, is_pseudo, index):
+        """Parse combinator tokens."""
+
+        combinator = m.group('relation').strip()
+        if not combinator:
+            combinator = WS_COMBINATOR
+        if not has_selector:
+            raise SelectorSyntaxError(
+                "The combinator '{}' at postion {}, must have a selector before it".format(combinator, index),
+                self.pattern,
+                index
+            )
+
+        if combinator == COMMA_COMBINATOR:
+            if not sel.tag and not is_pseudo:
+                # Implied `*`
+                sel.tag = ct.SelectorTag('*', None)
+            sel.relations.extend(relations)
+            selectors.append(sel)
+            del relations[:]
+        else:
+            sel.relations.extend(relations)
+            sel.rel_type = combinator
+            del relations[:]
+            relations.append(sel)
+        sel = _Selector()
+
+        has_selector = False
+        return has_selector, sel
+
+    def parse_class_id(self, sel, m, has_selector):
+        """Parse HTML classes and ids."""
+
+        selector = m.group(0)
+        if selector.startswith('.'):
+            sel.classes.append(css_unescape(selector[1:]))
+        else:
+            sel.ids.append(css_unescape(selector[1:]))
+        has_selector = True
+        return has_selector
+
+    def parse_pseudo_contains(self, sel, m, has_selector):
+        """Parse contains."""
+
+        pseudo = util.lower(css_unescape(m.group('name')))
+        if pseudo == ":contains":
+            warnings.warn(
+                "The pseudo class ':contains' is deprecated, ':-soup-contains' should be used moving forward.",
+                FutureWarning
+            )
+        contains_own = pseudo == ":-soup-contains-own"
+        values = css_unescape(m.group('values'))
+        patterns = []
+        for token in RE_VALUES.finditer(values):
+            if token.group('split'):
+                continue
+            value = token.group('value')
+            if value.startswith(("'", '"')):
+                value = css_unescape(value[1:-1], True)
+            else:
+                value = css_unescape(value)
+            patterns.append(value)
+        sel.contains.append(ct.SelectorContains(tuple(patterns), contains_own))
+        has_selector = True
+        return has_selector
+
+    def parse_pseudo_lang(self, sel, m, has_selector):
+        """Parse pseudo language."""
+
+        values = m.group('values')
+        patterns = []
+        for token in RE_VALUES.finditer(values):
+            if token.group('split'):
+                continue
+            value = token.group('value')
+            if value.startswith(('"', "'")):
+                value = css_unescape(value[1:-1], True)
+            else:
+                value = css_unescape(value)
+
+            patterns.append(value)
+
+        sel.lang.append(ct.SelectorLang(patterns))
+        has_selector = True
+
+        return has_selector
+
+    def parse_pseudo_dir(self, sel, m, has_selector):
+        """Parse pseudo direction."""
+
+        value = ct.SEL_DIR_LTR if util.lower(m.group('dir')) == 'ltr' else ct.SEL_DIR_RTL
+        sel.flags |= value
+        has_selector = True
+        return has_selector
+
+    def parse_selectors(self, iselector, index=0, flags=0):
+        """Parse selectors."""
+
+        sel = _Selector()
+        selectors = []
+        has_selector = False
+        closed = False
+        relations = []
+        rel_type = ":" + WS_COMBINATOR
+        is_open = bool(flags & FLG_OPEN)
+        is_pseudo = bool(flags & FLG_PSEUDO)
+        is_relative = bool(flags & FLG_RELATIVE)
+        is_not = bool(flags & FLG_NOT)
+        is_html = bool(flags & FLG_HTML)
+        is_default = bool(flags & FLG_DEFAULT)
+        is_indeterminate = bool(flags & FLG_INDETERMINATE)
+        is_in_range = bool(flags & FLG_IN_RANGE)
+        is_out_of_range = bool(flags & FLG_OUT_OF_RANGE)
+        is_placeholder_shown = bool(flags & FLG_PLACEHOLDER_SHOWN)
+
+        if self.debug:  # pragma: no cover
+            if is_pseudo:
+                print('    is_pseudo: True')
+            if is_open:
+                print('    is_open: True')
+            if is_relative:
+                print('    is_relative: True')
+            if is_not:
+                print('    is_not: True')
+            if is_html:
+                print('    is_html: True')
+            if is_default:
+                print('    is_default: True')
+            if is_indeterminate:
+                print('    is_indeterminate: True')
+            if is_in_range:
+                print('    is_in_range: True')
+            if is_out_of_range:
+                print('    is_out_of_range: True')
+            if is_placeholder_shown:
+                print('    is_placeholder_shown: True')
+
+        if is_relative:
+            selectors.append(_Selector())
+
+        try:
+            while True:
+                key, m = next(iselector)
+
+                # Handle parts
+                if key == "at_rule":
+                    raise NotImplementedError("At-rules found at position {}".format(m.start(0)))
+                elif key == 'pseudo_class_custom':
+                    has_selector = self.parse_pseudo_class_custom(sel, m, has_selector)
+                elif key == 'pseudo_class':
+                    has_selector, is_html = self.parse_pseudo_class(sel, m, has_selector, iselector, is_html)
+                elif key == 'pseudo_element':
+                    raise NotImplementedError("Pseudo-element found at position {}".format(m.start(0)))
+                elif key == 'pseudo_contains':
+                    has_selector = self.parse_pseudo_contains(sel, m, has_selector)
+                elif key in ('pseudo_nth_type', 'pseudo_nth_child'):
+                    has_selector = self.parse_pseudo_nth(sel, m, has_selector, iselector)
+                elif key == 'pseudo_lang':
+                    has_selector = self.parse_pseudo_lang(sel, m, has_selector)
+                elif key == 'pseudo_dir':
+                    has_selector = self.parse_pseudo_dir(sel, m, has_selector)
+                    # Currently only supports HTML
+                    is_html = True
+                elif key == 'pseudo_close':
+                    if not has_selector:
+                        raise SelectorSyntaxError(
+                            "Expected a selector at postion {}".format(m.start(0)),
+                            self.pattern,
+                            m.start(0)
+                        )
+                    if is_open:
+                        closed = True
+                        break
+                    else:
+                        raise SelectorSyntaxError(
+                            "Unmatched pseudo-class close at postion {}".format(m.start(0)),
+                            self.pattern,
+                            m.start(0)
+                        )
+                elif key == 'combine':
+                    if is_relative:
+                        has_selector, sel, rel_type = self.parse_has_combinator(
+                            sel, m, has_selector, selectors, rel_type, index
+                        )
+                    else:
+                        has_selector, sel = self.parse_combinator(
+                            sel, m, has_selector, selectors, relations, is_pseudo, index
+                        )
+                elif key == 'attribute':
+                    has_selector = self.parse_attribute_selector(sel, m, has_selector)
+                elif key == 'tag':
+                    if has_selector:
+                        raise SelectorSyntaxError(
+                            "Tag name found at position {} instead of at the start".format(m.start(0)),
+                            self.pattern,
+                            m.start(0)
+                        )
+                    has_selector = self.parse_tag_pattern(sel, m, has_selector)
+                elif key in ('class', 'id'):
+                    has_selector = self.parse_class_id(sel, m, has_selector)
+
+                index = m.end(0)
+        except StopIteration:
+            pass
+
+        if is_open and not closed:
+            raise SelectorSyntaxError(
+                "Unclosed pseudo-class at position {}".format(index),
+                self.pattern,
+                index
+            )
+
+        if has_selector:
+            if not sel.tag and not is_pseudo:
+                # Implied `*`
+                sel.tag = ct.SelectorTag('*', None)
+            if is_relative:
+                sel.rel_type = rel_type
+                selectors[-1].relations.append(sel)
+            else:
+                sel.relations.extend(relations)
+                del relations[:]
+                selectors.append(sel)
+        else:
+            # We will always need to finish a selector when `:has()` is used as it leads with combining.
+            raise SelectorSyntaxError(
+                'Expected a selector at position {}'.format(index),
+                self.pattern,
+                index
+            )
+
+        # Some patterns require additional logic, such as default. We try to make these the
+        # last pattern, and append the appropriate flag to that selector which communicates
+        # to the matcher what additional logic is required.
+        if is_default:
+            selectors[-1].flags = ct.SEL_DEFAULT
+        if is_indeterminate:
+            selectors[-1].flags = ct.SEL_INDETERMINATE
+        if is_in_range:
+            selectors[-1].flags = ct.SEL_IN_RANGE
+        if is_out_of_range:
+            selectors[-1].flags = ct.SEL_OUT_OF_RANGE
+        if is_placeholder_shown:
+            selectors[-1].flags = ct.SEL_PLACEHOLDER_SHOWN
+
+        return ct.SelectorList([s.freeze() for s in selectors], is_not, is_html)
+
+    def selector_iter(self, pattern):
+        """Iterate selector tokens."""
+
+        # Ignore whitespace and comments at start and end of pattern
+        m = RE_WS_BEGIN.search(pattern)
+        index = m.end(0) if m else 0
+        m = RE_WS_END.search(pattern)
+        end = (m.start(0) - 1) if m else (len(pattern) - 1)
+
+        if self.debug:  # pragma: no cover
+            print('## PARSING: {!r}'.format(pattern))
+        while index <= end:
+            m = None
+            for v in self.css_tokens:
+                m = v.match(pattern, index, self.flags)
+                if m:
+                    name = v.get_name()
+                    if self.debug:  # pragma: no cover
+                        print("TOKEN: '{}' --> {!r} at position {}".format(name, m.group(0), m.start(0)))
+                    index = m.end(0)
+                    yield name, m
+                    break
+            if m is None:
+                c = pattern[index]
+                # If the character represents the start of one of the known selector types,
+                # throw an exception mentioning that the known selector type is in error;
+                # otherwise, report the invalid character.
+                if c == '[':
+                    msg = "Malformed attribute selector at position {}".format(index)
+                elif c == '.':
+                    msg = "Malformed class selector at position {}".format(index)
+                elif c == '#':
+                    msg = "Malformed id selector at position {}".format(index)
+                elif c == ':':
+                    msg = "Malformed pseudo-class selector at position {}".format(index)
+                else:
+                    msg = "Invalid character {!r} position {}".format(c, index)
+                raise SelectorSyntaxError(msg, self.pattern, index)
+        if self.debug:  # pragma: no cover
+            print('## END PARSING')
+
+    def process_selectors(self, index=0, flags=0):
+        """Process selectors."""
+
+        return self.parse_selectors(self.selector_iter(self.pattern), index, flags)
+
+
+# Precompile CSS selector lists for pseudo-classes (additional logic may be required beyond the pattern)
+# A few patterns are order dependent as they use patterns previous compiled.
+
+# CSS pattern for `:link` and `:any-link`
+CSS_LINK = CSSParser(
+    'html|*:is(a, area)[href]'
+).process_selectors(flags=FLG_PSEUDO | FLG_HTML)
+# CSS pattern for `:checked`
+CSS_CHECKED = CSSParser(
+    '''
+    html|*:is(input[type=checkbox], input[type=radio])[checked], html|option[selected]
+    '''
+).process_selectors(flags=FLG_PSEUDO | FLG_HTML)
+# CSS pattern for `:default` (must compile CSS_CHECKED first)
+CSS_DEFAULT = CSSParser(
+    '''
+    :checked,
+
+    /*
+    This pattern must be at the end.
+    Special logic is applied to the last selector.
+    */
+    html|form html|*:is(button, input)[type="submit"]
+    '''
+).process_selectors(flags=FLG_PSEUDO | FLG_HTML | FLG_DEFAULT)
+# CSS pattern for `:indeterminate`
+CSS_INDETERMINATE = CSSParser(
+    '''
+    html|input[type="checkbox"][indeterminate],
+    html|input[type="radio"]:is(:not([name]), [name=""]):not([checked]),
+    html|progress:not([value]),
+
+    /*
+    This pattern must be at the end.
+    Special logic is applied to the last selector.
+    */
+    html|input[type="radio"][name]:not([name='']):not([checked])
+    '''
+).process_selectors(flags=FLG_PSEUDO | FLG_HTML | FLG_INDETERMINATE)
+# CSS pattern for `:disabled`
+CSS_DISABLED = CSSParser(
+    '''
+    html|*:is(input:not([type=hidden]), button, select, textarea, fieldset, optgroup, option, fieldset)[disabled],
+    html|optgroup[disabled] > html|option,
+    html|fieldset[disabled] > html|*:is(input:not([type=hidden]), button, select, textarea, fieldset),
+    html|fieldset[disabled] >
+        html|*:not(legend:nth-of-type(1)) html|*:is(input:not([type=hidden]), button, select, textarea, fieldset)
+    '''
+).process_selectors(flags=FLG_PSEUDO | FLG_HTML)
+# CSS pattern for `:enabled`
+CSS_ENABLED = CSSParser(
+    '''
+    html|*:is(input:not([type=hidden]), button, select, textarea, fieldset, optgroup, option, fieldset):not(:disabled)
+    '''
+).process_selectors(flags=FLG_PSEUDO | FLG_HTML)
+# CSS pattern for `:required`
+CSS_REQUIRED = CSSParser(
+    'html|*:is(input, textarea, select)[required]'
+).process_selectors(flags=FLG_PSEUDO | FLG_HTML)
+# CSS pattern for `:optional`
+CSS_OPTIONAL = CSSParser(
+    'html|*:is(input, textarea, select):not([required])'
+).process_selectors(flags=FLG_PSEUDO | FLG_HTML)
+# CSS pattern for `:placeholder-shown`
+CSS_PLACEHOLDER_SHOWN = CSSParser(
+    '''
+    html|input:is(
+        :not([type]),
+        [type=""],
+        [type=text],
+        [type=search],
+        [type=url],
+        [type=tel],
+        [type=email],
+        [type=password],
+        [type=number]
+    )[placeholder]:not([placeholder='']):is(:not([value]), [value=""]),
+    html|textarea[placeholder]:not([placeholder=''])
+    '''
+).process_selectors(flags=FLG_PSEUDO | FLG_HTML | FLG_PLACEHOLDER_SHOWN)
+# CSS pattern default for `:nth-child` "of S" feature
+CSS_NTH_OF_S_DEFAULT = CSSParser(
+    '*|*'
+).process_selectors(flags=FLG_PSEUDO)
+# CSS pattern for `:read-write` (CSS_DISABLED must be compiled first)
+CSS_READ_WRITE = CSSParser(
+    '''
+    html|*:is(
+        textarea,
+        input:is(
+            :not([type]),
+            [type=""],
+            [type=text],
+            [type=search],
+            [type=url],
+            [type=tel],
+            [type=email],
+            [type=number],
+            [type=password],
+            [type=date],
+            [type=datetime-local],
+            [type=month],
+            [type=time],
+            [type=week]
+        )
+    ):not([readonly], :disabled),
+    html|*:is([contenteditable=""], [contenteditable="true" i])
+    '''
+).process_selectors(flags=FLG_PSEUDO | FLG_HTML)
+# CSS pattern for `:read-only`
+CSS_READ_ONLY = CSSParser(
+    '''
+    html|*:not(:read-write)
+    '''
+).process_selectors(flags=FLG_PSEUDO | FLG_HTML)
+# CSS pattern for `:in-range`
+CSS_IN_RANGE = CSSParser(
+    '''
+    html|input:is(
+        [type="date"],
+        [type="month"],
+        [type="week"],
+        [type="time"],
+        [type="datetime-local"],
+        [type="number"],
+        [type="range"]
+    ):is(
+        [min],
+        [max]
+    )
+    '''
+).process_selectors(flags=FLG_PSEUDO | FLG_IN_RANGE | FLG_HTML)
+# CSS pattern for `:out-of-range`
+CSS_OUT_OF_RANGE = CSSParser(
+    '''
+    html|input:is(
+        [type="date"],
+        [type="month"],
+        [type="week"],
+        [type="time"],
+        [type="datetime-local"],
+        [type="number"],
+        [type="range"]
+    ):is(
+        [min],
+        [max]
+    )
+    '''
+).process_selectors(flags=FLG_PSEUDO | FLG_OUT_OF_RANGE | FLG_HTML)
Index: latest/Lib/site-packages/soupsieve/css_types.py
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/latest/Lib/site-packages/soupsieve/css_types.py b/latest/Lib/site-packages/soupsieve/css_types.py
new file mode 100644
--- /dev/null	(date 1616411341746)
+++ b/latest/Lib/site-packages/soupsieve/css_types.py	(date 1616411341746)
@@ -0,0 +1,344 @@
+"""CSS selector structure items."""
+import copyreg
+from collections.abc import Hashable, Mapping
+
+__all__ = (
+    'Selector',
+    'SelectorNull',
+    'SelectorTag',
+    'SelectorAttribute',
+    'SelectorContains',
+    'SelectorNth',
+    'SelectorLang',
+    'SelectorList',
+    'Namespaces',
+    'CustomSelectors'
+)
+
+
+SEL_EMPTY = 0x1
+SEL_ROOT = 0x2
+SEL_DEFAULT = 0x4
+SEL_INDETERMINATE = 0x8
+SEL_SCOPE = 0x10
+SEL_DIR_LTR = 0x20
+SEL_DIR_RTL = 0x40
+SEL_IN_RANGE = 0x80
+SEL_OUT_OF_RANGE = 0x100
+SEL_DEFINED = 0x200
+SEL_PLACEHOLDER_SHOWN = 0x400
+
+
+class Immutable(object):
+    """Immutable."""
+
+    __slots__ = ('_hash',)
+
+    def __init__(self, **kwargs):
+        """Initialize."""
+
+        temp = []
+        for k, v in kwargs.items():
+            temp.append(type(v))
+            temp.append(v)
+            super(Immutable, self).__setattr__(k, v)
+        super(Immutable, self).__setattr__('_hash', hash(tuple(temp)))
+
+    @classmethod
+    def __base__(cls):
+        """Get base class."""
+
+        return cls
+
+    def __eq__(self, other):
+        """Equal."""
+
+        return (
+            isinstance(other, self.__base__()) and
+            all([getattr(other, key) == getattr(self, key) for key in self.__slots__ if key != '_hash'])
+        )
+
+    def __ne__(self, other):
+        """Equal."""
+
+        return (
+            not isinstance(other, self.__base__()) or
+            any([getattr(other, key) != getattr(self, key) for key in self.__slots__ if key != '_hash'])
+        )
+
+    def __hash__(self):
+        """Hash."""
+
+        return self._hash
+
+    def __setattr__(self, name, value):
+        """Prevent mutability."""
+
+        raise AttributeError("'{}' is immutable".format(self.__class__.__name__))
+
+    def __repr__(self):  # pragma: no cover
+        """Representation."""
+
+        return "{}({})".format(
+            self.__base__(), ', '.join(["{}={!r}".format(k, getattr(self, k)) for k in self.__slots__[:-1]])
+        )
+
+    __str__ = __repr__
+
+
+class ImmutableDict(Mapping):
+    """Hashable, immutable dictionary."""
+
+    def __init__(self, arg):
+        """Initialize."""
+
+        arg
+        is_dict = isinstance(arg, dict)
+        if (
+            is_dict and not all([isinstance(v, Hashable) for v in arg.values()]) or
+            not is_dict and not all([isinstance(k, Hashable) and isinstance(v, Hashable) for k, v in arg])
+        ):
+            raise TypeError('All values must be hashable')
+
+        self._d = dict(arg)
+        self._hash = hash(tuple([(type(x), x, type(y), y) for x, y in sorted(self._d.items())]))
+
+    def __iter__(self):
+        """Iterator."""
+
+        return iter(self._d)
+
+    def __len__(self):
+        """Length."""
+
+        return len(self._d)
+
+    def __getitem__(self, key):
+        """Get item: `namespace['key']`."""
+        return self._d[key]
+
+    def __hash__(self):
+        """Hash."""
+
+        return self._hash
+
+    def __repr__(self):  # pragma: no cover
+        """Representation."""
+
+        return "{!r}".format(self._d)
+
+    __str__ = __repr__
+
+
+class Namespaces(ImmutableDict):
+    """Namespaces."""
+
+    def __init__(self, arg):
+        """Initialize."""
+
+        # If there are arguments, check the first index.
+        # `super` should fail if the user gave multiple arguments,
+        # so don't bother checking that.
+        is_dict = isinstance(arg, dict)
+        if is_dict and not all([isinstance(k, str) and isinstance(v, str) for k, v in arg.items()]):
+            raise TypeError('Namespace keys and values must be Unicode strings')
+        elif not is_dict and not all([isinstance(k, str) and isinstance(v, str) for k, v in arg]):
+            raise TypeError('Namespace keys and values must be Unicode strings')
+
+        super(Namespaces, self).__init__(arg)
+
+
+class CustomSelectors(ImmutableDict):
+    """Custom selectors."""
+
+    def __init__(self, arg):
+        """Initialize."""
+
+        # If there are arguments, check the first index.
+        # `super` should fail if the user gave multiple arguments,
+        # so don't bother checking that.
+        is_dict = isinstance(arg, dict)
+        if is_dict and not all([isinstance(k, str) and isinstance(v, str) for k, v in arg.items()]):
+            raise TypeError('CustomSelectors keys and values must be Unicode strings')
+        elif not is_dict and not all([isinstance(k, str) and isinstance(v, str) for k, v in arg]):
+            raise TypeError('CustomSelectors keys and values must be Unicode strings')
+
+        super(CustomSelectors, self).__init__(arg)
+
+
+class Selector(Immutable):
+    """Selector."""
+
+    __slots__ = (
+        'tag', 'ids', 'classes', 'attributes', 'nth', 'selectors',
+        'relation', 'rel_type', 'contains', 'lang', 'flags', '_hash'
+    )
+
+    def __init__(
+        self, tag, ids, classes, attributes, nth, selectors,
+        relation, rel_type, contains, lang, flags
+    ):
+        """Initialize."""
+
+        super(Selector, self).__init__(
+            tag=tag,
+            ids=ids,
+            classes=classes,
+            attributes=attributes,
+            nth=nth,
+            selectors=selectors,
+            relation=relation,
+            rel_type=rel_type,
+            contains=contains,
+            lang=lang,
+            flags=flags
+        )
+
+
+class SelectorNull(Immutable):
+    """Null Selector."""
+
+    def __init__(self):
+        """Initialize."""
+
+        super(SelectorNull, self).__init__()
+
+
+class SelectorTag(Immutable):
+    """Selector tag."""
+
+    __slots__ = ("name", "prefix", "_hash")
+
+    def __init__(self, name, prefix):
+        """Initialize."""
+
+        super(SelectorTag, self).__init__(
+            name=name,
+            prefix=prefix
+        )
+
+
+class SelectorAttribute(Immutable):
+    """Selector attribute rule."""
+
+    __slots__ = ("attribute", "prefix", "pattern", "xml_type_pattern", "_hash")
+
+    def __init__(self, attribute, prefix, pattern, xml_type_pattern):
+        """Initialize."""
+
+        super(SelectorAttribute, self).__init__(
+            attribute=attribute,
+            prefix=prefix,
+            pattern=pattern,
+            xml_type_pattern=xml_type_pattern
+        )
+
+
+class SelectorContains(Immutable):
+    """Selector contains rule."""
+
+    __slots__ = ("text", "own", "_hash")
+
+    def __init__(self, text, own):
+        """Initialize."""
+
+        super(SelectorContains, self).__init__(
+            text=text,
+            own=own
+        )
+
+
+class SelectorNth(Immutable):
+    """Selector nth type."""
+
+    __slots__ = ("a", "n", "b", "of_type", "last", "selectors", "_hash")
+
+    def __init__(self, a, n, b, of_type, last, selectors):
+        """Initialize."""
+
+        super(SelectorNth, self).__init__(
+            a=a,
+            n=n,
+            b=b,
+            of_type=of_type,
+            last=last,
+            selectors=selectors
+        )
+
+
+class SelectorLang(Immutable):
+    """Selector language rules."""
+
+    __slots__ = ("languages", "_hash",)
+
+    def __init__(self, languages):
+        """Initialize."""
+
+        super(SelectorLang, self).__init__(
+            languages=tuple(languages)
+        )
+
+    def __iter__(self):
+        """Iterator."""
+
+        return iter(self.languages)
+
+    def __len__(self):  # pragma: no cover
+        """Length."""
+
+        return len(self.languages)
+
+    def __getitem__(self, index):  # pragma: no cover
+        """Get item."""
+
+        return self.languages[index]
+
+
+class SelectorList(Immutable):
+    """Selector list."""
+
+    __slots__ = ("selectors", "is_not", "is_html", "_hash")
+
+    def __init__(self, selectors=tuple(), is_not=False, is_html=False):
+        """Initialize."""
+
+        super(SelectorList, self).__init__(
+            selectors=tuple(selectors),
+            is_not=is_not,
+            is_html=is_html
+        )
+
+    def __iter__(self):
+        """Iterator."""
+
+        return iter(self.selectors)
+
+    def __len__(self):
+        """Length."""
+
+        return len(self.selectors)
+
+    def __getitem__(self, index):
+        """Get item."""
+
+        return self.selectors[index]
+
+
+def _pickle(p):
+    return p.__base__(), tuple([getattr(p, s) for s in p.__slots__[:-1]])
+
+
+def pickle_register(obj):
+    """Allow object to be pickled."""
+
+    copyreg.pickle(obj, _pickle)
+
+
+pickle_register(Selector)
+pickle_register(SelectorNull)
+pickle_register(SelectorTag)
+pickle_register(SelectorAttribute)
+pickle_register(SelectorContains)
+pickle_register(SelectorNth)
+pickle_register(SelectorLang)
+pickle_register(SelectorList)
Index: latest/Lib/site-packages/soupsieve/util.py
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/latest/Lib/site-packages/soupsieve/util.py b/latest/Lib/site-packages/soupsieve/util.py
new file mode 100644
--- /dev/null	(date 1616411341747)
+++ b/latest/Lib/site-packages/soupsieve/util.py	(date 1616411341747)
@@ -0,0 +1,110 @@
+"""Utility."""
+from functools import wraps, lru_cache
+import warnings
+import re
+
+DEBUG = 0x00001
+
+RE_PATTERN_LINE_SPLIT = re.compile(r'(?:\r\n|(?!\r\n)[\n\r])|$')
+
+UC_A = ord('A')
+UC_Z = ord('Z')
+
+
+@lru_cache(maxsize=512)
+def lower(string):
+    """Lower."""
+
+    new_string = []
+    for c in string:
+        o = ord(c)
+        new_string.append(chr(o + 32) if UC_A <= o <= UC_Z else c)
+    return ''.join(new_string)
+
+
+class SelectorSyntaxError(Exception):
+    """Syntax error in a CSS selector."""
+
+    def __init__(self, msg, pattern=None, index=None):
+        """Initialize."""
+
+        self.line = None
+        self.col = None
+        self.context = None
+
+        if pattern is not None and index is not None:
+            # Format pattern to show line and column position
+            self.context, self.line, self.col = get_pattern_context(pattern, index)
+            msg = '{}\n  line {}:\n{}'.format(msg, self.line, self.context)
+
+        super(SelectorSyntaxError, self).__init__(msg)
+
+
+def deprecated(message, stacklevel=2):  # pragma: no cover
+    """
+    Raise a `DeprecationWarning` when wrapped function/method is called.
+
+    Borrowed from https://stackoverflow.com/a/48632082/866026
+    """
+
+    def _decorator(func):
+        @wraps(func)
+        def _func(*args, **kwargs):
+            warnings.warn(
+                "'{}' is deprecated. {}".format(func.__name__, message),
+                category=DeprecationWarning,
+                stacklevel=stacklevel
+            )
+            return func(*args, **kwargs)
+        return _func
+    return _decorator
+
+
+def warn_deprecated(message, stacklevel=2):  # pragma: no cover
+    """Warn deprecated."""
+
+    warnings.warn(
+        message,
+        category=DeprecationWarning,
+        stacklevel=stacklevel
+    )
+
+
+def get_pattern_context(pattern, index):
+    """Get the pattern context."""
+
+    last = 0
+    current_line = 1
+    col = 1
+    text = []
+    line = 1
+
+    # Split pattern by newline and handle the text before the newline
+    for m in RE_PATTERN_LINE_SPLIT.finditer(pattern):
+        linetext = pattern[last:m.start(0)]
+        if not len(m.group(0)) and not len(text):
+            indent = ''
+            offset = -1
+            col = index - last + 1
+        elif last <= index < m.end(0):
+            indent = '--> '
+            offset = (-1 if index > m.start(0) else 0) + 3
+            col = index - last + 1
+        else:
+            indent = '    '
+            offset = None
+        if len(text):
+            # Regardless of whether we are presented with `\r\n`, `\r`, or `\n`,
+            # we will render the output with just `\n`. We will still log the column
+            # correctly though.
+            text.append('\n')
+        text.append('{}{}'.format(indent, linetext))
+        if offset is not None:
+            text.append('\n')
+            text.append(' ' * (col + offset) + '^')
+            line = current_line
+
+        current_line += 1
+        last = m.end(0)
+
+    return ''.join(text), line, col
Index: latest/Lib/site-packages/soupsieve/__init__.py
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/latest/Lib/site-packages/soupsieve/__init__.py b/latest/Lib/site-packages/soupsieve/__init__.py
new file mode 100644
--- /dev/null	(date 1616411341718)
+++ b/latest/Lib/site-packages/soupsieve/__init__.py	(date 1616411341718)
@@ -0,0 +1,111 @@
+"""
+Soup Sieve.
+
+A CSS selector filter for BeautifulSoup4.
+
+MIT License
+
+Copyright (c) 2018 Isaac Muse
+
+Permission is hereby granted, free of charge, to any person obtaining a copy
+of this software and associated documentation files (the "Software"), to deal
+in the Software without restriction, including without limitation the rights
+to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
+copies of the Software, and to permit persons to whom the Software is
+furnished to do so, subject to the following conditions:
+
+The above copyright notice and this permission notice shall be included in all
+copies or substantial portions of the Software.
+
+THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
+IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
+FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
+AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
+LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
+OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
+SOFTWARE.
+"""
+from .__meta__ import __version__, __version_info__  # noqa: F401
+from . import css_parser as cp
+from . import css_match as cm
+from . import css_types as ct
+from .util import DEBUG, SelectorSyntaxError  # noqa: F401
+
+__all__ = (
+    'DEBUG', 'SelectorSyntaxError', 'SoupSieve',
+    'closest', 'compile', 'filter', 'iselect',
+    'match', 'select', 'select_one'
+)
+
+SoupSieve = cm.SoupSieve
+
+
+def compile(pattern, namespaces=None, flags=0, **kwargs):  # noqa: A001
+    """Compile CSS pattern."""
+
+    if namespaces is not None:
+        namespaces = ct.Namespaces(namespaces)
+
+    custom = kwargs.get('custom')
+    if custom is not None:
+        custom = ct.CustomSelectors(custom)
+
+    if isinstance(pattern, SoupSieve):
+        if flags:
+            raise ValueError("Cannot process 'flags' argument on a compiled selector list")
+        elif namespaces is not None:
+            raise ValueError("Cannot process 'namespaces' argument on a compiled selector list")
+        elif custom is not None:
+            raise ValueError("Cannot process 'custom' argument on a compiled selector list")
+        return pattern
+
+    return cp._cached_css_compile(pattern, namespaces, custom, flags)
+
+
+def purge():
+    """Purge cached patterns."""
+
+    cp._purge_cache()
+
+
+def closest(select, tag, namespaces=None, flags=0, **kwargs):
+    """Match closest ancestor."""
+
+    return compile(select, namespaces, flags, **kwargs).closest(tag)
+
+
+def match(select, tag, namespaces=None, flags=0, **kwargs):
+    """Match node."""
+
+    return compile(select, namespaces, flags, **kwargs).match(tag)
+
+
+def filter(select, iterable, namespaces=None, flags=0, **kwargs):  # noqa: A001
+    """Filter list of nodes."""
+
+    return compile(select, namespaces, flags, **kwargs).filter(iterable)
+
+
+def select_one(select, tag, namespaces=None, flags=0, **kwargs):
+    """Select a single tag."""
+
+    return compile(select, namespaces, flags, **kwargs).select_one(tag)
+
+
+def select(select, tag, namespaces=None, limit=0, flags=0, **kwargs):
+    """Select the specified tags."""
+
+    return compile(select, namespaces, flags, **kwargs).select(tag, limit)
+
+
+def iselect(select, tag, namespaces=None, limit=0, flags=0, **kwargs):
+    """Iterate the specified tags."""
+
+    for el in compile(select, namespaces, flags, **kwargs).iselect(tag, limit):
+        yield el
+
+
+def escape(ident):
+    """Escape identifier."""
+
+    return cp.escape(ident)
Index: latest/Lib/site-packages/soupsieve/__meta__.py
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/latest/Lib/site-packages/soupsieve/__meta__.py b/latest/Lib/site-packages/soupsieve/__meta__.py
new file mode 100644
--- /dev/null	(date 1616411341720)
+++ b/latest/Lib/site-packages/soupsieve/__meta__.py	(date 1616411341720)
@@ -0,0 +1,192 @@
+"""Meta related things."""
+from collections import namedtuple
+import re
+
+RE_VER = re.compile(
+    r'''(?x)
+    (?P<major>\d+)(?:\.(?P<minor>\d+))?(?:\.(?P<micro>\d+))?
+    (?:(?P<type>a|b|rc)(?P<pre>\d+))?
+    (?:\.post(?P<post>\d+))?
+    (?:\.dev(?P<dev>\d+))?
+    '''
+)
+
+REL_MAP = {
+    ".dev": "",
+    ".dev-alpha": "a",
+    ".dev-beta": "b",
+    ".dev-candidate": "rc",
+    "alpha": "a",
+    "beta": "b",
+    "candidate": "rc",
+    "final": ""
+}
+
+DEV_STATUS = {
+    ".dev": "2 - Pre-Alpha",
+    ".dev-alpha": "2 - Pre-Alpha",
+    ".dev-beta": "2 - Pre-Alpha",
+    ".dev-candidate": "2 - Pre-Alpha",
+    "alpha": "3 - Alpha",
+    "beta": "4 - Beta",
+    "candidate": "4 - Beta",
+    "final": "5 - Production/Stable"
+}
+
+PRE_REL_MAP = {"a": 'alpha', "b": 'beta', "rc": 'candidate'}
+
+
+class Version(namedtuple("Version", ["major", "minor", "micro", "release", "pre", "post", "dev"])):
+    """
+    Get the version (PEP 440).
+
+    A biased approach to the PEP 440 semantic version.
+
+    Provides a tuple structure which is sorted for comparisons `v1 > v2` etc.
+      (major, minor, micro, release type, pre-release build, post-release build, development release build)
+    Release types are named in is such a way they are comparable with ease.
+    Accessors to check if a development, pre-release, or post-release build. Also provides accessor to get
+    development status for setup files.
+
+    How it works (currently):
+
+    - You must specify a release type as either `final`, `alpha`, `beta`, or `candidate`.
+    - To define a development release, you can use either `.dev`, `.dev-alpha`, `.dev-beta`, or `.dev-candidate`.
+      The dot is used to ensure all development specifiers are sorted before `alpha`.
+      You can specify a `dev` number for development builds, but do not have to as implicit development releases
+      are allowed.
+    - You must specify a `pre` value greater than zero if using a prerelease as this project (not PEP 440) does not
+      allow implicit prereleases.
+    - You can optionally set `post` to a value greater than zero to make the build a post release. While post releases
+      are technically allowed in prereleases, it is strongly discouraged, so we are rejecting them. It should be
+      noted that we do not allow `post0` even though PEP 440 does not restrict this. This project specifically
+      does not allow implicit post releases.
+    - It should be noted that we do not support epochs `1!` or local versions `+some-custom.version-1`.
+
+    Acceptable version releases:
+
+    ```
+    Version(1, 0, 0, "final")                    1.0
+    Version(1, 2, 0, "final")                    1.2
+    Version(1, 2, 3, "final")                    1.2.3
+    Version(1, 2, 0, ".dev-alpha", pre=4)        1.2a4
+    Version(1, 2, 0, ".dev-beta", pre=4)         1.2b4
+    Version(1, 2, 0, ".dev-candidate", pre=4)    1.2rc4
+    Version(1, 2, 0, "final", post=1)            1.2.post1
+    Version(1, 2, 3, ".dev")                     1.2.3.dev0
+    Version(1, 2, 3, ".dev", dev=1)              1.2.3.dev1
+    ```
+
+    """
+
+    def __new__(cls, major, minor, micro, release="final", pre=0, post=0, dev=0):
+        """Validate version info."""
+
+        # Ensure all parts are positive integers.
+        for value in (major, minor, micro, pre, post):
+            if not (isinstance(value, int) and value >= 0):
+                raise ValueError("All version parts except 'release' should be integers.")
+
+        if release not in REL_MAP:
+            raise ValueError("'{}' is not a valid release type.".format(release))
+
+        # Ensure valid pre-release (we do not allow implicit pre-releases).
+        if ".dev-candidate" < release < "final":
+            if pre == 0:
+                raise ValueError("Implicit pre-releases not allowed.")
+            elif dev:
+                raise ValueError("Version is not a development release.")
+            elif post:
+                raise ValueError("Post-releases are not allowed with pre-releases.")
+
+        # Ensure valid development or development/pre release
+        elif release < "alpha":
+            if release > ".dev" and pre == 0:
+                raise ValueError("Implicit pre-release not allowed.")
+            elif post:
+                raise ValueError("Post-releases are not allowed with pre-releases.")
+
+        # Ensure a valid normal release
+        else:
+            if pre:
+                raise ValueError("Version is not a pre-release.")
+            elif dev:
+                raise ValueError("Version is not a development release.")
+
+        return super(Version, cls).__new__(cls, major, minor, micro, release, pre, post, dev)
+
+    def _is_pre(self):
+        """Is prerelease."""
+
+        return self.pre > 0
+
+    def _is_dev(self):
+        """Is development."""
+
+        return bool(self.release < "alpha")
+
+    def _is_post(self):
+        """Is post."""
+
+        return self.post > 0
+
+    def _get_dev_status(self):  # pragma: no cover
+        """Get development status string."""
+
+        return DEV_STATUS[self.release]
+
+    def _get_canonical(self):
+        """Get the canonical output string."""
+
+        # Assemble major, minor, micro version and append `pre`, `post`, or `dev` if needed..
+        if self.micro == 0:
+            ver = "{}.{}".format(self.major, self.minor)
+        else:
+            ver = "{}.{}.{}".format(self.major, self.minor, self.micro)
+        if self._is_pre():
+            ver += '{}{}'.format(REL_MAP[self.release], self.pre)
+        if self._is_post():
+            ver += ".post{}".format(self.post)
+        if self._is_dev():
+            ver += ".dev{}".format(self.dev)
+
+        return ver
+
+
+def parse_version(ver):
+    """Parse version into a comparable Version tuple."""
+
+    m = RE_VER.match(ver)
+
+    if m is None:
+        raise ValueError("'{}' is not a valid version".format(ver))
+
+    # Handle major, minor, micro
+    major = int(m.group('major'))
+    minor = int(m.group('minor')) if m.group('minor') else 0
+    micro = int(m.group('micro')) if m.group('micro') else 0
+
+    # Handle pre releases
+    if m.group('type'):
+        release = PRE_REL_MAP[m.group('type')]
+        pre = int(m.group('pre'))
+    else:
+        release = "final"
+        pre = 0
+
+    # Handle development releases
+    dev = m.group('dev') if m.group('dev') else 0
+    if m.group('dev'):
+        dev = int(m.group('dev'))
+        release = '.dev-' + release if pre else '.dev'
+    else:
+        dev = 0
+
+    # Handle post
+    post = int(m.group('post')) if m.group('post') else 0
+
+    return Version(major, minor, micro, release, pre, post, dev)
+
+
+__version_info__ = Version(2, 2, 1, "final")
+__version__ = __version_info__._get_canonical()
Index: latest/Lib/site-packages/bs4/dammit.py
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/latest/Lib/site-packages/bs4/dammit.py b/latest/Lib/site-packages/bs4/dammit.py
new file mode 100644
--- /dev/null	(date 1616411342090)
+++ b/latest/Lib/site-packages/bs4/dammit.py	(date 1616411342090)
@@ -0,0 +1,939 @@
+# -*- coding: utf-8 -*-
+"""Beautiful Soup bonus library: Unicode, Dammit
+
+This library converts a bytestream to Unicode through any means
+necessary. It is heavily based on code from Mark Pilgrim's Universal
+Feed Parser. It works best on XML and HTML, but it does not rewrite the
+XML or HTML to reflect a new encoding; that's the tree builder's job.
+"""
+# Use of this source code is governed by the MIT license.
+__license__ = "MIT"
+
+import codecs
+from html.entities import codepoint2name
+import re
+import logging
+import string
+
+# Import a library to autodetect character encodings.
+chardet_type = None
+try:
+    # First try the fast C implementation.
+    #  PyPI package: cchardet
+    import cchardet
+    def chardet_dammit(s):
+        if isinstance(s, str):
+            return None
+        return cchardet.detect(s)['encoding']
+except ImportError:
+    try:
+        # Fall back to the pure Python implementation
+        #  Debian package: python-chardet
+        #  PyPI package: chardet
+        import chardet
+        def chardet_dammit(s):
+            if isinstance(s, str):
+                return None
+            return chardet.detect(s)['encoding']
+        #import chardet.constants
+        #chardet.constants._debug = 1
+    except ImportError:
+        # No chardet available.
+        def chardet_dammit(s):
+            return None
+
+# Available from http://cjkpython.i18n.org/.
+#
+# TODO: This doesn't work anymore and the closest thing, iconv_codecs,
+# is GPL-licensed. Check whether this is still necessary.
+try:
+    import iconv_codec
+except ImportError:
+    pass
+
+# Build bytestring and Unicode versions of regular expressions for finding
+# a declared encoding inside an XML or HTML document.
+xml_encoding = '^\\s*<\\?.*encoding=[\'"](.*?)[\'"].*\\?>'
+html_meta = '<\\s*meta[^>]+charset\\s*=\\s*["\']?([^>]*?)[ /;\'">]'
+encoding_res = dict()
+encoding_res[bytes] = {
+    'html' : re.compile(html_meta.encode("ascii"), re.I),
+    'xml' : re.compile(xml_encoding.encode("ascii"), re.I),
+}
+encoding_res[str] = {
+    'html' : re.compile(html_meta, re.I),
+    'xml' : re.compile(xml_encoding, re.I)
+}
+
+class EntitySubstitution(object):
+    """The ability to substitute XML or HTML entities for certain characters."""
+
+    def _populate_class_variables():
+        lookup = {}
+        reverse_lookup = {}
+        characters_for_re = []
+
+        # &apos is an XHTML entity and an HTML 5, but not an HTML 4
+        # entity. We don't want to use it, but we want to recognize it on the way in.
+        #
+        # TODO: Ideally we would be able to recognize all HTML 5 named
+        # entities, but that's a little tricky.
+        extra = [(39, 'apos')]
+        for codepoint, name in list(codepoint2name.items()) + extra:
+            character = chr(codepoint)
+            if codepoint not in (34, 39):
+                # There's no point in turning the quotation mark into
+                # &quot; or the single quote into &apos;, unless it
+                # happens within an attribute value, which is handled
+                # elsewhere.
+                characters_for_re.append(character)
+                lookup[character] = name
+            # But we do want to recognize those entities on the way in and
+            # convert them to Unicode characters.
+            reverse_lookup[name] = character
+        re_definition = "[%s]" % "".join(characters_for_re)
+        return lookup, reverse_lookup, re.compile(re_definition)
+    (CHARACTER_TO_HTML_ENTITY, HTML_ENTITY_TO_CHARACTER,
+     CHARACTER_TO_HTML_ENTITY_RE) = _populate_class_variables()
+
+    CHARACTER_TO_XML_ENTITY = {
+        "'": "apos",
+        '"': "quot",
+        "&": "amp",
+        "<": "lt",
+        ">": "gt",
+        }
+
+    BARE_AMPERSAND_OR_BRACKET = re.compile("([<>]|"
+                                           "&(?!#\\d+;|#x[0-9a-fA-F]+;|\\w+;)"
+                                           ")")
+
+    AMPERSAND_OR_BRACKET = re.compile("([<>&])")
+
+    @classmethod
+    def _substitute_html_entity(cls, matchobj):
+        """Used with a regular expression to substitute the
+        appropriate HTML entity for a special character."""
+        entity = cls.CHARACTER_TO_HTML_ENTITY.get(matchobj.group(0))
+        return "&%s;" % entity
+
+    @classmethod
+    def _substitute_xml_entity(cls, matchobj):
+        """Used with a regular expression to substitute the
+        appropriate XML entity for a special character."""
+        entity = cls.CHARACTER_TO_XML_ENTITY[matchobj.group(0)]
+        return "&%s;" % entity
+
+    @classmethod
+    def quoted_attribute_value(self, value):
+        """Make a value into a quoted XML attribute, possibly escaping it.
+
+         Most strings will be quoted using double quotes.
+
+          Bob's Bar -> "Bob's Bar"
+
+         If a string contains double quotes, it will be quoted using
+         single quotes.
+
+          Welcome to "my bar" -> 'Welcome to "my bar"'
+
+         If a string contains both single and double quotes, the
+         double quotes will be escaped, and the string will be quoted
+         using double quotes.
+
+          Welcome to "Bob's Bar" -> "Welcome to &quot;Bob's bar&quot;
+        """
+        quote_with = '"'
+        if '"' in value:
+            if "'" in value:
+                # The string contains both single and double
+                # quotes.  Turn the double quotes into
+                # entities. We quote the double quotes rather than
+                # the single quotes because the entity name is
+                # "&quot;" whether this is HTML or XML.  If we
+                # quoted the single quotes, we'd have to decide
+                # between &apos; and &squot;.
+                replace_with = "&quot;"
+                value = value.replace('"', replace_with)
+            else:
+                # There are double quotes but no single quotes.
+                # We can use single quotes to quote the attribute.
+                quote_with = "'"
+        return quote_with + value + quote_with
+
+    @classmethod
+    def substitute_xml(cls, value, make_quoted_attribute=False):
+        """Substitute XML entities for special XML characters.
+
+        :param value: A string to be substituted. The less-than sign
+          will become &lt;, the greater-than sign will become &gt;,
+          and any ampersands will become &amp;. If you want ampersands
+          that appear to be part of an entity definition to be left
+          alone, use substitute_xml_containing_entities() instead.
+
+        :param make_quoted_attribute: If True, then the string will be
+         quoted, as befits an attribute value.
+        """
+        # Escape angle brackets and ampersands.
+        value = cls.AMPERSAND_OR_BRACKET.sub(
+            cls._substitute_xml_entity, value)
+
+        if make_quoted_attribute:
+            value = cls.quoted_attribute_value(value)
+        return value
+
+    @classmethod
+    def substitute_xml_containing_entities(
+        cls, value, make_quoted_attribute=False):
+        """Substitute XML entities for special XML characters.
+
+        :param value: A string to be substituted. The less-than sign will
+          become &lt;, the greater-than sign will become &gt;, and any
+          ampersands that are not part of an entity defition will
+          become &amp;.
+
+        :param make_quoted_attribute: If True, then the string will be
+         quoted, as befits an attribute value.
+        """
+        # Escape angle brackets, and ampersands that aren't part of
+        # entities.
+        value = cls.BARE_AMPERSAND_OR_BRACKET.sub(
+            cls._substitute_xml_entity, value)
+
+        if make_quoted_attribute:
+            value = cls.quoted_attribute_value(value)
+        return value
+
+    @classmethod
+    def substitute_html(cls, s):
+        """Replace certain Unicode characters with named HTML entities.
+
+        This differs from data.encode(encoding, 'xmlcharrefreplace')
+        in that the goal is to make the result more readable (to those
+        with ASCII displays) rather than to recover from
+        errors. There's absolutely nothing wrong with a UTF-8 string
+        containg a LATIN SMALL LETTER E WITH ACUTE, but replacing that
+        character with "&eacute;" will make it more readable to some
+        people.
+
+        :param s: A Unicode string.
+        """
+        return cls.CHARACTER_TO_HTML_ENTITY_RE.sub(
+            cls._substitute_html_entity, s)
+
+
+class EncodingDetector:
+    """Suggests a number of possible encodings for a bytestring.
+
+    Order of precedence:
+
+    1. Encodings you specifically tell EncodingDetector to try first
+    (the override_encodings argument to the constructor).
+
+    2. An encoding declared within the bytestring itself, either in an
+    XML declaration (if the bytestring is to be interpreted as an XML
+    document), or in a <meta> tag (if the bytestring is to be
+    interpreted as an HTML document.)
+
+    3. An encoding detected through textual analysis by chardet,
+    cchardet, or a similar external library.
+
+    4. UTF-8.
+
+    5. Windows-1252.
+    """
+    def __init__(self, markup, override_encodings=None, is_html=False,
+                 exclude_encodings=None):
+        """Constructor.
+
+        :param markup: Some markup in an unknown encoding.
+        :param override_encodings: These encodings will be tried first.
+        :param is_html: If True, this markup is considered to be HTML. Otherwise
+            it's assumed to be XML.
+        :param exclude_encodings: These encodings will not be tried, even
+            if they otherwise would be.
+        """
+        self.override_encodings = override_encodings or []
+        exclude_encodings = exclude_encodings or []
+        self.exclude_encodings = set([x.lower() for x in exclude_encodings])
+        self.chardet_encoding = None
+        self.is_html = is_html
+        self.declared_encoding = None
+
+        # First order of business: strip a byte-order mark.
+        self.markup, self.sniffed_encoding = self.strip_byte_order_mark(markup)
+
+    def _usable(self, encoding, tried):
+        """Should we even bother to try this encoding?
+
+        :param encoding: Name of an encoding.
+        :param tried: Encodings that have already been tried. This will be modified
+            as a side effect.
+        """
+        if encoding is not None:
+            encoding = encoding.lower()
+            if encoding in self.exclude_encodings:
+                return False
+            if encoding not in tried:
+                tried.add(encoding)
+                return True
+        return False
+
+    @property
+    def encodings(self):
+        """Yield a number of encodings that might work for this markup.
+
+        :yield: A sequence of strings.
+        """
+        tried = set()
+        for e in self.override_encodings:
+            if self._usable(e, tried):
+                yield e
+
+        # Did the document originally start with a byte-order mark
+        # that indicated its encoding?
+        if self._usable(self.sniffed_encoding, tried):
+            yield self.sniffed_encoding
+
+        # Look within the document for an XML or HTML encoding
+        # declaration.
+        if self.declared_encoding is None:
+            self.declared_encoding = self.find_declared_encoding(
+                self.markup, self.is_html)
+        if self._usable(self.declared_encoding, tried):
+            yield self.declared_encoding
+
+        # Use third-party character set detection to guess at the
+        # encoding.
+        if self.chardet_encoding is None:
+            self.chardet_encoding = chardet_dammit(self.markup)
+        if self._usable(self.chardet_encoding, tried):
+            yield self.chardet_encoding
+
+        # As a last-ditch effort, try utf-8 and windows-1252.
+        for e in ('utf-8', 'windows-1252'):
+            if self._usable(e, tried):
+                yield e
+
+    @classmethod
+    def strip_byte_order_mark(cls, data):
+        """If a byte-order mark is present, strip it and return the encoding it implies.
+
+        :param data: Some markup.
+        :return: A 2-tuple (modified data, implied encoding)
+        """
+        encoding = None
+        if isinstance(data, str):
+            # Unicode data cannot have a byte-order mark.
+            return data, encoding
+        if (len(data) >= 4) and (data[:2] == b'\xfe\xff') \
+               and (data[2:4] != '\x00\x00'):
+            encoding = 'utf-16be'
+            data = data[2:]
+        elif (len(data) >= 4) and (data[:2] == b'\xff\xfe') \
+                 and (data[2:4] != '\x00\x00'):
+            encoding = 'utf-16le'
+            data = data[2:]
+        elif data[:3] == b'\xef\xbb\xbf':
+            encoding = 'utf-8'
+            data = data[3:]
+        elif data[:4] == b'\x00\x00\xfe\xff':
+            encoding = 'utf-32be'
+            data = data[4:]
+        elif data[:4] == b'\xff\xfe\x00\x00':
+            encoding = 'utf-32le'
+            data = data[4:]
+        return data, encoding
+
+    @classmethod
+    def find_declared_encoding(cls, markup, is_html=False, search_entire_document=False):
+        """Given a document, tries to find its declared encoding.
+
+        An XML encoding is declared at the beginning of the document.
+
+        An HTML encoding is declared in a <meta> tag, hopefully near the
+        beginning of the document.
+
+        :param markup: Some markup.
+        :param is_html: If True, this markup is considered to be HTML. Otherwise
+            it's assumed to be XML.
+        :param search_entire_document: Since an encoding is supposed to declared near the beginning
+            of the document, most of the time it's only necessary to search a few kilobytes of data.
+            Set this to True to force this method to search the entire document.
+        """
+        if search_entire_document:
+            xml_endpos = html_endpos = len(markup)
+        else:
+            xml_endpos = 1024
+            html_endpos = max(2048, int(len(markup) * 0.05))
+
+        if isinstance(markup, bytes):
+            res = encoding_res[bytes]
+        else:
+            res = encoding_res[str]
+
+        xml_re = res['xml']
+        html_re = res['html']
+        declared_encoding = None
+        declared_encoding_match = xml_re.search(markup, endpos=xml_endpos)
+        if not declared_encoding_match and is_html:
+            declared_encoding_match = html_re.search(markup, endpos=html_endpos)
+        if declared_encoding_match is not None:
+            declared_encoding = declared_encoding_match.groups()[0]
+        if declared_encoding:
+            if isinstance(declared_encoding, bytes):
+                declared_encoding = declared_encoding.decode('ascii', 'replace')
+            return declared_encoding.lower()
+        return None
+
+class UnicodeDammit:
+    """A class for detecting the encoding of a *ML document and
+    converting it to a Unicode string. If the source encoding is
+    windows-1252, can replace MS smart quotes with their HTML or XML
+    equivalents."""
+
+    # This dictionary maps commonly seen values for "charset" in HTML
+    # meta tags to the corresponding Python codec names. It only covers
+    # values that aren't in Python's aliases and can't be determined
+    # by the heuristics in find_codec.
+    CHARSET_ALIASES = {"macintosh": "mac-roman",
+                       "x-sjis": "shift-jis"}
+
+    ENCODINGS_WITH_SMART_QUOTES = [
+        "windows-1252",
+        "iso-8859-1",
+        "iso-8859-2",
+        ]
+
+    def __init__(self, markup, override_encodings=[],
+                 smart_quotes_to=None, is_html=False, exclude_encodings=[]):
+        """Constructor.
+
+        :param markup: A bytestring representing markup in an unknown encoding.
+        :param override_encodings: These encodings will be tried first,
+           before any sniffing code is run.
+
+        :param smart_quotes_to: By default, Microsoft smart quotes will, like all other characters, be converted
+           to Unicode characters. Setting this to 'ascii' will convert them to ASCII quotes instead.
+           Setting it to 'xml' will convert them to XML entity references, and setting it to 'html'
+           will convert them to HTML entity references.
+        :param is_html: If True, this markup is considered to be HTML. Otherwise
+            it's assumed to be XML.
+        :param exclude_encodings: These encodings will not be considered, even
+            if the sniffing code thinks they might make sense.
+        """
+        self.smart_quotes_to = smart_quotes_to
+        self.tried_encodings = []
+        self.contains_replacement_characters = False
+        self.is_html = is_html
+        self.log = logging.getLogger(__name__)
+        self.detector = EncodingDetector(
+            markup, override_encodings, is_html, exclude_encodings)
+
+        # Short-circuit if the data is in Unicode to begin with.
+        if isinstance(markup, str) or markup == '':
+            self.markup = markup
+            self.unicode_markup = str(markup)
+            self.original_encoding = None
+            return
+
+        # The encoding detector may have stripped a byte-order mark.
+        # Use the stripped markup from this point on.
+        self.markup = self.detector.markup
+
+        u = None
+        for encoding in self.detector.encodings:
+            markup = self.detector.markup
+            u = self._convert_from(encoding)
+            if u is not None:
+                break
+
+        if not u:
+            # None of the encodings worked. As an absolute last resort,
+            # try them again with character replacement.
+
+            for encoding in self.detector.encodings:
+                if encoding != "ascii":
+                    u = self._convert_from(encoding, "replace")
+                if u is not None:
+                    self.log.warning(
+                            "Some characters could not be decoded, and were "
+                            "replaced with REPLACEMENT CHARACTER."
+                    )
+                    self.contains_replacement_characters = True
+                    break
+
+        # If none of that worked, we could at this point force it to
+        # ASCII, but that would destroy so much data that I think
+        # giving up is better.
+        self.unicode_markup = u
+        if not u:
+            self.original_encoding = None
+
+    def _sub_ms_char(self, match):
+        """Changes a MS smart quote character to an XML or HTML
+        entity, or an ASCII character."""
+        orig = match.group(1)
+        if self.smart_quotes_to == 'ascii':
+            sub = self.MS_CHARS_TO_ASCII.get(orig).encode()
+        else:
+            sub = self.MS_CHARS.get(orig)
+            if type(sub) == tuple:
+                if self.smart_quotes_to == 'xml':
+                    sub = '&#x'.encode() + sub[1].encode() + ';'.encode()
+                else:
+                    sub = '&'.encode() + sub[0].encode() + ';'.encode()
+            else:
+                sub = sub.encode()
+        return sub
+
+    def _convert_from(self, proposed, errors="strict"):
+        """Attempt to convert the markup to the proposed encoding.
+
+        :param proposed: The name of a character encoding.
+        """
+        proposed = self.find_codec(proposed)
+        if not proposed or (proposed, errors) in self.tried_encodings:
+            return None
+        self.tried_encodings.append((proposed, errors))
+        markup = self.markup
+        # Convert smart quotes to HTML if coming from an encoding
+        # that might have them.
+        if (self.smart_quotes_to is not None
+            and proposed in self.ENCODINGS_WITH_SMART_QUOTES):
+            smart_quotes_re = b"([\x80-\x9f])"
+            smart_quotes_compiled = re.compile(smart_quotes_re)
+            markup = smart_quotes_compiled.sub(self._sub_ms_char, markup)
+
+        try:
+            #print("Trying to convert document to %s (errors=%s)" % (
+            #    proposed, errors))
+            u = self._to_unicode(markup, proposed, errors)
+            self.markup = u
+            self.original_encoding = proposed
+        except Exception as e:
+            #print("That didn't work!")
+            #print(e)
+            return None
+        #print("Correct encoding: %s" % proposed)
+        return self.markup
+
+    def _to_unicode(self, data, encoding, errors="strict"):
+        """Given a string and its encoding, decodes the string into Unicode.
+
+        :param encoding: The name of an encoding.
+        """
+        return str(data, encoding, errors)
+
+    @property
+    def declared_html_encoding(self):
+        """If the markup is an HTML document, returns the encoding declared _within_
+        the document.
+        """
+        if not self.is_html:
+            return None
+        return self.detector.declared_encoding
+
+    def find_codec(self, charset):
+        """Convert the name of a character set to a codec name.
+
+        :param charset: The name of a character set.
+        :return: The name of a codec.
+        """
+        value = (self._codec(self.CHARSET_ALIASES.get(charset, charset))
+               or (charset and self._codec(charset.replace("-", "")))
+               or (charset and self._codec(charset.replace("-", "_")))
+               or (charset and charset.lower())
+               or charset
+                )
+        if value:
+            return value.lower()
+        return None
+
+    def _codec(self, charset):
+        if not charset:
+            return charset
+        codec = None
+        try:
+            codecs.lookup(charset)
+            codec = charset
+        except (LookupError, ValueError):
+            pass
+        return codec
+
+
+    # A partial mapping of ISO-Latin-1 to HTML entities/XML numeric entities.
+    MS_CHARS = {b'\x80': ('euro', '20AC'),
+                b'\x81': ' ',
+                b'\x82': ('sbquo', '201A'),
+                b'\x83': ('fnof', '192'),
+                b'\x84': ('bdquo', '201E'),
+                b'\x85': ('hellip', '2026'),
+                b'\x86': ('dagger', '2020'),
+                b'\x87': ('Dagger', '2021'),
+                b'\x88': ('circ', '2C6'),
+                b'\x89': ('permil', '2030'),
+                b'\x8A': ('Scaron', '160'),
+                b'\x8B': ('lsaquo', '2039'),
+                b'\x8C': ('OElig', '152'),
+                b'\x8D': '?',
+                b'\x8E': ('#x17D', '17D'),
+                b'\x8F': '?',
+                b'\x90': '?',
+                b'\x91': ('lsquo', '2018'),
+                b'\x92': ('rsquo', '2019'),
+                b'\x93': ('ldquo', '201C'),
+                b'\x94': ('rdquo', '201D'),
+                b'\x95': ('bull', '2022'),
+                b'\x96': ('ndash', '2013'),
+                b'\x97': ('mdash', '2014'),
+                b'\x98': ('tilde', '2DC'),
+                b'\x99': ('trade', '2122'),
+                b'\x9a': ('scaron', '161'),
+                b'\x9b': ('rsaquo', '203A'),
+                b'\x9c': ('oelig', '153'),
+                b'\x9d': '?',
+                b'\x9e': ('#x17E', '17E'),
+                b'\x9f': ('Yuml', ''),}
+
+    # A parochial partial mapping of ISO-Latin-1 to ASCII. Contains
+    # horrors like stripping diacritical marks to turn á into a, but also
+    # contains non-horrors like turning “ into ".
+    MS_CHARS_TO_ASCII = {
+        b'\x80' : 'EUR',
+        b'\x81' : ' ',
+        b'\x82' : ',',
+        b'\x83' : 'f',
+        b'\x84' : ',,',
+        b'\x85' : '...',
+        b'\x86' : '+',
+        b'\x87' : '++',
+        b'\x88' : '^',
+        b'\x89' : '%',
+        b'\x8a' : 'S',
+        b'\x8b' : '<',
+        b'\x8c' : 'OE',
+        b'\x8d' : '?',
+        b'\x8e' : 'Z',
+        b'\x8f' : '?',
+        b'\x90' : '?',
+        b'\x91' : "'",
+        b'\x92' : "'",
+        b'\x93' : '"',
+        b'\x94' : '"',
+        b'\x95' : '*',
+        b'\x96' : '-',
+        b'\x97' : '--',
+        b'\x98' : '~',
+        b'\x99' : '(TM)',
+        b'\x9a' : 's',
+        b'\x9b' : '>',
+        b'\x9c' : 'oe',
+        b'\x9d' : '?',
+        b'\x9e' : 'z',
+        b'\x9f' : 'Y',
+        b'\xa0' : ' ',
+        b'\xa1' : '!',
+        b'\xa2' : 'c',
+        b'\xa3' : 'GBP',
+        b'\xa4' : '$', #This approximation is especially parochial--this is the
+                       #generic currency symbol.
+        b'\xa5' : 'YEN',
+        b'\xa6' : '|',
+        b'\xa7' : 'S',
+        b'\xa8' : '..',
+        b'\xa9' : '',
+        b'\xaa' : '(th)',
+        b'\xab' : '<<',
+        b'\xac' : '!',
+        b'\xad' : ' ',
+        b'\xae' : '(R)',
+        b'\xaf' : '-',
+        b'\xb0' : 'o',
+        b'\xb1' : '+-',
+        b'\xb2' : '2',
+        b'\xb3' : '3',
+        b'\xb4' : ("'", 'acute'),
+        b'\xb5' : 'u',
+        b'\xb6' : 'P',
+        b'\xb7' : '*',
+        b'\xb8' : ',',
+        b'\xb9' : '1',
+        b'\xba' : '(th)',
+        b'\xbb' : '>>',
+        b'\xbc' : '1/4',
+        b'\xbd' : '1/2',
+        b'\xbe' : '3/4',
+        b'\xbf' : '?',
+        b'\xc0' : 'A',
+        b'\xc1' : 'A',
+        b'\xc2' : 'A',
+        b'\xc3' : 'A',
+        b'\xc4' : 'A',
+        b'\xc5' : 'A',
+        b'\xc6' : 'AE',
+        b'\xc7' : 'C',
+        b'\xc8' : 'E',
+        b'\xc9' : 'E',
+        b'\xca' : 'E',
+        b'\xcb' : 'E',
+        b'\xcc' : 'I',
+        b'\xcd' : 'I',
+        b'\xce' : 'I',
+        b'\xcf' : 'I',
+        b'\xd0' : 'D',
+        b'\xd1' : 'N',
+        b'\xd2' : 'O',
+        b'\xd3' : 'O',
+        b'\xd4' : 'O',
+        b'\xd5' : 'O',
+        b'\xd6' : 'O',
+        b'\xd7' : '*',
+        b'\xd8' : 'O',
+        b'\xd9' : 'U',
+        b'\xda' : 'U',
+        b'\xdb' : 'U',
+        b'\xdc' : 'U',
+        b'\xdd' : 'Y',
+        b'\xde' : 'b',
+        b'\xdf' : 'B',
+        b'\xe0' : 'a',
+        b'\xe1' : 'a',
+        b'\xe2' : 'a',
+        b'\xe3' : 'a',
+        b'\xe4' : 'a',
+        b'\xe5' : 'a',
+        b'\xe6' : 'ae',
+        b'\xe7' : 'c',
+        b'\xe8' : 'e',
+        b'\xe9' : 'e',
+        b'\xea' : 'e',
+        b'\xeb' : 'e',
+        b'\xec' : 'i',
+        b'\xed' : 'i',
+        b'\xee' : 'i',
+        b'\xef' : 'i',
+        b'\xf0' : 'o',
+        b'\xf1' : 'n',
+        b'\xf2' : 'o',
+        b'\xf3' : 'o',
+        b'\xf4' : 'o',
+        b'\xf5' : 'o',
+        b'\xf6' : 'o',
+        b'\xf7' : '/',
+        b'\xf8' : 'o',
+        b'\xf9' : 'u',
+        b'\xfa' : 'u',
+        b'\xfb' : 'u',
+        b'\xfc' : 'u',
+        b'\xfd' : 'y',
+        b'\xfe' : 'b',
+        b'\xff' : 'y',
+        }
+
+    # A map used when removing rogue Windows-1252/ISO-8859-1
+    # characters in otherwise UTF-8 documents.
+    #
+    # Note that \x81, \x8d, \x8f, \x90, and \x9d are undefined in
+    # Windows-1252.
+    WINDOWS_1252_TO_UTF8 = {
+        0x80 : b'\xe2\x82\xac', # €
+        0x82 : b'\xe2\x80\x9a', # ‚
+        0x83 : b'\xc6\x92',     # ƒ
+        0x84 : b'\xe2\x80\x9e', # „
+        0x85 : b'\xe2\x80\xa6', # …
+        0x86 : b'\xe2\x80\xa0', # †
+        0x87 : b'\xe2\x80\xa1', # ‡
+        0x88 : b'\xcb\x86',     # ˆ
+        0x89 : b'\xe2\x80\xb0', # ‰
+        0x8a : b'\xc5\xa0',     # Š
+        0x8b : b'\xe2\x80\xb9', # ‹
+        0x8c : b'\xc5\x92',     # Œ
+        0x8e : b'\xc5\xbd',     # Ž
+        0x91 : b'\xe2\x80\x98', # ‘
+        0x92 : b'\xe2\x80\x99', # ’
+        0x93 : b'\xe2\x80\x9c', # “
+        0x94 : b'\xe2\x80\x9d', # ”
+        0x95 : b'\xe2\x80\xa2', # •
+        0x96 : b'\xe2\x80\x93', # –
+        0x97 : b'\xe2\x80\x94', # —
+        0x98 : b'\xcb\x9c',     # ˜
+        0x99 : b'\xe2\x84\xa2', # ™
+        0x9a : b'\xc5\xa1',     # š
+        0x9b : b'\xe2\x80\xba', # ›
+        0x9c : b'\xc5\x93',     # œ
+        0x9e : b'\xc5\xbe',     # ž
+        0x9f : b'\xc5\xb8',     # Ÿ
+        0xa0 : b'\xc2\xa0',     #  
+        0xa1 : b'\xc2\xa1',     # ¡
+        0xa2 : b'\xc2\xa2',     # ¢
+        0xa3 : b'\xc2\xa3',     # £
+        0xa4 : b'\xc2\xa4',     # ¤
+        0xa5 : b'\xc2\xa5',     # ¥
+        0xa6 : b'\xc2\xa6',     # ¦
+        0xa7 : b'\xc2\xa7',     # §
+        0xa8 : b'\xc2\xa8',     # ¨
+        0xa9 : b'\xc2\xa9',     # ©
+        0xaa : b'\xc2\xaa',     # ª
+        0xab : b'\xc2\xab',     # «
+        0xac : b'\xc2\xac',     # ¬
+        0xad : b'\xc2\xad',     # ­
+        0xae : b'\xc2\xae',     # ®
+        0xaf : b'\xc2\xaf',     # ¯
+        0xb0 : b'\xc2\xb0',     # °
+        0xb1 : b'\xc2\xb1',     # ±
+        0xb2 : b'\xc2\xb2',     # ²
+        0xb3 : b'\xc2\xb3',     # ³
+        0xb4 : b'\xc2\xb4',     # ´
+        0xb5 : b'\xc2\xb5',     # µ
+        0xb6 : b'\xc2\xb6',     # ¶
+        0xb7 : b'\xc2\xb7',     # ·
+        0xb8 : b'\xc2\xb8',     # ¸
+        0xb9 : b'\xc2\xb9',     # ¹
+        0xba : b'\xc2\xba',     # º
+        0xbb : b'\xc2\xbb',     # »
+        0xbc : b'\xc2\xbc',     # ¼
+        0xbd : b'\xc2\xbd',     # ½
+        0xbe : b'\xc2\xbe',     # ¾
+        0xbf : b'\xc2\xbf',     # ¿
+        0xc0 : b'\xc3\x80',     # À
+        0xc1 : b'\xc3\x81',     # Á
+        0xc2 : b'\xc3\x82',     # Â
+        0xc3 : b'\xc3\x83',     # Ã
+        0xc4 : b'\xc3\x84',     # Ä
+        0xc5 : b'\xc3\x85',     # Å
+        0xc6 : b'\xc3\x86',     # Æ
+        0xc7 : b'\xc3\x87',     # Ç
+        0xc8 : b'\xc3\x88',     # È
+        0xc9 : b'\xc3\x89',     # É
+        0xca : b'\xc3\x8a',     # Ê
+        0xcb : b'\xc3\x8b',     # Ë
+        0xcc : b'\xc3\x8c',     # Ì
+        0xcd : b'\xc3\x8d',     # Í
+        0xce : b'\xc3\x8e',     # Î
+        0xcf : b'\xc3\x8f',     # Ï
+        0xd0 : b'\xc3\x90',     # Ð
+        0xd1 : b'\xc3\x91',     # Ñ
+        0xd2 : b'\xc3\x92',     # Ò
+        0xd3 : b'\xc3\x93',     # Ó
+        0xd4 : b'\xc3\x94',     # Ô
+        0xd5 : b'\xc3\x95',     # Õ
+        0xd6 : b'\xc3\x96',     # Ö
+        0xd7 : b'\xc3\x97',     # ×
+        0xd8 : b'\xc3\x98',     # Ø
+        0xd9 : b'\xc3\x99',     # Ù
+        0xda : b'\xc3\x9a',     # Ú
+        0xdb : b'\xc3\x9b',     # Û
+        0xdc : b'\xc3\x9c',     # Ü
+        0xdd : b'\xc3\x9d',     # Ý
+        0xde : b'\xc3\x9e',     # Þ
+        0xdf : b'\xc3\x9f',     # ß
+        0xe0 : b'\xc3\xa0',     # à
+        0xe1 : b'\xa1',         # á
+        0xe2 : b'\xc3\xa2',     # â
+        0xe3 : b'\xc3\xa3',     # ã
+        0xe4 : b'\xc3\xa4',     # ä
+        0xe5 : b'\xc3\xa5',     # å
+        0xe6 : b'\xc3\xa6',     # æ
+        0xe7 : b'\xc3\xa7',     # ç
+        0xe8 : b'\xc3\xa8',     # è
+        0xe9 : b'\xc3\xa9',     # é
+        0xea : b'\xc3\xaa',     # ê
+        0xeb : b'\xc3\xab',     # ë
+        0xec : b'\xc3\xac',     # ì
+        0xed : b'\xc3\xad',     # í
+        0xee : b'\xc3\xae',     # î
+        0xef : b'\xc3\xaf',     # ï
+        0xf0 : b'\xc3\xb0',     # ð
+        0xf1 : b'\xc3\xb1',     # ñ
+        0xf2 : b'\xc3\xb2',     # ò
+        0xf3 : b'\xc3\xb3',     # ó
+        0xf4 : b'\xc3\xb4',     # ô
+        0xf5 : b'\xc3\xb5',     # õ
+        0xf6 : b'\xc3\xb6',     # ö
+        0xf7 : b'\xc3\xb7',     # ÷
+        0xf8 : b'\xc3\xb8',     # ø
+        0xf9 : b'\xc3\xb9',     # ù
+        0xfa : b'\xc3\xba',     # ú
+        0xfb : b'\xc3\xbb',     # û
+        0xfc : b'\xc3\xbc',     # ü
+        0xfd : b'\xc3\xbd',     # ý
+        0xfe : b'\xc3\xbe',     # þ
+        }
+
+    MULTIBYTE_MARKERS_AND_SIZES = [
+        (0xc2, 0xdf, 2), # 2-byte characters start with a byte C2-DF
+        (0xe0, 0xef, 3), # 3-byte characters start with E0-EF
+        (0xf0, 0xf4, 4), # 4-byte characters start with F0-F4
+        ]
+
+    FIRST_MULTIBYTE_MARKER = MULTIBYTE_MARKERS_AND_SIZES[0][0]
+    LAST_MULTIBYTE_MARKER = MULTIBYTE_MARKERS_AND_SIZES[-1][1]
+
+    @classmethod
+    def detwingle(cls, in_bytes, main_encoding="utf8",
+                  embedded_encoding="windows-1252"):
+        """Fix characters from one encoding embedded in some other encoding.
+
+        Currently the only situation supported is Windows-1252 (or its
+        subset ISO-8859-1), embedded in UTF-8.
+
+        :param in_bytes: A bytestring that you suspect contains
+            characters from multiple encodings. Note that this _must_
+            be a bytestring. If you've already converted the document
+            to Unicode, you're too late.
+        :param main_encoding: The primary encoding of `in_bytes`.
+        :param embedded_encoding: The encoding that was used to embed characters
+            in the main document.
+        :return: A bytestring in which `embedded_encoding`
+          characters have been converted to their `main_encoding`
+          equivalents.
+        """
+        if embedded_encoding.replace('_', '-').lower() not in (
+            'windows-1252', 'windows_1252'):
+            raise NotImplementedError(
+                "Windows-1252 and ISO-8859-1 are the only currently supported "
+                "embedded encodings.")
+
+        if main_encoding.lower() not in ('utf8', 'utf-8'):
+            raise NotImplementedError(
+                "UTF-8 is the only currently supported main encoding.")
+
+        byte_chunks = []
+
+        chunk_start = 0
+        pos = 0
+        while pos < len(in_bytes):
+            byte = in_bytes[pos]
+            if not isinstance(byte, int):
+                # Python 2.x
+                byte = ord(byte)
+            if (byte >= cls.FIRST_MULTIBYTE_MARKER
+                and byte <= cls.LAST_MULTIBYTE_MARKER):
+                # This is the start of a UTF-8 multibyte character. Skip
+                # to the end.
+                for start, end, size in cls.MULTIBYTE_MARKERS_AND_SIZES:
+                    if byte >= start and byte <= end:
+                        pos += size
+                        break
+            elif byte >= 0x80 and byte in cls.WINDOWS_1252_TO_UTF8:
+                # We found a Windows-1252 character!
+                # Save the string up to this point as a chunk.
+                byte_chunks.append(in_bytes[chunk_start:pos])
+
+                # Now translate the Windows-1252 character into UTF-8
+                # and add it as another, one-byte chunk.
+                byte_chunks.append(cls.WINDOWS_1252_TO_UTF8[byte])
+                pos += 1
+                chunk_start = pos
+            else:
+                # Go on to the next character.
+                pos += 1
+        if chunk_start == 0:
+            # The string is unchanged.
+            return in_bytes
+        else:
+            # Store the final chunk.
+            byte_chunks.append(in_bytes[chunk_start:])
+        return b''.join(byte_chunks)
+
Index: latest/Lib/site-packages/bs4/diagnose.py
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/latest/Lib/site-packages/bs4/diagnose.py b/latest/Lib/site-packages/bs4/diagnose.py
new file mode 100644
--- /dev/null	(date 1616411342093)
+++ b/latest/Lib/site-packages/bs4/diagnose.py	(date 1616411342093)
@@ -0,0 +1,242 @@
+"""Diagnostic functions, mainly for use when doing tech support."""
+
+# Use of this source code is governed by the MIT license.
+__license__ = "MIT"
+
+import cProfile
+from io import StringIO
+from html.parser import HTMLParser
+import bs4
+from bs4 import BeautifulSoup, __version__
+from bs4.builder import builder_registry
+
+import os
+import pstats
+import random
+import tempfile
+import time
+import traceback
+import sys
+import cProfile
+
+def diagnose(data):
+    """Diagnostic suite for isolating common problems.
+
+    :param data: A string containing markup that needs to be explained.
+    :return: None; diagnostics are printed to standard output.
+    """
+    print(("Diagnostic running on Beautiful Soup %s" % __version__))
+    print(("Python version %s" % sys.version))
+
+    basic_parsers = ["html.parser", "html5lib", "lxml"]
+    for name in basic_parsers:
+        for builder in builder_registry.builders:
+            if name in builder.features:
+                break
+        else:
+            basic_parsers.remove(name)
+            print((
+                "I noticed that %s is not installed. Installing it may help." %
+                name))
+
+    if 'lxml' in basic_parsers:
+        basic_parsers.append("lxml-xml")
+        try:
+            from lxml import etree
+            print(("Found lxml version %s" % ".".join(map(str,etree.LXML_VERSION))))
+        except ImportError as e:
+            print(
+                "lxml is not installed or couldn't be imported.")
+
+
+    if 'html5lib' in basic_parsers:
+        try:
+            import html5lib
+            print(("Found html5lib version %s" % html5lib.__version__))
+        except ImportError as e:
+            print(
+                "html5lib is not installed or couldn't be imported.")
+
+    if hasattr(data, 'read'):
+        data = data.read()
+    elif data.startswith("http:") or data.startswith("https:"):
+        print(('"%s" looks like a URL. Beautiful Soup is not an HTTP client.' % data))
+        print("You need to use some other library to get the document behind the URL, and feed that document to Beautiful Soup.")
+        return
+    else:
+        try:
+            if os.path.exists(data):
+                print(('"%s" looks like a filename. Reading data from the file.' % data))
+                with open(data) as fp:
+                    data = fp.read()
+        except ValueError:
+            # This can happen on some platforms when the 'filename' is
+            # too long. Assume it's data and not a filename.
+            pass
+        print("")
+
+    for parser in basic_parsers:
+        print(("Trying to parse your markup with %s" % parser))
+        success = False
+        try:
+            soup = BeautifulSoup(data, features=parser)
+            success = True
+        except Exception as e:
+            print(("%s could not parse the markup." % parser))
+            traceback.print_exc()
+        if success:
+            print(("Here's what %s did with the markup:" % parser))
+            print((soup.prettify()))
+
+        print(("-" * 80))
+
+def lxml_trace(data, html=True, **kwargs):
+    """Print out the lxml events that occur during parsing.
+
+    This lets you see how lxml parses a document when no Beautiful
+    Soup code is running. You can use this to determine whether
+    an lxml-specific problem is in Beautiful Soup's lxml tree builders
+    or in lxml itself.
+
+    :param data: Some markup.
+    :param html: If True, markup will be parsed with lxml's HTML parser.
+       if False, lxml's XML parser will be used.
+    """
+    from lxml import etree
+    for event, element in etree.iterparse(StringIO(data), html=html, **kwargs):
+        print(("%s, %4s, %s" % (event, element.tag, element.text)))
+
+class AnnouncingParser(HTMLParser):
+    """Subclass of HTMLParser that announces parse events, without doing
+    anything else.
+
+    You can use this to get a picture of how html.parser sees a given
+    document. The easiest way to do this is to call `htmlparser_trace`.
+    """
+
+    def _p(self, s):
+        print(s)
+
+    def handle_starttag(self, name, attrs):
+        self._p("%s START" % name)
+
+    def handle_endtag(self, name):
+        self._p("%s END" % name)
+
+    def handle_data(self, data):
+        self._p("%s DATA" % data)
+
+    def handle_charref(self, name):
+        self._p("%s CHARREF" % name)
+
+    def handle_entityref(self, name):
+        self._p("%s ENTITYREF" % name)
+
+    def handle_comment(self, data):
+        self._p("%s COMMENT" % data)
+
+    def handle_decl(self, data):
+        self._p("%s DECL" % data)
+
+    def unknown_decl(self, data):
+        self._p("%s UNKNOWN-DECL" % data)
+
+    def handle_pi(self, data):
+        self._p("%s PI" % data)
+
+def htmlparser_trace(data):
+    """Print out the HTMLParser events that occur during parsing.
+
+    This lets you see how HTMLParser parses a document when no
+    Beautiful Soup code is running.
+
+    :param data: Some markup.
+    """
+    parser = AnnouncingParser()
+    parser.feed(data)
+
+_vowels = "aeiou"
+_consonants = "bcdfghjklmnpqrstvwxyz"
+
+def rword(length=5):
+    "Generate a random word-like string."
+    s = ''
+    for i in range(length):
+        if i % 2 == 0:
+            t = _consonants
+        else:
+            t = _vowels
+        s += random.choice(t)
+    return s
+
+def rsentence(length=4):
+    "Generate a random sentence-like string."
+    return " ".join(rword(random.randint(4,9)) for i in range(length))
+        
+def rdoc(num_elements=1000):
+    """Randomly generate an invalid HTML document."""
+    tag_names = ['p', 'div', 'span', 'i', 'b', 'script', 'table']
+    elements = []
+    for i in range(num_elements):
+        choice = random.randint(0,3)
+        if choice == 0:
+            # New tag.
+            tag_name = random.choice(tag_names)
+            elements.append("<%s>" % tag_name)
+        elif choice == 1:
+            elements.append(rsentence(random.randint(1,4)))
+        elif choice == 2:
+            # Close a tag.
+            tag_name = random.choice(tag_names)
+            elements.append("</%s>" % tag_name)
+    return "<html>" + "\n".join(elements) + "</html>"
+
+def benchmark_parsers(num_elements=100000):
+    """Very basic head-to-head performance benchmark."""
+    print(("Comparative parser benchmark on Beautiful Soup %s" % __version__))
+    data = rdoc(num_elements)
+    print(("Generated a large invalid HTML document (%d bytes)." % len(data)))
+    
+    for parser in ["lxml", ["lxml", "html"], "html5lib", "html.parser"]:
+        success = False
+        try:
+            a = time.time()
+            soup = BeautifulSoup(data, parser)
+            b = time.time()
+            success = True
+        except Exception as e:
+            print(("%s could not parse the markup." % parser))
+            traceback.print_exc()
+        if success:
+            print(("BS4+%s parsed the markup in %.2fs." % (parser, b-a)))
+
+    from lxml import etree
+    a = time.time()
+    etree.HTML(data)
+    b = time.time()
+    print(("Raw lxml parsed the markup in %.2fs." % (b-a)))
+
+    import html5lib
+    parser = html5lib.HTMLParser()
+    a = time.time()
+    parser.parse(data)
+    b = time.time()
+    print(("Raw html5lib parsed the markup in %.2fs." % (b-a)))
+
+def profile(num_elements=100000, parser="lxml"):
+    """Use Python's profiler on a randomly generated document."""
+    filehandle = tempfile.NamedTemporaryFile()
+    filename = filehandle.name
+
+    data = rdoc(num_elements)
+    vars = dict(bs4=bs4, data=data, parser=parser)
+    cProfile.runctx('bs4.BeautifulSoup(data, parser)' , vars, vars, filename)
+
+    stats = pstats.Stats(filename)
+    # stats.strip_dirs()
+    stats.sort_stats("cumulative")
+    stats.print_stats('_html5lib|bs4', 50)
+
+# If this file is run as a script, standard input is diagnosed.
+if __name__ == '__main__':
+    diagnose(sys.stdin.read())
Index: latest/Lib/site-packages/bs4/element.py
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/latest/Lib/site-packages/bs4/element.py b/latest/Lib/site-packages/bs4/element.py
new file mode 100644
--- /dev/null	(date 1616411342095)
+++ b/latest/Lib/site-packages/bs4/element.py	(date 1616411342095)
@@ -0,0 +1,2175 @@
+# Use of this source code is governed by the MIT license.
+__license__ = "MIT"
+
+try:
+    from collections.abc import Callable # Python 3.6
+except ImportError as e:
+    from collections import Callable
+import re
+import sys
+import warnings
+try:
+    import soupsieve
+except ImportError as e:
+    soupsieve = None
+    warnings.warn(
+        'The soupsieve package is not installed. CSS selectors cannot be used.'
+    )
+
+from bs4.formatter import (
+    Formatter,
+    HTMLFormatter,
+    XMLFormatter,
+)
+
+DEFAULT_OUTPUT_ENCODING = "utf-8"
+PY3K = (sys.version_info[0] > 2)
+
+nonwhitespace_re = re.compile(r"\S+")
+
+# NOTE: This isn't used as of 4.7.0. I'm leaving it for a little bit on
+# the off chance someone imported it for their own use.
+whitespace_re = re.compile(r"\s+")
+
+def _alias(attr):
+    """Alias one attribute name to another for backward compatibility"""
+    @property
+    def alias(self):
+        return getattr(self, attr)
+
+    @alias.setter
+    def alias(self):
+        return setattr(self, attr)
+    return alias
+
+
+# These encodings are recognized by Python (so PageElement.encode
+# could theoretically support them) but XML and HTML don't recognize
+# them (so they should not show up in an XML or HTML document as that
+# document's encoding).
+#
+# If an XML document is encoded in one of these encodings, no encoding
+# will be mentioned in the XML declaration. If an HTML document is
+# encoded in one of these encodings, and the HTML document has a
+# <meta> tag that mentions an encoding, the encoding will be given as
+# the empty string.
+#
+# Source:
+# https://docs.python.org/3/library/codecs.html#python-specific-encodings
+PYTHON_SPECIFIC_ENCODINGS = set([
+    "idna",
+    "mbcs",
+    "oem",
+    "palmos",
+    "punycode",
+    "raw_unicode_escape",
+    "undefined",
+    "unicode_escape",
+    "raw-unicode-escape",
+    "unicode-escape",
+    "string-escape",
+    "string_escape",
+])
+    
+
+class NamespacedAttribute(str):
+    """A namespaced string (e.g. 'xml:lang') that remembers the namespace
+    ('xml') and the name ('lang') that were used to create it.
+    """
+    
+    def __new__(cls, prefix, name=None, namespace=None):
+        if not name:
+            # This is the default namespace. Its name "has no value"
+            # per https://www.w3.org/TR/xml-names/#defaulting
+            name = None
+
+        if name is None:
+            obj = str.__new__(cls, prefix)
+        elif prefix is None:
+            # Not really namespaced.
+            obj = str.__new__(cls, name)
+        else:
+            obj = str.__new__(cls, prefix + ":" + name)
+        obj.prefix = prefix
+        obj.name = name
+        obj.namespace = namespace
+        return obj
+
+class AttributeValueWithCharsetSubstitution(str):
+    """A stand-in object for a character encoding specified in HTML."""
+
+class CharsetMetaAttributeValue(AttributeValueWithCharsetSubstitution):
+    """A generic stand-in for the value of a meta tag's 'charset' attribute.
+
+    When Beautiful Soup parses the markup '<meta charset="utf8">', the
+    value of the 'charset' attribute will be one of these objects.
+    """
+
+    def __new__(cls, original_value):
+        obj = str.__new__(cls, original_value)
+        obj.original_value = original_value
+        return obj
+
+    def encode(self, encoding):
+        """When an HTML document is being encoded to a given encoding, the
+        value of a meta tag's 'charset' is the name of the encoding.
+        """
+        if encoding in PYTHON_SPECIFIC_ENCODINGS:
+            return ''
+        return encoding
+
+
+class ContentMetaAttributeValue(AttributeValueWithCharsetSubstitution):
+    """A generic stand-in for the value of a meta tag's 'content' attribute.
+
+    When Beautiful Soup parses the markup:
+     <meta http-equiv="content-type" content="text/html; charset=utf8">
+
+    The value of the 'content' attribute will be one of these objects.
+    """
+
+    CHARSET_RE = re.compile(r"((^|;)\s*charset=)([^;]*)", re.M)
+
+    def __new__(cls, original_value):
+        match = cls.CHARSET_RE.search(original_value)
+        if match is None:
+            # No substitution necessary.
+            return str.__new__(str, original_value)
+
+        obj = str.__new__(cls, original_value)
+        obj.original_value = original_value
+        return obj
+
+    def encode(self, encoding):
+        if encoding in PYTHON_SPECIFIC_ENCODINGS:
+            return ''
+        def rewrite(match):
+            return match.group(1) + encoding
+        return self.CHARSET_RE.sub(rewrite, self.original_value)
+
+    
+class PageElement(object):
+    """Contains the navigational information for some part of the page:
+    that is, its current location in the parse tree.
+
+    NavigableString, Tag, etc. are all subclasses of PageElement.
+    """
+   
+    def setup(self, parent=None, previous_element=None, next_element=None,
+              previous_sibling=None, next_sibling=None):
+        """Sets up the initial relations between this element and
+        other elements.
+
+        :param parent: The parent of this element.
+
+        :param previous_element: The element parsed immediately before
+            this one.
+        
+        :param next_element: The element parsed immediately before
+            this one.
+
+        :param previous_sibling: The most recently encountered element
+            on the same level of the parse tree as this one.
+
+        :param previous_sibling: The next element to be encountered
+            on the same level of the parse tree as this one.
+        """
+        self.parent = parent
+
+        self.previous_element = previous_element
+        if previous_element is not None:
+            self.previous_element.next_element = self
+
+        self.next_element = next_element
+        if self.next_element is not None:
+            self.next_element.previous_element = self
+
+        self.next_sibling = next_sibling
+        if self.next_sibling is not None:
+            self.next_sibling.previous_sibling = self
+
+        if (previous_sibling is None
+            and self.parent is not None and self.parent.contents):
+            previous_sibling = self.parent.contents[-1]
+
+        self.previous_sibling = previous_sibling
+        if previous_sibling is not None:
+            self.previous_sibling.next_sibling = self
+
+    def format_string(self, s, formatter):
+        """Format the given string using the given formatter.
+
+        :param s: A string.
+        :param formatter: A Formatter object, or a string naming one of the standard formatters.
+        """
+        if formatter is None:
+            return s
+        if not isinstance(formatter, Formatter):
+            formatter = self.formatter_for_name(formatter)
+        output = formatter.substitute(s)
+        return output
+
+    def formatter_for_name(self, formatter):
+        """Look up or create a Formatter for the given identifier,
+        if necessary.
+
+        :param formatter: Can be a Formatter object (used as-is), a
+            function (used as the entity substitution hook for an
+            XMLFormatter or HTMLFormatter), or a string (used to look
+            up an XMLFormatter or HTMLFormatter in the appropriate
+            registry.
+        """
+        if isinstance(formatter, Formatter):
+            return formatter
+        if self._is_xml:
+            c = XMLFormatter
+        else:
+            c = HTMLFormatter
+        if isinstance(formatter, Callable):
+            return c(entity_substitution=formatter)
+        return c.REGISTRY[formatter]
+
+    @property
+    def _is_xml(self):
+        """Is this element part of an XML tree or an HTML tree?
+
+        This is used in formatter_for_name, when deciding whether an
+        XMLFormatter or HTMLFormatter is more appropriate. It can be
+        inefficient, but it should be called very rarely.
+        """
+        if self.known_xml is not None:
+            # Most of the time we will have determined this when the
+            # document is parsed.
+            return self.known_xml
+
+        # Otherwise, it's likely that this element was created by
+        # direct invocation of the constructor from within the user's
+        # Python code.
+        if self.parent is None:
+            # This is the top-level object. It should have .known_xml set
+            # from tree creation. If not, take a guess--BS is usually
+            # used on HTML markup.
+            return getattr(self, 'is_xml', False)
+        return self.parent._is_xml
+
+    nextSibling = _alias("next_sibling")  # BS3
+    previousSibling = _alias("previous_sibling")  # BS3
+
+    def replace_with(self, replace_with):
+        """Replace this PageElement with another one, keeping the rest of the
+        tree the same.
+        
+        :param replace_with: A PageElement.
+        :return: `self`, no longer part of the tree.
+        """
+        if self.parent is None:
+            raise ValueError(
+                "Cannot replace one element with another when the "
+                "element to be replaced is not part of a tree.")
+        if replace_with is self:
+            return
+        if replace_with is self.parent:
+            raise ValueError("Cannot replace a Tag with its parent.")
+        old_parent = self.parent
+        my_index = self.parent.index(self)
+        self.extract(_self_index=my_index)
+        old_parent.insert(my_index, replace_with)
+        return self
+    replaceWith = replace_with  # BS3
+
+    def unwrap(self):
+        """Replace this PageElement with its contents.
+
+        :return: `self`, no longer part of the tree.
+        """
+        my_parent = self.parent
+        if self.parent is None:
+            raise ValueError(
+                "Cannot replace an element with its contents when that"
+                "element is not part of a tree.")
+        my_index = self.parent.index(self)
+        self.extract(_self_index=my_index)
+        for child in reversed(self.contents[:]):
+            my_parent.insert(my_index, child)
+        return self
+    replace_with_children = unwrap
+    replaceWithChildren = unwrap  # BS3
+
+    def wrap(self, wrap_inside):
+        """Wrap this PageElement inside another one.
+
+        :param wrap_inside: A PageElement.
+        :return: `wrap_inside`, occupying the position in the tree that used
+           to be occupied by `self`, and with `self` inside it.
+        """
+        me = self.replace_with(wrap_inside)
+        wrap_inside.append(me)
+        return wrap_inside
+
+    def extract(self, _self_index=None):
+        """Destructively rips this element out of the tree.
+
+        :param _self_index: The location of this element in its parent's
+           .contents, if known. Passing this in allows for a performance
+           optimization.
+
+        :return: `self`, no longer part of the tree.
+        """
+        if self.parent is not None:
+            if _self_index is None:
+                _self_index = self.parent.index(self)
+            del self.parent.contents[_self_index]
+
+        #Find the two elements that would be next to each other if
+        #this element (and any children) hadn't been parsed. Connect
+        #the two.
+        last_child = self._last_descendant()
+        next_element = last_child.next_element
+
+        if (self.previous_element is not None and
+            self.previous_element is not next_element):
+            self.previous_element.next_element = next_element
+        if next_element is not None and next_element is not self.previous_element:
+            next_element.previous_element = self.previous_element
+        self.previous_element = None
+        last_child.next_element = None
+
+        self.parent = None
+        if (self.previous_sibling is not None
+            and self.previous_sibling is not self.next_sibling):
+            self.previous_sibling.next_sibling = self.next_sibling
+        if (self.next_sibling is not None
+            and self.next_sibling is not self.previous_sibling):
+            self.next_sibling.previous_sibling = self.previous_sibling
+        self.previous_sibling = self.next_sibling = None
+        return self
+
+    def _last_descendant(self, is_initialized=True, accept_self=True):
+        """Finds the last element beneath this object to be parsed.
+
+        :param is_initialized: Has `setup` been called on this PageElement
+            yet?
+        :param accept_self: Is `self` an acceptable answer to the question?
+        """
+        if is_initialized and self.next_sibling is not None:
+            last_child = self.next_sibling.previous_element
+        else:
+            last_child = self
+            while isinstance(last_child, Tag) and last_child.contents:
+                last_child = last_child.contents[-1]
+        if not accept_self and last_child is self:
+            last_child = None
+        return last_child
+    # BS3: Not part of the API!
+    _lastRecursiveChild = _last_descendant
+
+    def insert(self, position, new_child):
+        """Insert a new PageElement in the list of this PageElement's children.
+
+        This works the same way as `list.insert`.
+
+        :param position: The numeric position that should be occupied
+           in `self.children` by the new PageElement. 
+        :param new_child: A PageElement.
+        """
+        if new_child is None:
+            raise ValueError("Cannot insert None into a tag.")
+        if new_child is self:
+            raise ValueError("Cannot insert a tag into itself.")
+        if (isinstance(new_child, str)
+            and not isinstance(new_child, NavigableString)):
+            new_child = NavigableString(new_child)
+
+        from bs4 import BeautifulSoup
+        if isinstance(new_child, BeautifulSoup):
+            # We don't want to end up with a situation where one BeautifulSoup
+            # object contains another. Insert the children one at a time.
+            for subchild in list(new_child.contents):
+                self.insert(position, subchild)
+                position += 1
+            return
+        position = min(position, len(self.contents))
+        if hasattr(new_child, 'parent') and new_child.parent is not None:
+            # We're 'inserting' an element that's already one
+            # of this object's children.
+            if new_child.parent is self:
+                current_index = self.index(new_child)
+                if current_index < position:
+                    # We're moving this element further down the list
+                    # of this object's children. That means that when
+                    # we extract this element, our target index will
+                    # jump down one.
+                    position -= 1
+            new_child.extract()
+
+        new_child.parent = self
+        previous_child = None
+        if position == 0:
+            new_child.previous_sibling = None
+            new_child.previous_element = self
+        else:
+            previous_child = self.contents[position - 1]
+            new_child.previous_sibling = previous_child
+            new_child.previous_sibling.next_sibling = new_child
+            new_child.previous_element = previous_child._last_descendant(False)
+        if new_child.previous_element is not None:
+            new_child.previous_element.next_element = new_child
+
+        new_childs_last_element = new_child._last_descendant(False)
+
+        if position >= len(self.contents):
+            new_child.next_sibling = None
+
+            parent = self
+            parents_next_sibling = None
+            while parents_next_sibling is None and parent is not None:
+                parents_next_sibling = parent.next_sibling
+                parent = parent.parent
+                if parents_next_sibling is not None:
+                    # We found the element that comes next in the document.
+                    break
+            if parents_next_sibling is not None:
+                new_childs_last_element.next_element = parents_next_sibling
+            else:
+                # The last element of this tag is the last element in
+                # the document.
+                new_childs_last_element.next_element = None
+        else:
+            next_child = self.contents[position]
+            new_child.next_sibling = next_child
+            if new_child.next_sibling is not None:
+                new_child.next_sibling.previous_sibling = new_child
+            new_childs_last_element.next_element = next_child
+
+        if new_childs_last_element.next_element is not None:
+            new_childs_last_element.next_element.previous_element = new_childs_last_element
+        self.contents.insert(position, new_child)
+
+    def append(self, tag):
+        """Appends the given PageElement to the contents of this one.
+
+        :param tag: A PageElement.
+        """
+        self.insert(len(self.contents), tag)
+
+    def extend(self, tags):
+        """Appends the given PageElements to this one's contents.
+
+        :param tags: A list of PageElements.
+        """
+        if isinstance(tags, Tag):
+            # Calling self.append() on another tag's contents will change
+            # the list we're iterating over. Make a list that won't
+            # change.
+            tags = list(tags.contents)
+        for tag in tags:
+            self.append(tag)
+
+    def insert_before(self, *args):
+        """Makes the given element(s) the immediate predecessor of this one.
+
+        All the elements will have the same parent, and the given elements
+        will be immediately before this one.
+
+        :param args: One or more PageElements.
+        """
+        parent = self.parent
+        if parent is None:
+            raise ValueError(
+                "Element has no parent, so 'before' has no meaning.")
+        if any(x is self for x in args):
+                raise ValueError("Can't insert an element before itself.")
+        for predecessor in args:
+            # Extract first so that the index won't be screwed up if they
+            # are siblings.
+            if isinstance(predecessor, PageElement):
+                predecessor.extract()
+            index = parent.index(self)
+            parent.insert(index, predecessor)
+
+    def insert_after(self, *args):
+        """Makes the given element(s) the immediate successor of this one.
+
+        The elements will have the same parent, and the given elements
+        will be immediately after this one.
+
+        :param args: One or more PageElements.
+        """
+        # Do all error checking before modifying the tree.
+        parent = self.parent
+        if parent is None:
+            raise ValueError(
+                "Element has no parent, so 'after' has no meaning.")
+        if any(x is self for x in args):
+            raise ValueError("Can't insert an element after itself.")
+        
+        offset = 0
+        for successor in args:
+            # Extract first so that the index won't be screwed up if they
+            # are siblings.
+            if isinstance(successor, PageElement):
+                successor.extract()
+            index = parent.index(self)
+            parent.insert(index+1+offset, successor)
+            offset += 1
+
+    def find_next(self, name=None, attrs={}, text=None, **kwargs):
+        """Find the first PageElement that matches the given criteria and
+        appears later in the document than this PageElement.
+
+        All find_* methods take a common set of arguments. See the online
+        documentation for detailed explanations.
+
+        :param name: A filter on tag name.
+        :param attrs: A dictionary of filters on attribute values.
+        :param text: A filter for a NavigableString with specific text.
+        :kwargs: A dictionary of filters on attribute values.
+        :return: A PageElement.
+        :rtype: bs4.element.Tag | bs4.element.NavigableString
+        """
+        return self._find_one(self.find_all_next, name, attrs, text, **kwargs)
+    findNext = find_next  # BS3
+
+    def find_all_next(self, name=None, attrs={}, text=None, limit=None,
+                    **kwargs):
+        """Find all PageElements that match the given criteria and appear
+        later in the document than this PageElement.
+
+        All find_* methods take a common set of arguments. See the online
+        documentation for detailed explanations.
+
+        :param name: A filter on tag name.
+        :param attrs: A dictionary of filters on attribute values.
+        :param text: A filter for a NavigableString with specific text.
+        :param limit: Stop looking after finding this many results.
+        :kwargs: A dictionary of filters on attribute values.
+        :return: A ResultSet containing PageElements.
+        """
+        return self._find_all(name, attrs, text, limit, self.next_elements,
+                             **kwargs)
+    findAllNext = find_all_next  # BS3
+
+    def find_next_sibling(self, name=None, attrs={}, text=None, **kwargs):
+        """Find the closest sibling to this PageElement that matches the
+        given criteria and appears later in the document.
+
+        All find_* methods take a common set of arguments. See the
+        online documentation for detailed explanations.
+
+        :param name: A filter on tag name.
+        :param attrs: A dictionary of filters on attribute values.
+        :param text: A filter for a NavigableString with specific text.
+        :kwargs: A dictionary of filters on attribute values.
+        :return: A PageElement.
+        :rtype: bs4.element.Tag | bs4.element.NavigableString
+        """
+        return self._find_one(self.find_next_siblings, name, attrs, text,
+                             **kwargs)
+    findNextSibling = find_next_sibling  # BS3
+
+    def find_next_siblings(self, name=None, attrs={}, text=None, limit=None,
+                           **kwargs):
+        """Find all siblings of this PageElement that match the given criteria
+        and appear later in the document.
+
+        All find_* methods take a common set of arguments. See the online
+        documentation for detailed explanations.
+
+        :param name: A filter on tag name.
+        :param attrs: A dictionary of filters on attribute values.
+        :param text: A filter for a NavigableString with specific text.
+        :param limit: Stop looking after finding this many results.
+        :kwargs: A dictionary of filters on attribute values.
+        :return: A ResultSet of PageElements.
+        :rtype: bs4.element.ResultSet
+        """
+        return self._find_all(name, attrs, text, limit,
+                              self.next_siblings, **kwargs)
+    findNextSiblings = find_next_siblings   # BS3
+    fetchNextSiblings = find_next_siblings  # BS2
+
+    def find_previous(self, name=None, attrs={}, text=None, **kwargs):
+        """Look backwards in the document from this PageElement and find the
+        first PageElement that matches the given criteria.
+
+        All find_* methods take a common set of arguments. See the online
+        documentation for detailed explanations.
+
+        :param name: A filter on tag name.
+        :param attrs: A dictionary of filters on attribute values.
+        :param text: A filter for a NavigableString with specific text.
+        :kwargs: A dictionary of filters on attribute values.
+        :return: A PageElement.
+        :rtype: bs4.element.Tag | bs4.element.NavigableString
+        """
+        return self._find_one(
+            self.find_all_previous, name, attrs, text, **kwargs)
+    findPrevious = find_previous  # BS3
+
+    def find_all_previous(self, name=None, attrs={}, text=None, limit=None,
+                        **kwargs):
+        """Look backwards in the document from this PageElement and find all
+        PageElements that match the given criteria.
+
+        All find_* methods take a common set of arguments. See the online
+        documentation for detailed explanations.
+
+        :param name: A filter on tag name.
+        :param attrs: A dictionary of filters on attribute values.
+        :param text: A filter for a NavigableString with specific text.
+        :param limit: Stop looking after finding this many results.
+        :kwargs: A dictionary of filters on attribute values.
+        :return: A ResultSet of PageElements.
+        :rtype: bs4.element.ResultSet
+        """
+        return self._find_all(name, attrs, text, limit, self.previous_elements,
+                           **kwargs)
+    findAllPrevious = find_all_previous  # BS3
+    fetchPrevious = find_all_previous    # BS2
+
+    def find_previous_sibling(self, name=None, attrs={}, text=None, **kwargs):
+        """Returns the closest sibling to this PageElement that matches the
+        given criteria and appears earlier in the document.
+
+        All find_* methods take a common set of arguments. See the online
+        documentation for detailed explanations.
+
+        :param name: A filter on tag name.
+        :param attrs: A dictionary of filters on attribute values.
+        :param text: A filter for a NavigableString with specific text.
+        :kwargs: A dictionary of filters on attribute values.
+        :return: A PageElement.
+        :rtype: bs4.element.Tag | bs4.element.NavigableString
+        """
+        return self._find_one(self.find_previous_siblings, name, attrs, text,
+                             **kwargs)
+    findPreviousSibling = find_previous_sibling  # BS3
+
+    def find_previous_siblings(self, name=None, attrs={}, text=None,
+                               limit=None, **kwargs):
+        """Returns all siblings to this PageElement that match the
+        given criteria and appear earlier in the document.
+
+        All find_* methods take a common set of arguments. See the online
+        documentation for detailed explanations.
+
+        :param name: A filter on tag name.
+        :param attrs: A dictionary of filters on attribute values.
+        :param text: A filter for a NavigableString with specific text.
+        :param limit: Stop looking after finding this many results.
+        :kwargs: A dictionary of filters on attribute values.
+        :return: A ResultSet of PageElements.
+        :rtype: bs4.element.ResultSet
+        """
+        return self._find_all(name, attrs, text, limit,
+                              self.previous_siblings, **kwargs)
+    findPreviousSiblings = find_previous_siblings   # BS3
+    fetchPreviousSiblings = find_previous_siblings  # BS2
+
+    def find_parent(self, name=None, attrs={}, **kwargs):
+        """Find the closest parent of this PageElement that matches the given
+        criteria.
+
+        All find_* methods take a common set of arguments. See the online
+        documentation for detailed explanations.
+
+        :param name: A filter on tag name.
+        :param attrs: A dictionary of filters on attribute values.
+        :kwargs: A dictionary of filters on attribute values.
+
+        :return: A PageElement.
+        :rtype: bs4.element.Tag | bs4.element.NavigableString
+        """
+        # NOTE: We can't use _find_one because findParents takes a different
+        # set of arguments.
+        r = None
+        l = self.find_parents(name, attrs, 1, **kwargs)
+        if l:
+            r = l[0]
+        return r
+    findParent = find_parent  # BS3
+
+    def find_parents(self, name=None, attrs={}, limit=None, **kwargs):
+        """Find all parents of this PageElement that match the given criteria.
+
+        All find_* methods take a common set of arguments. See the online
+        documentation for detailed explanations.
+
+        :param name: A filter on tag name.
+        :param attrs: A dictionary of filters on attribute values.
+        :param limit: Stop looking after finding this many results.
+        :kwargs: A dictionary of filters on attribute values.
+
+        :return: A PageElement.
+        :rtype: bs4.element.Tag | bs4.element.NavigableString
+        """
+        return self._find_all(name, attrs, None, limit, self.parents,
+                             **kwargs)
+    findParents = find_parents   # BS3
+    fetchParents = find_parents  # BS2
+
+    @property
+    def next(self):
+        """The PageElement, if any, that was parsed just after this one.
+
+        :return: A PageElement.
+        :rtype: bs4.element.Tag | bs4.element.NavigableString
+        """
+        return self.next_element
+
+    @property
+    def previous(self):
+        """The PageElement, if any, that was parsed just before this one.
+
+        :return: A PageElement.
+        :rtype: bs4.element.Tag | bs4.element.NavigableString
+        """
+        return self.previous_element
+
+    #These methods do the real heavy lifting.
+
+    def _find_one(self, method, name, attrs, text, **kwargs):
+        r = None
+        l = method(name, attrs, text, 1, **kwargs)
+        if l:
+            r = l[0]
+        return r
+
+    def _find_all(self, name, attrs, text, limit, generator, **kwargs):
+        "Iterates over a generator looking for things that match."
+
+        if text is None and 'string' in kwargs:
+            text = kwargs['string']
+            del kwargs['string']
+
+        if isinstance(name, SoupStrainer):
+            strainer = name
+        else:
+            strainer = SoupStrainer(name, attrs, text, **kwargs)
+
+        if text is None and not limit and not attrs and not kwargs:
+            if name is True or name is None:
+                # Optimization to find all tags.
+                result = (element for element in generator
+                          if isinstance(element, Tag))
+                return ResultSet(strainer, result)
+            elif isinstance(name, str):
+                # Optimization to find all tags with a given name.
+                if name.count(':') == 1:
+                    # This is a name with a prefix. If this is a namespace-aware document,
+                    # we need to match the local name against tag.name. If not,
+                    # we need to match the fully-qualified name against tag.name.
+                    prefix, local_name = name.split(':', 1)
+                else:
+                    prefix = None
+                    local_name = name
+                result = (element for element in generator
+                          if isinstance(element, Tag)
+                          and (
+                              element.name == name
+                          ) or (
+                              element.name == local_name
+                              and (prefix is None or element.prefix == prefix)
+                          )
+                )
+                return ResultSet(strainer, result)
+        results = ResultSet(strainer)
+        while True:
+            try:
+                i = next(generator)
+            except StopIteration:
+                break
+            if i:
+                found = strainer.search(i)
+                if found:
+                    results.append(found)
+                    if limit and len(results) >= limit:
+                        break
+        return results
+
+    #These generators can be used to navigate starting from both
+    #NavigableStrings and Tags.
+    @property
+    def next_elements(self):
+        """All PageElements that were parsed after this one.
+
+        :yield: A sequence of PageElements.
+        """
+        i = self.next_element
+        while i is not None:
+            yield i
+            i = i.next_element
+
+    @property
+    def next_siblings(self):
+        """All PageElements that are siblings of this one but were parsed
+        later.
+
+        :yield: A sequence of PageElements.
+        """
+        i = self.next_sibling
+        while i is not None:
+            yield i
+            i = i.next_sibling
+
+    @property
+    def previous_elements(self):
+        """All PageElements that were parsed before this one.
+
+        :yield: A sequence of PageElements.
+        """
+        i = self.previous_element
+        while i is not None:
+            yield i
+            i = i.previous_element
+
+    @property
+    def previous_siblings(self):
+        """All PageElements that are siblings of this one but were parsed
+        earlier.
+
+        :yield: A sequence of PageElements.
+        """
+        i = self.previous_sibling
+        while i is not None:
+            yield i
+            i = i.previous_sibling
+
+    @property
+    def parents(self):
+        """All PageElements that are parents of this PageElement.
+
+        :yield: A sequence of PageElements.
+        """
+        i = self.parent
+        while i is not None:
+            yield i
+            i = i.parent
+
+    @property
+    def decomposed(self):
+        """Check whether a PageElement has been decomposed.
+
+        :rtype: bool
+        """
+        return getattr(self, '_decomposed', False) or False
+            
+    # Old non-property versions of the generators, for backwards
+    # compatibility with BS3.
+    def nextGenerator(self):
+        return self.next_elements
+
+    def nextSiblingGenerator(self):
+        return self.next_siblings
+
+    def previousGenerator(self):
+        return self.previous_elements
+
+    def previousSiblingGenerator(self):
+        return self.previous_siblings
+
+    def parentGenerator(self):
+        return self.parents
+
+
+class NavigableString(str, PageElement):
+    """A Python Unicode string that is part of a parse tree.
+
+    When Beautiful Soup parses the markup <b>penguin</b>, it will
+    create a NavigableString for the string "penguin".
+    """   
+
+    PREFIX = ''
+    SUFFIX = ''
+
+    # We can't tell just by looking at a string whether it's contained
+    # in an XML document or an HTML document.
+
+    known_xml = None
+
+    def __new__(cls, value):
+        """Create a new NavigableString.
+
+        When unpickling a NavigableString, this method is called with
+        the string in DEFAULT_OUTPUT_ENCODING. That encoding needs to be
+        passed in to the superclass's __new__ or the superclass won't know
+        how to handle non-ASCII characters.
+        """
+        if isinstance(value, str):
+            u = str.__new__(cls, value)
+        else:
+            u = str.__new__(cls, value, DEFAULT_OUTPUT_ENCODING)
+        u.setup()
+        return u
+
+    def __copy__(self):
+        """A copy of a NavigableString has the same contents and class
+        as the original, but it is not connected to the parse tree.
+        """
+        return type(self)(self)
+
+    def __getnewargs__(self):
+        return (str(self),)
+
+    def __getattr__(self, attr):
+        """text.string gives you text. This is for backwards
+        compatibility for Navigable*String, but for CData* it lets you
+        get the string without the CData wrapper."""
+        if attr == 'string':
+            return self
+        else:
+            raise AttributeError(
+                "'%s' object has no attribute '%s'" % (
+                    self.__class__.__name__, attr))
+
+    def output_ready(self, formatter="minimal"):
+        """Run the string through the provided formatter.
+
+        :param formatter: A Formatter object, or a string naming one of the standard formatters.
+        """
+        output = self.format_string(self, formatter)
+        return self.PREFIX + output + self.SUFFIX
+
+    @property
+    def name(self):
+        """Since a NavigableString is not a Tag, it has no .name.
+
+        This property is implemented so that code like this doesn't crash
+        when run on a mixture of Tag and NavigableString objects:
+            [x.name for x in tag.children]
+        """
+        return None
+
+    @name.setter
+    def name(self, name):
+        """Prevent NavigableString.name from ever being set."""
+        raise AttributeError("A NavigableString cannot be given a name.")
+
+    
+class PreformattedString(NavigableString):
+    """A NavigableString not subject to the normal formatting rules.
+
+    This is an abstract class used for special kinds of strings such
+    as comments (the Comment class) and CDATA blocks (the CData
+    class).
+    """
+    
+    PREFIX = ''
+    SUFFIX = ''
+    
+    def output_ready(self, formatter=None):
+        """Make this string ready for output by adding any subclass-specific
+            prefix or suffix.
+
+        :param formatter: A Formatter object, or a string naming one
+            of the standard formatters. The string will be passed into the
+            Formatter, but only to trigger any side effects: the return
+            value is ignored.
+
+        :return: The string, with any subclass-specific prefix and
+           suffix added on.
+        """
+        if formatter is not None:
+            ignore = self.format_string(self, formatter)
+        return self.PREFIX + self + self.SUFFIX
+
+class CData(PreformattedString):
+    """A CDATA block."""
+    PREFIX = '<![CDATA['
+    SUFFIX = ']]>'
+
+class ProcessingInstruction(PreformattedString):
+    """A SGML processing instruction."""
+
+    PREFIX = '<?'
+    SUFFIX = '>'
+
+class XMLProcessingInstruction(ProcessingInstruction):
+    """An XML processing instruction."""
+    PREFIX = '<?'
+    SUFFIX = '?>'
+
+class Comment(PreformattedString):
+    """An HTML or XML comment."""
+    PREFIX = '<!--'
+    SUFFIX = '-->'
+
+
+class Declaration(PreformattedString):
+    """An XML declaration."""
+    PREFIX = '<?'
+    SUFFIX = '?>'
+
+
+class Doctype(PreformattedString):
+    """A document type declaration."""
+    @classmethod
+    def for_name_and_ids(cls, name, pub_id, system_id):
+        """Generate an appropriate document type declaration for a given
+        public ID and system ID.
+
+        :param name: The name of the document's root element, e.g. 'html'.
+        :param pub_id: The Formal Public Identifier for this document type,
+            e.g. '-//W3C//DTD XHTML 1.1//EN'
+        :param system_id: The system identifier for this document type,
+            e.g. 'http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd'
+
+        :return: A Doctype.
+        """
+        value = name or ''
+        if pub_id is not None:
+            value += ' PUBLIC "%s"' % pub_id
+            if system_id is not None:
+                value += ' "%s"' % system_id
+        elif system_id is not None:
+            value += ' SYSTEM "%s"' % system_id
+
+        return Doctype(value)
+
+    PREFIX = '<!DOCTYPE '
+    SUFFIX = '>\n'
+
+
+class Stylesheet(NavigableString):
+    """A NavigableString representing an stylesheet (probably
+    CSS).
+
+    Used to distinguish embedded stylesheets from textual content.
+    """
+    pass
+
+    
+class Script(NavigableString):
+    """A NavigableString representing an executable script (probably
+    Javascript).
+
+    Used to distinguish executable code from textual content.
+    """
+    pass
+
+
+class TemplateString(NavigableString):
+    """A NavigableString representing a string found inside an HTML
+    template embedded in a larger document.
+
+    Used to distinguish such strings from the main body of the document.
+    """
+    pass
+
+
+class Tag(PageElement):
+    """Represents an HTML or XML tag that is part of a parse tree, along
+    with its attributes and contents.
+
+    When Beautiful Soup parses the markup <b>penguin</b>, it will
+    create a Tag object representing the <b> tag.
+    """
+
+    def __init__(self, parser=None, builder=None, name=None, namespace=None,
+                 prefix=None, attrs=None, parent=None, previous=None,
+                 is_xml=None, sourceline=None, sourcepos=None,
+                 can_be_empty_element=None, cdata_list_attributes=None,
+                 preserve_whitespace_tags=None
+    ):
+        """Basic constructor.
+
+        :param parser: A BeautifulSoup object.
+        :param builder: A TreeBuilder.
+        :param name: The name of the tag.
+        :param namespace: The URI of this Tag's XML namespace, if any.
+        :param prefix: The prefix for this Tag's XML namespace, if any.
+        :param attrs: A dictionary of this Tag's attribute values.
+        :param parent: The PageElement to use as this Tag's parent.
+        :param previous: The PageElement that was parsed immediately before
+            this tag.
+        :param is_xml: If True, this is an XML tag. Otherwise, this is an
+            HTML tag.
+        :param sourceline: The line number where this tag was found in its
+            source document.
+        :param sourcepos: The character position within `sourceline` where this
+            tag was found.
+        :param can_be_empty_element: If True, this tag should be
+            represented as <tag/>. If False, this tag should be represented
+            as <tag></tag>.
+        :param cdata_list_attributes: A list of attributes whose values should
+            be treated as CDATA if they ever show up on this tag.
+        :param preserve_whitespace_tags: A list of tag names whose contents
+            should have their whitespace preserved.
+        """
+        if parser is None:
+            self.parser_class = None
+        else:
+            # We don't actually store the parser object: that lets extracted
+            # chunks be garbage-collected.
+            self.parser_class = parser.__class__
+        if name is None:
+            raise ValueError("No value provided for new tag's name.")
+        self.name = name
+        self.namespace = namespace
+        self.prefix = prefix
+        if ((not builder or builder.store_line_numbers)
+            and (sourceline is not None or sourcepos is not None)):
+            self.sourceline = sourceline
+            self.sourcepos = sourcepos        
+        if attrs is None:
+            attrs = {}
+        elif attrs:
+            if builder is not None and builder.cdata_list_attributes:
+                attrs = builder._replace_cdata_list_attribute_values(
+                    self.name, attrs)
+            else:
+                attrs = dict(attrs)
+        else:
+            attrs = dict(attrs)
+
+        # If possible, determine ahead of time whether this tag is an
+        # XML tag.
+        if builder:
+            self.known_xml = builder.is_xml
+        else:
+            self.known_xml = is_xml
+        self.attrs = attrs
+        self.contents = []
+        self.setup(parent, previous)
+        self.hidden = False
+
+        if builder is None:
+            # In the absence of a TreeBuilder, use whatever values were
+            # passed in here. They're probably None, unless this is a copy of some
+            # other tag.
+            self.can_be_empty_element = can_be_empty_element
+            self.cdata_list_attributes = cdata_list_attributes
+            self.preserve_whitespace_tags = preserve_whitespace_tags
+        else:
+            # Set up any substitutions for this tag, such as the charset in a META tag.
+            builder.set_up_substitutions(self)
+
+            # Ask the TreeBuilder whether this tag might be an empty-element tag.
+            self.can_be_empty_element = builder.can_be_empty_element(name)
+
+            # Keep track of the list of attributes of this tag that
+            # might need to be treated as a list.
+            #
+            # For performance reasons, we store the whole data structure
+            # rather than asking the question of every tag. Asking would
+            # require building a new data structure every time, and
+            # (unlike can_be_empty_element), we almost never need
+            # to check this.
+            self.cdata_list_attributes = builder.cdata_list_attributes
+
+            # Keep track of the names that might cause this tag to be treated as a
+            # whitespace-preserved tag.
+            self.preserve_whitespace_tags = builder.preserve_whitespace_tags
+            
+    parserClass = _alias("parser_class")  # BS3
+
+    def __copy__(self):
+        """A copy of a Tag is a new Tag, unconnected to the parse tree.
+        Its contents are a copy of the old Tag's contents.
+        """
+        clone = type(self)(
+            None, self.builder, self.name, self.namespace,
+            self.prefix, self.attrs, is_xml=self._is_xml,
+            sourceline=self.sourceline, sourcepos=self.sourcepos,
+            can_be_empty_element=self.can_be_empty_element,
+            cdata_list_attributes=self.cdata_list_attributes,
+            preserve_whitespace_tags=self.preserve_whitespace_tags
+        )
+        for attr in ('can_be_empty_element', 'hidden'):
+            setattr(clone, attr, getattr(self, attr))
+        for child in self.contents:
+            clone.append(child.__copy__())
+        return clone
+
+    @property
+    def is_empty_element(self):
+        """Is this tag an empty-element tag? (aka a self-closing tag)
+
+        A tag that has contents is never an empty-element tag.
+
+        A tag that has no contents may or may not be an empty-element
+        tag. It depends on the builder used to create the tag. If the
+        builder has a designated list of empty-element tags, then only
+        a tag whose name shows up in that list is considered an
+        empty-element tag.
+
+        If the builder has no designated list of empty-element tags,
+        then any tag with no contents is an empty-element tag.
+        """
+        return len(self.contents) == 0 and self.can_be_empty_element
+    isSelfClosing = is_empty_element  # BS3
+
+    @property
+    def string(self):
+        """Convenience property to get the single string within this
+        PageElement.
+
+        TODO It might make sense to have NavigableString.string return
+        itself.
+
+        :return: If this element has a single string child, return
+         value is that string. If this element has one child tag,
+         return value is the 'string' attribute of the child tag,
+         recursively. If this element is itself a string, has no
+         children, or has more than one child, return value is None.
+        """
+        if len(self.contents) != 1:
+            return None
+        child = self.contents[0]
+        if isinstance(child, NavigableString):
+            return child
+        return child.string
+
+    @string.setter
+    def string(self, string):
+        """Replace this PageElement's contents with `string`."""
+        self.clear()
+        self.append(string.__class__(string))
+
+    def _all_strings(self, strip=False, types=(NavigableString, CData)):
+        """Yield all strings of certain classes, possibly stripping them.
+
+        :param strip: If True, all strings will be stripped before being
+            yielded.
+
+        :types: A tuple of NavigableString subclasses. Any strings of
+            a subclass not found in this list will be ignored. By
+            default, this means only NavigableString and CData objects
+            will be considered. So no comments, processing instructions,
+            etc.
+
+        :yield: A sequence of strings.
+        """
+        for descendant in self.descendants:
+            if (
+                (types is None and not isinstance(descendant, NavigableString))
+                or
+                (types is not None and type(descendant) not in types)):
+                continue
+            if strip:
+                descendant = descendant.strip()
+                if len(descendant) == 0:
+                    continue
+            yield descendant
+
+    strings = property(_all_strings)
+
+    @property
+    def stripped_strings(self):
+        """Yield all strings in the document, stripping them first.
+
+        :yield: A sequence of stripped strings.
+        """
+        for string in self._all_strings(True):
+            yield string
+
+    def get_text(self, separator="", strip=False,
+                 types=(NavigableString, CData)):
+        """Get all child strings, concatenated using the given separator.
+
+        :param separator: Strings will be concatenated using this separator.
+
+        :param strip: If True, strings will be stripped before being
+            concatenated.
+
+        :types: A tuple of NavigableString subclasses. Any strings of
+            a subclass not found in this list will be ignored. By
+            default, this means only NavigableString and CData objects
+            will be considered. So no comments, processing instructions,
+            stylesheets, etc.
+
+        :return: A string.
+        """
+        return separator.join([s for s in self._all_strings(
+                    strip, types=types)])
+    getText = get_text
+    text = property(get_text)
+
+    def decompose(self):
+        """Recursively destroys this PageElement and its children.
+
+        This element will be removed from the tree and wiped out; so
+        will everything beneath it.
+
+        The behavior of a decomposed PageElement is undefined and you
+        should never use one for anything, but if you need to _check_
+        whether an element has been decomposed, you can use the
+        `decomposed` property.
+        """
+        self.extract()
+        i = self
+        while i is not None:
+            n = i.next_element
+            i.__dict__.clear()
+            i.contents = []
+            i._decomposed = True
+            i = n
+           
+    def clear(self, decompose=False):
+        """Wipe out all children of this PageElement by calling extract()
+           on them.
+
+        :param decompose: If this is True, decompose() (a more
+            destructive method) will be called instead of extract().
+        """
+        if decompose:
+            for element in self.contents[:]:
+                if isinstance(element, Tag):
+                    element.decompose()
+                else:
+                    element.extract()
+        else:
+            for element in self.contents[:]:
+                element.extract()
+
+    def smooth(self):
+        """Smooth out this element's children by consolidating consecutive
+        strings.
+
+        This makes pretty-printed output look more natural following a
+        lot of operations that modified the tree.
+        """
+        # Mark the first position of every pair of children that need
+        # to be consolidated.  Do this rather than making a copy of
+        # self.contents, since in most cases very few strings will be
+        # affected.
+        marked = []
+        for i, a in enumerate(self.contents):
+            if isinstance(a, Tag):
+                # Recursively smooth children.
+                a.smooth()
+            if i == len(self.contents)-1:
+                # This is the last item in .contents, and it's not a
+                # tag. There's no chance it needs any work.
+                continue
+            b = self.contents[i+1]
+            if (isinstance(a, NavigableString)
+                and isinstance(b, NavigableString)
+                and not isinstance(a, PreformattedString)
+                and not isinstance(b, PreformattedString)
+            ):
+                marked.append(i)
+
+        # Go over the marked positions in reverse order, so that
+        # removing items from .contents won't affect the remaining
+        # positions.
+        for i in reversed(marked):
+            a = self.contents[i]
+            b = self.contents[i+1]
+            b.extract()
+            n = NavigableString(a+b)
+            a.replace_with(n)
+
+    def index(self, element):
+        """Find the index of a child by identity, not value.
+
+        Avoids issues with tag.contents.index(element) getting the
+        index of equal elements.
+
+        :param element: Look for this PageElement in `self.contents`.
+        """
+        for i, child in enumerate(self.contents):
+            if child is element:
+                return i
+        raise ValueError("Tag.index: element not in tag")
+
+    def get(self, key, default=None):
+        """Returns the value of the 'key' attribute for the tag, or
+        the value given for 'default' if it doesn't have that
+        attribute."""
+        return self.attrs.get(key, default)
+
+    def get_attribute_list(self, key, default=None):
+        """The same as get(), but always returns a list.
+
+        :param key: The attribute to look for.
+        :param default: Use this value if the attribute is not present
+            on this PageElement.
+        :return: A list of values, probably containing only a single
+            value.
+        """
+        value = self.get(key, default)
+        if not isinstance(value, list):
+            value = [value]
+        return value
+    
+    def has_attr(self, key):
+        """Does this PageElement have an attribute with the given name?"""
+        return key in self.attrs
+
+    def __hash__(self):
+        return str(self).__hash__()
+
+    def __getitem__(self, key):
+        """tag[key] returns the value of the 'key' attribute for the Tag,
+        and throws an exception if it's not there."""
+        return self.attrs[key]
+
+    def __iter__(self):
+        "Iterating over a Tag iterates over its contents."
+        return iter(self.contents)
+
+    def __len__(self):
+        "The length of a Tag is the length of its list of contents."
+        return len(self.contents)
+
+    def __contains__(self, x):
+        return x in self.contents
+
+    def __bool__(self):
+        "A tag is non-None even if it has no contents."
+        return True
+
+    def __setitem__(self, key, value):
+        """Setting tag[key] sets the value of the 'key' attribute for the
+        tag."""
+        self.attrs[key] = value
+
+    def __delitem__(self, key):
+        "Deleting tag[key] deletes all 'key' attributes for the tag."
+        self.attrs.pop(key, None)
+
+    def __call__(self, *args, **kwargs):
+        """Calling a Tag like a function is the same as calling its
+        find_all() method. Eg. tag('a') returns a list of all the A tags
+        found within this tag."""
+        return self.find_all(*args, **kwargs)
+
+    def __getattr__(self, tag):
+        """Calling tag.subtag is the same as calling tag.find(name="subtag")"""
+        #print("Getattr %s.%s" % (self.__class__, tag))
+        if len(tag) > 3 and tag.endswith('Tag'):
+            # BS3: soup.aTag -> "soup.find("a")
+            tag_name = tag[:-3]
+            warnings.warn(
+                '.%(name)sTag is deprecated, use .find("%(name)s") instead. If you really were looking for a tag called %(name)sTag, use .find("%(name)sTag")' % dict(
+                    name=tag_name
+                )
+            )
+            return self.find(tag_name)
+        # We special case contents to avoid recursion.
+        elif not tag.startswith("__") and not tag == "contents":
+            return self.find(tag)
+        raise AttributeError(
+            "'%s' object has no attribute '%s'" % (self.__class__, tag))
+
+    def __eq__(self, other):
+        """Returns true iff this Tag has the same name, the same attributes,
+        and the same contents (recursively) as `other`."""
+        if self is other:
+            return True
+        if (not hasattr(other, 'name') or
+            not hasattr(other, 'attrs') or
+            not hasattr(other, 'contents') or
+            self.name != other.name or
+            self.attrs != other.attrs or
+            len(self) != len(other)):
+            return False
+        for i, my_child in enumerate(self.contents):
+            if my_child != other.contents[i]:
+                return False
+        return True
+
+    def __ne__(self, other):
+        """Returns true iff this Tag is not identical to `other`,
+        as defined in __eq__."""
+        return not self == other
+
+    def __repr__(self, encoding="unicode-escape"):
+        """Renders this PageElement as a string.
+
+        :param encoding: The encoding to use (Python 2 only).
+        :return: Under Python 2, a bytestring; under Python 3,
+            a Unicode string.
+        """
+        if PY3K:
+            # "The return value must be a string object", i.e. Unicode
+            return self.decode()
+        else:
+            # "The return value must be a string object", i.e. a bytestring.
+            # By convention, the return value of __repr__ should also be
+            # an ASCII string.
+            return self.encode(encoding)
+
+    def __unicode__(self):
+        """Renders this PageElement as a Unicode string."""
+        return self.decode()
+
+    def __str__(self):
+        """Renders this PageElement as a generic string.
+
+        :return: Under Python 2, a UTF-8 bytestring; under Python 3,
+            a Unicode string.        
+        """
+        if PY3K:
+            return self.decode()
+        else:
+            return self.encode()
+
+    if PY3K:
+        __str__ = __repr__ = __unicode__
+
+    def encode(self, encoding=DEFAULT_OUTPUT_ENCODING,
+               indent_level=None, formatter="minimal",
+               errors="xmlcharrefreplace"):
+        """Render a bytestring representation of this PageElement and its
+        contents.
+
+        :param encoding: The destination encoding.
+        :param indent_level: Each line of the rendering will be
+            indented this many spaces. Used internally in
+            recursive calls while pretty-printing.
+        :param formatter: A Formatter object, or a string naming one of
+            the standard formatters.
+        :param errors: An error handling strategy such as
+            'xmlcharrefreplace'. This value is passed along into
+            encode() and its value should be one of the constants
+            defined by Python.
+        :return: A bytestring.
+
+        """
+        # Turn the data structure into Unicode, then encode the
+        # Unicode.
+        u = self.decode(indent_level, encoding, formatter)
+        return u.encode(encoding, errors)
+
+    def decode(self, indent_level=None,
+               eventual_encoding=DEFAULT_OUTPUT_ENCODING,
+               formatter="minimal"):
+        """Render a Unicode representation of this PageElement and its
+        contents.
+
+        :param indent_level: Each line of the rendering will be
+             indented this many spaces. Used internally in
+             recursive calls while pretty-printing.
+        :param eventual_encoding: The tag is destined to be
+            encoded into this encoding. This method is _not_
+            responsible for performing that encoding. This information
+            is passed in so that it can be substituted in if the
+            document contains a <META> tag that mentions the document's
+            encoding.
+        :param formatter: A Formatter object, or a string naming one of
+            the standard formatters.
+        """
+
+        # First off, turn a non-Formatter `formatter` into a Formatter
+        # object. This will stop the lookup from happening over and
+        # over again.
+        if not isinstance(formatter, Formatter):
+            formatter = self.formatter_for_name(formatter)
+        attributes = formatter.attributes(self)
+        attrs = []
+        for key, val in attributes:
+            if val is None:
+                decoded = key
+            else:
+                if isinstance(val, list) or isinstance(val, tuple):
+                    val = ' '.join(val)
+                elif not isinstance(val, str):
+                    val = str(val)
+                elif (
+                        isinstance(val, AttributeValueWithCharsetSubstitution)
+                        and eventual_encoding is not None
+                ):
+                    val = val.encode(eventual_encoding)
+
+                text = formatter.attribute_value(val)
+                decoded = (
+                    str(key) + '='
+                    + formatter.quoted_attribute_value(text))
+            attrs.append(decoded)
+        close = ''
+        closeTag = ''
+
+        prefix = ''
+        if self.prefix:
+            prefix = self.prefix + ":"
+
+        if self.is_empty_element:
+            close = formatter.void_element_close_prefix or ''
+        else:
+            closeTag = '</%s%s>' % (prefix, self.name)
+
+        pretty_print = self._should_pretty_print(indent_level)
+        space = ''
+        indent_space = ''
+        if indent_level is not None:
+            indent_space = (' ' * (indent_level - 1))
+        if pretty_print:
+            space = indent_space
+            indent_contents = indent_level + 1
+        else:
+            indent_contents = None
+        contents = self.decode_contents(
+            indent_contents, eventual_encoding, formatter
+        )
+
+        if self.hidden:
+            # This is the 'document root' object.
+            s = contents
+        else:
+            s = []
+            attribute_string = ''
+            if attrs:
+                attribute_string = ' ' + ' '.join(attrs)
+            if indent_level is not None:
+                # Even if this particular tag is not pretty-printed,
+                # we should indent up to the start of the tag.
+                s.append(indent_space)
+            s.append('<%s%s%s%s>' % (
+                    prefix, self.name, attribute_string, close))
+            if pretty_print:
+                s.append("\n")
+            s.append(contents)
+            if pretty_print and contents and contents[-1] != "\n":
+                s.append("\n")
+            if pretty_print and closeTag:
+                s.append(space)
+            s.append(closeTag)
+            if indent_level is not None and closeTag and self.next_sibling:
+                # Even if this particular tag is not pretty-printed,
+                # we're now done with the tag, and we should add a
+                # newline if appropriate.
+                s.append("\n")
+            s = ''.join(s)
+        return s
+
+    def _should_pretty_print(self, indent_level):
+        """Should this tag be pretty-printed?
+
+        Most of them should, but some (such as <pre> in HTML
+        documents) should not.
+        """
+        return (
+            indent_level is not None
+            and (
+                not self.preserve_whitespace_tags
+                or self.name not in self.preserve_whitespace_tags
+            )
+        )
+
+    def prettify(self, encoding=None, formatter="minimal"):
+        """Pretty-print this PageElement as a string.
+
+        :param encoding: The eventual encoding of the string. If this is None,
+            a Unicode string will be returned.
+        :param formatter: A Formatter object, or a string naming one of
+            the standard formatters.
+        :return: A Unicode string (if encoding==None) or a bytestring 
+            (otherwise).
+        """
+        if encoding is None:
+            return self.decode(True, formatter=formatter)
+        else:
+            return self.encode(encoding, True, formatter=formatter)
+
+    def decode_contents(self, indent_level=None,
+                       eventual_encoding=DEFAULT_OUTPUT_ENCODING,
+                       formatter="minimal"):
+        """Renders the contents of this tag as a Unicode string.
+
+        :param indent_level: Each line of the rendering will be
+           indented this many spaces. Used internally in
+           recursive calls while pretty-printing.
+
+        :param eventual_encoding: The tag is destined to be
+           encoded into this encoding. decode_contents() is _not_
+           responsible for performing that encoding. This information
+           is passed in so that it can be substituted in if the
+           document contains a <META> tag that mentions the document's
+           encoding.
+
+        :param formatter: A Formatter object, or a string naming one of
+            the standard Formatters.
+        """
+        # First off, turn a string formatter into a Formatter object. This
+        # will stop the lookup from happening over and over again.
+        if not isinstance(formatter, Formatter):
+            formatter = self.formatter_for_name(formatter)
+
+        pretty_print = (indent_level is not None)
+        s = []
+        for c in self:
+            text = None
+            if isinstance(c, NavigableString):
+                text = c.output_ready(formatter)
+            elif isinstance(c, Tag):
+                s.append(c.decode(indent_level, eventual_encoding,
+                                  formatter))
+            preserve_whitespace = (
+                self.preserve_whitespace_tags and self.name in self.preserve_whitespace_tags
+            )
+            if text and indent_level and not preserve_whitespace:
+                text = text.strip()
+            if text:
+                if pretty_print and not preserve_whitespace:
+                    s.append(" " * (indent_level - 1))
+                s.append(text)
+                if pretty_print and not preserve_whitespace:
+                    s.append("\n")
+        return ''.join(s)
+       
+    def encode_contents(
+        self, indent_level=None, encoding=DEFAULT_OUTPUT_ENCODING,
+        formatter="minimal"):
+        """Renders the contents of this PageElement as a bytestring.
+
+        :param indent_level: Each line of the rendering will be
+           indented this many spaces. Used internally in
+           recursive calls while pretty-printing.
+
+        :param eventual_encoding: The bytestring will be in this encoding.
+
+        :param formatter: A Formatter object, or a string naming one of
+            the standard Formatters.
+
+        :return: A bytestring.
+        """
+        contents = self.decode_contents(indent_level, encoding, formatter)
+        return contents.encode(encoding)
+
+    # Old method for BS3 compatibility
+    def renderContents(self, encoding=DEFAULT_OUTPUT_ENCODING,
+                       prettyPrint=False, indentLevel=0):
+        """Deprecated method for BS3 compatibility."""
+        if not prettyPrint:
+            indentLevel = None
+        return self.encode_contents(
+            indent_level=indentLevel, encoding=encoding)
+
+    #Soup methods
+
+    def find(self, name=None, attrs={}, recursive=True, text=None,
+             **kwargs):
+        """Look in the children of this PageElement and find the first
+        PageElement that matches the given criteria.
+
+        All find_* methods take a common set of arguments. See the online
+        documentation for detailed explanations.
+
+        :param name: A filter on tag name.
+        :param attrs: A dictionary of filters on attribute values.
+        :param recursive: If this is True, find() will perform a
+            recursive search of this PageElement's children. Otherwise,
+            only the direct children will be considered.
+        :param limit: Stop looking after finding this many results.
+        :kwargs: A dictionary of filters on attribute values.
+        :return: A PageElement.
+        :rtype: bs4.element.Tag | bs4.element.NavigableString
+        """
+        r = None
+        l = self.find_all(name, attrs, recursive, text, 1, **kwargs)
+        if l:
+            r = l[0]
+        return r
+    findChild = find #BS2
+
+    def find_all(self, name=None, attrs={}, recursive=True, text=None,
+                 limit=None, **kwargs):
+        """Look in the children of this PageElement and find all
+        PageElements that match the given criteria.
+
+        All find_* methods take a common set of arguments. See the online
+        documentation for detailed explanations.
+
+        :param name: A filter on tag name.
+        :param attrs: A dictionary of filters on attribute values.
+        :param recursive: If this is True, find_all() will perform a
+            recursive search of this PageElement's children. Otherwise,
+            only the direct children will be considered.
+        :param limit: Stop looking after finding this many results.
+        :kwargs: A dictionary of filters on attribute values.
+        :return: A ResultSet of PageElements.
+        :rtype: bs4.element.ResultSet
+        """
+        generator = self.descendants
+        if not recursive:
+            generator = self.children
+        return self._find_all(name, attrs, text, limit, generator, **kwargs)
+    findAll = find_all       # BS3
+    findChildren = find_all  # BS2
+
+    #Generator methods
+    @property
+    def children(self):
+        """Iterate over all direct children of this PageElement.
+
+        :yield: A sequence of PageElements.
+        """
+        # return iter() to make the purpose of the method clear
+        return iter(self.contents)  # XXX This seems to be untested.
+
+    @property
+    def descendants(self):
+        """Iterate over all children of this PageElement in a
+        breadth-first sequence.
+
+        :yield: A sequence of PageElements.
+        """
+        if not len(self.contents):
+            return
+        stopNode = self._last_descendant().next_element
+        current = self.contents[0]
+        while current is not stopNode:
+            yield current
+            current = current.next_element
+
+    # CSS selector code
+    def select_one(self, selector, namespaces=None, **kwargs):
+        """Perform a CSS selection operation on the current element.
+
+        :param selector: A CSS selector.
+
+        :param namespaces: A dictionary mapping namespace prefixes
+           used in the CSS selector to namespace URIs. By default,
+           Beautiful Soup will use the prefixes it encountered while
+           parsing the document.
+
+        :param kwargs: Keyword arguments to be passed into SoupSieve's 
+           soupsieve.select() method.
+
+        :return: A Tag.
+        :rtype: bs4.element.Tag
+        """
+        value = self.select(selector, namespaces, 1, **kwargs)
+        if value:
+            return value[0]
+        return None
+
+    def select(self, selector, namespaces=None, limit=None, **kwargs):
+        """Perform a CSS selection operation on the current element.
+
+        This uses the SoupSieve library.
+
+        :param selector: A string containing a CSS selector.
+
+        :param namespaces: A dictionary mapping namespace prefixes
+           used in the CSS selector to namespace URIs. By default,
+           Beautiful Soup will use the prefixes it encountered while
+           parsing the document.
+
+        :param limit: After finding this number of results, stop looking.
+
+        :param kwargs: Keyword arguments to be passed into SoupSieve's 
+           soupsieve.select() method.
+
+        :return: A ResultSet of Tags.
+        :rtype: bs4.element.ResultSet
+        """
+        if namespaces is None:
+            namespaces = self._namespaces
+        
+        if limit is None:
+            limit = 0
+        if soupsieve is None:
+            raise NotImplementedError(
+                "Cannot execute CSS selectors because the soupsieve package is not installed."
+            )
+            
+        results = soupsieve.select(selector, self, namespaces, limit, **kwargs)
+
+        # We do this because it's more consistent and because
+        # ResultSet.__getattr__ has a helpful error message.
+        return ResultSet(None, results)
+
+    # Old names for backwards compatibility
+    def childGenerator(self):
+        """Deprecated generator."""
+        return self.children
+
+    def recursiveChildGenerator(self):
+        """Deprecated generator."""
+        return self.descendants
+
+    def has_key(self, key):
+        """Deprecated method. This was kind of misleading because has_key()
+        (attributes) was different from __in__ (contents).
+
+        has_key() is gone in Python 3, anyway.
+        """
+        warnings.warn('has_key is deprecated. Use has_attr("%s") instead.' % (
+                key))
+        return self.has_attr(key)
+
+# Next, a couple classes to represent queries and their results.
+class SoupStrainer(object):
+    """Encapsulates a number of ways of matching a markup element (tag or
+    string).
+
+    This is primarily used to underpin the find_* methods, but you can
+    create one yourself and pass it in as `parse_only` to the
+    `BeautifulSoup` constructor, to parse a subset of a large
+    document.
+    """
+
+    def __init__(self, name=None, attrs={}, text=None, **kwargs):
+        """Constructor.
+
+        The SoupStrainer constructor takes the same arguments passed
+        into the find_* methods. See the online documentation for
+        detailed explanations.
+
+        :param name: A filter on tag name.
+        :param attrs: A dictionary of filters on attribute values.
+        :param text: A filter for a NavigableString with specific text.
+        :kwargs: A dictionary of filters on attribute values.
+        """        
+        self.name = self._normalize_search_value(name)
+        if not isinstance(attrs, dict):
+            # Treat a non-dict value for attrs as a search for the 'class'
+            # attribute.
+            kwargs['class'] = attrs
+            attrs = None
+
+        if 'class_' in kwargs:
+            # Treat class_="foo" as a search for the 'class'
+            # attribute, overriding any non-dict value for attrs.
+            kwargs['class'] = kwargs['class_']
+            del kwargs['class_']
+
+        if kwargs:
+            if attrs:
+                attrs = attrs.copy()
+                attrs.update(kwargs)
+            else:
+                attrs = kwargs
+        normalized_attrs = {}
+        for key, value in list(attrs.items()):
+            normalized_attrs[key] = self._normalize_search_value(value)
+
+        self.attrs = normalized_attrs
+        self.text = self._normalize_search_value(text)
+
+    def _normalize_search_value(self, value):
+        # Leave it alone if it's a Unicode string, a callable, a
+        # regular expression, a boolean, or None.
+        if (isinstance(value, str) or isinstance(value, Callable) or hasattr(value, 'match')
+            or isinstance(value, bool) or value is None):
+            return value
+
+        # If it's a bytestring, convert it to Unicode, treating it as UTF-8.
+        if isinstance(value, bytes):
+            return value.decode("utf8")
+
+        # If it's listlike, convert it into a list of strings.
+        if hasattr(value, '__iter__'):
+            new_value = []
+            for v in value:
+                if (hasattr(v, '__iter__') and not isinstance(v, bytes)
+                    and not isinstance(v, str)):
+                    # This is almost certainly the user's mistake. In the
+                    # interests of avoiding infinite loops, we'll let
+                    # it through as-is rather than doing a recursive call.
+                    new_value.append(v)
+                else:
+                    new_value.append(self._normalize_search_value(v))
+            return new_value
+
+        # Otherwise, convert it into a Unicode string.
+        # The unicode(str()) thing is so this will do the same thing on Python 2
+        # and Python 3.
+        return str(str(value))
+
+    def __str__(self):
+        """A human-readable representation of this SoupStrainer."""
+        if self.text:
+            return self.text
+        else:
+            return "%s|%s" % (self.name, self.attrs)
+
+    def search_tag(self, markup_name=None, markup_attrs={}):
+        """Check whether a Tag with the given name and attributes would
+        match this SoupStrainer.
+
+        Used prospectively to decide whether to even bother creating a Tag
+        object.
+
+        :param markup_name: A tag name as found in some markup.
+        :param markup_attrs: A dictionary of attributes as found in some markup.
+
+        :return: True if the prospective tag would match this SoupStrainer;
+            False otherwise.
+        """
+        found = None
+        markup = None
+        if isinstance(markup_name, Tag):
+            markup = markup_name
+            markup_attrs = markup
+
+        if isinstance(self.name, str):
+            # Optimization for a very common case where the user is
+            # searching for a tag with one specific name, and we're
+            # looking at a tag with a different name.
+            if markup and not markup.prefix and self.name != markup.name:
+                 return False
+            
+        call_function_with_tag_data = (
+            isinstance(self.name, Callable)
+            and not isinstance(markup_name, Tag))
+
+        if ((not self.name)
+            or call_function_with_tag_data
+            or (markup and self._matches(markup, self.name))
+            or (not markup and self._matches(markup_name, self.name))):
+            if call_function_with_tag_data:
+                match = self.name(markup_name, markup_attrs)
+            else:
+                match = True
+                markup_attr_map = None
+                for attr, match_against in list(self.attrs.items()):
+                    if not markup_attr_map:
+                        if hasattr(markup_attrs, 'get'):
+                            markup_attr_map = markup_attrs
+                        else:
+                            markup_attr_map = {}
+                            for k, v in markup_attrs:
+                                markup_attr_map[k] = v
+                    attr_value = markup_attr_map.get(attr)
+                    if not self._matches(attr_value, match_against):
+                        match = False
+                        break
+            if match:
+                if markup:
+                    found = markup
+                else:
+                    found = markup_name
+        if found and self.text and not self._matches(found.string, self.text):
+            found = None
+        return found
+
+    # For BS3 compatibility.
+    searchTag = search_tag
+
+    def search(self, markup):
+        """Find all items in `markup` that match this SoupStrainer.
+
+        Used by the core _find_all() method, which is ultimately
+        called by all find_* methods.
+
+        :param markup: A PageElement or a list of them.
+        """
+        # print('looking for %s in %s' % (self, markup))
+        found = None
+        # If given a list of items, scan it for a text element that
+        # matches.
+        if hasattr(markup, '__iter__') and not isinstance(markup, (Tag, str)):
+            for element in markup:
+                if isinstance(element, NavigableString) \
+                       and self.search(element):
+                    found = element
+                    break
+        # If it's a Tag, make sure its name or attributes match.
+        # Don't bother with Tags if we're searching for text.
+        elif isinstance(markup, Tag):
+            if not self.text or self.name or self.attrs:
+                found = self.search_tag(markup)
+        # If it's text, make sure the text matches.
+        elif isinstance(markup, NavigableString) or \
+                 isinstance(markup, str):
+            if not self.name and not self.attrs and self._matches(markup, self.text):
+                found = markup
+        else:
+            raise Exception(
+                "I don't know how to match against a %s" % markup.__class__)
+        return found
+
+    def _matches(self, markup, match_against, already_tried=None):
+        # print(u"Matching %s against %s" % (markup, match_against))
+        result = False
+        if isinstance(markup, list) or isinstance(markup, tuple):
+            # This should only happen when searching a multi-valued attribute
+            # like 'class'.
+            for item in markup:
+                if self._matches(item, match_against):
+                    return True
+            # We didn't match any particular value of the multivalue
+            # attribute, but maybe we match the attribute value when
+            # considered as a string.
+            if self._matches(' '.join(markup), match_against):
+                return True
+            return False
+        
+        if match_against is True:
+            # True matches any non-None value.
+            return markup is not None
+
+        if isinstance(match_against, Callable):
+            return match_against(markup)
+
+        # Custom callables take the tag as an argument, but all
+        # other ways of matching match the tag name as a string.
+        original_markup = markup
+        if isinstance(markup, Tag):
+            markup = markup.name
+
+        # Ensure that `markup` is either a Unicode string, or None.
+        markup = self._normalize_search_value(markup)
+
+        if markup is None:
+            # None matches None, False, an empty string, an empty list, and so on.
+            return not match_against
+
+        if (hasattr(match_against, '__iter__')
+            and not isinstance(match_against, str)):
+            # We're asked to match against an iterable of items.
+            # The markup must be match at least one item in the
+            # iterable. We'll try each one in turn.
+            #
+            # To avoid infinite recursion we need to keep track of
+            # items we've already seen.
+            if not already_tried:
+                already_tried = set()
+            for item in match_against:
+                if item.__hash__:
+                    key = item
+                else:
+                    key = id(item)
+                if key in already_tried:
+                    continue
+                else:
+                    already_tried.add(key)
+                    if self._matches(original_markup, item, already_tried):
+                        return True
+            else:
+                return False
+        
+        # Beyond this point we might need to run the test twice: once against
+        # the tag's name and once against its prefixed name.
+        match = False
+        
+        if not match and isinstance(match_against, str):
+            # Exact string match
+            match = markup == match_against
+
+        if not match and hasattr(match_against, 'search'):
+            # Regexp match
+            return match_against.search(markup)
+
+        if (not match
+            and isinstance(original_markup, Tag)
+            and original_markup.prefix):
+            # Try the whole thing again with the prefixed tag name.
+            return self._matches(
+                original_markup.prefix + ':' + original_markup.name, match_against
+            )
+
+        return match
+
+
+class ResultSet(list):
+    """A ResultSet is just a list that keeps track of the SoupStrainer
+    that created it."""
+    def __init__(self, source, result=()):
+        """Constructor.
+
+        :param source: A SoupStrainer.
+        :param result: A list of PageElements.
+        """
+        super(ResultSet, self).__init__(result)
+        self.source = source
+
+    def __getattr__(self, key):
+        """Raise a helpful exception to explain a common code fix."""
+        raise AttributeError(
+            "ResultSet object has no attribute '%s'. You're probably treating a list of elements like a single element. Did you call find_all() when you meant to call find()?" % key
+        )
Index: latest/Lib/site-packages/bs4/formatter.py
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/latest/Lib/site-packages/bs4/formatter.py b/latest/Lib/site-packages/bs4/formatter.py
new file mode 100644
--- /dev/null	(date 1616411342097)
+++ b/latest/Lib/site-packages/bs4/formatter.py	(date 1616411342097)
@@ -0,0 +1,152 @@
+from bs4.dammit import EntitySubstitution
+
+class Formatter(EntitySubstitution):
+    """Describes a strategy to use when outputting a parse tree to a string.
+
+    Some parts of this strategy come from the distinction between
+    HTML4, HTML5, and XML. Others are configurable by the user.
+
+    Formatters are passed in as the `formatter` argument to methods
+    like `PageElement.encode`. Most people won't need to think about
+    formatters, and most people who need to think about them can pass
+    in one of these predefined strings as `formatter` rather than
+    making a new Formatter object:
+
+    For HTML documents:
+     * 'html' - HTML entity substitution for generic HTML documents. (default)
+     * 'html5' - HTML entity substitution for HTML5 documents.
+     * 'minimal' - Only make the substitutions necessary to guarantee
+                   valid HTML.
+     * None - Do not perform any substitution. This will be faster
+              but may result in invalid markup.
+
+    For XML documents:
+     * 'html' - Entity substitution for XHTML documents.
+     * 'minimal' - Only make the substitutions necessary to guarantee
+                   valid XML. (default)
+     * None - Do not perform any substitution. This will be faster
+              but may result in invalid markup.
+    """
+    # Registries of XML and HTML formatters.
+    XML_FORMATTERS = {}
+    HTML_FORMATTERS = {}
+
+    HTML = 'html'
+    XML = 'xml'
+
+    HTML_DEFAULTS = dict(
+        cdata_containing_tags=set(["script", "style"]),
+    )
+
+    def _default(self, language, value, kwarg):
+        if value is not None:
+            return value
+        if language == self.XML:
+            return set()
+        return self.HTML_DEFAULTS[kwarg]
+
+    def __init__(
+            self, language=None, entity_substitution=None,
+            void_element_close_prefix='/', cdata_containing_tags=None,
+    ):
+        """Constructor.
+
+        :param language: This should be Formatter.XML if you are formatting
+           XML markup and Formatter.HTML if you are formatting HTML markup.
+
+        :param entity_substitution: A function to call to replace special
+           characters with XML/HTML entities. For examples, see 
+           bs4.dammit.EntitySubstitution.substitute_html and substitute_xml.
+        :param void_element_close_prefix: By default, void elements
+           are represented as <tag/> (XML rules) rather than <tag>
+           (HTML rules). To get <tag>, pass in the empty string.
+        :param cdata_containing_tags: The list of tags that are defined
+           as containing CDATA in this dialect. For example, in HTML,
+           <script> and <style> tags are defined as containing CDATA,
+           and their contents should not be formatted.
+        """
+        self.language = language
+        self.entity_substitution = entity_substitution
+        self.void_element_close_prefix = void_element_close_prefix
+        self.cdata_containing_tags = self._default(
+            language, cdata_containing_tags, 'cdata_containing_tags'
+        )
+            
+    def substitute(self, ns):
+        """Process a string that needs to undergo entity substitution.
+        This may be a string encountered in an attribute value or as
+        text.
+
+        :param ns: A string.
+        :return: A string with certain characters replaced by named
+           or numeric entities.
+        """
+        if not self.entity_substitution:
+            return ns
+        from .element import NavigableString
+        if (isinstance(ns, NavigableString)
+            and ns.parent is not None
+            and ns.parent.name in self.cdata_containing_tags):
+            # Do nothing.
+            return ns
+        # Substitute.
+        return self.entity_substitution(ns)
+
+    def attribute_value(self, value):
+        """Process the value of an attribute.
+
+        :param ns: A string.
+        :return: A string with certain characters replaced by named
+           or numeric entities.
+        """
+        return self.substitute(value)
+    
+    def attributes(self, tag):
+        """Reorder a tag's attributes however you want.
+        
+        By default, attributes are sorted alphabetically. This makes
+        behavior consistent between Python 2 and Python 3, and preserves
+        backwards compatibility with older versions of Beautiful Soup.
+        """
+        if tag.attrs is None:
+            return []
+        return sorted(tag.attrs.items())
+
+   
+class HTMLFormatter(Formatter):
+    """A generic Formatter for HTML."""
+    REGISTRY = {}
+    def __init__(self, *args, **kwargs):
+        return super(HTMLFormatter, self).__init__(self.HTML, *args, **kwargs)
+
+    
+class XMLFormatter(Formatter):
+    """A generic Formatter for XML."""
+    REGISTRY = {}
+    def __init__(self, *args, **kwargs):
+        return super(XMLFormatter, self).__init__(self.XML, *args, **kwargs)
+
+
+# Set up aliases for the default formatters.
+HTMLFormatter.REGISTRY['html'] = HTMLFormatter(
+    entity_substitution=EntitySubstitution.substitute_html
+)
+HTMLFormatter.REGISTRY["html5"] = HTMLFormatter(
+    entity_substitution=EntitySubstitution.substitute_html,
+    void_element_close_prefix = None
+)
+HTMLFormatter.REGISTRY["minimal"] = HTMLFormatter(
+    entity_substitution=EntitySubstitution.substitute_xml
+)
+HTMLFormatter.REGISTRY[None] = HTMLFormatter(
+    entity_substitution=None
+)
+XMLFormatter.REGISTRY["html"] =  XMLFormatter(
+    entity_substitution=EntitySubstitution.substitute_html
+)
+XMLFormatter.REGISTRY["minimal"] = XMLFormatter(
+    entity_substitution=EntitySubstitution.substitute_xml
+)
+XMLFormatter.REGISTRY[None] = Formatter(
+    Formatter(Formatter.XML, entity_substitution=None)
+)
Index: latest/Lib/site-packages/bs4/testing.py
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/latest/Lib/site-packages/bs4/testing.py b/latest/Lib/site-packages/bs4/testing.py
new file mode 100644
--- /dev/null	(date 1616411342099)
+++ b/latest/Lib/site-packages/bs4/testing.py	(date 1616411342099)
@@ -0,0 +1,1101 @@
+# encoding: utf-8
+"""Helper classes for tests."""
+
+# Use of this source code is governed by the MIT license.
+__license__ = "MIT"
+
+import pickle
+import copy
+import functools
+import unittest
+from unittest import TestCase
+from bs4 import BeautifulSoup
+from bs4.element import (
+    CharsetMetaAttributeValue,
+    Comment,
+    ContentMetaAttributeValue,
+    Doctype,
+    PYTHON_SPECIFIC_ENCODINGS,
+    SoupStrainer,
+    Script,
+    Stylesheet,
+    Tag
+)
+
+from bs4.builder import HTMLParserTreeBuilder
+default_builder = HTMLParserTreeBuilder
+
+BAD_DOCUMENT = """A bare string
+<!DOCTYPE xsl:stylesheet SYSTEM "htmlent.dtd">
+<!DOCTYPE xsl:stylesheet PUBLIC "htmlent.dtd">
+<div><![CDATA[A CDATA section where it doesn't belong]]></div>
+<div><svg><![CDATA[HTML5 does allow CDATA sections in SVG]]></svg></div>
+<div>A <meta> tag</div>
+<div>A <br> tag that supposedly has contents.</br></div>
+<div>AT&T</div>
+<div><textarea>Within a textarea, markup like <b> tags and <&<&amp; should be treated as literal</textarea></div>
+<div><script>if (i < 2) { alert("<b>Markup within script tags should be treated as literal.</b>"); }</script></div>
+<div>This numeric entity is missing the final semicolon: <x t="pi&#241ata"></div>
+<div><a href="http://example.com/</a> that attribute value never got closed</div>
+<div><a href="foo</a>, </a><a href="bar">that attribute value was closed by the subsequent tag</a></div>
+<! This document starts with a bogus declaration ><div>a</div>
+<div>This document contains <!an incomplete declaration <div>(do you see it?)</div>
+<div>This document ends with <!an incomplete declaration
+<div><a style={height:21px;}>That attribute value was bogus</a></div>
+<! DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN">The doctype is invalid because it contains extra whitespace
+<div><table><td nowrap>That boolean attribute had no value</td></table></div>
+<div>Here's a nonexistent entity: &#foo; (do you see it?)</div>
+<div>This document ends before the entity finishes: &gt
+<div><p>Paragraphs shouldn't contain block display elements, but this one does: <dl><dt>you see?</dt></p>
+<b b="20" a="1" b="10" a="2" a="3" a="4">Multiple values for the same attribute.</b>
+<div><table><tr><td>Here's a table</td></tr></table></div>
+<div><table id="1"><tr><td>Here's a nested table:<table id="2"><tr><td>foo</td></tr></table></td></div>
+<div>This tag contains nothing but whitespace: <b>    </b></div>
+<div><blockquote><p><b>This p tag is cut off by</blockquote></p>the end of the blockquote tag</div>
+<div><table><div>This table contains bare markup</div></table></div>
+<div><div id="1">\n <a href="link1">This link is never closed.\n</div>\n<div id="2">\n <div id="3">\n   <a href="link2">This link is closed.</a>\n  </div>\n</div></div>
+<div>This document contains a <!DOCTYPE surprise>surprise doctype</div>
+<div><a><B><Cd><EFG>Mixed case tags are folded to lowercase</efg></CD></b></A></div>
+<div><our\u2603>Tag name contains Unicode characters</our\u2603></div>
+<div><a \u2603="snowman">Attribute name contains Unicode characters</a></div>
+<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
+"""
+
+
+class SoupTest(unittest.TestCase):
+
+    @property
+    def default_builder(self):
+        return default_builder
+
+    def soup(self, markup, **kwargs):
+        """Build a Beautiful Soup object from markup."""
+        builder = kwargs.pop('builder', self.default_builder)
+        return BeautifulSoup(markup, builder=builder, **kwargs)
+
+    def document_for(self, markup, **kwargs):
+        """Turn an HTML fragment into a document.
+
+        The details depend on the builder.
+        """
+        return self.default_builder(**kwargs).test_fragment_to_document(markup)
+
+    def assertSoupEquals(self, to_parse, compare_parsed_to=None):
+        builder = self.default_builder
+        obj = BeautifulSoup(to_parse, builder=builder)
+        if compare_parsed_to is None:
+            compare_parsed_to = to_parse
+
+        # Verify that the documents come out the same.
+        self.assertEqual(obj.decode(), self.document_for(compare_parsed_to))
+
+        # Also run some checks on the BeautifulSoup object itself:
+
+        # Verify that every tag that was opened was eventually closed.
+
+        # There are no tags in the open tag counter.
+        assert all(v==0 for v in list(obj.open_tag_counter.values()))
+
+        # The only tag in the tag stack is the one for the root
+        # document.
+        self.assertEqual(
+            [obj.ROOT_TAG_NAME], [x.name for x in obj.tagStack]
+        )
+        
+    def assertConnectedness(self, element):
+        """Ensure that next_element and previous_element are properly
+        set for all descendants of the given element.
+        """
+        earlier = None
+        for e in element.descendants:
+            if earlier:
+                self.assertEqual(e, earlier.next_element)
+                self.assertEqual(earlier, e.previous_element)
+            earlier = e
+
+    def linkage_validator(self, el, _recursive_call=False):
+        """Ensure proper linkage throughout the document."""
+        descendant = None
+        # Document element should have no previous element or previous sibling.
+        # It also shouldn't have a next sibling.
+        if el.parent is None:
+            assert el.previous_element is None,\
+                "Bad previous_element\nNODE: {}\nPREV: {}\nEXPECTED: {}".format(
+                    el, el.previous_element, None
+                )
+            assert el.previous_sibling is None,\
+                "Bad previous_sibling\nNODE: {}\nPREV: {}\nEXPECTED: {}".format(
+                    el, el.previous_sibling, None
+                )
+            assert el.next_sibling is None,\
+                "Bad next_sibling\nNODE: {}\nNEXT: {}\nEXPECTED: {}".format(
+                    el, el.next_sibling, None
+                )
+
+        idx = 0
+        child = None
+        last_child = None
+        last_idx = len(el.contents) - 1
+        for child in el.contents:
+            descendant = None
+
+            # Parent should link next element to their first child
+            # That child should have no previous sibling
+            if idx == 0:
+                if el.parent is not None:
+                    assert el.next_element is child,\
+                       "Bad next_element\nNODE: {}\nNEXT: {}\nEXPECTED: {}".format(
+                            el, el.next_element, child
+                        )
+                    assert child.previous_element is el,\
+                       "Bad previous_element\nNODE: {}\nPREV: {}\nEXPECTED: {}".format(
+                            child, child.previous_element, el
+                        )
+                    assert child.previous_sibling is None,\
+                       "Bad previous_sibling\nNODE: {}\nPREV {}\nEXPECTED: {}".format(
+                            child, child.previous_sibling, None
+                        )
+
+            # If not the first child, previous index should link as sibling to this index
+            # Previous element should match the last index or the last bubbled up descendant
+            else:
+                assert child.previous_sibling is el.contents[idx - 1],\
+                    "Bad previous_sibling\nNODE: {}\nPREV {}\nEXPECTED {}".format(
+                        child, child.previous_sibling, el.contents[idx - 1]
+                    )
+                assert el.contents[idx - 1].next_sibling is child,\
+                    "Bad next_sibling\nNODE: {}\nNEXT {}\nEXPECTED {}".format(
+                        el.contents[idx - 1], el.contents[idx - 1].next_sibling, child
+                    )
+
+                if last_child is not None:
+                    assert child.previous_element is last_child,\
+                        "Bad previous_element\nNODE: {}\nPREV {}\nEXPECTED {}\nCONTENTS {}".format(
+                            child, child.previous_element, last_child, child.parent.contents
+                        )
+                    assert last_child.next_element is child,\
+                        "Bad next_element\nNODE: {}\nNEXT {}\nEXPECTED {}".format(
+                            last_child, last_child.next_element, child
+                        )
+
+            if isinstance(child, Tag) and child.contents:
+                descendant = self.linkage_validator(child, True)
+                # A bubbled up descendant should have no next siblings
+                assert descendant.next_sibling is None,\
+                    "Bad next_sibling\nNODE: {}\nNEXT {}\nEXPECTED {}".format(
+                        descendant, descendant.next_sibling, None
+                    )
+
+            # Mark last child as either the bubbled up descendant or the current child
+            if descendant is not None:
+                last_child = descendant
+            else:
+                last_child = child
+
+            # If last child, there are non next siblings
+            if idx == last_idx:
+                assert child.next_sibling is None,\
+                    "Bad next_sibling\nNODE: {}\nNEXT {}\nEXPECTED {}".format(
+                        child, child.next_sibling, None
+                    )
+            idx += 1
+
+        child = descendant if descendant is not None else child
+        if child is None:
+            child = el
+
+        if not _recursive_call and child is not None:
+            target = el
+            while True:
+                if target is None:
+                    assert child.next_element is None, \
+                        "Bad next_element\nNODE: {}\nNEXT {}\nEXPECTED {}".format(
+                            child, child.next_element, None
+                        )
+                    break
+                elif target.next_sibling is not None:
+                    assert child.next_element is target.next_sibling, \
+                        "Bad next_element\nNODE: {}\nNEXT {}\nEXPECTED {}".format(
+                            child, child.next_element, target.next_sibling
+                        )
+                    break
+                target = target.parent
+
+            # We are done, so nothing to return
+            return None
+        else:
+            # Return the child to the recursive caller
+            return child
+
+
+class HTMLTreeBuilderSmokeTest(object):
+
+    """A basic test of a treebuilder's competence.
+
+    Any HTML treebuilder, present or future, should be able to pass
+    these tests. With invalid markup, there's room for interpretation,
+    and different parsers can handle it differently. But with the
+    markup in these tests, there's not much room for interpretation.
+    """
+
+    def test_empty_element_tags(self):
+        """Verify that all HTML4 and HTML5 empty element (aka void element) tags
+        are handled correctly.
+        """
+        for name in [
+                'area', 'base', 'br', 'col', 'embed', 'hr', 'img', 'input', 'keygen', 'link', 'menuitem', 'meta', 'param', 'source', 'track', 'wbr',
+                'spacer', 'frame'
+        ]:
+            soup = self.soup("")
+            new_tag = soup.new_tag(name)
+            self.assertEqual(True, new_tag.is_empty_element)
+
+    def test_special_string_containers(self):
+        soup = self.soup(
+            "<style>Some CSS</style><script>Some Javascript</script>"
+        )
+        assert isinstance(soup.style.string, Stylesheet)
+        assert isinstance(soup.script.string, Script)
+
+        soup = self.soup(
+            "<style><!--Some CSS--></style>"
+        )
+        assert isinstance(soup.style.string, Stylesheet)
+        # The contents of the style tag resemble an HTML comment, but
+        # it's not treated as a comment.
+        self.assertEqual("<!--Some CSS-->", soup.style.string)
+        assert isinstance(soup.style.string, Stylesheet)
+        
+    def test_pickle_and_unpickle_identity(self):
+        # Pickling a tree, then unpickling it, yields a tree identical
+        # to the original.
+        tree = self.soup("<a><b>foo</a>")
+        dumped = pickle.dumps(tree, 2)
+        loaded = pickle.loads(dumped)
+        self.assertEqual(loaded.__class__, BeautifulSoup)
+        self.assertEqual(loaded.decode(), tree.decode())
+
+    def assertDoctypeHandled(self, doctype_fragment):
+        """Assert that a given doctype string is handled correctly."""
+        doctype_str, soup = self._document_with_doctype(doctype_fragment)
+
+        # Make sure a Doctype object was created.
+        doctype = soup.contents[0]
+        self.assertEqual(doctype.__class__, Doctype)
+        self.assertEqual(doctype, doctype_fragment)
+        self.assertEqual(
+            soup.encode("utf8")[:len(doctype_str)],
+            doctype_str
+        )
+
+        # Make sure that the doctype was correctly associated with the
+        # parse tree and that the rest of the document parsed.
+        self.assertEqual(soup.p.contents[0], 'foo')
+
+    def _document_with_doctype(self, doctype_fragment, doctype_string="DOCTYPE"):
+        """Generate and parse a document with the given doctype."""
+        doctype = '<!%s %s>' % (doctype_string, doctype_fragment)
+        markup = doctype + '\n<p>foo</p>'
+        soup = self.soup(markup)
+        return doctype.encode("utf8"), soup
+
+    def test_normal_doctypes(self):
+        """Make sure normal, everyday HTML doctypes are handled correctly."""
+        self.assertDoctypeHandled("html")
+        self.assertDoctypeHandled(
+            'html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN"')
+
+    def test_empty_doctype(self):
+        soup = self.soup("<!DOCTYPE>")
+        doctype = soup.contents[0]
+        self.assertEqual("", doctype.strip())
+
+    def test_mixed_case_doctype(self):
+        # A lowercase or mixed-case doctype becomes a Doctype.
+        for doctype_fragment in ("doctype", "DocType"):
+            doctype_str, soup = self._document_with_doctype(
+                "html", doctype_fragment
+            )
+
+            # Make sure a Doctype object was created and that the DOCTYPE
+            # is uppercase.
+            doctype = soup.contents[0]
+            self.assertEqual(doctype.__class__, Doctype)
+            self.assertEqual(doctype, "html")
+            self.assertEqual(
+                soup.encode("utf8")[:len(doctype_str)],
+                b"<!DOCTYPE html>"
+            )
+
+            # Make sure that the doctype was correctly associated with the
+            # parse tree and that the rest of the document parsed.
+            self.assertEqual(soup.p.contents[0], 'foo')
+        
+    def test_public_doctype_with_url(self):
+        doctype = 'html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd"'
+        self.assertDoctypeHandled(doctype)
+
+    def test_system_doctype(self):
+        self.assertDoctypeHandled('foo SYSTEM "http://www.example.com/"')
+
+    def test_namespaced_system_doctype(self):
+        # We can handle a namespaced doctype with a system ID.
+        self.assertDoctypeHandled('xsl:stylesheet SYSTEM "htmlent.dtd"')
+
+    def test_namespaced_public_doctype(self):
+        # Test a namespaced doctype with a public id.
+        self.assertDoctypeHandled('xsl:stylesheet PUBLIC "htmlent.dtd"')
+
+    def test_real_xhtml_document(self):
+        """A real XHTML document should come out more or less the same as it went in."""
+        markup = b"""<?xml version="1.0" encoding="utf-8"?>
+<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN">
+<html xmlns="http://www.w3.org/1999/xhtml">
+<head><title>Hello.</title></head>
+<body>Goodbye.</body>
+</html>"""
+        soup = self.soup(markup)
+        self.assertEqual(
+            soup.encode("utf-8").replace(b"\n", b""),
+            markup.replace(b"\n", b""))
+
+    def test_namespaced_html(self):
+        """When a namespaced XML document is parsed as HTML it should
+        be treated as HTML with weird tag names.
+        """
+        markup = b"""<ns1:foo>content</ns1:foo><ns1:foo/><ns2:foo/>"""
+        soup = self.soup(markup)
+        self.assertEqual(2, len(soup.find_all("ns1:foo")))
+        
+    def test_processing_instruction(self):
+        # We test both Unicode and bytestring to verify that
+        # process_markup correctly sets processing_instruction_class
+        # even when the markup is already Unicode and there is no
+        # need to process anything.
+        markup = """<?PITarget PIContent?>"""
+        soup = self.soup(markup)
+        self.assertEqual(markup, soup.decode())
+
+        markup = b"""<?PITarget PIContent?>"""
+        soup = self.soup(markup)
+        self.assertEqual(markup, soup.encode("utf8"))
+
+    def test_deepcopy(self):
+        """Make sure you can copy the tree builder.
+
+        This is important because the builder is part of a
+        BeautifulSoup object, and we want to be able to copy that.
+        """
+        copy.deepcopy(self.default_builder)
+
+    def test_p_tag_is_never_empty_element(self):
+        """A <p> tag is never designated as an empty-element tag.
+
+        Even if the markup shows it as an empty-element tag, it
+        shouldn't be presented that way.
+        """
+        soup = self.soup("<p/>")
+        self.assertFalse(soup.p.is_empty_element)
+        self.assertEqual(str(soup.p), "<p></p>")
+
+    def test_unclosed_tags_get_closed(self):
+        """A tag that's not closed by the end of the document should be closed.
+
+        This applies to all tags except empty-element tags.
+        """
+        self.assertSoupEquals("<p>", "<p></p>")
+        self.assertSoupEquals("<b>", "<b></b>")
+
+        self.assertSoupEquals("<br>", "<br/>")
+
+    def test_br_is_always_empty_element_tag(self):
+        """A <br> tag is designated as an empty-element tag.
+
+        Some parsers treat <br></br> as one <br/> tag, some parsers as
+        two tags, but it should always be an empty-element tag.
+        """
+        soup = self.soup("<br></br>")
+        self.assertTrue(soup.br.is_empty_element)
+        self.assertEqual(str(soup.br), "<br/>")
+
+    def test_nested_formatting_elements(self):
+        self.assertSoupEquals("<em><em></em></em>")
+
+    def test_double_head(self):
+        html = '''<!DOCTYPE html>
+<html>
+<head>
+<title>Ordinary HEAD element test</title>
+</head>
+<script type="text/javascript">
+alert("Help!");
+</script>
+<body>
+Hello, world!
+</body>
+</html>
+'''
+        soup = self.soup(html)
+        self.assertEqual("text/javascript", soup.find('script')['type'])
+
+    def test_comment(self):
+        # Comments are represented as Comment objects.
+        markup = "<p>foo<!--foobar-->baz</p>"
+        self.assertSoupEquals(markup)
+
+        soup = self.soup(markup)
+        comment = soup.find(text="foobar")
+        self.assertEqual(comment.__class__, Comment)
+
+        # The comment is properly integrated into the tree.
+        foo = soup.find(text="foo")
+        self.assertEqual(comment, foo.next_element)
+        baz = soup.find(text="baz")
+        self.assertEqual(comment, baz.previous_element)
+
+    def test_preserved_whitespace_in_pre_and_textarea(self):
+        """Whitespace must be preserved in <pre> and <textarea> tags,
+        even if that would mean not prettifying the markup.
+        """
+        pre_markup = "<pre>   </pre>"
+        textarea_markup = "<textarea> woo\nwoo  </textarea>"
+        self.assertSoupEquals(pre_markup)
+        self.assertSoupEquals(textarea_markup)
+
+        soup = self.soup(pre_markup)
+        self.assertEqual(soup.pre.prettify(), pre_markup)
+
+        soup = self.soup(textarea_markup)
+        self.assertEqual(soup.textarea.prettify(), textarea_markup)
+
+        soup = self.soup("<textarea></textarea>")
+        self.assertEqual(soup.textarea.prettify(), "<textarea></textarea>")
+
+    def test_nested_inline_elements(self):
+        """Inline elements can be nested indefinitely."""
+        b_tag = "<b>Inside a B tag</b>"
+        self.assertSoupEquals(b_tag)
+
+        nested_b_tag = "<p>A <i>nested <b>tag</b></i></p>"
+        self.assertSoupEquals(nested_b_tag)
+
+        double_nested_b_tag = "<p>A <a>doubly <i>nested <b>tag</b></i></a></p>"
+        self.assertSoupEquals(nested_b_tag)
+
+    def test_nested_block_level_elements(self):
+        """Block elements can be nested."""
+        soup = self.soup('<blockquote><p><b>Foo</b></p></blockquote>')
+        blockquote = soup.blockquote
+        self.assertEqual(blockquote.p.b.string, 'Foo')
+        self.assertEqual(blockquote.b.string, 'Foo')
+
+    def test_correctly_nested_tables(self):
+        """One table can go inside another one."""
+        markup = ('<table id="1">'
+                  '<tr>'
+                  "<td>Here's another table:"
+                  '<table id="2">'
+                  '<tr><td>foo</td></tr>'
+                  '</table></td>')
+
+        self.assertSoupEquals(
+            markup,
+            '<table id="1"><tr><td>Here\'s another table:'
+            '<table id="2"><tr><td>foo</td></tr></table>'
+            '</td></tr></table>')
+
+        self.assertSoupEquals(
+            "<table><thead><tr><td>Foo</td></tr></thead>"
+            "<tbody><tr><td>Bar</td></tr></tbody>"
+            "<tfoot><tr><td>Baz</td></tr></tfoot></table>")
+
+    def test_multivalued_attribute_with_whitespace(self):
+        # Whitespace separating the values of a multi-valued attribute
+        # should be ignored.
+
+        markup = '<div class=" foo bar	 "></a>'
+        soup = self.soup(markup)
+        self.assertEqual(['foo', 'bar'], soup.div['class'])
+
+        # If you search by the literal name of the class it's like the whitespace
+        # wasn't there.
+        self.assertEqual(soup.div, soup.find('div', class_="foo bar"))
+        
+    def test_deeply_nested_multivalued_attribute(self):
+        # html5lib can set the attributes of the same tag many times
+        # as it rearranges the tree. This has caused problems with
+        # multivalued attributes.
+        markup = '<table><div><div class="css"></div></div></table>'
+        soup = self.soup(markup)
+        self.assertEqual(["css"], soup.div.div['class'])
+
+    def test_multivalued_attribute_on_html(self):
+        # html5lib uses a different API to set the attributes ot the
+        # <html> tag. This has caused problems with multivalued
+        # attributes.
+        markup = '<html class="a b"></html>'
+        soup = self.soup(markup)
+        self.assertEqual(["a", "b"], soup.html['class'])
+
+    def test_angle_brackets_in_attribute_values_are_escaped(self):
+        self.assertSoupEquals('<a b="<a>"></a>', '<a b="&lt;a&gt;"></a>')
+
+    def test_strings_resembling_character_entity_references(self):
+        # "&T" and "&p" look like incomplete character entities, but they are
+        # not.
+        self.assertSoupEquals(
+            "<p>&bull; AT&T is in the s&p 500</p>",
+            "<p>\u2022 AT&amp;T is in the s&amp;p 500</p>"
+        )
+
+    def test_apos_entity(self):
+        self.assertSoupEquals(
+            "<p>Bob&apos;s Bar</p>",
+            "<p>Bob's Bar</p>",
+        )
+        
+    def test_entities_in_foreign_document_encoding(self):
+        # &#147; and &#148; are invalid numeric entities referencing
+        # Windows-1252 characters. &#45; references a character common
+        # to Windows-1252 and Unicode, and &#9731; references a
+        # character only found in Unicode.
+        #
+        # All of these entities should be converted to Unicode
+        # characters.
+        markup = "<p>&#147;Hello&#148; &#45;&#9731;</p>"
+        soup = self.soup(markup)
+        self.assertEqual("“Hello” -☃", soup.p.string)
+        
+    def test_entities_in_attributes_converted_to_unicode(self):
+        expect = '<p id="pi\N{LATIN SMALL LETTER N WITH TILDE}ata"></p>'
+        self.assertSoupEquals('<p id="pi&#241;ata"></p>', expect)
+        self.assertSoupEquals('<p id="pi&#xf1;ata"></p>', expect)
+        self.assertSoupEquals('<p id="pi&#Xf1;ata"></p>', expect)
+        self.assertSoupEquals('<p id="pi&ntilde;ata"></p>', expect)
+
+    def test_entities_in_text_converted_to_unicode(self):
+        expect = '<p>pi\N{LATIN SMALL LETTER N WITH TILDE}ata</p>'
+        self.assertSoupEquals("<p>pi&#241;ata</p>", expect)
+        self.assertSoupEquals("<p>pi&#xf1;ata</p>", expect)
+        self.assertSoupEquals("<p>pi&#Xf1;ata</p>", expect)
+        self.assertSoupEquals("<p>pi&ntilde;ata</p>", expect)
+
+    def test_quot_entity_converted_to_quotation_mark(self):
+        self.assertSoupEquals("<p>I said &quot;good day!&quot;</p>",
+                              '<p>I said "good day!"</p>')
+
+    def test_out_of_range_entity(self):
+        expect = "\N{REPLACEMENT CHARACTER}"
+        self.assertSoupEquals("&#10000000000000;", expect)
+        self.assertSoupEquals("&#x10000000000000;", expect)
+        self.assertSoupEquals("&#1000000000;", expect)
+        
+    def test_multipart_strings(self):
+        "Mostly to prevent a recurrence of a bug in the html5lib treebuilder."
+        soup = self.soup("<html><h2>\nfoo</h2><p></p></html>")
+        self.assertEqual("p", soup.h2.string.next_element.name)
+        self.assertEqual("p", soup.p.name)
+        self.assertConnectedness(soup)
+
+    def test_empty_element_tags(self):
+        """Verify consistent handling of empty-element tags,
+        no matter how they come in through the markup.
+        """
+        self.assertSoupEquals('<br/><br/><br/>', "<br/><br/><br/>")
+        self.assertSoupEquals('<br /><br /><br />', "<br/><br/><br/>")
+        
+    def test_head_tag_between_head_and_body(self):
+        "Prevent recurrence of a bug in the html5lib treebuilder."
+        content = """<html><head></head>
+  <link></link>
+  <body>foo</body>
+</html>
+"""
+        soup = self.soup(content)
+        self.assertNotEqual(None, soup.html.body)
+        self.assertConnectedness(soup)
+
+    def test_multiple_copies_of_a_tag(self):
+        "Prevent recurrence of a bug in the html5lib treebuilder."
+        content = """<!DOCTYPE html>
+<html>
+ <body>
+   <article id="a" >
+   <div><a href="1"></div>
+   <footer>
+     <a href="2"></a>
+   </footer>
+  </article>
+  </body>
+</html>
+"""
+        soup = self.soup(content)
+        self.assertConnectedness(soup.article)
+
+    def test_basic_namespaces(self):
+        """Parsers don't need to *understand* namespaces, but at the
+        very least they should not choke on namespaces or lose
+        data."""
+
+        markup = b'<html xmlns="http://www.w3.org/1999/xhtml" xmlns:mathml="http://www.w3.org/1998/Math/MathML" xmlns:svg="http://www.w3.org/2000/svg"><head></head><body><mathml:msqrt>4</mathml:msqrt><b svg:fill="red"></b></body></html>'
+        soup = self.soup(markup)
+        self.assertEqual(markup, soup.encode())
+        html = soup.html
+        self.assertEqual('http://www.w3.org/1999/xhtml', soup.html['xmlns'])
+        self.assertEqual(
+            'http://www.w3.org/1998/Math/MathML', soup.html['xmlns:mathml'])
+        self.assertEqual(
+            'http://www.w3.org/2000/svg', soup.html['xmlns:svg'])
+
+    def test_multivalued_attribute_value_becomes_list(self):
+        markup = b'<a class="foo bar">'
+        soup = self.soup(markup)
+        self.assertEqual(['foo', 'bar'], soup.a['class'])
+
+    #
+    # Generally speaking, tests below this point are more tests of
+    # Beautiful Soup than tests of the tree builders. But parsers are
+    # weird, so we run these tests separately for every tree builder
+    # to detect any differences between them.
+    #
+
+    def test_can_parse_unicode_document(self):
+        # A seemingly innocuous document... but it's in Unicode! And
+        # it contains characters that can't be represented in the
+        # encoding found in the  declaration! The horror!
+        markup = '<html><head><meta encoding="euc-jp"></head><body>Sacr\N{LATIN SMALL LETTER E WITH ACUTE} bleu!</body>'
+        soup = self.soup(markup)
+        self.assertEqual('Sacr\xe9 bleu!', soup.body.string)
+
+    def test_soupstrainer(self):
+        """Parsers should be able to work with SoupStrainers."""
+        strainer = SoupStrainer("b")
+        soup = self.soup("A <b>bold</b> <meta/> <i>statement</i>",
+                         parse_only=strainer)
+        self.assertEqual(soup.decode(), "<b>bold</b>")
+
+    def test_single_quote_attribute_values_become_double_quotes(self):
+        self.assertSoupEquals("<foo attr='bar'></foo>",
+                              '<foo attr="bar"></foo>')
+
+    def test_attribute_values_with_nested_quotes_are_left_alone(self):
+        text = """<foo attr='bar "brawls" happen'>a</foo>"""
+        self.assertSoupEquals(text)
+
+    def test_attribute_values_with_double_nested_quotes_get_quoted(self):
+        text = """<foo attr='bar "brawls" happen'>a</foo>"""
+        soup = self.soup(text)
+        soup.foo['attr'] = 'Brawls happen at "Bob\'s Bar"'
+        self.assertSoupEquals(
+            soup.foo.decode(),
+            """<foo attr="Brawls happen at &quot;Bob\'s Bar&quot;">a</foo>""")
+
+    def test_ampersand_in_attribute_value_gets_escaped(self):
+        self.assertSoupEquals('<this is="really messed up & stuff"></this>',
+                              '<this is="really messed up &amp; stuff"></this>')
+
+        self.assertSoupEquals(
+            '<a href="http://example.org?a=1&b=2;3">foo</a>',
+            '<a href="http://example.org?a=1&amp;b=2;3">foo</a>')
+
+    def test_escaped_ampersand_in_attribute_value_is_left_alone(self):
+        self.assertSoupEquals('<a href="http://example.org?a=1&amp;b=2;3"></a>')
+
+    def test_entities_in_strings_converted_during_parsing(self):
+        # Both XML and HTML entities are converted to Unicode characters
+        # during parsing.
+        text = "<p>&lt;&lt;sacr&eacute;&#32;bleu!&gt;&gt;</p>"
+        expected = "<p>&lt;&lt;sacr\N{LATIN SMALL LETTER E WITH ACUTE} bleu!&gt;&gt;</p>"
+        self.assertSoupEquals(text, expected)
+
+    def test_smart_quotes_converted_on_the_way_in(self):
+        # Microsoft smart quotes are converted to Unicode characters during
+        # parsing.
+        quote = b"<p>\x91Foo\x92</p>"
+        soup = self.soup(quote)
+        self.assertEqual(
+            soup.p.string,
+            "\N{LEFT SINGLE QUOTATION MARK}Foo\N{RIGHT SINGLE QUOTATION MARK}")
+
+    def test_non_breaking_spaces_converted_on_the_way_in(self):
+        soup = self.soup("<a>&nbsp;&nbsp;</a>")
+        self.assertEqual(soup.a.string, "\N{NO-BREAK SPACE}" * 2)
+
+    def test_entities_converted_on_the_way_out(self):
+        text = "<p>&lt;&lt;sacr&eacute;&#32;bleu!&gt;&gt;</p>"
+        expected = "<p>&lt;&lt;sacr\N{LATIN SMALL LETTER E WITH ACUTE} bleu!&gt;&gt;</p>".encode("utf-8")
+        soup = self.soup(text)
+        self.assertEqual(soup.p.encode("utf-8"), expected)
+
+    def test_real_iso_latin_document(self):
+        # Smoke test of interrelated functionality, using an
+        # easy-to-understand document.
+
+        # Here it is in Unicode. Note that it claims to be in ISO-Latin-1.
+        unicode_html = '<html><head><meta content="text/html; charset=ISO-Latin-1" http-equiv="Content-type"/></head><body><p>Sacr\N{LATIN SMALL LETTER E WITH ACUTE} bleu!</p></body></html>'
+
+        # That's because we're going to encode it into ISO-Latin-1, and use
+        # that to test.
+        iso_latin_html = unicode_html.encode("iso-8859-1")
+
+        # Parse the ISO-Latin-1 HTML.
+        soup = self.soup(iso_latin_html)
+        # Encode it to UTF-8.
+        result = soup.encode("utf-8")
+
+        # What do we expect the result to look like? Well, it would
+        # look like unicode_html, except that the META tag would say
+        # UTF-8 instead of ISO-Latin-1.
+        expected = unicode_html.replace("ISO-Latin-1", "utf-8")
+
+        # And, of course, it would be in UTF-8, not Unicode.
+        expected = expected.encode("utf-8")
+
+        # Ta-da!
+        self.assertEqual(result, expected)
+
+    def test_real_shift_jis_document(self):
+        # Smoke test to make sure the parser can handle a document in
+        # Shift-JIS encoding, without choking.
+        shift_jis_html = (
+            b'<html><head></head><body><pre>'
+            b'\x82\xb1\x82\xea\x82\xcdShift-JIS\x82\xc5\x83R\x81[\x83f'
+            b'\x83B\x83\x93\x83O\x82\xb3\x82\xea\x82\xbd\x93\xfa\x96{\x8c'
+            b'\xea\x82\xcc\x83t\x83@\x83C\x83\x8b\x82\xc5\x82\xb7\x81B'
+            b'</pre></body></html>')
+        unicode_html = shift_jis_html.decode("shift-jis")
+        soup = self.soup(unicode_html)
+
+        # Make sure the parse tree is correctly encoded to various
+        # encodings.
+        self.assertEqual(soup.encode("utf-8"), unicode_html.encode("utf-8"))
+        self.assertEqual(soup.encode("euc_jp"), unicode_html.encode("euc_jp"))
+
+    def test_real_hebrew_document(self):
+        # A real-world test to make sure we can convert ISO-8859-9 (a
+        # Hebrew encoding) to UTF-8.
+        hebrew_document = b'<html><head><title>Hebrew (ISO 8859-8) in Visual Directionality</title></head><body><h1>Hebrew (ISO 8859-8) in Visual Directionality</h1>\xed\xe5\xec\xf9</body></html>'
+        soup = self.soup(
+            hebrew_document, from_encoding="iso8859-8")
+        # Some tree builders call it iso8859-8, others call it iso-8859-9.
+        # That's not a difference we really care about.
+        assert soup.original_encoding in ('iso8859-8', 'iso-8859-8')
+        self.assertEqual(
+            soup.encode('utf-8'),
+            hebrew_document.decode("iso8859-8").encode("utf-8"))
+
+    def test_meta_tag_reflects_current_encoding(self):
+        # Here's the <meta> tag saying that a document is
+        # encoded in Shift-JIS.
+        meta_tag = ('<meta content="text/html; charset=x-sjis" '
+                    'http-equiv="Content-type"/>')
+
+        # Here's a document incorporating that meta tag.
+        shift_jis_html = (
+            '<html><head>\n%s\n'
+            '<meta http-equiv="Content-language" content="ja"/>'
+            '</head><body>Shift-JIS markup goes here.') % meta_tag
+        soup = self.soup(shift_jis_html)
+
+        # Parse the document, and the charset is seemingly unaffected.
+        parsed_meta = soup.find('meta', {'http-equiv': 'Content-type'})
+        content = parsed_meta['content']
+        self.assertEqual('text/html; charset=x-sjis', content)
+
+        # But that value is actually a ContentMetaAttributeValue object.
+        self.assertTrue(isinstance(content, ContentMetaAttributeValue))
+
+        # And it will take on a value that reflects its current
+        # encoding.
+        self.assertEqual('text/html; charset=utf8', content.encode("utf8"))
+
+        # For the rest of the story, see TestSubstitutions in
+        # test_tree.py.
+
+    def test_html5_style_meta_tag_reflects_current_encoding(self):
+        # Here's the <meta> tag saying that a document is
+        # encoded in Shift-JIS.
+        meta_tag = ('<meta id="encoding" charset="x-sjis" />')
+
+        # Here's a document incorporating that meta tag.
+        shift_jis_html = (
+            '<html><head>\n%s\n'
+            '<meta http-equiv="Content-language" content="ja"/>'
+            '</head><body>Shift-JIS markup goes here.') % meta_tag
+        soup = self.soup(shift_jis_html)
+
+        # Parse the document, and the charset is seemingly unaffected.
+        parsed_meta = soup.find('meta', id="encoding")
+        charset = parsed_meta['charset']
+        self.assertEqual('x-sjis', charset)
+
+        # But that value is actually a CharsetMetaAttributeValue object.
+        self.assertTrue(isinstance(charset, CharsetMetaAttributeValue))
+
+        # And it will take on a value that reflects its current
+        # encoding.
+        self.assertEqual('utf8', charset.encode("utf8"))
+
+    def test_python_specific_encodings_not_used_in_charset(self):
+        # You can encode an HTML document using a Python-specific
+        # encoding, but that encoding won't be mentioned _inside_ the
+        # resulting document. Instead, the document will appear to
+        # have no encoding.
+        for markup in [
+            b'<meta charset="utf8"></head>'
+            b'<meta id="encoding" charset="utf-8" />'
+        ]:
+            soup = self.soup(markup)
+            for encoding in PYTHON_SPECIFIC_ENCODINGS:
+                if encoding in (
+                    'idna', 'mbcs', 'oem', 'undefined',
+                    'string_escape', 'string-escape'
+                ):
+                    # For one reason or another, these will raise an
+                    # exception if we actually try to use them, so don't
+                    # bother.
+                    continue
+                encoded = soup.encode(encoding)
+                assert b'meta charset=""' in encoded
+                assert encoding.encode("ascii") not in encoded
+        
+    def test_tag_with_no_attributes_can_have_attributes_added(self):
+        data = self.soup("<a>text</a>")
+        data.a['foo'] = 'bar'
+        self.assertEqual('<a foo="bar">text</a>', data.a.decode())
+
+    def test_closing_tag_with_no_opening_tag(self):
+        # Without BeautifulSoup.open_tag_counter, the </span> tag will
+        # cause _popToTag to be called over and over again as we look
+        # for a <span> tag that wasn't there. The result is that 'text2'
+        # will show up outside the body of the document.
+        soup = self.soup("<body><div><p>text1</p></span>text2</div></body>")
+        self.assertEqual(
+            "<body><div><p>text1</p>text2</div></body>", soup.body.decode()
+        )
+        
+    def test_worst_case(self):
+        """Test the worst case (currently) for linking issues."""
+
+        soup = self.soup(BAD_DOCUMENT)
+        self.linkage_validator(soup)
+
+
+class XMLTreeBuilderSmokeTest(object):
+
+    def test_pickle_and_unpickle_identity(self):
+        # Pickling a tree, then unpickling it, yields a tree identical
+        # to the original.
+        tree = self.soup("<a><b>foo</a>")
+        dumped = pickle.dumps(tree, 2)
+        loaded = pickle.loads(dumped)
+        self.assertEqual(loaded.__class__, BeautifulSoup)
+        self.assertEqual(loaded.decode(), tree.decode())
+
+    def test_docstring_generated(self):
+        soup = self.soup("<root/>")
+        self.assertEqual(
+            soup.encode(), b'<?xml version="1.0" encoding="utf-8"?>\n<root/>')
+
+    def test_xml_declaration(self):
+        markup = b"""<?xml version="1.0" encoding="utf8"?>\n<foo/>"""
+        soup = self.soup(markup)
+        self.assertEqual(markup, soup.encode("utf8"))
+
+    def test_python_specific_encodings_not_used_in_xml_declaration(self):
+        # You can encode an XML document using a Python-specific
+        # encoding, but that encoding won't be mentioned _inside_ the
+        # resulting document.
+        markup = b"""<?xml version="1.0"?>\n<foo/>"""
+        soup = self.soup(markup)
+        for encoding in PYTHON_SPECIFIC_ENCODINGS:
+            if encoding in (
+                'idna', 'mbcs', 'oem', 'undefined',
+                'string_escape', 'string-escape'
+            ):
+                # For one reason or another, these will raise an
+                # exception if we actually try to use them, so don't
+                # bother.
+                continue
+            encoded = soup.encode(encoding)
+            assert b'<?xml version="1.0"?>' in encoded
+            assert encoding.encode("ascii") not in encoded
+
+    def test_processing_instruction(self):
+        markup = b"""<?xml version="1.0" encoding="utf8"?>\n<?PITarget PIContent?>"""
+        soup = self.soup(markup)
+        self.assertEqual(markup, soup.encode("utf8"))
+
+    def test_real_xhtml_document(self):
+        """A real XHTML document should come out *exactly* the same as it went in."""
+        markup = b"""<?xml version="1.0" encoding="utf-8"?>
+<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN">
+<html xmlns="http://www.w3.org/1999/xhtml">
+<head><title>Hello.</title></head>
+<body>Goodbye.</body>
+</html>"""
+        soup = self.soup(markup)
+        self.assertEqual(
+            soup.encode("utf-8"), markup)
+       
+    def test_nested_namespaces(self):
+        doc = b"""<?xml version="1.0" encoding="utf-8"?>
+<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.1//EN" "http://www.w3.org/TR/xhtml11/DTD/xhtml11.dtd">
+<parent xmlns="http://ns1/">
+<child xmlns="http://ns2/" xmlns:ns3="http://ns3/">
+<grandchild ns3:attr="value" xmlns="http://ns4/"/>
+</child>
+</parent>"""
+        soup = self.soup(doc)
+        self.assertEqual(doc, soup.encode())
+        
+    def test_formatter_processes_script_tag_for_xml_documents(self):
+        doc = """
+  <script type="text/javascript">
+  </script>
+"""
+        soup = BeautifulSoup(doc, "lxml-xml")
+        # lxml would have stripped this while parsing, but we can add
+        # it later.
+        soup.script.string = 'console.log("< < hey > > ");'
+        encoded = soup.encode()
+        self.assertTrue(b"&lt; &lt; hey &gt; &gt;" in encoded)
+
+    def test_can_parse_unicode_document(self):
+        markup = '<?xml version="1.0" encoding="euc-jp"><root>Sacr\N{LATIN SMALL LETTER E WITH ACUTE} bleu!</root>'
+        soup = self.soup(markup)
+        self.assertEqual('Sacr\xe9 bleu!', soup.root.string)
+
+    def test_popping_namespaced_tag(self):
+        markup = '<rss xmlns:dc="foo"><dc:creator>b</dc:creator><dc:date>2012-07-02T20:33:42Z</dc:date><dc:rights>c</dc:rights><image>d</image></rss>'
+        soup = self.soup(markup)
+        self.assertEqual(
+            str(soup.rss), markup)
+
+    def test_docstring_includes_correct_encoding(self):
+        soup = self.soup("<root/>")
+        self.assertEqual(
+            soup.encode("latin1"),
+            b'<?xml version="1.0" encoding="latin1"?>\n<root/>')
+
+    def test_large_xml_document(self):
+        """A large XML document should come out the same as it went in."""
+        markup = (b'<?xml version="1.0" encoding="utf-8"?>\n<root>'
+                  + b'0' * (2**12)
+                  + b'</root>')
+        soup = self.soup(markup)
+        self.assertEqual(soup.encode("utf-8"), markup)
+
+
+    def test_tags_are_empty_element_if_and_only_if_they_are_empty(self):
+        self.assertSoupEquals("<p>", "<p/>")
+        self.assertSoupEquals("<p>foo</p>")
+
+    def test_namespaces_are_preserved(self):
+        markup = '<root xmlns:a="http://example.com/" xmlns:b="http://example.net/"><a:foo>This tag is in the a namespace</a:foo><b:foo>This tag is in the b namespace</b:foo></root>'
+        soup = self.soup(markup)
+        root = soup.root
+        self.assertEqual("http://example.com/", root['xmlns:a'])
+        self.assertEqual("http://example.net/", root['xmlns:b'])
+
+    def test_closing_namespaced_tag(self):
+        markup = '<p xmlns:dc="http://purl.org/dc/elements/1.1/"><dc:date>20010504</dc:date></p>'
+        soup = self.soup(markup)
+        self.assertEqual(str(soup.p), markup)
+
+    def test_namespaced_attributes(self):
+        markup = '<foo xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><bar xsi:schemaLocation="http://www.example.com"/></foo>'
+        soup = self.soup(markup)
+        self.assertEqual(str(soup.foo), markup)
+
+    def test_namespaced_attributes_xml_namespace(self):
+        markup = '<foo xml:lang="fr">bar</foo>'
+        soup = self.soup(markup)
+        self.assertEqual(str(soup.foo), markup)
+
+    def test_find_by_prefixed_name(self):
+        doc = """<?xml version="1.0" encoding="utf-8"?>
+<Document xmlns="http://example.com/ns0"
+    xmlns:ns1="http://example.com/ns1"
+    xmlns:ns2="http://example.com/ns2"
+    <ns1:tag>foo</ns1:tag>
+    <ns1:tag>bar</ns1:tag>
+    <ns2:tag key="value">baz</ns2:tag>
+</Document>
+"""
+        soup = self.soup(doc)
+
+        # There are three <tag> tags.
+        self.assertEqual(3, len(soup.find_all('tag')))
+
+        # But two of them are ns1:tag and one of them is ns2:tag.
+        self.assertEqual(2, len(soup.find_all('ns1:tag')))
+        self.assertEqual(1, len(soup.find_all('ns2:tag')))
+        
+        self.assertEqual(1, len(soup.find_all('ns2:tag', key='value')))
+        self.assertEqual(3, len(soup.find_all(['ns1:tag', 'ns2:tag'])))
+        
+    def test_copy_tag_preserves_namespace(self):
+        xml = """<?xml version="1.0" encoding="UTF-8" standalone="yes"?>
+<w:document xmlns:w="http://example.com/ns0"/>"""
+    
+        soup = self.soup(xml)
+        tag = soup.document
+        duplicate = copy.copy(tag)
+
+        # The two tags have the same namespace prefix.
+        self.assertEqual(tag.prefix, duplicate.prefix)
+
+    def test_worst_case(self):
+        """Test the worst case (currently) for linking issues."""
+
+        soup = self.soup(BAD_DOCUMENT)
+        self.linkage_validator(soup)
+
+
+class HTML5TreeBuilderSmokeTest(HTMLTreeBuilderSmokeTest):
+    """Smoke test for a tree builder that supports HTML5."""
+
+    def test_real_xhtml_document(self):
+        # Since XHTML is not HTML5, HTML5 parsers are not tested to handle
+        # XHTML documents in any particular way.
+        pass
+
+    def test_html_tags_have_namespace(self):
+        markup = "<a>"
+        soup = self.soup(markup)
+        self.assertEqual("http://www.w3.org/1999/xhtml", soup.a.namespace)
+
+    def test_svg_tags_have_namespace(self):
+        markup = '<svg><circle/></svg>'
+        soup = self.soup(markup)
+        namespace = "http://www.w3.org/2000/svg"
+        self.assertEqual(namespace, soup.svg.namespace)
+        self.assertEqual(namespace, soup.circle.namespace)
+
+
+    def test_mathml_tags_have_namespace(self):
+        markup = '<math><msqrt>5</msqrt></math>'
+        soup = self.soup(markup)
+        namespace = 'http://www.w3.org/1998/Math/MathML'
+        self.assertEqual(namespace, soup.math.namespace)
+        self.assertEqual(namespace, soup.msqrt.namespace)
+
+    def test_xml_declaration_becomes_comment(self):
+        markup = '<?xml version="1.0" encoding="utf-8"?><html></html>'
+        soup = self.soup(markup)
+        self.assertTrue(isinstance(soup.contents[0], Comment))
+        self.assertEqual(soup.contents[0], '?xml version="1.0" encoding="utf-8"?')
+        self.assertEqual("html", soup.contents[0].next_element.name)
+
+def skipIf(condition, reason):
+   def nothing(test, *args, **kwargs):
+       return None
+
+   def decorator(test_item):
+       if condition:
+           return nothing
+       else:
+           return test_item
+
+   return decorator
Index: latest/Lib/site-packages/bs4/__init__.py
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/latest/Lib/site-packages/bs4/__init__.py b/latest/Lib/site-packages/bs4/__init__.py
new file mode 100644
--- /dev/null	(date 1616411342088)
+++ b/latest/Lib/site-packages/bs4/__init__.py	(date 1616411342088)
@@ -0,0 +1,791 @@
+"""Beautiful Soup Elixir and Tonic - "The Screen-Scraper's Friend".
+
+http://www.crummy.com/software/BeautifulSoup/
+
+Beautiful Soup uses a pluggable XML or HTML parser to parse a
+(possibly invalid) document into a tree representation. Beautiful Soup
+provides methods and Pythonic idioms that make it easy to navigate,
+search, and modify the parse tree.
+
+Beautiful Soup works with Python 2.7 and up. It works better if lxml
+and/or html5lib is installed.
+
+For more than you ever wanted to know about Beautiful Soup, see the
+documentation: http://www.crummy.com/software/BeautifulSoup/bs4/doc/
+"""
+
+__author__ = "Leonard Richardson (leonardr@segfault.org)"
+__version__ = "4.9.3"
+__copyright__ = "Copyright (c) 2004-2020 Leonard Richardson"
+# Use of this source code is governed by the MIT license.
+__license__ = "MIT"
+
+__all__ = ['BeautifulSoup']
+
+from collections import Counter
+import os
+import re
+import sys
+import traceback
+import warnings
+
+from .builder import builder_registry, ParserRejectedMarkup
+from .dammit import UnicodeDammit
+from .element import (
+    CData,
+    Comment,
+    DEFAULT_OUTPUT_ENCODING,
+    Declaration,
+    Doctype,
+    NavigableString,
+    PageElement,
+    ProcessingInstruction,
+    PYTHON_SPECIFIC_ENCODINGS,
+    ResultSet,
+    Script,
+    Stylesheet,
+    SoupStrainer,
+    Tag,
+    TemplateString,
+    )
+
+# The very first thing we do is give a useful error if someone is
+# running this code under Python 3 without converting it.
+'You are trying to run the Python 2 version of Beautiful Soup under Python 3. This will not work.'!='You need to convert the code, either by installing it (`python setup.py install`) or by running 2to3 (`2to3 -w bs4`).'
+
+# Define some custom warnings.
+class GuessedAtParserWarning(UserWarning):
+    """The warning issued when BeautifulSoup has to guess what parser to
+    use -- probably because no parser was specified in the constructor.
+    """
+
+class MarkupResemblesLocatorWarning(UserWarning):
+    """The warning issued when BeautifulSoup is given 'markup' that
+    actually looks like a resource locator -- a URL or a path to a file
+    on disk.
+    """
+
+
+class BeautifulSoup(Tag):
+    """A data structure representing a parsed HTML or XML document.
+
+    Most of the methods you'll call on a BeautifulSoup object are inherited from
+    PageElement or Tag.
+
+    Internally, this class defines the basic interface called by the
+    tree builders when converting an HTML/XML document into a data
+    structure. The interface abstracts away the differences between
+    parsers. To write a new tree builder, you'll need to understand
+    these methods as a whole.
+
+    These methods will be called by the BeautifulSoup constructor:
+      * reset()
+      * feed(markup)
+
+    The tree builder may call these methods from its feed() implementation:
+      * handle_starttag(name, attrs) # See note about return value
+      * handle_endtag(name)
+      * handle_data(data) # Appends to the current data node
+      * endData(containerClass) # Ends the current data node
+
+    No matter how complicated the underlying parser is, you should be
+    able to build a tree using 'start tag' events, 'end tag' events,
+    'data' events, and "done with data" events.
+
+    If you encounter an empty-element tag (aka a self-closing tag,
+    like HTML's <br> tag), call handle_starttag and then
+    handle_endtag.
+    """
+
+    # Since BeautifulSoup subclasses Tag, it's possible to treat it as
+    # a Tag with a .name. This name makes it clear the BeautifulSoup
+    # object isn't a real markup tag.
+    ROOT_TAG_NAME = '[document]'
+
+    # If the end-user gives no indication which tree builder they
+    # want, look for one with these features.
+    DEFAULT_BUILDER_FEATURES = ['html', 'fast']
+
+    # A string containing all ASCII whitespace characters, used in
+    # endData() to detect data chunks that seem 'empty'.
+    ASCII_SPACES = '\x20\x0a\x09\x0c\x0d'
+
+    NO_PARSER_SPECIFIED_WARNING = "No parser was explicitly specified, so I'm using the best available %(markup_type)s parser for this system (\"%(parser)s\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n\nThe code that caused this warning is on line %(line_number)s of the file %(filename)s. To get rid of this warning, pass the additional argument 'features=\"%(parser)s\"' to the BeautifulSoup constructor.\n"
+    
+    def __init__(self, markup="", features=None, builder=None,
+                 parse_only=None, from_encoding=None, exclude_encodings=None,
+                 element_classes=None, **kwargs):
+        """Constructor.
+
+        :param markup: A string or a file-like object representing
+         markup to be parsed.
+
+        :param features: Desirable features of the parser to be
+         used. This may be the name of a specific parser ("lxml",
+         "lxml-xml", "html.parser", or "html5lib") or it may be the
+         type of markup to be used ("html", "html5", "xml"). It's
+         recommended that you name a specific parser, so that
+         Beautiful Soup gives you the same results across platforms
+         and virtual environments.
+
+        :param builder: A TreeBuilder subclass to instantiate (or
+         instance to use) instead of looking one up based on
+         `features`. You only need to use this if you've implemented a
+         custom TreeBuilder.
+
+        :param parse_only: A SoupStrainer. Only parts of the document
+         matching the SoupStrainer will be considered. This is useful
+         when parsing part of a document that would otherwise be too
+         large to fit into memory.
+
+        :param from_encoding: A string indicating the encoding of the
+         document to be parsed. Pass this in if Beautiful Soup is
+         guessing wrongly about the document's encoding.
+
+        :param exclude_encodings: A list of strings indicating
+         encodings known to be wrong. Pass this in if you don't know
+         the document's encoding but you know Beautiful Soup's guess is
+         wrong.
+
+        :param element_classes: A dictionary mapping BeautifulSoup
+         classes like Tag and NavigableString, to other classes you'd
+         like to be instantiated instead as the parse tree is
+         built. This is useful for subclassing Tag or NavigableString
+         to modify default behavior.
+
+        :param kwargs: For backwards compatibility purposes, the
+         constructor accepts certain keyword arguments used in
+         Beautiful Soup 3. None of these arguments do anything in
+         Beautiful Soup 4; they will result in a warning and then be
+         ignored.
+         
+         Apart from this, any keyword arguments passed into the
+         BeautifulSoup constructor are propagated to the TreeBuilder
+         constructor. This makes it possible to configure a
+         TreeBuilder by passing in arguments, not just by saying which
+         one to use.
+        """
+        if 'convertEntities' in kwargs:
+            del kwargs['convertEntities']
+            warnings.warn(
+                "BS4 does not respect the convertEntities argument to the "
+                "BeautifulSoup constructor. Entities are always converted "
+                "to Unicode characters.")
+
+        if 'markupMassage' in kwargs:
+            del kwargs['markupMassage']
+            warnings.warn(
+                "BS4 does not respect the markupMassage argument to the "
+                "BeautifulSoup constructor. The tree builder is responsible "
+                "for any necessary markup massage.")
+
+        if 'smartQuotesTo' in kwargs:
+            del kwargs['smartQuotesTo']
+            warnings.warn(
+                "BS4 does not respect the smartQuotesTo argument to the "
+                "BeautifulSoup constructor. Smart quotes are always converted "
+                "to Unicode characters.")
+
+        if 'selfClosingTags' in kwargs:
+            del kwargs['selfClosingTags']
+            warnings.warn(
+                "BS4 does not respect the selfClosingTags argument to the "
+                "BeautifulSoup constructor. The tree builder is responsible "
+                "for understanding self-closing tags.")
+
+        if 'isHTML' in kwargs:
+            del kwargs['isHTML']
+            warnings.warn(
+                "BS4 does not respect the isHTML argument to the "
+                "BeautifulSoup constructor. Suggest you use "
+                "features='lxml' for HTML and features='lxml-xml' for "
+                "XML.")
+
+        def deprecated_argument(old_name, new_name):
+            if old_name in kwargs:
+                warnings.warn(
+                    'The "%s" argument to the BeautifulSoup constructor '
+                    'has been renamed to "%s."' % (old_name, new_name))
+                value = kwargs[old_name]
+                del kwargs[old_name]
+                return value
+            return None
+
+        parse_only = parse_only or deprecated_argument(
+            "parseOnlyThese", "parse_only")
+
+        from_encoding = from_encoding or deprecated_argument(
+            "fromEncoding", "from_encoding")
+
+        if from_encoding and isinstance(markup, str):
+            warnings.warn("You provided Unicode markup but also provided a value for from_encoding. Your from_encoding will be ignored.")
+            from_encoding = None
+
+        self.element_classes = element_classes or dict()
+
+        # We need this information to track whether or not the builder
+        # was specified well enough that we can omit the 'you need to
+        # specify a parser' warning.
+        original_builder = builder
+        original_features = features
+            
+        if isinstance(builder, type):
+            # A builder class was passed in; it needs to be instantiated.
+            builder_class = builder
+            builder = None
+        elif builder is None:
+            if isinstance(features, str):
+                features = [features]
+            if features is None or len(features) == 0:
+                features = self.DEFAULT_BUILDER_FEATURES
+            builder_class = builder_registry.lookup(*features)
+            if builder_class is None:
+                raise FeatureNotFound(
+                    "Couldn't find a tree builder with the features you "
+                    "requested: %s. Do you need to install a parser library?"
+                    % ",".join(features))
+
+        # At this point either we have a TreeBuilder instance in
+        # builder, or we have a builder_class that we can instantiate
+        # with the remaining **kwargs.
+        if builder is None:
+            builder = builder_class(**kwargs)
+            if not original_builder and not (
+                    original_features == builder.NAME or
+                    original_features in builder.ALTERNATE_NAMES
+            ) and markup:
+                # The user did not tell us which TreeBuilder to use,
+                # and we had to guess. Issue a warning.
+                if builder.is_xml:
+                    markup_type = "XML"
+                else:
+                    markup_type = "HTML"
+
+                # This code adapted from warnings.py so that we get the same line
+                # of code as our warnings.warn() call gets, even if the answer is wrong
+                # (as it may be in a multithreading situation).
+                caller = None
+                try:
+                    caller = sys._getframe(1)
+                except ValueError:
+                    pass
+                if caller:
+                    globals = caller.f_globals
+                    line_number = caller.f_lineno
+                else:
+                    globals = sys.__dict__
+                    line_number= 1                    
+                filename = globals.get('__file__')
+                if filename:
+                    fnl = filename.lower()
+                    if fnl.endswith((".pyc", ".pyo")):
+                        filename = filename[:-1]
+                if filename:
+                    # If there is no filename at all, the user is most likely in a REPL,
+                    # and the warning is not necessary.
+                    values = dict(
+                        filename=filename,
+                        line_number=line_number,
+                        parser=builder.NAME,
+                        markup_type=markup_type
+                    )
+                    warnings.warn(
+                        self.NO_PARSER_SPECIFIED_WARNING % values,
+                        GuessedAtParserWarning, stacklevel=2
+                    )
+        else:
+            if kwargs:
+                warnings.warn("Keyword arguments to the BeautifulSoup constructor will be ignored. These would normally be passed into the TreeBuilder constructor, but a TreeBuilder instance was passed in as `builder`.")
+                    
+        self.builder = builder
+        self.is_xml = builder.is_xml
+        self.known_xml = self.is_xml
+        self._namespaces = dict()
+        self.parse_only = parse_only
+
+        self.builder.initialize_soup(self)
+
+        if hasattr(markup, 'read'):        # It's a file-type object.
+            markup = markup.read()
+        elif len(markup) <= 256 and (
+                (isinstance(markup, bytes) and not b'<' in markup)
+                or (isinstance(markup, str) and not '<' in markup)
+        ):
+            # Print out warnings for a couple beginner problems
+            # involving passing non-markup to Beautiful Soup.
+            # Beautiful Soup will still parse the input as markup,
+            # just in case that's what the user really wants.
+            if (isinstance(markup, str)
+                and not os.path.supports_unicode_filenames):
+                possible_filename = markup.encode("utf8")
+            else:
+                possible_filename = markup
+            is_file = False
+            try:
+                is_file = os.path.exists(possible_filename)
+            except Exception as e:
+                # This is almost certainly a problem involving
+                # characters not valid in filenames on this
+                # system. Just let it go.
+                pass
+            if is_file:
+                warnings.warn(
+                    '"%s" looks like a filename, not markup. You should'
+                    ' probably open this file and pass the filehandle into'
+                    ' Beautiful Soup.' % self._decode_markup(markup),
+                    MarkupResemblesLocatorWarning
+                )
+            self._check_markup_is_url(markup)
+
+        rejections = []
+        success = False
+        for (self.markup, self.original_encoding, self.declared_html_encoding,
+         self.contains_replacement_characters) in (
+             self.builder.prepare_markup(
+                 markup, from_encoding, exclude_encodings=exclude_encodings)):
+            self.reset()
+            try:
+                self._feed()
+                success = True
+                break
+            except ParserRejectedMarkup as e:
+                rejections.append(e)
+                pass
+
+        if not success:
+            other_exceptions = [str(e) for e in rejections]
+            raise ParserRejectedMarkup(
+                "The markup you provided was rejected by the parser. Trying a different parser or a different encoding may help.\n\nOriginal exception(s) from parser:\n " + "\n ".join(other_exceptions)
+            )
+
+        # Clear out the markup and remove the builder's circular
+        # reference to this object.
+        self.markup = None
+        self.builder.soup = None
+
+    def __copy__(self):
+        """Copy a BeautifulSoup object by converting the document to a string and parsing it again."""
+        copy = type(self)(
+            self.encode('utf-8'), builder=self.builder, from_encoding='utf-8'
+        )
+
+        # Although we encoded the tree to UTF-8, that may not have
+        # been the encoding of the original markup. Set the copy's
+        # .original_encoding to reflect the original object's
+        # .original_encoding.
+        copy.original_encoding = self.original_encoding
+        return copy
+
+    def __getstate__(self):
+        # Frequently a tree builder can't be pickled.
+        d = dict(self.__dict__)
+        if 'builder' in d and not self.builder.picklable:
+            d['builder'] = None
+        return d
+
+    @classmethod
+    def _decode_markup(cls, markup):
+        """Ensure `markup` is bytes so it's safe to send into warnings.warn.
+
+        TODO: warnings.warn had this problem back in 2010 but it might not
+        anymore.
+        """
+        if isinstance(markup, bytes):
+            decoded = markup.decode('utf-8', 'replace')
+        else:
+            decoded = markup
+        return decoded
+
+    @classmethod
+    def _check_markup_is_url(cls, markup):
+        """Error-handling method to raise a warning if incoming markup looks
+        like a URL.
+
+        :param markup: A string.
+        """
+        if isinstance(markup, bytes):
+            space = b' '
+            cant_start_with = (b"http:", b"https:")
+        elif isinstance(markup, str):
+            space = ' '
+            cant_start_with = ("http:", "https:")
+        else:
+            return
+
+        if any(markup.startswith(prefix) for prefix in cant_start_with):
+            if not space in markup:
+                warnings.warn(
+                    '"%s" looks like a URL. Beautiful Soup is not an'
+                    ' HTTP client. You should probably use an HTTP client like'
+                    ' requests to get the document behind the URL, and feed'
+                    ' that document to Beautiful Soup.' % cls._decode_markup(
+                        markup
+                    ),
+                    MarkupResemblesLocatorWarning
+                )
+
+    def _feed(self):
+        """Internal method that parses previously set markup, creating a large
+        number of Tag and NavigableString objects.
+        """
+        # Convert the document to Unicode.
+        self.builder.reset()
+
+        self.builder.feed(self.markup)
+        # Close out any unfinished strings and close all the open tags.
+        self.endData()
+        while self.currentTag.name != self.ROOT_TAG_NAME:
+            self.popTag()
+
+    def reset(self):
+        """Reset this object to a state as though it had never parsed any
+        markup.
+        """
+        Tag.__init__(self, self, self.builder, self.ROOT_TAG_NAME)
+        self.hidden = 1
+        self.builder.reset()
+        self.current_data = []
+        self.currentTag = None
+        self.tagStack = []
+        self.open_tag_counter = Counter()
+        self.preserve_whitespace_tag_stack = []
+        self.string_container_stack = []
+        self.pushTag(self)
+
+    def new_tag(self, name, namespace=None, nsprefix=None, attrs={},
+                sourceline=None, sourcepos=None, **kwattrs):
+        """Create a new Tag associated with this BeautifulSoup object.
+
+        :param name: The name of the new Tag.
+        :param namespace: The URI of the new Tag's XML namespace, if any.
+        :param prefix: The prefix for the new Tag's XML namespace, if any.
+        :param attrs: A dictionary of this Tag's attribute values; can
+            be used instead of `kwattrs` for attributes like 'class'
+            that are reserved words in Python.
+        :param sourceline: The line number where this tag was
+            (purportedly) found in its source document.
+        :param sourcepos: The character position within `sourceline` where this
+            tag was (purportedly) found.
+        :param kwattrs: Keyword arguments for the new Tag's attribute values.
+
+        """
+        kwattrs.update(attrs)
+        return self.element_classes.get(Tag, Tag)(
+            None, self.builder, name, namespace, nsprefix, kwattrs,
+            sourceline=sourceline, sourcepos=sourcepos
+        )
+
+    def string_container(self, base_class=None):
+        container = base_class or NavigableString
+        
+        # There may be a general override of NavigableString.
+        container = self.element_classes.get(
+            container, container
+        )
+
+        # On top of that, we may be inside a tag that needs a special
+        # container class.
+        if self.string_container_stack:
+            container = self.builder.string_containers.get(
+                self.string_container_stack[-1].name, container
+            )
+        return container
+        
+    def new_string(self, s, subclass=None):
+        """Create a new NavigableString associated with this BeautifulSoup
+        object.
+        """
+        container = self.string_container(subclass)
+        return container(s)
+
+    def insert_before(self, *args):
+        """This method is part of the PageElement API, but `BeautifulSoup` doesn't implement
+        it because there is nothing before or after it in the parse tree.
+        """
+        raise NotImplementedError("BeautifulSoup objects don't support insert_before().")
+
+    def insert_after(self, *args):
+        """This method is part of the PageElement API, but `BeautifulSoup` doesn't implement
+        it because there is nothing before or after it in the parse tree.
+        """
+        raise NotImplementedError("BeautifulSoup objects don't support insert_after().")
+
+    def popTag(self):
+        """Internal method called by _popToTag when a tag is closed."""
+        tag = self.tagStack.pop()
+        if tag.name in self.open_tag_counter:
+            self.open_tag_counter[tag.name] -= 1
+        if self.preserve_whitespace_tag_stack and tag == self.preserve_whitespace_tag_stack[-1]:
+            self.preserve_whitespace_tag_stack.pop()
+        if self.string_container_stack and tag == self.string_container_stack[-1]:
+            self.string_container_stack.pop()
+        #print("Pop", tag.name)
+        if self.tagStack:
+            self.currentTag = self.tagStack[-1]
+        return self.currentTag
+
+    def pushTag(self, tag):
+        """Internal method called by handle_starttag when a tag is opened."""
+        #print("Push", tag.name)
+        if self.currentTag is not None:
+            self.currentTag.contents.append(tag)
+        self.tagStack.append(tag)
+        self.currentTag = self.tagStack[-1]
+        if tag.name != self.ROOT_TAG_NAME:
+            self.open_tag_counter[tag.name] += 1
+        if tag.name in self.builder.preserve_whitespace_tags:
+            self.preserve_whitespace_tag_stack.append(tag)
+        if tag.name in self.builder.string_containers:
+            self.string_container_stack.append(tag)
+
+    def endData(self, containerClass=None):
+        """Method called by the TreeBuilder when the end of a data segment
+        occurs.
+        """
+        containerClass = self.string_container(containerClass)
+        
+        if self.current_data:
+            current_data = ''.join(self.current_data)
+            # If whitespace is not preserved, and this string contains
+            # nothing but ASCII spaces, replace it with a single space
+            # or newline.
+            if not self.preserve_whitespace_tag_stack:
+                strippable = True
+                for i in current_data:
+                    if i not in self.ASCII_SPACES:
+                        strippable = False
+                        break
+                if strippable:
+                    if '\n' in current_data:
+                        current_data = '\n'
+                    else:
+                        current_data = ' '
+
+            # Reset the data collector.
+            self.current_data = []
+
+            # Should we add this string to the tree at all?
+            if self.parse_only and len(self.tagStack) <= 1 and \
+                   (not self.parse_only.text or \
+                    not self.parse_only.search(current_data)):
+                return
+
+            o = containerClass(current_data)
+            self.object_was_parsed(o)
+
+    def object_was_parsed(self, o, parent=None, most_recent_element=None):
+        """Method called by the TreeBuilder to integrate an object into the parse tree."""
+        if parent is None:
+            parent = self.currentTag
+        if most_recent_element is not None:
+            previous_element = most_recent_element
+        else:
+            previous_element = self._most_recent_element
+
+        next_element = previous_sibling = next_sibling = None
+        if isinstance(o, Tag):
+            next_element = o.next_element
+            next_sibling = o.next_sibling
+            previous_sibling = o.previous_sibling
+            if previous_element is None:
+                previous_element = o.previous_element
+
+        fix = parent.next_element is not None
+
+        o.setup(parent, previous_element, next_element, previous_sibling, next_sibling)
+
+        self._most_recent_element = o
+        parent.contents.append(o)
+
+        # Check if we are inserting into an already parsed node.
+        if fix:
+            self._linkage_fixer(parent)
+
+    def _linkage_fixer(self, el):
+        """Make sure linkage of this fragment is sound."""
+
+        first = el.contents[0]
+        child = el.contents[-1]
+        descendant = child
+
+        if child is first and el.parent is not None:
+            # Parent should be linked to first child
+            el.next_element = child
+            # We are no longer linked to whatever this element is
+            prev_el = child.previous_element
+            if prev_el is not None and prev_el is not el:
+                prev_el.next_element = None
+            # First child should be linked to the parent, and no previous siblings.
+            child.previous_element = el
+            child.previous_sibling = None
+
+        # We have no sibling as we've been appended as the last.
+        child.next_sibling = None
+
+        # This index is a tag, dig deeper for a "last descendant"
+        if isinstance(child, Tag) and child.contents:
+            descendant = child._last_descendant(False)
+
+        # As the final step, link last descendant. It should be linked
+        # to the parent's next sibling (if found), else walk up the chain
+        # and find a parent with a sibling. It should have no next sibling.
+        descendant.next_element = None
+        descendant.next_sibling = None
+        target = el
+        while True:
+            if target is None:
+                break
+            elif target.next_sibling is not None:
+                descendant.next_element = target.next_sibling
+                target.next_sibling.previous_element = child
+                break
+            target = target.parent
+
+    def _popToTag(self, name, nsprefix=None, inclusivePop=True):
+        """Pops the tag stack up to and including the most recent
+        instance of the given tag.
+
+        If there are no open tags with the given name, nothing will be
+        popped.
+
+        :param name: Pop up to the most recent tag with this name.
+        :param nsprefix: The namespace prefix that goes with `name`.
+        :param inclusivePop: It this is false, pops the tag stack up
+          to but *not* including the most recent instqance of the
+          given tag.
+
+        """
+        #print("Popping to %s" % name)
+        if name == self.ROOT_TAG_NAME:
+            # The BeautifulSoup object itself can never be popped.
+            return
+
+        most_recently_popped = None
+
+        stack_size = len(self.tagStack)
+        for i in range(stack_size - 1, 0, -1):
+            if not self.open_tag_counter.get(name):
+                break
+            t = self.tagStack[i]
+            if (name == t.name and nsprefix == t.prefix):
+                if inclusivePop:
+                    most_recently_popped = self.popTag()
+                break
+            most_recently_popped = self.popTag()
+
+        return most_recently_popped
+
+    def handle_starttag(self, name, namespace, nsprefix, attrs, sourceline=None,
+                        sourcepos=None):
+        """Called by the tree builder when a new tag is encountered.
+
+        :param name: Name of the tag.
+        :param nsprefix: Namespace prefix for the tag.
+        :param attrs: A dictionary of attribute values.
+        :param sourceline: The line number where this tag was found in its
+            source document.
+        :param sourcepos: The character position within `sourceline` where this
+            tag was found.
+
+        If this method returns None, the tag was rejected by an active
+        SoupStrainer. You should proceed as if the tag had not occurred
+        in the document. For instance, if this was a self-closing tag,
+        don't call handle_endtag.
+        """
+        # print("Start tag %s: %s" % (name, attrs))
+        self.endData()
+
+        if (self.parse_only and len(self.tagStack) <= 1
+            and (self.parse_only.text
+                 or not self.parse_only.search_tag(name, attrs))):
+            return None
+
+        tag = self.element_classes.get(Tag, Tag)(
+            self, self.builder, name, namespace, nsprefix, attrs,
+            self.currentTag, self._most_recent_element,
+            sourceline=sourceline, sourcepos=sourcepos
+        )
+        if tag is None:
+            return tag
+        if self._most_recent_element is not None:
+            self._most_recent_element.next_element = tag
+        self._most_recent_element = tag
+        self.pushTag(tag)
+        return tag
+
+    def handle_endtag(self, name, nsprefix=None):
+        """Called by the tree builder when an ending tag is encountered.
+
+        :param name: Name of the tag.
+        :param nsprefix: Namespace prefix for the tag.
+        """
+        #print("End tag: " + name)
+        self.endData()
+        self._popToTag(name, nsprefix)
+
+    def handle_data(self, data):
+        """Called by the tree builder when a chunk of textual data is encountered."""
+        self.current_data.append(data)
+       
+    def decode(self, pretty_print=False,
+               eventual_encoding=DEFAULT_OUTPUT_ENCODING,
+               formatter="minimal"):
+        """Returns a string or Unicode representation of the parse tree
+            as an HTML or XML document.
+
+        :param pretty_print: If this is True, indentation will be used to
+            make the document more readable.
+        :param eventual_encoding: The encoding of the final document.
+            If this is None, the document will be a Unicode string.
+        """
+        if self.is_xml:
+            # Print the XML declaration
+            encoding_part = ''
+            if eventual_encoding in PYTHON_SPECIFIC_ENCODINGS:
+                # This is a special Python encoding; it can't actually
+                # go into an XML document because it means nothing
+                # outside of Python.
+                eventual_encoding = None
+            if eventual_encoding != None:
+                encoding_part = ' encoding="%s"' % eventual_encoding
+            prefix = '<?xml version="1.0"%s?>\n' % encoding_part
+        else:
+            prefix = ''
+        if not pretty_print:
+            indent_level = None
+        else:
+            indent_level = 0
+        return prefix + super(BeautifulSoup, self).decode(
+            indent_level, eventual_encoding, formatter)
+
+# Aliases to make it easier to get started quickly, e.g. 'from bs4 import _soup'
+_s = BeautifulSoup
+_soup = BeautifulSoup
+
+class BeautifulStoneSoup(BeautifulSoup):
+    """Deprecated interface to an XML parser."""
+
+    def __init__(self, *args, **kwargs):
+        kwargs['features'] = 'xml'
+        warnings.warn(
+            'The BeautifulStoneSoup class is deprecated. Instead of using '
+            'it, pass features="xml" into the BeautifulSoup constructor.')
+        super(BeautifulStoneSoup, self).__init__(*args, **kwargs)
+
+
+class StopParsing(Exception):
+    """Exception raised by a TreeBuilder if it's unable to continue parsing."""
+    pass
+
+class FeatureNotFound(ValueError):
+    """Exception raised by the BeautifulSoup constructor if no parser with the
+    requested features is found.
+    """
+    pass
+
+
+#If this file is run as a script, act as an HTML pretty-printer.
+if __name__ == '__main__':
+    import sys
+    soup = BeautifulSoup(sys.stdin)
+    print((soup.prettify()))
Index: latest/Lib/site-packages/bs4/tests/test_builder_registry.py
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/latest/Lib/site-packages/bs4/tests/test_builder_registry.py b/latest/Lib/site-packages/bs4/tests/test_builder_registry.py
new file mode 100644
--- /dev/null	(date 1616411342112)
+++ b/latest/Lib/site-packages/bs4/tests/test_builder_registry.py	(date 1616411342112)
@@ -0,0 +1,147 @@
+"""Tests of the builder registry."""
+
+import unittest
+import warnings
+
+from bs4 import BeautifulSoup
+from bs4.builder import (
+    builder_registry as registry,
+    HTMLParserTreeBuilder,
+    TreeBuilderRegistry,
+)
+
+try:
+    from bs4.builder import HTML5TreeBuilder
+    HTML5LIB_PRESENT = True
+except ImportError:
+    HTML5LIB_PRESENT = False
+
+try:
+    from bs4.builder import (
+        LXMLTreeBuilderForXML,
+        LXMLTreeBuilder,
+        )
+    LXML_PRESENT = True
+except ImportError:
+    LXML_PRESENT = False
+
+
+class BuiltInRegistryTest(unittest.TestCase):
+    """Test the built-in registry with the default builders registered."""
+
+    def test_combination(self):
+        if LXML_PRESENT:
+            self.assertEqual(registry.lookup('fast', 'html'),
+                             LXMLTreeBuilder)
+
+        if LXML_PRESENT:
+            self.assertEqual(registry.lookup('permissive', 'xml'),
+                             LXMLTreeBuilderForXML)
+        self.assertEqual(registry.lookup('strict', 'html'),
+                          HTMLParserTreeBuilder)
+        if HTML5LIB_PRESENT:
+            self.assertEqual(registry.lookup('html5lib', 'html'),
+                              HTML5TreeBuilder)
+
+    def test_lookup_by_markup_type(self):
+        if LXML_PRESENT:
+            self.assertEqual(registry.lookup('html'), LXMLTreeBuilder)
+            self.assertEqual(registry.lookup('xml'), LXMLTreeBuilderForXML)
+        else:
+            self.assertEqual(registry.lookup('xml'), None)
+            if HTML5LIB_PRESENT:
+                self.assertEqual(registry.lookup('html'), HTML5TreeBuilder)
+            else:
+                self.assertEqual(registry.lookup('html'), HTMLParserTreeBuilder)
+
+    def test_named_library(self):
+        if LXML_PRESENT:
+            self.assertEqual(registry.lookup('lxml', 'xml'),
+                             LXMLTreeBuilderForXML)
+            self.assertEqual(registry.lookup('lxml', 'html'),
+                             LXMLTreeBuilder)
+        if HTML5LIB_PRESENT:
+            self.assertEqual(registry.lookup('html5lib'),
+                              HTML5TreeBuilder)
+
+        self.assertEqual(registry.lookup('html.parser'),
+                          HTMLParserTreeBuilder)
+
+    def test_beautifulsoup_constructor_does_lookup(self):
+
+        with warnings.catch_warnings(record=True) as w:
+            # This will create a warning about not explicitly
+            # specifying a parser, but we'll ignore it.
+
+            # You can pass in a string.
+            BeautifulSoup("", features="html")
+            # Or a list of strings.
+            BeautifulSoup("", features=["html", "fast"])
+
+        # You'll get an exception if BS can't find an appropriate
+        # builder.
+        self.assertRaises(ValueError, BeautifulSoup,
+                          "", features="no-such-feature")
+
+class RegistryTest(unittest.TestCase):
+    """Test the TreeBuilderRegistry class in general."""
+
+    def setUp(self):
+        self.registry = TreeBuilderRegistry()
+
+    def builder_for_features(self, *feature_list):
+        cls = type('Builder_' + '_'.join(feature_list),
+                   (object,), {'features' : feature_list})
+
+        self.registry.register(cls)
+        return cls
+
+    def test_register_with_no_features(self):
+        builder = self.builder_for_features()
+
+        # Since the builder advertises no features, you can't find it
+        # by looking up features.
+        self.assertEqual(self.registry.lookup('foo'), None)
+
+        # But you can find it by doing a lookup with no features, if
+        # this happens to be the only registered builder.
+        self.assertEqual(self.registry.lookup(), builder)
+
+    def test_register_with_features_makes_lookup_succeed(self):
+        builder = self.builder_for_features('foo', 'bar')
+        self.assertEqual(self.registry.lookup('foo'), builder)
+        self.assertEqual(self.registry.lookup('bar'), builder)
+
+    def test_lookup_fails_when_no_builder_implements_feature(self):
+        builder = self.builder_for_features('foo', 'bar')
+        self.assertEqual(self.registry.lookup('baz'), None)
+
+    def test_lookup_gets_most_recent_registration_when_no_feature_specified(self):
+        builder1 = self.builder_for_features('foo')
+        builder2 = self.builder_for_features('bar')
+        self.assertEqual(self.registry.lookup(), builder2)
+
+    def test_lookup_fails_when_no_tree_builders_registered(self):
+        self.assertEqual(self.registry.lookup(), None)
+
+    def test_lookup_gets_most_recent_builder_supporting_all_features(self):
+        has_one = self.builder_for_features('foo')
+        has_the_other = self.builder_for_features('bar')
+        has_both_early = self.builder_for_features('foo', 'bar', 'baz')
+        has_both_late = self.builder_for_features('foo', 'bar', 'quux')
+        lacks_one = self.builder_for_features('bar')
+        has_the_other = self.builder_for_features('foo')
+
+        # There are two builders featuring 'foo' and 'bar', but
+        # the one that also features 'quux' was registered later.
+        self.assertEqual(self.registry.lookup('foo', 'bar'),
+                          has_both_late)
+
+        # There is only one builder featuring 'foo', 'bar', and 'baz'.
+        self.assertEqual(self.registry.lookup('foo', 'bar', 'baz'),
+                          has_both_early)
+
+    def test_lookup_fails_when_cannot_reconcile_requested_features(self):
+        builder1 = self.builder_for_features('foo', 'bar')
+        builder2 = self.builder_for_features('foo', 'baz')
+        self.assertEqual(self.registry.lookup('bar', 'baz'), None)
Index: latest/Lib/site-packages/bs4/tests/test_docs.py
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/latest/Lib/site-packages/bs4/tests/test_docs.py b/latest/Lib/site-packages/bs4/tests/test_docs.py
new file mode 100644
--- /dev/null	(date 1616411342114)
+++ b/latest/Lib/site-packages/bs4/tests/test_docs.py	(date 1616411342114)
@@ -0,0 +1,36 @@
+"Test harness for doctests."
+
+# pylint: disable-msg=E0611,W0142
+
+__metaclass__ = type
+__all__ = [
+    'additional_tests',
+    ]
+
+import atexit
+import doctest
+import os
+#from pkg_resources import (
+#    resource_filename, resource_exists, resource_listdir, cleanup_resources)
+import unittest
+
+DOCTEST_FLAGS = (
+    doctest.ELLIPSIS |
+    doctest.NORMALIZE_WHITESPACE |
+    doctest.REPORT_NDIFF)
+
+
+# def additional_tests():
+#     "Run the doc tests (README.txt and docs/*, if any exist)"
+#     doctest_files = [
+#         os.path.abspath(resource_filename('bs4', 'README.txt'))]
+#     if resource_exists('bs4', 'docs'):
+#         for name in resource_listdir('bs4', 'docs'):
+#             if name.endswith('.txt'):
+#                 doctest_files.append(
+#                     os.path.abspath(
+#                         resource_filename('bs4', 'docs/%s' % name)))
+#     kwargs = dict(module_relative=False, optionflags=DOCTEST_FLAGS)
+#     atexit.register(cleanup_resources)
+#     return unittest.TestSuite((
+#         doctest.DocFileSuite(*doctest_files, **kwargs)))
Index: latest/Lib/site-packages/bs4/tests/test_html5lib.py
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/latest/Lib/site-packages/bs4/tests/test_html5lib.py b/latest/Lib/site-packages/bs4/tests/test_html5lib.py
new file mode 100644
--- /dev/null	(date 1616411342117)
+++ b/latest/Lib/site-packages/bs4/tests/test_html5lib.py	(date 1616411342117)
@@ -0,0 +1,190 @@
+"""Tests to ensure that the html5lib tree builder generates good trees."""
+
+import warnings
+
+try:
+    from bs4.builder import HTML5TreeBuilder
+    HTML5LIB_PRESENT = True
+except ImportError as e:
+    HTML5LIB_PRESENT = False
+from bs4.element import SoupStrainer
+from bs4.testing import (
+    HTML5TreeBuilderSmokeTest,
+    SoupTest,
+    skipIf,
+)
+
+@skipIf(
+    not HTML5LIB_PRESENT,
+    "html5lib seems not to be present, not testing its tree builder.")
+class HTML5LibBuilderSmokeTest(SoupTest, HTML5TreeBuilderSmokeTest):
+    """See ``HTML5TreeBuilderSmokeTest``."""
+
+    @property
+    def default_builder(self):
+        return HTML5TreeBuilder
+
+    def test_soupstrainer(self):
+        # The html5lib tree builder does not support SoupStrainers.
+        strainer = SoupStrainer("b")
+        markup = "<p>A <b>bold</b> statement.</p>"
+        with warnings.catch_warnings(record=True) as w:
+            soup = self.soup(markup, parse_only=strainer)
+        self.assertEqual(
+            soup.decode(), self.document_for(markup))
+
+        self.assertTrue(
+            "the html5lib tree builder doesn't support parse_only" in
+            str(w[0].message))
+
+    def test_correctly_nested_tables(self):
+        """html5lib inserts <tbody> tags where other parsers don't."""
+        markup = ('<table id="1">'
+                  '<tr>'
+                  "<td>Here's another table:"
+                  '<table id="2">'
+                  '<tr><td>foo</td></tr>'
+                  '</table></td>')
+
+        self.assertSoupEquals(
+            markup,
+            '<table id="1"><tbody><tr><td>Here\'s another table:'
+            '<table id="2"><tbody><tr><td>foo</td></tr></tbody></table>'
+            '</td></tr></tbody></table>')
+
+        self.assertSoupEquals(
+            "<table><thead><tr><td>Foo</td></tr></thead>"
+            "<tbody><tr><td>Bar</td></tr></tbody>"
+            "<tfoot><tr><td>Baz</td></tr></tfoot></table>")
+
+    def test_xml_declaration_followed_by_doctype(self):
+        markup = '''<?xml version="1.0" encoding="utf-8"?>
+<!DOCTYPE html>
+<html>
+  <head>
+  </head>
+  <body>
+   <p>foo</p>
+  </body>
+</html>'''
+        soup = self.soup(markup)
+        # Verify that we can reach the <p> tag; this means the tree is connected.
+        self.assertEqual(b"<p>foo</p>", soup.p.encode())
+
+    def test_reparented_markup(self):
+        markup = '<p><em>foo</p>\n<p>bar<a></a></em></p>'
+        soup = self.soup(markup)
+        self.assertEqual("<body><p><em>foo</em></p><em>\n</em><p><em>bar<a></a></em></p></body>", soup.body.decode())
+        self.assertEqual(2, len(soup.find_all('p')))
+
+
+    def test_reparented_markup_ends_with_whitespace(self):
+        markup = '<p><em>foo</p>\n<p>bar<a></a></em></p>\n'
+        soup = self.soup(markup)
+        self.assertEqual("<body><p><em>foo</em></p><em>\n</em><p><em>bar<a></a></em></p>\n</body>", soup.body.decode())
+        self.assertEqual(2, len(soup.find_all('p')))
+
+    def test_reparented_markup_containing_identical_whitespace_nodes(self):
+        """Verify that we keep the two whitespace nodes in this
+        document distinct when reparenting the adjacent <tbody> tags.
+        """
+        markup = '<table> <tbody><tbody><ims></tbody> </table>'
+        soup = self.soup(markup)
+        space1, space2 = soup.find_all(string=' ')
+        tbody1, tbody2 = soup.find_all('tbody')
+        assert space1.next_element is tbody1
+        assert tbody2.next_element is space2
+
+    def test_reparented_markup_containing_children(self):
+        markup = '<div><a>aftermath<p><noscript>target</noscript>aftermath</a></p></div>'
+        soup = self.soup(markup)
+        noscript = soup.noscript
+        self.assertEqual("target", noscript.next_element)
+        target = soup.find(string='target')
+
+        # The 'aftermath' string was duplicated; we want the second one.
+        final_aftermath = soup.find_all(string='aftermath')[-1]
+
+        # The <noscript> tag was moved beneath a copy of the <a> tag,
+        # but the 'target' string within is still connected to the
+        # (second) 'aftermath' string.
+        self.assertEqual(final_aftermath, target.next_element)
+        self.assertEqual(target, final_aftermath.previous_element)
+        
+    def test_processing_instruction(self):
+        """Processing instructions become comments."""
+        markup = b"""<?PITarget PIContent?>"""
+        soup = self.soup(markup)
+        assert str(soup).startswith("<!--?PITarget PIContent?-->")
+
+    def test_cloned_multivalue_node(self):
+        markup = b"""<a class="my_class"><p></a>"""
+        soup = self.soup(markup)
+        a1, a2 = soup.find_all('a')
+        self.assertEqual(a1, a2)
+        assert a1 is not a2
+
+    def test_foster_parenting(self):
+        markup = b"""<table><td></tbody>A"""
+        soup = self.soup(markup)
+        self.assertEqual("<body>A<table><tbody><tr><td></td></tr></tbody></table></body>", soup.body.decode())
+
+    def test_extraction(self):
+        """
+        Test that extraction does not destroy the tree.
+
+        https://bugs.launchpad.net/beautifulsoup/+bug/1782928
+        """
+
+        markup = """
+<html><head></head>
+<style>
+</style><script></script><body><p>hello</p></body></html>
+"""
+        soup = self.soup(markup)
+        [s.extract() for s in soup('script')]
+        [s.extract() for s in soup('style')]
+
+        self.assertEqual(len(soup.find_all("p")), 1)
+
+    def test_empty_comment(self):
+        """
+        Test that empty comment does not break structure.
+
+        https://bugs.launchpad.net/beautifulsoup/+bug/1806598
+        """
+
+        markup = """
+<html>
+<body>
+<form>
+<!----><input type="text">
+</form>
+</body>
+</html>
+"""
+        soup = self.soup(markup)
+        inputs = []
+        for form in soup.find_all('form'):
+            inputs.extend(form.find_all('input'))
+        self.assertEqual(len(inputs), 1)
+
+    def test_tracking_line_numbers(self):
+        # The html.parser TreeBuilder keeps track of line number and
+        # position of each element.
+        markup = "\n   <p>\n\n<sourceline>\n<b>text</b></sourceline><sourcepos></p>"
+        soup = self.soup(markup)
+        self.assertEqual(2, soup.p.sourceline)
+        self.assertEqual(5, soup.p.sourcepos)
+        self.assertEqual("sourceline", soup.p.find('sourceline').name)
+
+        # You can deactivate this behavior.
+        soup = self.soup(markup, store_line_numbers=False)
+        self.assertEqual("sourceline", soup.p.sourceline.name)
+        self.assertEqual("sourcepos", soup.p.sourcepos.name)
+
+    def test_special_string_containers(self):
+        # The html5lib tree builder doesn't support this standard feature,
+        # because there's no way of knowing, when a string is created,
+        # where in the tree it will eventually end up.
+        pass
Index: latest/Lib/site-packages/bs4/tests/test_htmlparser.py
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/latest/Lib/site-packages/bs4/tests/test_htmlparser.py b/latest/Lib/site-packages/bs4/tests/test_htmlparser.py
new file mode 100644
--- /dev/null	(date 1616411342119)
+++ b/latest/Lib/site-packages/bs4/tests/test_htmlparser.py	(date 1616411342119)
@@ -0,0 +1,97 @@
+"""Tests to ensure that the html.parser tree builder generates good
+trees."""
+
+from pdb import set_trace
+import pickle
+from bs4.testing import SoupTest, HTMLTreeBuilderSmokeTest
+from bs4.builder import HTMLParserTreeBuilder
+from bs4.builder._htmlparser import BeautifulSoupHTMLParser
+
+class HTMLParserTreeBuilderSmokeTest(SoupTest, HTMLTreeBuilderSmokeTest):
+
+    default_builder = HTMLParserTreeBuilder
+
+    def test_namespaced_system_doctype(self):
+        # html.parser can't handle namespaced doctypes, so skip this one.
+        pass
+
+    def test_namespaced_public_doctype(self):
+        # html.parser can't handle namespaced doctypes, so skip this one.
+        pass
+
+    def test_builder_is_pickled(self):
+        """Unlike most tree builders, HTMLParserTreeBuilder and will
+        be restored after pickling.
+        """
+        tree = self.soup("<a><b>foo</a>")
+        dumped = pickle.dumps(tree, 2)
+        loaded = pickle.loads(dumped)
+        self.assertTrue(isinstance(loaded.builder, type(tree.builder)))
+
+    def test_redundant_empty_element_closing_tags(self):
+        self.assertSoupEquals('<br></br><br></br><br></br>', "<br/><br/><br/>")
+        self.assertSoupEquals('</br></br></br>', "")
+
+    def test_empty_element(self):
+        # This verifies that any buffered data present when the parser
+        # finishes working is handled.
+        self.assertSoupEquals("foo &# bar", "foo &amp;# bar")
+
+    def test_tracking_line_numbers(self):
+        # The html.parser TreeBuilder keeps track of line number and
+        # position of each element.
+        markup = "\n   <p>\n\n<sourceline>\n<b>text</b></sourceline><sourcepos></p>"
+        soup = self.soup(markup)
+        self.assertEqual(2, soup.p.sourceline)
+        self.assertEqual(3, soup.p.sourcepos)
+        self.assertEqual("sourceline", soup.p.find('sourceline').name)
+
+        # You can deactivate this behavior.
+        soup = self.soup(markup, store_line_numbers=False)
+        self.assertEqual("sourceline", soup.p.sourceline.name)
+        self.assertEqual("sourcepos", soup.p.sourcepos.name)
+
+    def test_on_duplicate_attribute(self):
+        # The html.parser tree builder has a variety of ways of
+        # handling a tag that contains the same attribute multiple times.
+
+        markup = '<a class="cls" href="url1" href="url2" href="url3" id="id">'
+
+        # If you don't provide any particular value for
+        # on_duplicate_attribute, later values replace earlier values.
+        soup = self.soup(markup)
+        self.assertEqual("url3", soup.a['href'])
+        self.assertEqual(["cls"], soup.a['class'])
+        self.assertEqual("id", soup.a['id'])
+        
+        # You can also get this behavior explicitly.
+        def assert_attribute(on_duplicate_attribute, expected):
+            soup = self.soup(
+                markup, on_duplicate_attribute=on_duplicate_attribute
+            )
+            self.assertEqual(expected, soup.a['href'])
+
+            # Verify that non-duplicate attributes are treated normally.
+            self.assertEqual(["cls"], soup.a['class'])
+            self.assertEqual("id", soup.a['id'])
+        assert_attribute(None, "url3")
+        assert_attribute(BeautifulSoupHTMLParser.REPLACE, "url3")
+
+        # You can ignore subsequent values in favor of the first.
+        assert_attribute(BeautifulSoupHTMLParser.IGNORE, "url1")
+
+        # And you can pass in a callable that does whatever you want.
+        def accumulate(attrs, key, value):
+            if not isinstance(attrs[key], list):
+                attrs[key] = [attrs[key]]
+            attrs[key].append(value)
+        assert_attribute(accumulate, ["url1", "url2", "url3"])            
+
+
+class TestHTMLParserSubclass(SoupTest):
+    def test_error(self):
+        """Verify that our HTMLParser subclass implements error() in a way
+        that doesn't cause a crash.
+        """
+        parser = BeautifulSoupHTMLParser()
+        parser.error("don't crash")
Index: latest/Lib/site-packages/bs4/tests/test_lxml.py
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/latest/Lib/site-packages/bs4/tests/test_lxml.py b/latest/Lib/site-packages/bs4/tests/test_lxml.py
new file mode 100644
--- /dev/null	(date 1616411342120)
+++ b/latest/Lib/site-packages/bs4/tests/test_lxml.py	(date 1616411342120)
@@ -0,0 +1,115 @@
+"""Tests to ensure that the lxml tree builder generates good trees."""
+
+import re
+import warnings
+
+try:
+    import lxml.etree
+    LXML_PRESENT = True
+    LXML_VERSION = lxml.etree.LXML_VERSION
+except ImportError as e:
+    LXML_PRESENT = False
+    LXML_VERSION = (0,)
+
+if LXML_PRESENT:
+    from bs4.builder import LXMLTreeBuilder, LXMLTreeBuilderForXML
+
+from bs4 import (
+    BeautifulSoup,
+    BeautifulStoneSoup,
+    )
+from bs4.element import Comment, Doctype, SoupStrainer
+from bs4.testing import skipIf
+from bs4.tests import test_htmlparser
+from bs4.testing import (
+    HTMLTreeBuilderSmokeTest,
+    XMLTreeBuilderSmokeTest,
+    SoupTest,
+    skipIf,
+)
+
+@skipIf(
+    not LXML_PRESENT,
+    "lxml seems not to be present, not testing its tree builder.")
+class LXMLTreeBuilderSmokeTest(SoupTest, HTMLTreeBuilderSmokeTest):
+    """See ``HTMLTreeBuilderSmokeTest``."""
+
+    @property
+    def default_builder(self):
+        return LXMLTreeBuilder
+
+    def test_out_of_range_entity(self):
+        self.assertSoupEquals(
+            "<p>foo&#10000000000000;bar</p>", "<p>foobar</p>")
+        self.assertSoupEquals(
+            "<p>foo&#x10000000000000;bar</p>", "<p>foobar</p>")
+        self.assertSoupEquals(
+            "<p>foo&#1000000000;bar</p>", "<p>foobar</p>")
+
+    def test_entities_in_foreign_document_encoding(self):
+        # We can't implement this case correctly because by the time we
+        # hear about markup like "&#147;", it's been (incorrectly) converted into
+        # a string like u'\x93'
+        pass
+        
+    # In lxml < 2.3.5, an empty doctype causes a segfault. Skip this
+    # test if an old version of lxml is installed.
+
+    @skipIf(
+        not LXML_PRESENT or LXML_VERSION < (2,3,5,0),
+        "Skipping doctype test for old version of lxml to avoid segfault.")
+    def test_empty_doctype(self):
+        soup = self.soup("<!DOCTYPE>")
+        doctype = soup.contents[0]
+        self.assertEqual("", doctype.strip())
+
+    def test_beautifulstonesoup_is_xml_parser(self):
+        # Make sure that the deprecated BSS class uses an xml builder
+        # if one is installed.
+        with warnings.catch_warnings(record=True) as w:
+            soup = BeautifulStoneSoup("<b />")
+        self.assertEqual("<b/>", str(soup.b))
+        self.assertTrue("BeautifulStoneSoup class is deprecated" in str(w[0].message))
+
+    def test_tracking_line_numbers(self):
+        # The lxml TreeBuilder cannot keep track of line numbers from
+        # the original markup. Even if you ask for line numbers, we
+        # don't have 'em.
+        #
+        # This means that if you have a tag like <sourceline> or
+        # <sourcepos>, attribute access will find it rather than
+        # giving you a numeric answer.
+        soup = self.soup(
+            "\n   <p>\n\n<sourceline>\n<b>text</b></sourceline><sourcepos></p>",
+            store_line_numbers=True
+        )
+        self.assertEqual("sourceline", soup.p.sourceline.name)
+        self.assertEqual("sourcepos", soup.p.sourcepos.name)
+        
+@skipIf(
+    not LXML_PRESENT,
+    "lxml seems not to be present, not testing its XML tree builder.")
+class LXMLXMLTreeBuilderSmokeTest(SoupTest, XMLTreeBuilderSmokeTest):
+    """See ``HTMLTreeBuilderSmokeTest``."""
+
+    @property
+    def default_builder(self):
+        return LXMLTreeBuilderForXML
+
+    def test_namespace_indexing(self):
+        # We should not track un-prefixed namespaces as we can only hold one
+        # and it will be recognized as the default namespace by soupsieve,
+        # which may be confusing in some situations. When no namespace is provided
+        # for a selector, the default namespace (if defined) is assumed.
+
+        soup = self.soup(
+            '<?xml version="1.1"?>\n'
+            '<root>'
+            '<tag xmlns="http://unprefixed-namespace.com">content</tag>'
+            '<prefix:tag xmlns:prefix="http://prefixed-namespace.com">content</tag>'
+            '</root>'
+        )
+        self.assertEqual(
+            soup._namespaces,
+            {'xml': 'http://www.w3.org/XML/1998/namespace', 'prefix': 'http://prefixed-namespace.com'}
+        )
Index: latest/Lib/site-packages/bs4/tests/test_soup.py
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/latest/Lib/site-packages/bs4/tests/test_soup.py b/latest/Lib/site-packages/bs4/tests/test_soup.py
new file mode 100644
--- /dev/null	(date 1616411342122)
+++ b/latest/Lib/site-packages/bs4/tests/test_soup.py	(date 1616411342122)
@@ -0,0 +1,728 @@
+# -*- coding: utf-8 -*-
+"""Tests of Beautiful Soup as a whole."""
+
+from pdb import set_trace
+import logging
+import unittest
+import sys
+import tempfile
+
+from bs4 import (
+    BeautifulSoup,
+    BeautifulStoneSoup,
+    GuessedAtParserWarning,
+    MarkupResemblesLocatorWarning,
+)
+from bs4.builder import (
+    TreeBuilder,
+    ParserRejectedMarkup,
+)
+from bs4.element import (
+    CharsetMetaAttributeValue,
+    Comment,
+    ContentMetaAttributeValue,
+    SoupStrainer,
+    NamespacedAttribute,
+    Tag,
+    NavigableString,
+    )
+
+import bs4.dammit
+from bs4.dammit import (
+    EntitySubstitution,
+    UnicodeDammit,
+    EncodingDetector,
+)
+from bs4.testing import (
+    default_builder,
+    SoupTest,
+    skipIf,
+)
+import warnings
+
+try:
+    from bs4.builder import LXMLTreeBuilder, LXMLTreeBuilderForXML
+    LXML_PRESENT = True
+except ImportError as e:
+    LXML_PRESENT = False
+
+PYTHON_3_PRE_3_2 = (sys.version_info[0] == 3 and sys.version_info < (3,2))
+
+class TestConstructor(SoupTest):
+
+    def test_short_unicode_input(self):
+        data = "<h1>éé</h1>"
+        soup = self.soup(data)
+        self.assertEqual("éé", soup.h1.string)
+
+    def test_embedded_null(self):
+        data = "<h1>foo\0bar</h1>"
+        soup = self.soup(data)
+        self.assertEqual("foo\0bar", soup.h1.string)
+
+    def test_exclude_encodings(self):
+        utf8_data = "Räksmörgås".encode("utf-8")
+        soup = self.soup(utf8_data, exclude_encodings=["utf-8"])
+        self.assertEqual("windows-1252", soup.original_encoding)
+
+    def test_custom_builder_class(self):
+        # Verify that you can pass in a custom Builder class and
+        # it'll be instantiated with the appropriate keyword arguments.
+        class Mock(object):
+            def __init__(self, **kwargs):
+                self.called_with = kwargs
+                self.is_xml = True
+                self.store_line_numbers = False
+                self.cdata_list_attributes = []
+                self.preserve_whitespace_tags = []
+                self.string_containers = {}
+            def initialize_soup(self, soup):
+                pass
+            def feed(self, markup):
+                self.fed = markup
+            def reset(self):
+                pass
+            def ignore(self, ignore):
+                pass
+            set_up_substitutions = can_be_empty_element = ignore
+            def prepare_markup(self, *args, **kwargs):
+                yield "prepared markup", "original encoding", "declared encoding", "contains replacement characters"
+                
+        kwargs = dict(
+            var="value",
+            # This is a deprecated BS3-era keyword argument, which
+            # will be stripped out.
+            convertEntities=True,
+        )
+        with warnings.catch_warnings(record=True):
+            soup = BeautifulSoup('', builder=Mock, **kwargs)
+        assert isinstance(soup.builder, Mock)
+        self.assertEqual(dict(var="value"), soup.builder.called_with)
+        self.assertEqual("prepared markup", soup.builder.fed)
+        
+        # You can also instantiate the TreeBuilder yourself. In this
+        # case, that specific object is used and any keyword arguments
+        # to the BeautifulSoup constructor are ignored.
+        builder = Mock(**kwargs)
+        with warnings.catch_warnings(record=True) as w:
+            soup = BeautifulSoup(
+                '', builder=builder, ignored_value=True,
+            )
+        msg = str(w[0].message)
+        assert msg.startswith("Keyword arguments to the BeautifulSoup constructor will be ignored.")
+        self.assertEqual(builder, soup.builder)
+        self.assertEqual(kwargs, builder.called_with)
+
+    def test_parser_markup_rejection(self):
+        # If markup is completely rejected by the parser, an
+        # explanatory ParserRejectedMarkup exception is raised.
+        class Mock(TreeBuilder):
+            def feed(self, *args, **kwargs):
+                raise ParserRejectedMarkup("Nope.")
+
+        def prepare_markup(self, *args, **kwargs):
+            # We're going to try two different ways of preparing this markup,
+            # but feed() will reject both of them.
+            yield markup, None, None, False
+            yield markup, None, None, False
+            
+        import re
+        self.assertRaisesRegex(
+            ParserRejectedMarkup,
+            "The markup you provided was rejected by the parser. Trying a different parser or a different encoding may help.",
+            BeautifulSoup, '', builder=Mock,
+        )
+        
+    def test_cdata_list_attributes(self):
+        # Most attribute values are represented as scalars, but the
+        # HTML standard says that some attributes, like 'class' have
+        # space-separated lists as values.
+        markup = '<a id=" an id " class=" a class "></a>'
+        soup = self.soup(markup)
+
+        # Note that the spaces are stripped for 'class' but not for 'id'.
+        a = soup.a
+        self.assertEqual(" an id ", a['id'])
+        self.assertEqual(["a", "class"], a['class'])
+
+        # TreeBuilder takes an argument called 'mutli_valued_attributes'  which lets
+        # you customize or disable this. As always, you can customize the TreeBuilder
+        # by passing in a keyword argument to the BeautifulSoup constructor.
+        soup = self.soup(markup, builder=default_builder, multi_valued_attributes=None)
+        self.assertEqual(" a class ", soup.a['class'])
+
+        # Here are two ways of saying that `id` is a multi-valued
+        # attribute in this context, but 'class' is not.
+        for switcheroo in ({'*': 'id'}, {'a': 'id'}):
+            with warnings.catch_warnings(record=True) as w:
+                # This will create a warning about not explicitly
+                # specifying a parser, but we'll ignore it.
+                soup = self.soup(markup, builder=None, multi_valued_attributes=switcheroo)
+            a = soup.a
+            self.assertEqual(["an", "id"], a['id'])
+            self.assertEqual(" a class ", a['class'])
+
+    def test_replacement_classes(self):
+        # Test the ability to pass in replacements for element classes
+        # which will be used when building the tree.
+        class TagPlus(Tag):
+            pass
+
+        class StringPlus(NavigableString):
+            pass
+
+        class CommentPlus(Comment):
+            pass
+        
+        soup = self.soup(
+            "<a><b>foo</b>bar</a><!--whee-->",
+            element_classes = {
+                Tag: TagPlus,
+                NavigableString: StringPlus,
+                Comment: CommentPlus,
+            }
+        )
+
+        # The tree was built with TagPlus, StringPlus, and CommentPlus objects,
+        # rather than Tag, String, and Comment objects.
+        assert all(
+            isinstance(x, (TagPlus, StringPlus, CommentPlus))
+            for x in soup.recursiveChildGenerator()
+        )
+
+    def test_alternate_string_containers(self):
+        # Test the ability to customize the string containers for
+        # different types of tags.
+        class PString(NavigableString):
+            pass
+
+        class BString(NavigableString):
+            pass
+
+        soup = self.soup(
+            "<div>Hello.<p>Here is <b>some <i>bolded</i></b> text",
+            string_containers = {
+                'b': BString,
+                'p': PString,
+            }
+        )
+
+        # The string before the <p> tag is a regular NavigableString.
+        assert isinstance(soup.div.contents[0], NavigableString)
+        
+        # The string inside the <p> tag, but not inside the <i> tag,
+        # is a PString.
+        assert isinstance(soup.p.contents[0], PString)
+
+        # Every string inside the <b> tag is a BString, even the one that
+        # was also inside an <i> tag.
+        for s in soup.b.strings:
+            assert isinstance(s, BString)
+
+        # Now that parsing was complete, the string_container_stack
+        # (where this information was kept) has been cleared out.
+        self.assertEqual([], soup.string_container_stack)
+
+
+class TestWarnings(SoupTest):
+
+    def _assert_warning(self, warnings, cls):
+        for w in warnings:
+            if isinstance(w.message, cls):
+                return w
+        raise Exception("%s warning not found in %r" % cls, warnings)
+    
+    def _assert_no_parser_specified(self, w):
+        warning = self._assert_warning(w, GuessedAtParserWarning)
+        message = str(warning.message)
+        self.assertTrue(
+            message.startswith(BeautifulSoup.NO_PARSER_SPECIFIED_WARNING[:60])
+        )
+
+    def test_warning_if_no_parser_specified(self):
+        with warnings.catch_warnings(record=True) as w:
+            soup = BeautifulSoup("<a><b></b></a>")
+        self._assert_no_parser_specified(w)
+
+    def test_warning_if_parser_specified_too_vague(self):
+        with warnings.catch_warnings(record=True) as w:
+            soup = BeautifulSoup("<a><b></b></a>", "html")
+        self._assert_no_parser_specified(w)
+
+    def test_no_warning_if_explicit_parser_specified(self):
+        with warnings.catch_warnings(record=True) as w:
+            soup = BeautifulSoup("<a><b></b></a>", "html.parser")
+        self.assertEqual([], w)
+
+    def test_parseOnlyThese_renamed_to_parse_only(self):
+        with warnings.catch_warnings(record=True) as w:
+            soup = self.soup("<a><b></b></a>", parseOnlyThese=SoupStrainer("b"))
+        msg = str(w[0].message)
+        self.assertTrue("parseOnlyThese" in msg)
+        self.assertTrue("parse_only" in msg)
+        self.assertEqual(b"<b></b>", soup.encode())
+
+    def test_fromEncoding_renamed_to_from_encoding(self):
+        with warnings.catch_warnings(record=True) as w:
+            utf8 = b"\xc3\xa9"
+            soup = self.soup(utf8, fromEncoding="utf8")
+        msg = str(w[0].message)
+        self.assertTrue("fromEncoding" in msg)
+        self.assertTrue("from_encoding" in msg)
+        self.assertEqual("utf8", soup.original_encoding)
+
+    def test_unrecognized_keyword_argument(self):
+        self.assertRaises(
+            TypeError, self.soup, "<a>", no_such_argument=True)
+
+    def test_disk_file_warning(self):
+        filehandle = tempfile.NamedTemporaryFile()
+        filename = filehandle.name
+        try:
+            with warnings.catch_warnings(record=True) as w:
+                soup = self.soup(filename)
+            warning = self._assert_warning(w, MarkupResemblesLocatorWarning)
+            self.assertTrue("looks like a filename" in str(warning.message))
+        finally:
+            filehandle.close()
+
+        # The file no longer exists, so Beautiful Soup will no longer issue the warning.
+        with warnings.catch_warnings(record=True) as w:
+            soup = self.soup(filename)
+        self.assertEqual([], w)
+
+    def test_url_warning_with_bytes_url(self):
+        with warnings.catch_warnings(record=True) as warning_list:
+            soup = self.soup(b"http://www.crummybytes.com/")
+        warning = self._assert_warning(
+            warning_list, MarkupResemblesLocatorWarning
+        )
+        self.assertTrue("looks like a URL" in str(warning.message))
+
+    def test_url_warning_with_unicode_url(self):
+        with warnings.catch_warnings(record=True) as warning_list:
+            # note - this url must differ from the bytes one otherwise
+            # python's warnings system swallows the second warning
+            soup = self.soup("http://www.crummyunicode.com/")
+        warning = self._assert_warning(
+            warning_list, MarkupResemblesLocatorWarning
+        )
+        self.assertTrue("looks like a URL" in str(warning.message))
+
+    def test_url_warning_with_bytes_and_space(self):
+        # Here the markup contains something besides a URL, so no warning
+        # is issued.
+        with warnings.catch_warnings(record=True) as warning_list:
+            soup = self.soup(b"http://www.crummybytes.com/ is great")
+        self.assertFalse(any("looks like a URL" in str(w.message) 
+            for w in warning_list))
+
+    def test_url_warning_with_unicode_and_space(self):
+        with warnings.catch_warnings(record=True) as warning_list:
+            soup = self.soup("http://www.crummyuncode.com/ is great")
+        self.assertFalse(any("looks like a URL" in str(w.message) 
+            for w in warning_list))
+
+
+class TestSelectiveParsing(SoupTest):
+
+    def test_parse_with_soupstrainer(self):
+        markup = "No<b>Yes</b><a>No<b>Yes <c>Yes</c></b>"
+        strainer = SoupStrainer("b")
+        soup = self.soup(markup, parse_only=strainer)
+        self.assertEqual(soup.encode(), b"<b>Yes</b><b>Yes <c>Yes</c></b>")
+
+
+class TestEntitySubstitution(unittest.TestCase):
+    """Standalone tests of the EntitySubstitution class."""
+    def setUp(self):
+        self.sub = EntitySubstitution
+
+    def test_simple_html_substitution(self):
+        # Unicode characters corresponding to named HTML entites
+        # are substituted, and no others.
+        s = "foo\u2200\N{SNOWMAN}\u00f5bar"
+        self.assertEqual(self.sub.substitute_html(s),
+                          "foo&forall;\N{SNOWMAN}&otilde;bar")
+
+    def test_smart_quote_substitution(self):
+        # MS smart quotes are a common source of frustration, so we
+        # give them a special test.
+        quotes = b"\x91\x92foo\x93\x94"
+        dammit = UnicodeDammit(quotes)
+        self.assertEqual(self.sub.substitute_html(dammit.markup),
+                          "&lsquo;&rsquo;foo&ldquo;&rdquo;")
+
+    def test_xml_converstion_includes_no_quotes_if_make_quoted_attribute_is_false(self):
+        s = 'Welcome to "my bar"'
+        self.assertEqual(self.sub.substitute_xml(s, False), s)
+
+    def test_xml_attribute_quoting_normally_uses_double_quotes(self):
+        self.assertEqual(self.sub.substitute_xml("Welcome", True),
+                          '"Welcome"')
+        self.assertEqual(self.sub.substitute_xml("Bob's Bar", True),
+                          '"Bob\'s Bar"')
+
+    def test_xml_attribute_quoting_uses_single_quotes_when_value_contains_double_quotes(self):
+        s = 'Welcome to "my bar"'
+        self.assertEqual(self.sub.substitute_xml(s, True),
+                          "'Welcome to \"my bar\"'")
+
+    def test_xml_attribute_quoting_escapes_single_quotes_when_value_contains_both_single_and_double_quotes(self):
+        s = 'Welcome to "Bob\'s Bar"'
+        self.assertEqual(
+            self.sub.substitute_xml(s, True),
+            '"Welcome to &quot;Bob\'s Bar&quot;"')
+
+    def test_xml_quotes_arent_escaped_when_value_is_not_being_quoted(self):
+        quoted = 'Welcome to "Bob\'s Bar"'
+        self.assertEqual(self.sub.substitute_xml(quoted), quoted)
+
+    def test_xml_quoting_handles_angle_brackets(self):
+        self.assertEqual(
+            self.sub.substitute_xml("foo<bar>"),
+            "foo&lt;bar&gt;")
+
+    def test_xml_quoting_handles_ampersands(self):
+        self.assertEqual(self.sub.substitute_xml("AT&T"), "AT&amp;T")
+
+    def test_xml_quoting_including_ampersands_when_they_are_part_of_an_entity(self):
+        self.assertEqual(
+            self.sub.substitute_xml("&Aacute;T&T"),
+            "&amp;Aacute;T&amp;T")
+
+    def test_xml_quoting_ignoring_ampersands_when_they_are_part_of_an_entity(self):
+        self.assertEqual(
+            self.sub.substitute_xml_containing_entities("&Aacute;T&T"),
+            "&Aacute;T&amp;T")
+       
+    def test_quotes_not_html_substituted(self):
+        """There's no need to do this except inside attribute values."""
+        text = 'Bob\'s "bar"'
+        self.assertEqual(self.sub.substitute_html(text), text)
+
+
+class TestEncodingConversion(SoupTest):
+    # Test Beautiful Soup's ability to decode and encode from various
+    # encodings.
+
+    def setUp(self):
+        super(TestEncodingConversion, self).setUp()
+        self.unicode_data = '<html><head><meta charset="utf-8"/></head><body><foo>Sacr\N{LATIN SMALL LETTER E WITH ACUTE} bleu!</foo></body></html>'
+        self.utf8_data = self.unicode_data.encode("utf-8")
+        # Just so you know what it looks like.
+        self.assertEqual(
+            self.utf8_data,
+            b'<html><head><meta charset="utf-8"/></head><body><foo>Sacr\xc3\xa9 bleu!</foo></body></html>')
+
+    def test_ascii_in_unicode_out(self):
+        # ASCII input is converted to Unicode. The original_encoding
+        # attribute is set to 'utf-8', a superset of ASCII.
+        chardet = bs4.dammit.chardet_dammit
+        logging.disable(logging.WARNING)
+        try:
+            def noop(str):
+                return None
+            # Disable chardet, which will realize that the ASCII is ASCII.
+            bs4.dammit.chardet_dammit = noop
+            ascii = b"<foo>a</foo>"
+            soup_from_ascii = self.soup(ascii)
+            unicode_output = soup_from_ascii.decode()
+            self.assertTrue(isinstance(unicode_output, str))
+            self.assertEqual(unicode_output, self.document_for(ascii.decode()))
+            self.assertEqual(soup_from_ascii.original_encoding.lower(), "utf-8")
+        finally:
+            logging.disable(logging.NOTSET)
+            bs4.dammit.chardet_dammit = chardet
+
+    def test_unicode_in_unicode_out(self):
+        # Unicode input is left alone. The original_encoding attribute
+        # is not set.
+        soup_from_unicode = self.soup(self.unicode_data)
+        self.assertEqual(soup_from_unicode.decode(), self.unicode_data)
+        self.assertEqual(soup_from_unicode.foo.string, 'Sacr\xe9 bleu!')
+        self.assertEqual(soup_from_unicode.original_encoding, None)
+
+    def test_utf8_in_unicode_out(self):
+        # UTF-8 input is converted to Unicode. The original_encoding
+        # attribute is set.
+        soup_from_utf8 = self.soup(self.utf8_data)
+        self.assertEqual(soup_from_utf8.decode(), self.unicode_data)
+        self.assertEqual(soup_from_utf8.foo.string, 'Sacr\xe9 bleu!')
+
+    def test_utf8_out(self):
+        # The internal data structures can be encoded as UTF-8.
+        soup_from_unicode = self.soup(self.unicode_data)
+        self.assertEqual(soup_from_unicode.encode('utf-8'), self.utf8_data)
+
+    @skipIf(
+        PYTHON_3_PRE_3_2,
+        "Bad HTMLParser detected; skipping test of non-ASCII characters in attribute name.")
+    def test_attribute_name_containing_unicode_characters(self):
+        markup = '<div><a \N{SNOWMAN}="snowman"></a></div>'
+        self.assertEqual(self.soup(markup).div.encode("utf8"), markup.encode("utf8"))
+
+class TestUnicodeDammit(unittest.TestCase):
+    """Standalone tests of UnicodeDammit."""
+
+    def test_unicode_input(self):
+        markup = "I'm already Unicode! \N{SNOWMAN}"
+        dammit = UnicodeDammit(markup)
+        self.assertEqual(dammit.unicode_markup, markup)
+
+    def test_smart_quotes_to_unicode(self):
+        markup = b"<foo>\x91\x92\x93\x94</foo>"
+        dammit = UnicodeDammit(markup)
+        self.assertEqual(
+            dammit.unicode_markup, "<foo>\u2018\u2019\u201c\u201d</foo>")
+
+    def test_smart_quotes_to_xml_entities(self):
+        markup = b"<foo>\x91\x92\x93\x94</foo>"
+        dammit = UnicodeDammit(markup, smart_quotes_to="xml")
+        self.assertEqual(
+            dammit.unicode_markup, "<foo>&#x2018;&#x2019;&#x201C;&#x201D;</foo>")
+
+    def test_smart_quotes_to_html_entities(self):
+        markup = b"<foo>\x91\x92\x93\x94</foo>"
+        dammit = UnicodeDammit(markup, smart_quotes_to="html")
+        self.assertEqual(
+            dammit.unicode_markup, "<foo>&lsquo;&rsquo;&ldquo;&rdquo;</foo>")
+
+    def test_smart_quotes_to_ascii(self):
+        markup = b"<foo>\x91\x92\x93\x94</foo>"
+        dammit = UnicodeDammit(markup, smart_quotes_to="ascii")
+        self.assertEqual(
+            dammit.unicode_markup, """<foo>''""</foo>""")
+
+    def test_detect_utf8(self):
+        utf8 = b"Sacr\xc3\xa9 bleu! \xe2\x98\x83"
+        dammit = UnicodeDammit(utf8)
+        self.assertEqual(dammit.original_encoding.lower(), 'utf-8')
+        self.assertEqual(dammit.unicode_markup, 'Sacr\xe9 bleu! \N{SNOWMAN}')
+
+
+    def test_convert_hebrew(self):
+        hebrew = b"\xed\xe5\xec\xf9"
+        dammit = UnicodeDammit(hebrew, ["iso-8859-8"])
+        self.assertEqual(dammit.original_encoding.lower(), 'iso-8859-8')
+        self.assertEqual(dammit.unicode_markup, '\u05dd\u05d5\u05dc\u05e9')
+
+    def test_dont_see_smart_quotes_where_there_are_none(self):
+        utf_8 = b"\343\202\261\343\203\274\343\202\277\343\202\244 Watch"
+        dammit = UnicodeDammit(utf_8)
+        self.assertEqual(dammit.original_encoding.lower(), 'utf-8')
+        self.assertEqual(dammit.unicode_markup.encode("utf-8"), utf_8)
+
+    def test_ignore_inappropriate_codecs(self):
+        utf8_data = "Räksmörgås".encode("utf-8")
+        dammit = UnicodeDammit(utf8_data, ["iso-8859-8"])
+        self.assertEqual(dammit.original_encoding.lower(), 'utf-8')
+
+    def test_ignore_invalid_codecs(self):
+        utf8_data = "Räksmörgås".encode("utf-8")
+        for bad_encoding in ['.utf8', '...', 'utF---16.!']:
+            dammit = UnicodeDammit(utf8_data, [bad_encoding])
+            self.assertEqual(dammit.original_encoding.lower(), 'utf-8')
+
+    def test_exclude_encodings(self):
+        # This is UTF-8.
+        utf8_data = "Räksmörgås".encode("utf-8")
+
+        # But if we exclude UTF-8 from consideration, the guess is
+        # Windows-1252.
+        dammit = UnicodeDammit(utf8_data, exclude_encodings=["utf-8"])
+        self.assertEqual(dammit.original_encoding.lower(), 'windows-1252')
+
+        # And if we exclude that, there is no valid guess at all.
+        dammit = UnicodeDammit(
+            utf8_data, exclude_encodings=["utf-8", "windows-1252"])
+        self.assertEqual(dammit.original_encoding, None)
+
+    def test_encoding_detector_replaces_junk_in_encoding_name_with_replacement_character(self):
+        detected = EncodingDetector(
+            b'<?xml version="1.0" encoding="UTF-\xdb" ?>')
+        encodings = list(detected.encodings)
+        assert 'utf-\N{REPLACEMENT CHARACTER}' in encodings
+
+    def test_detect_html5_style_meta_tag(self):
+
+        for data in (
+            b'<html><meta charset="euc-jp" /></html>',
+            b"<html><meta charset='euc-jp' /></html>",
+            b"<html><meta charset=euc-jp /></html>",
+            b"<html><meta charset=euc-jp/></html>"):
+            dammit = UnicodeDammit(data, is_html=True)
+            self.assertEqual(
+                "euc-jp", dammit.original_encoding)
+
+    def test_last_ditch_entity_replacement(self):
+        # This is a UTF-8 document that contains bytestrings
+        # completely incompatible with UTF-8 (ie. encoded with some other
+        # encoding).
+        #
+        # Since there is no consistent encoding for the document,
+        # Unicode, Dammit will eventually encode the document as UTF-8
+        # and encode the incompatible characters as REPLACEMENT
+        # CHARACTER.
+        #
+        # If chardet is installed, it will detect that the document
+        # can be converted into ISO-8859-1 without errors. This happens
+        # to be the wrong encoding, but it is a consistent encoding, so the
+        # code we're testing here won't run.
+        #
+        # So we temporarily disable chardet if it's present.
+        doc = b"""\357\273\277<?xml version="1.0" encoding="UTF-8"?>
+<html><b>\330\250\330\252\330\261</b>
+<i>\310\322\321\220\312\321\355\344</i></html>"""
+        chardet = bs4.dammit.chardet_dammit
+        logging.disable(logging.WARNING)
+        try:
+            def noop(str):
+                return None
+            bs4.dammit.chardet_dammit = noop
+            dammit = UnicodeDammit(doc)
+            self.assertEqual(True, dammit.contains_replacement_characters)
+            self.assertTrue("\ufffd" in dammit.unicode_markup)
+
+            soup = BeautifulSoup(doc, "html.parser")
+            self.assertTrue(soup.contains_replacement_characters)
+        finally:
+            logging.disable(logging.NOTSET)
+            bs4.dammit.chardet_dammit = chardet
+
+    def test_byte_order_mark_removed(self):
+        # A document written in UTF-16LE will have its byte order marker stripped.
+        data = b'\xff\xfe<\x00a\x00>\x00\xe1\x00\xe9\x00<\x00/\x00a\x00>\x00'
+        dammit = UnicodeDammit(data)
+        self.assertEqual("<a>áé</a>", dammit.unicode_markup)
+        self.assertEqual("utf-16le", dammit.original_encoding)
+
+    def test_detwingle(self):
+        # Here's a UTF8 document.
+        utf8 = ("\N{SNOWMAN}" * 3).encode("utf8")
+
+        # Here's a Windows-1252 document.
+        windows_1252 = (
+            "\N{LEFT DOUBLE QUOTATION MARK}Hi, I like Windows!"
+            "\N{RIGHT DOUBLE QUOTATION MARK}").encode("windows_1252")
+
+        # Through some unholy alchemy, they've been stuck together.
+        doc = utf8 + windows_1252 + utf8
+
+        # The document can't be turned into UTF-8:
+        self.assertRaises(UnicodeDecodeError, doc.decode, "utf8")
+
+        # Unicode, Dammit thinks the whole document is Windows-1252,
+        # and decodes it into "â˜ƒâ˜ƒâ˜ƒ“Hi, I like Windows!”â˜ƒâ˜ƒâ˜ƒ"
+
+        # But if we run it through fix_embedded_windows_1252, it's fixed:
+
+        fixed = UnicodeDammit.detwingle(doc)
+        self.assertEqual(
+            "☃☃☃“Hi, I like Windows!”☃☃☃", fixed.decode("utf8"))
+
+    def test_detwingle_ignores_multibyte_characters(self):
+        # Each of these characters has a UTF-8 representation ending
+        # in \x93. \x93 is a smart quote if interpreted as
+        # Windows-1252. But our code knows to skip over multibyte
+        # UTF-8 characters, so they'll survive the process unscathed.
+        for tricky_unicode_char in (
+            "\N{LATIN SMALL LIGATURE OE}", # 2-byte char '\xc5\x93'
+            "\N{LATIN SUBSCRIPT SMALL LETTER X}", # 3-byte char '\xe2\x82\x93'
+            "\xf0\x90\x90\x93", # This is a CJK character, not sure which one.
+            ):
+            input = tricky_unicode_char.encode("utf8")
+            self.assertTrue(input.endswith(b'\x93'))
+            output = UnicodeDammit.detwingle(input)
+            self.assertEqual(output, input)
+
+    def test_find_declared_encoding(self):
+        # Test our ability to find a declared encoding inside an
+        # XML or HTML document.
+        #
+        # Even if the document comes in as Unicode, it may be
+        # interesting to know what encoding was claimed
+        # originally.
+
+        html_unicode = '<html><head><meta charset="utf-8"></head></html>'
+        html_bytes = html_unicode.encode("ascii")
+
+        xml_unicode= '<?xml version="1.0" encoding="ISO-8859-1" ?>'
+        xml_bytes = xml_unicode.encode("ascii")
+
+        m = EncodingDetector.find_declared_encoding
+        self.assertEqual(None, m(html_unicode, is_html=False))
+        self.assertEqual("utf-8", m(html_unicode, is_html=True))
+        self.assertEqual("utf-8", m(html_bytes, is_html=True))
+
+        self.assertEqual("iso-8859-1", m(xml_unicode))
+        self.assertEqual("iso-8859-1", m(xml_bytes))
+
+        # Normally, only the first few kilobytes of a document are checked for
+        # an encoding.
+        spacer = b' ' * 5000
+        self.assertEqual(None, m(spacer + html_bytes))
+        self.assertEqual(None, m(spacer + xml_bytes))
+
+        # But you can tell find_declared_encoding to search an entire
+        # HTML document.
+        self.assertEqual(
+            "utf-8",
+            m(spacer + html_bytes, is_html=True, search_entire_document=True)
+        )
+
+        # The XML encoding declaration has to be the very first thing
+        # in the document. We'll allow whitespace before the document
+        # starts, but nothing else.
+        self.assertEqual(
+            "iso-8859-1",
+            m(xml_bytes, search_entire_document=True)
+        )
+        self.assertEqual(
+            None, m(b'a' + xml_bytes, search_entire_document=True)
+        )
+            
+class TestNamedspacedAttribute(SoupTest):
+
+    def test_name_may_be_none_or_missing(self):
+        a = NamespacedAttribute("xmlns", None)
+        self.assertEqual(a, "xmlns")
+
+        a = NamespacedAttribute("xmlns")
+        self.assertEqual(a, "xmlns")
+        
+    def test_attribute_is_equivalent_to_colon_separated_string(self):
+        a = NamespacedAttribute("a", "b")
+        self.assertEqual("a:b", a)
+
+    def test_attributes_are_equivalent_if_prefix_and_name_identical(self):
+        a = NamespacedAttribute("a", "b", "c")
+        b = NamespacedAttribute("a", "b", "c")
+        self.assertEqual(a, b)
+
+        # The actual namespace is not considered.
+        c = NamespacedAttribute("a", "b", None)
+        self.assertEqual(a, c)
+
+        # But name and prefix are important.
+        d = NamespacedAttribute("a", "z", "c")
+        self.assertNotEqual(a, d)
+
+        e = NamespacedAttribute("z", "b", "c")
+        self.assertNotEqual(a, e)
+
+
+class TestAttributeValueWithCharsetSubstitution(unittest.TestCase):
+
+    def test_content_meta_attribute_value(self):
+        value = CharsetMetaAttributeValue("euc-jp")
+        self.assertEqual("euc-jp", value)
+        self.assertEqual("euc-jp", value.original_value)
+        self.assertEqual("utf8", value.encode("utf8"))
+
+
+    def test_content_meta_attribute_value(self):
+        value = ContentMetaAttributeValue("text/html; charset=euc-jp")
+        self.assertEqual("text/html; charset=euc-jp", value)
+        self.assertEqual("text/html; charset=euc-jp", value.original_value)
+        self.assertEqual("text/html; charset=utf8", value.encode("utf8"))
Index: latest/Lib/site-packages/bs4/tests/test_tree.py
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/latest/Lib/site-packages/bs4/tests/test_tree.py b/latest/Lib/site-packages/bs4/tests/test_tree.py
new file mode 100644
--- /dev/null	(date 1616411342124)
+++ b/latest/Lib/site-packages/bs4/tests/test_tree.py	(date 1616411342124)
@@ -0,0 +1,2333 @@
+# -*- coding: utf-8 -*-
+"""Tests for Beautiful Soup's tree traversal methods.
+
+The tree traversal methods are the main advantage of using Beautiful
+Soup over just using a parser.
+
+Different parsers will build different Beautiful Soup trees given the
+same markup, but all Beautiful Soup trees can be traversed with the
+methods tested here.
+"""
+
+from pdb import set_trace
+import copy
+import pickle
+import re
+import warnings
+from bs4 import BeautifulSoup
+from bs4.builder import (
+    builder_registry,
+    HTMLParserTreeBuilder,
+)
+from bs4.element import (
+    PY3K,
+    CData,
+    Comment,
+    Declaration,
+    Doctype,
+    Formatter,
+    NavigableString,
+    Script,
+    SoupStrainer,
+    Stylesheet,
+    Tag,
+    TemplateString,
+)
+from bs4.testing import (
+    SoupTest,
+    skipIf,
+)
+from soupsieve import SelectorSyntaxError
+
+XML_BUILDER_PRESENT = (builder_registry.lookup("xml") is not None)
+LXML_PRESENT = (builder_registry.lookup("lxml") is not None)
+
+class TreeTest(SoupTest):
+
+    def assertSelects(self, tags, should_match):
+        """Make sure that the given tags have the correct text.
+
+        This is used in tests that define a bunch of tags, each
+        containing a single string, and then select certain strings by
+        some mechanism.
+        """
+        self.assertEqual([tag.string for tag in tags], should_match)
+
+    def assertSelectsIDs(self, tags, should_match):
+        """Make sure that the given tags have the correct IDs.
+
+        This is used in tests that define a bunch of tags, each
+        containing a single string, and then select certain strings by
+        some mechanism.
+        """
+        self.assertEqual([tag['id'] for tag in tags], should_match)
+
+
+class TestFind(TreeTest):
+    """Basic tests of the find() method.
+
+    find() just calls find_all() with limit=1, so it's not tested all
+    that thouroughly here.
+    """
+
+    def test_find_tag(self):
+        soup = self.soup("<a>1</a><b>2</b><a>3</a><b>4</b>")
+        self.assertEqual(soup.find("b").string, "2")
+
+    def test_unicode_text_find(self):
+        soup = self.soup('<h1>Räksmörgås</h1>')
+        self.assertEqual(soup.find(string='Räksmörgås'), 'Räksmörgås')
+
+    def test_unicode_attribute_find(self):
+        soup = self.soup('<h1 id="Räksmörgås">here it is</h1>')
+        str(soup)
+        self.assertEqual("here it is", soup.find(id='Räksmörgås').text)
+
+
+    def test_find_everything(self):
+        """Test an optimization that finds all tags."""
+        soup = self.soup("<a>foo</a><b>bar</b>")
+        self.assertEqual(2, len(soup.find_all()))
+
+    def test_find_everything_with_name(self):
+        """Test an optimization that finds all tags with a given name."""
+        soup = self.soup("<a>foo</a><b>bar</b><a>baz</a>")
+        self.assertEqual(2, len(soup.find_all('a')))
+
+class TestFindAll(TreeTest):
+    """Basic tests of the find_all() method."""
+
+    def test_find_all_text_nodes(self):
+        """You can search the tree for text nodes."""
+        soup = self.soup("<html>Foo<b>bar</b>\xbb</html>")
+        # Exact match.
+        self.assertEqual(soup.find_all(string="bar"), ["bar"])
+        self.assertEqual(soup.find_all(text="bar"), ["bar"])
+        # Match any of a number of strings.
+        self.assertEqual(
+            soup.find_all(text=["Foo", "bar"]), ["Foo", "bar"])
+        # Match a regular expression.
+        self.assertEqual(soup.find_all(text=re.compile('.*')),
+                         ["Foo", "bar", '\xbb'])
+        # Match anything.
+        self.assertEqual(soup.find_all(text=True),
+                         ["Foo", "bar", '\xbb'])
+
+    def test_find_all_limit(self):
+        """You can limit the number of items returned by find_all."""
+        soup = self.soup("<a>1</a><a>2</a><a>3</a><a>4</a><a>5</a>")
+        self.assertSelects(soup.find_all('a', limit=3), ["1", "2", "3"])
+        self.assertSelects(soup.find_all('a', limit=1), ["1"])
+        self.assertSelects(
+            soup.find_all('a', limit=10), ["1", "2", "3", "4", "5"])
+
+        # A limit of 0 means no limit.
+        self.assertSelects(
+            soup.find_all('a', limit=0), ["1", "2", "3", "4", "5"])
+
+    def test_calling_a_tag_is_calling_findall(self):
+        soup = self.soup("<a>1</a><b>2<a id='foo'>3</a></b>")
+        self.assertSelects(soup('a', limit=1), ["1"])
+        self.assertSelects(soup.b(id="foo"), ["3"])
+
+    def test_find_all_with_self_referential_data_structure_does_not_cause_infinite_recursion(self):
+        soup = self.soup("<a></a>")
+        # Create a self-referential list.
+        l = []
+        l.append(l)
+
+        # Without special code in _normalize_search_value, this would cause infinite
+        # recursion.
+        self.assertEqual([], soup.find_all(l))
+
+    def test_find_all_resultset(self):
+        """All find_all calls return a ResultSet"""
+        soup = self.soup("<a></a>")
+        result = soup.find_all("a")
+        self.assertTrue(hasattr(result, "source"))
+
+        result = soup.find_all(True)
+        self.assertTrue(hasattr(result, "source"))
+
+        result = soup.find_all(text="foo")
+        self.assertTrue(hasattr(result, "source"))
+
+
+class TestFindAllBasicNamespaces(TreeTest):
+
+    def test_find_by_namespaced_name(self):
+        soup = self.soup('<mathml:msqrt>4</mathml:msqrt><a svg:fill="red">')
+        self.assertEqual("4", soup.find("mathml:msqrt").string)
+        self.assertEqual("a", soup.find(attrs= { "svg:fill" : "red" }).name)
+
+
+class TestFindAllByName(TreeTest):
+    """Test ways of finding tags by tag name."""
+
+    def setUp(self):
+        super(TreeTest, self).setUp()
+        self.tree =  self.soup("""<a>First tag.</a>
+                                  <b>Second tag.</b>
+                                  <c>Third <a>Nested tag.</a> tag.</c>""")
+
+    def test_find_all_by_tag_name(self):
+        # Find all the <a> tags.
+        self.assertSelects(
+            self.tree.find_all('a'), ['First tag.', 'Nested tag.'])
+
+    def test_find_all_by_name_and_text(self):
+        self.assertSelects(
+            self.tree.find_all('a', text='First tag.'), ['First tag.'])
+
+        self.assertSelects(
+            self.tree.find_all('a', text=True), ['First tag.', 'Nested tag.'])
+
+        self.assertSelects(
+            self.tree.find_all('a', text=re.compile("tag")),
+            ['First tag.', 'Nested tag.'])
+
+
+    def test_find_all_on_non_root_element(self):
+        # You can call find_all on any node, not just the root.
+        self.assertSelects(self.tree.c.find_all('a'), ['Nested tag.'])
+
+    def test_calling_element_invokes_find_all(self):
+        self.assertSelects(self.tree('a'), ['First tag.', 'Nested tag.'])
+
+    def test_find_all_by_tag_strainer(self):
+        self.assertSelects(
+            self.tree.find_all(SoupStrainer('a')),
+            ['First tag.', 'Nested tag.'])
+
+    def test_find_all_by_tag_names(self):
+        self.assertSelects(
+            self.tree.find_all(['a', 'b']),
+            ['First tag.', 'Second tag.', 'Nested tag.'])
+
+    def test_find_all_by_tag_dict(self):
+        self.assertSelects(
+            self.tree.find_all({'a' : True, 'b' : True}),
+            ['First tag.', 'Second tag.', 'Nested tag.'])
+
+    def test_find_all_by_tag_re(self):
+        self.assertSelects(
+            self.tree.find_all(re.compile('^[ab]$')),
+            ['First tag.', 'Second tag.', 'Nested tag.'])
+
+    def test_find_all_with_tags_matching_method(self):
+        # You can define an oracle method that determines whether
+        # a tag matches the search.
+        def id_matches_name(tag):
+            return tag.name == tag.get('id')
+
+        tree = self.soup("""<a id="a">Match 1.</a>
+                            <a id="1">Does not match.</a>
+                            <b id="b">Match 2.</a>""")
+
+        self.assertSelects(
+            tree.find_all(id_matches_name), ["Match 1.", "Match 2."])
+
+    def test_find_with_multi_valued_attribute(self):
+        soup = self.soup(
+            "<div class='a b'>1</div><div class='a c'>2</div><div class='a d'>3</div>"
+        )
+        r1 = soup.find('div', 'a d');
+        r2 = soup.find('div', re.compile(r'a d'));
+        r3, r4 = soup.find_all('div', ['a b', 'a d']);
+        self.assertEqual('3', r1.string)
+        self.assertEqual('3', r2.string)
+        self.assertEqual('1', r3.string)
+        self.assertEqual('3', r4.string)
+
+        
+class TestFindAllByAttribute(TreeTest):
+
+    def test_find_all_by_attribute_name(self):
+        # You can pass in keyword arguments to find_all to search by
+        # attribute.
+        tree = self.soup("""
+                         <a id="first">Matching a.</a>
+                         <a id="second">
+                          Non-matching <b id="first">Matching b.</b>a.
+                         </a>""")
+        self.assertSelects(tree.find_all(id='first'),
+                           ["Matching a.", "Matching b."])
+
+    def test_find_all_by_utf8_attribute_value(self):
+        peace = "םולש".encode("utf8")
+        data = '<a title="םולש"></a>'.encode("utf8")
+        soup = self.soup(data)
+        self.assertEqual([soup.a], soup.find_all(title=peace))
+        self.assertEqual([soup.a], soup.find_all(title=peace.decode("utf8")))
+        self.assertEqual([soup.a], soup.find_all(title=[peace, "something else"]))
+
+    def test_find_all_by_attribute_dict(self):
+        # You can pass in a dictionary as the argument 'attrs'. This
+        # lets you search for attributes like 'name' (a fixed argument
+        # to find_all) and 'class' (a reserved word in Python.)
+        tree = self.soup("""
+                         <a name="name1" class="class1">Name match.</a>
+                         <a name="name2" class="class2">Class match.</a>
+                         <a name="name3" class="class3">Non-match.</a>
+                         <name1>A tag called 'name1'.</name1>
+                         """)
+
+        # This doesn't do what you want.
+        self.assertSelects(tree.find_all(name='name1'),
+                           ["A tag called 'name1'."])
+        # This does what you want.
+        self.assertSelects(tree.find_all(attrs={'name' : 'name1'}),
+                           ["Name match."])
+
+        self.assertSelects(tree.find_all(attrs={'class' : 'class2'}),
+                           ["Class match."])
+
+    def test_find_all_by_class(self):
+        tree = self.soup("""
+                         <a class="1">Class 1.</a>
+                         <a class="2">Class 2.</a>
+                         <b class="1">Class 1.</b>
+                         <c class="3 4">Class 3 and 4.</c>
+                         """)
+
+        # Passing in the class_ keyword argument will search against
+        # the 'class' attribute.
+        self.assertSelects(tree.find_all('a', class_='1'), ['Class 1.'])
+        self.assertSelects(tree.find_all('c', class_='3'), ['Class 3 and 4.'])
+        self.assertSelects(tree.find_all('c', class_='4'), ['Class 3 and 4.'])
+
+        # Passing in a string to 'attrs' will also search the CSS class.
+        self.assertSelects(tree.find_all('a', '1'), ['Class 1.'])
+        self.assertSelects(tree.find_all(attrs='1'), ['Class 1.', 'Class 1.'])
+        self.assertSelects(tree.find_all('c', '3'), ['Class 3 and 4.'])
+        self.assertSelects(tree.find_all('c', '4'), ['Class 3 and 4.'])
+
+    def test_find_by_class_when_multiple_classes_present(self):
+        tree = self.soup("<gar class='foo bar'>Found it</gar>")
+
+        f = tree.find_all("gar", class_=re.compile("o"))
+        self.assertSelects(f, ["Found it"])
+
+        f = tree.find_all("gar", class_=re.compile("a"))
+        self.assertSelects(f, ["Found it"])
+
+        # If the search fails to match the individual strings "foo" and "bar",
+        # it will be tried against the combined string "foo bar".
+        f = tree.find_all("gar", class_=re.compile("o b"))
+        self.assertSelects(f, ["Found it"])
+
+    def test_find_all_with_non_dictionary_for_attrs_finds_by_class(self):
+        soup = self.soup("<a class='bar'>Found it</a>")
+
+        self.assertSelects(soup.find_all("a", re.compile("ba")), ["Found it"])
+
+        def big_attribute_value(value):
+            return len(value) > 3
+
+        self.assertSelects(soup.find_all("a", big_attribute_value), [])
+
+        def small_attribute_value(value):
+            return len(value) <= 3
+
+        self.assertSelects(
+            soup.find_all("a", small_attribute_value), ["Found it"])
+
+    def test_find_all_with_string_for_attrs_finds_multiple_classes(self):
+        soup = self.soup('<a class="foo bar"></a><a class="foo"></a>')
+        a, a2 = soup.find_all("a")
+        self.assertEqual([a, a2], soup.find_all("a", "foo"))
+        self.assertEqual([a], soup.find_all("a", "bar"))
+
+        # If you specify the class as a string that contains a
+        # space, only that specific value will be found.
+        self.assertEqual([a], soup.find_all("a", class_="foo bar"))
+        self.assertEqual([a], soup.find_all("a", "foo bar"))
+        self.assertEqual([], soup.find_all("a", "bar foo"))
+
+    def test_find_all_by_attribute_soupstrainer(self):
+        tree = self.soup("""
+                         <a id="first">Match.</a>
+                         <a id="second">Non-match.</a>""")
+
+        strainer = SoupStrainer(attrs={'id' : 'first'})
+        self.assertSelects(tree.find_all(strainer), ['Match.'])
+
+    def test_find_all_with_missing_attribute(self):
+        # You can pass in None as the value of an attribute to find_all.
+        # This will match tags that do not have that attribute set.
+        tree = self.soup("""<a id="1">ID present.</a>
+                            <a>No ID present.</a>
+                            <a id="">ID is empty.</a>""")
+        self.assertSelects(tree.find_all('a', id=None), ["No ID present."])
+
+    def test_find_all_with_defined_attribute(self):
+        # You can pass in None as the value of an attribute to find_all.
+        # This will match tags that have that attribute set to any value.
+        tree = self.soup("""<a id="1">ID present.</a>
+                            <a>No ID present.</a>
+                            <a id="">ID is empty.</a>""")
+        self.assertSelects(
+            tree.find_all(id=True), ["ID present.", "ID is empty."])
+
+    def test_find_all_with_numeric_attribute(self):
+        # If you search for a number, it's treated as a string.
+        tree = self.soup("""<a id=1>Unquoted attribute.</a>
+                            <a id="1">Quoted attribute.</a>""")
+
+        expected = ["Unquoted attribute.", "Quoted attribute."]
+        self.assertSelects(tree.find_all(id=1), expected)
+        self.assertSelects(tree.find_all(id="1"), expected)
+
+    def test_find_all_with_list_attribute_values(self):
+        # You can pass a list of attribute values instead of just one,
+        # and you'll get tags that match any of the values.
+        tree = self.soup("""<a id="1">1</a>
+                            <a id="2">2</a>
+                            <a id="3">3</a>
+                            <a>No ID.</a>""")
+        self.assertSelects(tree.find_all(id=["1", "3", "4"]),
+                           ["1", "3"])
+
+    def test_find_all_with_regular_expression_attribute_value(self):
+        # You can pass a regular expression as an attribute value, and
+        # you'll get tags whose values for that attribute match the
+        # regular expression.
+        tree = self.soup("""<a id="a">One a.</a>
+                            <a id="aa">Two as.</a>
+                            <a id="ab">Mixed as and bs.</a>
+                            <a id="b">One b.</a>
+                            <a>No ID.</a>""")
+
+        self.assertSelects(tree.find_all(id=re.compile("^a+$")),
+                           ["One a.", "Two as."])
+
+    def test_find_by_name_and_containing_string(self):
+        soup = self.soup("<b>foo</b><b>bar</b><a>foo</a>")
+        a = soup.a
+
+        self.assertEqual([a], soup.find_all("a", text="foo"))
+        self.assertEqual([], soup.find_all("a", text="bar"))
+        self.assertEqual([], soup.find_all("a", text="bar"))
+
+    def test_find_by_name_and_containing_string_when_string_is_buried(self):
+        soup = self.soup("<a>foo</a><a><b><c>foo</c></b></a>")
+        self.assertEqual(soup.find_all("a"), soup.find_all("a", text="foo"))
+
+    def test_find_by_attribute_and_containing_string(self):
+        soup = self.soup('<b id="1">foo</b><a id="2">foo</a>')
+        a = soup.a
+
+        self.assertEqual([a], soup.find_all(id=2, text="foo"))
+        self.assertEqual([], soup.find_all(id=1, text="bar"))
+
+
+class TestSmooth(TreeTest):
+    """Test Tag.smooth."""
+
+    def test_smooth(self):
+        soup = self.soup("<div>a</div>")
+        div = soup.div
+        div.append("b")
+        div.append("c")
+        div.append(Comment("Comment 1"))
+        div.append(Comment("Comment 2"))
+        div.append("d")
+        builder = self.default_builder()
+        span = Tag(soup, builder, 'span')
+        span.append('1')
+        span.append('2')
+        div.append(span)
+
+        # At this point the tree has a bunch of adjacent
+        # NavigableStrings. This is normal, but it has no meaning in
+        # terms of HTML, so we may want to smooth things out for
+        # output.
+
+        # Since the <span> tag has two children, its .string is None.
+        self.assertEqual(None, div.span.string)
+
+        self.assertEqual(7, len(div.contents))
+        div.smooth()
+        self.assertEqual(5, len(div.contents))
+
+        # The three strings at the beginning of div.contents have been
+        # merged into on string.
+        #
+        self.assertEqual('abc', div.contents[0])
+
+        # The call is recursive -- the <span> tag was also smoothed.
+        self.assertEqual('12', div.span.string)
+
+        # The two comments have _not_ been merged, even though
+        # comments are strings. Merging comments would change the
+        # meaning of the HTML.
+        self.assertEqual('Comment 1', div.contents[1])
+        self.assertEqual('Comment 2', div.contents[2])
+
+
+class TestIndex(TreeTest):
+    """Test Tag.index"""
+    def test_index(self):
+        tree = self.soup("""<div>
+                            <a>Identical</a>
+                            <b>Not identical</b>
+                            <a>Identical</a>
+
+                            <c><d>Identical with child</d></c>
+                            <b>Also not identical</b>
+                            <c><d>Identical with child</d></c>
+                            </div>""")
+        div = tree.div
+        for i, element in enumerate(div.contents):
+            self.assertEqual(i, div.index(element))
+        self.assertRaises(ValueError, tree.index, 1)
+
+
+class TestParentOperations(TreeTest):
+    """Test navigation and searching through an element's parents."""
+
+    def setUp(self):
+        super(TestParentOperations, self).setUp()
+        self.tree = self.soup('''<ul id="empty"></ul>
+                                 <ul id="top">
+                                  <ul id="middle">
+                                   <ul id="bottom">
+                                    <b>Start here</b>
+                                   </ul>
+                                  </ul>''')
+        self.start = self.tree.b
+
+
+    def test_parent(self):
+        self.assertEqual(self.start.parent['id'], 'bottom')
+        self.assertEqual(self.start.parent.parent['id'], 'middle')
+        self.assertEqual(self.start.parent.parent.parent['id'], 'top')
+
+    def test_parent_of_top_tag_is_soup_object(self):
+        top_tag = self.tree.contents[0]
+        self.assertEqual(top_tag.parent, self.tree)
+
+    def test_soup_object_has_no_parent(self):
+        self.assertEqual(None, self.tree.parent)
+
+    def test_find_parents(self):
+        self.assertSelectsIDs(
+            self.start.find_parents('ul'), ['bottom', 'middle', 'top'])
+        self.assertSelectsIDs(
+            self.start.find_parents('ul', id="middle"), ['middle'])
+
+    def test_find_parent(self):
+        self.assertEqual(self.start.find_parent('ul')['id'], 'bottom')
+        self.assertEqual(self.start.find_parent('ul', id='top')['id'], 'top')
+
+    def test_parent_of_text_element(self):
+        text = self.tree.find(text="Start here")
+        self.assertEqual(text.parent.name, 'b')
+
+    def test_text_element_find_parent(self):
+        text = self.tree.find(text="Start here")
+        self.assertEqual(text.find_parent('ul')['id'], 'bottom')
+
+    def test_parent_generator(self):
+        parents = [parent['id'] for parent in self.start.parents
+                   if parent is not None and 'id' in parent.attrs]
+        self.assertEqual(parents, ['bottom', 'middle', 'top'])
+
+
+class ProximityTest(TreeTest):
+
+    def setUp(self):
+        super(TreeTest, self).setUp()
+        self.tree = self.soup(
+            '<html id="start"><head></head><body><b id="1">One</b><b id="2">Two</b><b id="3">Three</b></body></html>')
+
+
+class TestNextOperations(ProximityTest):
+
+    def setUp(self):
+        super(TestNextOperations, self).setUp()
+        self.start = self.tree.b
+
+    def test_next(self):
+        self.assertEqual(self.start.next_element, "One")
+        self.assertEqual(self.start.next_element.next_element['id'], "2")
+
+    def test_next_of_last_item_is_none(self):
+        last = self.tree.find(text="Three")
+        self.assertEqual(last.next_element, None)
+
+    def test_next_of_root_is_none(self):
+        # The document root is outside the next/previous chain.
+        self.assertEqual(self.tree.next_element, None)
+
+    def test_find_all_next(self):
+        self.assertSelects(self.start.find_all_next('b'), ["Two", "Three"])
+        self.start.find_all_next(id=3)
+        self.assertSelects(self.start.find_all_next(id=3), ["Three"])
+
+    def test_find_next(self):
+        self.assertEqual(self.start.find_next('b')['id'], '2')
+        self.assertEqual(self.start.find_next(text="Three"), "Three")
+
+    def test_find_next_for_text_element(self):
+        text = self.tree.find(text="One")
+        self.assertEqual(text.find_next("b").string, "Two")
+        self.assertSelects(text.find_all_next("b"), ["Two", "Three"])
+
+    def test_next_generator(self):
+        start = self.tree.find(text="Two")
+        successors = [node for node in start.next_elements]
+        # There are two successors: the final <b> tag and its text contents.
+        tag, contents = successors
+        self.assertEqual(tag['id'], '3')
+        self.assertEqual(contents, "Three")
+
+class TestPreviousOperations(ProximityTest):
+
+    def setUp(self):
+        super(TestPreviousOperations, self).setUp()
+        self.end = self.tree.find(text="Three")
+
+    def test_previous(self):
+        self.assertEqual(self.end.previous_element['id'], "3")
+        self.assertEqual(self.end.previous_element.previous_element, "Two")
+
+    def test_previous_of_first_item_is_none(self):
+        first = self.tree.find('html')
+        self.assertEqual(first.previous_element, None)
+
+    def test_previous_of_root_is_none(self):
+        # The document root is outside the next/previous chain.
+        # XXX This is broken!
+        #self.assertEqual(self.tree.previous_element, None)
+        pass
+
+    def test_find_all_previous(self):
+        # The <b> tag containing the "Three" node is the predecessor
+        # of the "Three" node itself, which is why "Three" shows up
+        # here.
+        self.assertSelects(
+            self.end.find_all_previous('b'), ["Three", "Two", "One"])
+        self.assertSelects(self.end.find_all_previous(id=1), ["One"])
+
+    def test_find_previous(self):
+        self.assertEqual(self.end.find_previous('b')['id'], '3')
+        self.assertEqual(self.end.find_previous(text="One"), "One")
+
+    def test_find_previous_for_text_element(self):
+        text = self.tree.find(text="Three")
+        self.assertEqual(text.find_previous("b").string, "Three")
+        self.assertSelects(
+            text.find_all_previous("b"), ["Three", "Two", "One"])
+
+    def test_previous_generator(self):
+        start = self.tree.find(text="One")
+        predecessors = [node for node in start.previous_elements]
+
+        # There are four predecessors: the <b> tag containing "One"
+        # the <body> tag, the <head> tag, and the <html> tag.
+        b, body, head, html = predecessors
+        self.assertEqual(b['id'], '1')
+        self.assertEqual(body.name, "body")
+        self.assertEqual(head.name, "head")
+        self.assertEqual(html.name, "html")
+
+
+class SiblingTest(TreeTest):
+
+    def setUp(self):
+        super(SiblingTest, self).setUp()
+        markup = '''<html>
+                    <span id="1">
+                     <span id="1.1"></span>
+                    </span>
+                    <span id="2">
+                     <span id="2.1"></span>
+                    </span>
+                    <span id="3">
+                     <span id="3.1"></span>
+                    </span>
+                    <span id="4"></span>
+                    </html>'''
+        # All that whitespace looks good but makes the tests more
+        # difficult. Get rid of it.
+        markup = re.compile(r"\n\s*").sub("", markup)
+        self.tree = self.soup(markup)
+
+
+class TestNextSibling(SiblingTest):
+
+    def setUp(self):
+        super(TestNextSibling, self).setUp()
+        self.start = self.tree.find(id="1")
+
+    def test_next_sibling_of_root_is_none(self):
+        self.assertEqual(self.tree.next_sibling, None)
+
+    def test_next_sibling(self):
+        self.assertEqual(self.start.next_sibling['id'], '2')
+        self.assertEqual(self.start.next_sibling.next_sibling['id'], '3')
+
+        # Note the difference between next_sibling and next_element.
+        self.assertEqual(self.start.next_element['id'], '1.1')
+
+    def test_next_sibling_may_not_exist(self):
+        self.assertEqual(self.tree.html.next_sibling, None)
+
+        nested_span = self.tree.find(id="1.1")
+        self.assertEqual(nested_span.next_sibling, None)
+
+        last_span = self.tree.find(id="4")
+        self.assertEqual(last_span.next_sibling, None)
+
+    def test_find_next_sibling(self):
+        self.assertEqual(self.start.find_next_sibling('span')['id'], '2')
+
+    def test_next_siblings(self):
+        self.assertSelectsIDs(self.start.find_next_siblings("span"),
+                              ['2', '3', '4'])
+
+        self.assertSelectsIDs(self.start.find_next_siblings(id='3'), ['3'])
+
+    def test_next_sibling_for_text_element(self):
+        soup = self.soup("Foo<b>bar</b>baz")
+        start = soup.find(text="Foo")
+        self.assertEqual(start.next_sibling.name, 'b')
+        self.assertEqual(start.next_sibling.next_sibling, 'baz')
+
+        self.assertSelects(start.find_next_siblings('b'), ['bar'])
+        self.assertEqual(start.find_next_sibling(text="baz"), "baz")
+        self.assertEqual(start.find_next_sibling(text="nonesuch"), None)
+
+
+class TestPreviousSibling(SiblingTest):
+
+    def setUp(self):
+        super(TestPreviousSibling, self).setUp()
+        self.end = self.tree.find(id="4")
+
+    def test_previous_sibling_of_root_is_none(self):
+        self.assertEqual(self.tree.previous_sibling, None)
+
+    def test_previous_sibling(self):
+        self.assertEqual(self.end.previous_sibling['id'], '3')
+        self.assertEqual(self.end.previous_sibling.previous_sibling['id'], '2')
+
+        # Note the difference between previous_sibling and previous_element.
+        self.assertEqual(self.end.previous_element['id'], '3.1')
+
+    def test_previous_sibling_may_not_exist(self):
+        self.assertEqual(self.tree.html.previous_sibling, None)
+
+        nested_span = self.tree.find(id="1.1")
+        self.assertEqual(nested_span.previous_sibling, None)
+
+        first_span = self.tree.find(id="1")
+        self.assertEqual(first_span.previous_sibling, None)
+
+    def test_find_previous_sibling(self):
+        self.assertEqual(self.end.find_previous_sibling('span')['id'], '3')
+
+    def test_previous_siblings(self):
+        self.assertSelectsIDs(self.end.find_previous_siblings("span"),
+                              ['3', '2', '1'])
+
+        self.assertSelectsIDs(self.end.find_previous_siblings(id='1'), ['1'])
+
+    def test_previous_sibling_for_text_element(self):
+        soup = self.soup("Foo<b>bar</b>baz")
+        start = soup.find(text="baz")
+        self.assertEqual(start.previous_sibling.name, 'b')
+        self.assertEqual(start.previous_sibling.previous_sibling, 'Foo')
+
+        self.assertSelects(start.find_previous_siblings('b'), ['bar'])
+        self.assertEqual(start.find_previous_sibling(text="Foo"), "Foo")
+        self.assertEqual(start.find_previous_sibling(text="nonesuch"), None)
+
+
+class TestTag(SoupTest):
+
+    # Test various methods of Tag.
+
+    def test__should_pretty_print(self):
+        # Test the rules about when a tag should be pretty-printed.
+        tag = self.soup("").new_tag("a_tag")
+
+        # No list of whitespace-preserving tags -> pretty-print
+        tag._preserve_whitespace_tags = None
+        self.assertEqual(True, tag._should_pretty_print(0))
+
+        # List exists but tag is not on the list -> pretty-print
+        tag.preserve_whitespace_tags = ["some_other_tag"]
+        self.assertEqual(True, tag._should_pretty_print(1))
+
+        # Indent level is None -> don't pretty-print
+        self.assertEqual(False, tag._should_pretty_print(None))
+        
+        # Tag is on the whitespace-preserving list -> don't pretty-print
+        tag.preserve_whitespace_tags = ["some_other_tag", "a_tag"]
+        self.assertEqual(False, tag._should_pretty_print(1))
+
+        
+class TestTagCreation(SoupTest):
+    """Test the ability to create new tags."""
+    def test_new_tag(self):
+        soup = self.soup("")
+        new_tag = soup.new_tag("foo", bar="baz", attrs={"name": "a name"})
+        self.assertTrue(isinstance(new_tag, Tag))
+        self.assertEqual("foo", new_tag.name)
+        self.assertEqual(dict(bar="baz", name="a name"), new_tag.attrs)
+        self.assertEqual(None, new_tag.parent)
+        
+    def test_tag_inherits_self_closing_rules_from_builder(self):
+        if XML_BUILDER_PRESENT:
+            xml_soup = BeautifulSoup("", "lxml-xml")
+            xml_br = xml_soup.new_tag("br")
+            xml_p = xml_soup.new_tag("p")
+
+            # Both the <br> and <p> tag are empty-element, just because
+            # they have no contents.
+            self.assertEqual(b"<br/>", xml_br.encode())
+            self.assertEqual(b"<p/>", xml_p.encode())
+
+        html_soup = BeautifulSoup("", "html.parser")
+        html_br = html_soup.new_tag("br")
+        html_p = html_soup.new_tag("p")
+
+        # The HTML builder users HTML's rules about which tags are
+        # empty-element tags, and the new tags reflect these rules.
+        self.assertEqual(b"<br/>", html_br.encode())
+        self.assertEqual(b"<p></p>", html_p.encode())
+
+    def test_new_string_creates_navigablestring(self):
+        soup = self.soup("")
+        s = soup.new_string("foo")
+        self.assertEqual("foo", s)
+        self.assertTrue(isinstance(s, NavigableString))
+
+    def test_new_string_can_create_navigablestring_subclass(self):
+        soup = self.soup("")
+        s = soup.new_string("foo", Comment)
+        self.assertEqual("foo", s)
+        self.assertTrue(isinstance(s, Comment))
+
+class TestTreeModification(SoupTest):
+
+    def test_attribute_modification(self):
+        soup = self.soup('<a id="1"></a>')
+        soup.a['id'] = 2
+        self.assertEqual(soup.decode(), self.document_for('<a id="2"></a>'))
+        del(soup.a['id'])
+        self.assertEqual(soup.decode(), self.document_for('<a></a>'))
+        soup.a['id2'] = 'foo'
+        self.assertEqual(soup.decode(), self.document_for('<a id2="foo"></a>'))
+
+    def test_new_tag_creation(self):
+        builder = builder_registry.lookup('html')()
+        soup = self.soup("<body></body>", builder=builder)
+        a = Tag(soup, builder, 'a')
+        ol = Tag(soup, builder, 'ol')
+        a['href'] = 'http://foo.com/'
+        soup.body.insert(0, a)
+        soup.body.insert(1, ol)
+        self.assertEqual(
+            soup.body.encode(),
+            b'<body><a href="http://foo.com/"></a><ol></ol></body>')
+
+    def test_append_to_contents_moves_tag(self):
+        doc = """<p id="1">Don't leave me <b>here</b>.</p>
+                <p id="2">Don\'t leave!</p>"""
+        soup = self.soup(doc)
+        second_para = soup.find(id='2')
+        bold = soup.b
+
+        # Move the <b> tag to the end of the second paragraph.
+        soup.find(id='2').append(soup.b)
+
+        # The <b> tag is now a child of the second paragraph.
+        self.assertEqual(bold.parent, second_para)
+
+        self.assertEqual(
+            soup.decode(), self.document_for(
+                '<p id="1">Don\'t leave me .</p>\n'
+                '<p id="2">Don\'t leave!<b>here</b></p>'))
+
+    def test_replace_with_returns_thing_that_was_replaced(self):
+        text = "<a></a><b><c></c></b>"
+        soup = self.soup(text)
+        a = soup.a
+        new_a = a.replace_with(soup.c)
+        self.assertEqual(a, new_a)
+
+    def test_unwrap_returns_thing_that_was_replaced(self):
+        text = "<a><b></b><c></c></a>"
+        soup = self.soup(text)
+        a = soup.a
+        new_a = a.unwrap()
+        self.assertEqual(a, new_a)
+
+    def test_replace_with_and_unwrap_give_useful_exception_when_tag_has_no_parent(self):
+        soup = self.soup("<a><b>Foo</b></a><c>Bar</c>")
+        a = soup.a
+        a.extract()
+        self.assertEqual(None, a.parent)
+        self.assertRaises(ValueError, a.unwrap)
+        self.assertRaises(ValueError, a.replace_with, soup.c)
+
+    def test_replace_tag_with_itself(self):
+        text = "<a><b></b><c>Foo<d></d></c></a><a><e></e></a>"
+        soup = self.soup(text)
+        c = soup.c
+        soup.c.replace_with(c)
+        self.assertEqual(soup.decode(), self.document_for(text))
+
+    def test_replace_tag_with_its_parent_raises_exception(self):
+        text = "<a><b></b></a>"
+        soup = self.soup(text)
+        self.assertRaises(ValueError, soup.b.replace_with, soup.a)
+
+    def test_insert_tag_into_itself_raises_exception(self):
+        text = "<a><b></b></a>"
+        soup = self.soup(text)
+        self.assertRaises(ValueError, soup.a.insert, 0, soup.a)
+
+    def test_insert_beautifulsoup_object_inserts_children(self):
+        """Inserting one BeautifulSoup object into another actually inserts all
+        of its children -- you'll never combine BeautifulSoup objects.
+        """
+        soup = self.soup("<p>And now, a word:</p><p>And we're back.</p>")
+        
+        text = "<p>p2</p><p>p3</p>"
+        to_insert = self.soup(text)
+        soup.insert(1, to_insert)
+
+        for i in soup.descendants:
+            assert not isinstance(i, BeautifulSoup)
+        
+        p1, p2, p3, p4 = list(soup.children)
+        self.assertEqual("And now, a word:", p1.string)
+        self.assertEqual("p2", p2.string)
+        self.assertEqual("p3", p3.string)
+        self.assertEqual("And we're back.", p4.string)
+        
+        
+    def test_replace_with_maintains_next_element_throughout(self):
+        soup = self.soup('<p><a>one</a><b>three</b></p>')
+        a = soup.a
+        b = a.contents[0]
+        # Make it so the <a> tag has two text children.
+        a.insert(1, "two")
+
+        # Now replace each one with the empty string.
+        left, right = a.contents
+        left.replaceWith('')
+        right.replaceWith('')
+
+        # The <b> tag is still connected to the tree.
+        self.assertEqual("three", soup.b.string)
+
+    def test_replace_final_node(self):
+        soup = self.soup("<b>Argh!</b>")
+        soup.find(text="Argh!").replace_with("Hooray!")
+        new_text = soup.find(text="Hooray!")
+        b = soup.b
+        self.assertEqual(new_text.previous_element, b)
+        self.assertEqual(new_text.parent, b)
+        self.assertEqual(new_text.previous_element.next_element, new_text)
+        self.assertEqual(new_text.next_element, None)
+
+    def test_consecutive_text_nodes(self):
+        # A builder should never create two consecutive text nodes,
+        # but if you insert one next to another, Beautiful Soup will
+        # handle it correctly.
+        soup = self.soup("<a><b>Argh!</b><c></c></a>")
+        soup.b.insert(1, "Hooray!")
+
+        self.assertEqual(
+            soup.decode(), self.document_for(
+                "<a><b>Argh!Hooray!</b><c></c></a>"))
+
+        new_text = soup.find(text="Hooray!")
+        self.assertEqual(new_text.previous_element, "Argh!")
+        self.assertEqual(new_text.previous_element.next_element, new_text)
+
+        self.assertEqual(new_text.previous_sibling, "Argh!")
+        self.assertEqual(new_text.previous_sibling.next_sibling, new_text)
+
+        self.assertEqual(new_text.next_sibling, None)
+        self.assertEqual(new_text.next_element, soup.c)
+
+    def test_insert_string(self):
+        soup = self.soup("<a></a>")
+        soup.a.insert(0, "bar")
+        soup.a.insert(0, "foo")
+        # The string were added to the tag.
+        self.assertEqual(["foo", "bar"], soup.a.contents)
+        # And they were converted to NavigableStrings.
+        self.assertEqual(soup.a.contents[0].next_element, "bar")
+
+    def test_insert_tag(self):
+        builder = self.default_builder()
+        soup = self.soup(
+            "<a><b>Find</b><c>lady!</c><d></d></a>", builder=builder)
+        magic_tag = Tag(soup, builder, 'magictag')
+        magic_tag.insert(0, "the")
+        soup.a.insert(1, magic_tag)
+
+        self.assertEqual(
+            soup.decode(), self.document_for(
+                "<a><b>Find</b><magictag>the</magictag><c>lady!</c><d></d></a>"))
+
+        # Make sure all the relationships are hooked up correctly.
+        b_tag = soup.b
+        self.assertEqual(b_tag.next_sibling, magic_tag)
+        self.assertEqual(magic_tag.previous_sibling, b_tag)
+
+        find = b_tag.find(text="Find")
+        self.assertEqual(find.next_element, magic_tag)
+        self.assertEqual(magic_tag.previous_element, find)
+
+        c_tag = soup.c
+        self.assertEqual(magic_tag.next_sibling, c_tag)
+        self.assertEqual(c_tag.previous_sibling, magic_tag)
+
+        the = magic_tag.find(text="the")
+        self.assertEqual(the.parent, magic_tag)
+        self.assertEqual(the.next_element, c_tag)
+        self.assertEqual(c_tag.previous_element, the)
+
+    def test_append_child_thats_already_at_the_end(self):
+        data = "<a><b></b></a>"
+        soup = self.soup(data)
+        soup.a.append(soup.b)
+        self.assertEqual(data, soup.decode())
+
+    def test_extend(self):
+        data = "<a><b><c><d><e><f><g></g></f></e></d></c></b></a>"
+        soup = self.soup(data)
+        l = [soup.g, soup.f, soup.e, soup.d, soup.c, soup.b]
+        soup.a.extend(l)
+        self.assertEqual("<a><g></g><f></f><e></e><d></d><c></c><b></b></a>", soup.decode())
+
+    def test_extend_with_another_tags_contents(self):
+        data = '<body><div id="d1"><a>1</a><a>2</a><a>3</a><a>4</a></div><div id="d2"></div></body>'
+        soup = self.soup(data)
+        d1 = soup.find('div', id='d1')
+        d2 = soup.find('div', id='d2')
+        d2.extend(d1)
+        self.assertEqual('<div id="d1"></div>', d1.decode())
+        self.assertEqual('<div id="d2"><a>1</a><a>2</a><a>3</a><a>4</a></div>', d2.decode())
+        
+    def test_move_tag_to_beginning_of_parent(self):
+        data = "<a><b></b><c></c><d></d></a>"
+        soup = self.soup(data)
+        soup.a.insert(0, soup.d)
+        self.assertEqual("<a><d></d><b></b><c></c></a>", soup.decode())
+
+    def test_insert_works_on_empty_element_tag(self):
+        # This is a little strange, since most HTML parsers don't allow
+        # markup like this to come through. But in general, we don't
+        # know what the parser would or wouldn't have allowed, so
+        # I'm letting this succeed for now.
+        soup = self.soup("<br/>")
+        soup.br.insert(1, "Contents")
+        self.assertEqual(str(soup.br), "<br>Contents</br>")
+
+    def test_insert_before(self):
+        soup = self.soup("<a>foo</a><b>bar</b>")
+        soup.b.insert_before("BAZ")
+        soup.a.insert_before("QUUX")
+        self.assertEqual(
+            soup.decode(), self.document_for("QUUX<a>foo</a>BAZ<b>bar</b>"))
+
+        soup.a.insert_before(soup.b)
+        self.assertEqual(
+            soup.decode(), self.document_for("QUUX<b>bar</b><a>foo</a>BAZ"))
+
+        # Can't insert an element before itself.
+        b = soup.b
+        self.assertRaises(ValueError, b.insert_before, b)
+
+        # Can't insert before if an element has no parent.
+        b.extract()
+        self.assertRaises(ValueError, b.insert_before, "nope")
+
+        # Can insert an identical element
+        soup = self.soup("<a>")
+        soup.a.insert_before(soup.new_tag("a"))
+        
+    def test_insert_multiple_before(self):
+        soup = self.soup("<a>foo</a><b>bar</b>")
+        soup.b.insert_before("BAZ", " ", "QUUX")
+        soup.a.insert_before("QUUX", " ", "BAZ")
+        self.assertEqual(
+            soup.decode(), self.document_for("QUUX BAZ<a>foo</a>BAZ QUUX<b>bar</b>"))
+
+        soup.a.insert_before(soup.b, "FOO")
+        self.assertEqual(
+            soup.decode(), self.document_for("QUUX BAZ<b>bar</b>FOO<a>foo</a>BAZ QUUX"))
+
+    def test_insert_after(self):
+        soup = self.soup("<a>foo</a><b>bar</b>")
+        soup.b.insert_after("BAZ")
+        soup.a.insert_after("QUUX")
+        self.assertEqual(
+            soup.decode(), self.document_for("<a>foo</a>QUUX<b>bar</b>BAZ"))
+        soup.b.insert_after(soup.a)
+        self.assertEqual(
+            soup.decode(), self.document_for("QUUX<b>bar</b><a>foo</a>BAZ"))
+
+        # Can't insert an element after itself.
+        b = soup.b
+        self.assertRaises(ValueError, b.insert_after, b)
+
+        # Can't insert after if an element has no parent.
+        b.extract()
+        self.assertRaises(ValueError, b.insert_after, "nope")
+
+        # Can insert an identical element
+        soup = self.soup("<a>")
+        soup.a.insert_before(soup.new_tag("a"))
+        
+    def test_insert_multiple_after(self):
+        soup = self.soup("<a>foo</a><b>bar</b>")
+        soup.b.insert_after("BAZ", " ", "QUUX")
+        soup.a.insert_after("QUUX", " ", "BAZ")
+        self.assertEqual(
+            soup.decode(), self.document_for("<a>foo</a>QUUX BAZ<b>bar</b>BAZ QUUX"))
+        soup.b.insert_after(soup.a, "FOO ")
+        self.assertEqual(
+            soup.decode(), self.document_for("QUUX BAZ<b>bar</b><a>foo</a>FOO BAZ QUUX"))
+
+    def test_insert_after_raises_exception_if_after_has_no_meaning(self):
+        soup = self.soup("")
+        tag = soup.new_tag("a")
+        string = soup.new_string("")
+        self.assertRaises(ValueError, string.insert_after, tag)
+        self.assertRaises(NotImplementedError, soup.insert_after, tag)
+        self.assertRaises(ValueError, tag.insert_after, tag)
+
+    def test_insert_before_raises_notimplementederror_if_before_has_no_meaning(self):
+        soup = self.soup("")
+        tag = soup.new_tag("a")
+        string = soup.new_string("")
+        self.assertRaises(ValueError, string.insert_before, tag)
+        self.assertRaises(NotImplementedError, soup.insert_before, tag)
+        self.assertRaises(ValueError, tag.insert_before, tag)
+
+    def test_replace_with(self):
+        soup = self.soup(
+                "<p>There's <b>no</b> business like <b>show</b> business</p>")
+        no, show = soup.find_all('b')
+        show.replace_with(no)
+        self.assertEqual(
+            soup.decode(),
+            self.document_for(
+                "<p>There's  business like <b>no</b> business</p>"))
+
+        self.assertEqual(show.parent, None)
+        self.assertEqual(no.parent, soup.p)
+        self.assertEqual(no.next_element, "no")
+        self.assertEqual(no.next_sibling, " business")
+
+    def test_replace_first_child(self):
+        data = "<a><b></b><c></c></a>"
+        soup = self.soup(data)
+        soup.b.replace_with(soup.c)
+        self.assertEqual("<a><c></c></a>", soup.decode())
+
+    def test_replace_last_child(self):
+        data = "<a><b></b><c></c></a>"
+        soup = self.soup(data)
+        soup.c.replace_with(soup.b)
+        self.assertEqual("<a><b></b></a>", soup.decode())
+
+    def test_nested_tag_replace_with(self):
+        soup = self.soup(
+            """<a>We<b>reserve<c>the</c><d>right</d></b></a><e>to<f>refuse</f><g>service</g></e>""")
+
+        # Replace the entire <b> tag and its contents ("reserve the
+        # right") with the <f> tag ("refuse").
+        remove_tag = soup.b
+        move_tag = soup.f
+        remove_tag.replace_with(move_tag)
+
+        self.assertEqual(
+            soup.decode(), self.document_for(
+                "<a>We<f>refuse</f></a><e>to<g>service</g></e>"))
+
+        # The <b> tag is now an orphan.
+        self.assertEqual(remove_tag.parent, None)
+        self.assertEqual(remove_tag.find(text="right").next_element, None)
+        self.assertEqual(remove_tag.previous_element, None)
+        self.assertEqual(remove_tag.next_sibling, None)
+        self.assertEqual(remove_tag.previous_sibling, None)
+
+        # The <f> tag is now connected to the <a> tag.
+        self.assertEqual(move_tag.parent, soup.a)
+        self.assertEqual(move_tag.previous_element, "We")
+        self.assertEqual(move_tag.next_element.next_element, soup.e)
+        self.assertEqual(move_tag.next_sibling, None)
+
+        # The gap where the <f> tag used to be has been mended, and
+        # the word "to" is now connected to the <g> tag.
+        to_text = soup.find(text="to")
+        g_tag = soup.g
+        self.assertEqual(to_text.next_element, g_tag)
+        self.assertEqual(to_text.next_sibling, g_tag)
+        self.assertEqual(g_tag.previous_element, to_text)
+        self.assertEqual(g_tag.previous_sibling, to_text)
+
+    def test_unwrap(self):
+        tree = self.soup("""
+            <p>Unneeded <em>formatting</em> is unneeded</p>
+            """)
+        tree.em.unwrap()
+        self.assertEqual(tree.em, None)
+        self.assertEqual(tree.p.text, "Unneeded formatting is unneeded")
+
+    def test_wrap(self):
+        soup = self.soup("I wish I was bold.")
+        value = soup.string.wrap(soup.new_tag("b"))
+        self.assertEqual(value.decode(), "<b>I wish I was bold.</b>")
+        self.assertEqual(
+            soup.decode(), self.document_for("<b>I wish I was bold.</b>"))
+
+    def test_wrap_extracts_tag_from_elsewhere(self):
+        soup = self.soup("<b></b>I wish I was bold.")
+        soup.b.next_sibling.wrap(soup.b)
+        self.assertEqual(
+            soup.decode(), self.document_for("<b>I wish I was bold.</b>"))
+
+    def test_wrap_puts_new_contents_at_the_end(self):
+        soup = self.soup("<b>I like being bold.</b>I wish I was bold.")
+        soup.b.next_sibling.wrap(soup.b)
+        self.assertEqual(2, len(soup.b.contents))
+        self.assertEqual(
+            soup.decode(), self.document_for(
+                "<b>I like being bold.I wish I was bold.</b>"))
+
+    def test_extract(self):
+        soup = self.soup(
+            '<html><body>Some content. <div id="nav">Nav crap</div> More content.</body></html>')
+
+        self.assertEqual(len(soup.body.contents), 3)
+        extracted = soup.find(id="nav").extract()
+
+        self.assertEqual(
+            soup.decode(), "<html><body>Some content.  More content.</body></html>")
+        self.assertEqual(extracted.decode(), '<div id="nav">Nav crap</div>')
+
+        # The extracted tag is now an orphan.
+        self.assertEqual(len(soup.body.contents), 2)
+        self.assertEqual(extracted.parent, None)
+        self.assertEqual(extracted.previous_element, None)
+        self.assertEqual(extracted.next_element.next_element, None)
+
+        # The gap where the extracted tag used to be has been mended.
+        content_1 = soup.find(text="Some content. ")
+        content_2 = soup.find(text=" More content.")
+        self.assertEqual(content_1.next_element, content_2)
+        self.assertEqual(content_1.next_sibling, content_2)
+        self.assertEqual(content_2.previous_element, content_1)
+        self.assertEqual(content_2.previous_sibling, content_1)
+
+    def test_extract_distinguishes_between_identical_strings(self):
+        soup = self.soup("<a>foo</a><b>bar</b>")
+        foo_1 = soup.a.string
+        bar_1 = soup.b.string
+        foo_2 = soup.new_string("foo")
+        bar_2 = soup.new_string("bar")
+        soup.a.append(foo_2)
+        soup.b.append(bar_2)
+
+        # Now there are two identical strings in the <a> tag, and two
+        # in the <b> tag. Let's remove the first "foo" and the second
+        # "bar".
+        foo_1.extract()
+        bar_2.extract()
+        self.assertEqual(foo_2, soup.a.string)
+        self.assertEqual(bar_2, soup.b.string)
+
+    def test_extract_multiples_of_same_tag(self):
+        soup = self.soup("""
+<html>
+<head>
+<script>foo</script>
+</head>
+<body>
+ <script>bar</script>
+ <a></a>
+</body>
+<script>baz</script>
+</html>""")
+        [soup.script.extract() for i in soup.find_all("script")]
+        self.assertEqual("<body>\n\n<a></a>\n</body>", str(soup.body))
+
+
+    def test_extract_works_when_element_is_surrounded_by_identical_strings(self):
+        soup = self.soup(
+ '<html>\n'
+ '<body>hi</body>\n'
+ '</html>')
+        soup.find('body').extract()
+        self.assertEqual(None, soup.find('body'))
+
+
+    def test_clear(self):
+        """Tag.clear()"""
+        soup = self.soup("<p><a>String <em>Italicized</em></a> and another</p>")
+        # clear using extract()
+        a = soup.a
+        soup.p.clear()
+        self.assertEqual(len(soup.p.contents), 0)
+        self.assertTrue(hasattr(a, "contents"))
+
+        # clear using decompose()
+        em = a.em
+        a.clear(decompose=True)
+        self.assertEqual(0, len(em.contents))
+
+       
+    def test_decompose(self):
+        # Test PageElement.decompose() and PageElement.decomposed
+        soup = self.soup("<p><a>String <em>Italicized</em></a></p><p>Another para</p>")
+        p1, p2 = soup.find_all('p')
+        a = p1.a
+        text = p1.em.string
+        for i in [p1, p2, a, text]:
+            self.assertEqual(False, i.decomposed)
+
+        # This sets p1 and everything beneath it to decomposed.
+        p1.decompose()
+        for i in [p1, a, text]:
+            self.assertEqual(True, i.decomposed)
+        # p2 is unaffected.
+        self.assertEqual(False, p2.decomposed)
+            
+    def test_string_set(self):
+        """Tag.string = 'string'"""
+        soup = self.soup("<a></a> <b><c></c></b>")
+        soup.a.string = "foo"
+        self.assertEqual(soup.a.contents, ["foo"])
+        soup.b.string = "bar"
+        self.assertEqual(soup.b.contents, ["bar"])
+
+    def test_string_set_does_not_affect_original_string(self):
+        soup = self.soup("<a><b>foo</b><c>bar</c>")
+        soup.b.string = soup.c.string
+        self.assertEqual(soup.a.encode(), b"<a><b>bar</b><c>bar</c></a>")
+
+    def test_set_string_preserves_class_of_string(self):
+        soup = self.soup("<a></a>")
+        cdata = CData("foo")
+        soup.a.string = cdata
+        self.assertTrue(isinstance(soup.a.string, CData))
+
+class TestElementObjects(SoupTest):
+    """Test various features of element objects."""
+
+    def test_len(self):
+        """The length of an element is its number of children."""
+        soup = self.soup("<top>1<b>2</b>3</top>")
+
+        # The BeautifulSoup object itself contains one element: the
+        # <top> tag.
+        self.assertEqual(len(soup.contents), 1)
+        self.assertEqual(len(soup), 1)
+
+        # The <top> tag contains three elements: the text node "1", the
+        # <b> tag, and the text node "3".
+        self.assertEqual(len(soup.top), 3)
+        self.assertEqual(len(soup.top.contents), 3)
+
+    def test_member_access_invokes_find(self):
+        """Accessing a Python member .foo invokes find('foo')"""
+        soup = self.soup('<b><i></i></b>')
+        self.assertEqual(soup.b, soup.find('b'))
+        self.assertEqual(soup.b.i, soup.find('b').find('i'))
+        self.assertEqual(soup.a, None)
+
+    def test_deprecated_member_access(self):
+        soup = self.soup('<b><i></i></b>')
+        with warnings.catch_warnings(record=True) as w:
+            tag = soup.bTag
+        self.assertEqual(soup.b, tag)
+        self.assertEqual(
+            '.bTag is deprecated, use .find("b") instead. If you really were looking for a tag called bTag, use .find("bTag")',
+            str(w[0].message))
+
+    def test_has_attr(self):
+        """has_attr() checks for the presence of an attribute.
+
+        Please note note: has_attr() is different from
+        __in__. has_attr() checks the tag's attributes and __in__
+        checks the tag's chidlren.
+        """
+        soup = self.soup("<foo attr='bar'>")
+        self.assertTrue(soup.foo.has_attr('attr'))
+        self.assertFalse(soup.foo.has_attr('attr2'))
+
+
+    def test_attributes_come_out_in_alphabetical_order(self):
+        markup = '<b a="1" z="5" m="3" f="2" y="4"></b>'
+        self.assertSoupEquals(markup, '<b a="1" f="2" m="3" y="4" z="5"></b>')
+
+    def test_string(self):
+        # A tag that contains only a text node makes that node
+        # available as .string.
+        soup = self.soup("<b>foo</b>")
+        self.assertEqual(soup.b.string, 'foo')
+
+    def test_empty_tag_has_no_string(self):
+        # A tag with no children has no .stirng.
+        soup = self.soup("<b></b>")
+        self.assertEqual(soup.b.string, None)
+
+    def test_tag_with_multiple_children_has_no_string(self):
+        # A tag with no children has no .string.
+        soup = self.soup("<a>foo<b></b><b></b></b>")
+        self.assertEqual(soup.b.string, None)
+
+        soup = self.soup("<a>foo<b></b>bar</b>")
+        self.assertEqual(soup.b.string, None)
+
+        # Even if all the children are strings, due to trickery,
+        # it won't work--but this would be a good optimization.
+        soup = self.soup("<a>foo</b>")
+        soup.a.insert(1, "bar")
+        self.assertEqual(soup.a.string, None)
+
+    def test_tag_with_recursive_string_has_string(self):
+        # A tag with a single child which has a .string inherits that
+        # .string.
+        soup = self.soup("<a><b>foo</b></a>")
+        self.assertEqual(soup.a.string, "foo")
+        self.assertEqual(soup.string, "foo")
+
+    def test_lack_of_string(self):
+        """Only a tag containing a single text node has a .string."""
+        soup = self.soup("<b>f<i>e</i>o</b>")
+        self.assertFalse(soup.b.string)
+
+        soup = self.soup("<b></b>")
+        self.assertFalse(soup.b.string)
+
+    def test_all_text(self):
+        """Tag.text and Tag.get_text(sep=u"") -> all child text, concatenated"""
+        soup = self.soup("<a>a<b>r</b>   <r> t </r></a>")
+        self.assertEqual(soup.a.text, "ar  t ")
+        self.assertEqual(soup.a.get_text(strip=True), "art")
+        self.assertEqual(soup.a.get_text(","), "a,r, , t ")
+        self.assertEqual(soup.a.get_text(",", strip=True), "a,r,t")
+
+    def test_get_text_ignores_special_string_containers(self):
+        soup = self.soup("foo<!--IGNORE-->bar")
+        self.assertEqual(soup.get_text(), "foobar")
+
+        self.assertEqual(
+            soup.get_text(types=(NavigableString, Comment)), "fooIGNOREbar")
+        self.assertEqual(
+            soup.get_text(types=None), "fooIGNOREbar")
+
+        soup = self.soup("foo<style>CSS</style><script>Javascript</script>bar")
+        self.assertEqual(soup.get_text(), "foobar")
+        
+    def test_all_strings_ignores_special_string_containers(self):
+        soup = self.soup("foo<!--IGNORE-->bar")
+        self.assertEqual(['foo', 'bar'], list(soup.strings))
+
+        soup = self.soup("foo<style>CSS</style><script>Javascript</script>bar")
+        self.assertEqual(['foo', 'bar'], list(soup.strings))
+
+
+class TestCDAtaListAttributes(SoupTest):
+
+    """Testing cdata-list attributes like 'class'.
+    """
+    def test_single_value_becomes_list(self):
+        soup = self.soup("<a class='foo'>")
+        self.assertEqual(["foo"],soup.a['class'])
+
+    def test_multiple_values_becomes_list(self):
+        soup = self.soup("<a class='foo bar'>")
+        self.assertEqual(["foo", "bar"], soup.a['class'])
+
+    def test_multiple_values_separated_by_weird_whitespace(self):
+        soup = self.soup("<a class='foo\tbar\nbaz'>")
+        self.assertEqual(["foo", "bar", "baz"],soup.a['class'])
+
+    def test_attributes_joined_into_string_on_output(self):
+        soup = self.soup("<a class='foo\tbar'>")
+        self.assertEqual(b'<a class="foo bar"></a>', soup.a.encode())
+
+    def test_get_attribute_list(self):
+        soup = self.soup("<a id='abc def'>")
+        self.assertEqual(['abc def'], soup.a.get_attribute_list('id'))
+        
+    def test_accept_charset(self):
+        soup = self.soup('<form accept-charset="ISO-8859-1 UTF-8">')
+        self.assertEqual(['ISO-8859-1', 'UTF-8'], soup.form['accept-charset'])
+
+    def test_cdata_attribute_applying_only_to_one_tag(self):
+        data = '<a accept-charset="ISO-8859-1 UTF-8"></a>'
+        soup = self.soup(data)
+        # We saw in another test that accept-charset is a cdata-list
+        # attribute for the <form> tag. But it's not a cdata-list
+        # attribute for any other tag.
+        self.assertEqual('ISO-8859-1 UTF-8', soup.a['accept-charset'])
+
+    def test_string_has_immutable_name_property(self):
+        string = self.soup("s").string
+        self.assertEqual(None, string.name)
+        def t():
+            string.name = 'foo'
+        self.assertRaises(AttributeError, t)
+
+class TestPersistence(SoupTest):
+    "Testing features like pickle and deepcopy."
+
+    def setUp(self):
+        super(TestPersistence, self).setUp()
+        self.page = """<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.0 Transitional//EN"
+"http://www.w3.org/TR/REC-html40/transitional.dtd">
+<html>
+<head>
+<meta http-equiv="Content-Type" content="text/html; charset=utf-8">
+<title>Beautiful Soup: We called him Tortoise because he taught us.</title>
+<link rev="made" href="mailto:leonardr@segfault.org">
+<meta name="Description" content="Beautiful Soup: an HTML parser optimized for screen-scraping.">
+<meta name="generator" content="Markov Approximation 1.4 (module: leonardr)">
+<meta name="author" content="Leonard Richardson">
+</head>
+<body>
+<a href="foo">foo</a>
+<a href="foo"><b>bar</b></a>
+</body>
+</html>"""
+        self.tree = self.soup(self.page)
+
+    def test_pickle_and_unpickle_identity(self):
+        # Pickling a tree, then unpickling it, yields a tree identical
+        # to the original.
+        dumped = pickle.dumps(self.tree, 2)
+        loaded = pickle.loads(dumped)
+        self.assertEqual(loaded.__class__, BeautifulSoup)
+        self.assertEqual(loaded.decode(), self.tree.decode())
+
+    def test_deepcopy_identity(self):
+        # Making a deepcopy of a tree yields an identical tree.
+        copied = copy.deepcopy(self.tree)
+        self.assertEqual(copied.decode(), self.tree.decode())
+
+    def test_copy_preserves_encoding(self):
+        soup = BeautifulSoup(b'<p>&nbsp;</p>', 'html.parser')
+        encoding = soup.original_encoding
+        copy = soup.__copy__()
+        self.assertEqual("<p> </p>", str(copy))
+        self.assertEqual(encoding, copy.original_encoding)
+
+    def test_copy_preserves_builder_information(self):
+
+        tag = self.soup('<p></p>').p
+
+        # Simulate a tag obtained from a source file.
+        tag.sourceline = 10
+        tag.sourcepos = 33
+        
+        copied = tag.__copy__()
+
+        # The TreeBuilder object is no longer availble, but information
+        # obtained from it gets copied over to the new Tag object.
+        self.assertEqual(tag.sourceline, copied.sourceline)
+        self.assertEqual(tag.sourcepos, copied.sourcepos)
+        self.assertEqual(
+            tag.can_be_empty_element, copied.can_be_empty_element
+        )
+        self.assertEqual(
+            tag.cdata_list_attributes, copied.cdata_list_attributes
+        )
+        self.assertEqual(
+            tag.preserve_whitespace_tags, copied.preserve_whitespace_tags
+        )
+        
+        
+    def test_unicode_pickle(self):
+        # A tree containing Unicode characters can be pickled.
+        html = "<b>\N{SNOWMAN}</b>"
+        soup = self.soup(html)
+        dumped = pickle.dumps(soup, pickle.HIGHEST_PROTOCOL)
+        loaded = pickle.loads(dumped)
+        self.assertEqual(loaded.decode(), soup.decode())
+
+    def test_copy_navigablestring_is_not_attached_to_tree(self):
+        html = "<b>Foo<a></a></b><b>Bar</b>"
+        soup = self.soup(html)
+        s1 = soup.find(string="Foo")
+        s2 = copy.copy(s1)
+        self.assertEqual(s1, s2)
+        self.assertEqual(None, s2.parent)
+        self.assertEqual(None, s2.next_element)
+        self.assertNotEqual(None, s1.next_sibling)
+        self.assertEqual(None, s2.next_sibling)
+        self.assertEqual(None, s2.previous_element)
+
+    def test_copy_navigablestring_subclass_has_same_type(self):
+        html = "<b><!--Foo--></b>"
+        soup = self.soup(html)
+        s1 = soup.string
+        s2 = copy.copy(s1)
+        self.assertEqual(s1, s2)
+        self.assertTrue(isinstance(s2, Comment))
+
+    def test_copy_entire_soup(self):
+        html = "<div><b>Foo<a></a></b><b>Bar</b></div>end"
+        soup = self.soup(html)
+        soup_copy = copy.copy(soup)
+        self.assertEqual(soup, soup_copy)
+
+    def test_copy_tag_copies_contents(self):
+        html = "<div><b>Foo<a></a></b><b>Bar</b></div>end"
+        soup = self.soup(html)
+        div = soup.div
+        div_copy = copy.copy(div)
+
+        # The two tags look the same, and evaluate to equal.
+        self.assertEqual(str(div), str(div_copy))
+        self.assertEqual(div, div_copy)
+
+        # But they're not the same object.
+        self.assertFalse(div is div_copy)
+
+        # And they don't have the same relation to the parse tree. The
+        # copy is not associated with a parse tree at all.
+        self.assertEqual(None, div_copy.parent)
+        self.assertEqual(None, div_copy.previous_element)
+        self.assertEqual(None, div_copy.find(string='Bar').next_element)
+        self.assertNotEqual(None, div.find(string='Bar').next_element)
+
+class TestSubstitutions(SoupTest):
+
+    def test_default_formatter_is_minimal(self):
+        markup = "<b>&lt;&lt;Sacr\N{LATIN SMALL LETTER E WITH ACUTE} bleu!&gt;&gt;</b>"
+        soup = self.soup(markup)
+        decoded = soup.decode(formatter="minimal")
+        # The < is converted back into &lt; but the e-with-acute is left alone.
+        self.assertEqual(
+            decoded,
+            self.document_for(
+                "<b>&lt;&lt;Sacr\N{LATIN SMALL LETTER E WITH ACUTE} bleu!&gt;&gt;</b>"))
+
+    def test_formatter_html(self):
+        markup = "<br><b>&lt;&lt;Sacr\N{LATIN SMALL LETTER E WITH ACUTE} bleu!&gt;&gt;</b>"
+        soup = self.soup(markup)
+        decoded = soup.decode(formatter="html")
+        self.assertEqual(
+            decoded,
+            self.document_for("<br/><b>&lt;&lt;Sacr&eacute; bleu!&gt;&gt;</b>"))
+
+    def test_formatter_html5(self):
+        markup = "<br><b>&lt;&lt;Sacr\N{LATIN SMALL LETTER E WITH ACUTE} bleu!&gt;&gt;</b>"
+        soup = self.soup(markup)
+        decoded = soup.decode(formatter="html5")
+        self.assertEqual(
+            decoded,
+            self.document_for("<br><b>&lt;&lt;Sacr&eacute; bleu!&gt;&gt;</b>"))
+        
+    def test_formatter_minimal(self):
+        markup = "<b>&lt;&lt;Sacr\N{LATIN SMALL LETTER E WITH ACUTE} bleu!&gt;&gt;</b>"
+        soup = self.soup(markup)
+        decoded = soup.decode(formatter="minimal")
+        # The < is converted back into &lt; but the e-with-acute is left alone.
+        self.assertEqual(
+            decoded,
+            self.document_for(
+                "<b>&lt;&lt;Sacr\N{LATIN SMALL LETTER E WITH ACUTE} bleu!&gt;&gt;</b>"))
+
+    def test_formatter_null(self):
+        markup = "<b>&lt;&lt;Sacr\N{LATIN SMALL LETTER E WITH ACUTE} bleu!&gt;&gt;</b>"
+        soup = self.soup(markup)
+        decoded = soup.decode(formatter=None)
+        # Neither the angle brackets nor the e-with-acute are converted.
+        # This is not valid HTML, but it's what the user wanted.
+        self.assertEqual(decoded,
+                          self.document_for("<b><<Sacr\N{LATIN SMALL LETTER E WITH ACUTE} bleu!>></b>"))
+
+    def test_formatter_custom(self):
+        markup = "<b>&lt;foo&gt;</b><b>bar</b><br/>"
+        soup = self.soup(markup)
+        decoded = soup.decode(formatter = lambda x: x.upper())
+        # Instead of normal entity conversion code, the custom
+        # callable is called on every string.
+        self.assertEqual(
+            decoded,
+            self.document_for("<b><FOO></b><b>BAR</b><br/>"))
+
+    def test_formatter_is_run_on_attribute_values(self):
+        markup = '<a href="http://a.com?a=b&c=é">e</a>'
+        soup = self.soup(markup)
+        a = soup.a
+
+        expect_minimal = '<a href="http://a.com?a=b&amp;c=é">e</a>'
+
+        self.assertEqual(expect_minimal, a.decode())
+        self.assertEqual(expect_minimal, a.decode(formatter="minimal"))
+
+        expect_html = '<a href="http://a.com?a=b&amp;c=&eacute;">e</a>'
+        self.assertEqual(expect_html, a.decode(formatter="html"))
+
+        self.assertEqual(markup, a.decode(formatter=None))
+        expect_upper = '<a href="HTTP://A.COM?A=B&C=É">E</a>'
+        self.assertEqual(expect_upper, a.decode(formatter=lambda x: x.upper()))
+
+    def test_formatter_skips_script_tag_for_html_documents(self):
+        doc = """
+  <script type="text/javascript">
+   console.log("< < hey > > ");
+  </script>
+"""
+        encoded = BeautifulSoup(doc, 'html.parser').encode()
+        self.assertTrue(b"< < hey > >" in encoded)
+
+    def test_formatter_skips_style_tag_for_html_documents(self):
+        doc = """
+  <style type="text/css">
+   console.log("< < hey > > ");
+  </style>
+"""
+        encoded = BeautifulSoup(doc, 'html.parser').encode()
+        self.assertTrue(b"< < hey > >" in encoded)
+
+    def test_prettify_leaves_preformatted_text_alone(self):
+        soup = self.soup("<div>  foo  <pre>  \tbar\n  \n  </pre>  baz  <textarea> eee\nfff\t</textarea></div>")
+        # Everything outside the <pre> tag is reformatted, but everything
+        # inside is left alone.
+        self.assertEqual(
+            '<div>\n foo\n <pre>  \tbar\n  \n  </pre>\n baz\n <textarea> eee\nfff\t</textarea>\n</div>',
+            soup.div.prettify())
+
+    def test_prettify_accepts_formatter_function(self):
+        soup = BeautifulSoup("<html><body>foo</body></html>", 'html.parser')
+        pretty = soup.prettify(formatter = lambda x: x.upper())
+        self.assertTrue("FOO" in pretty)
+
+    def test_prettify_outputs_unicode_by_default(self):
+        soup = self.soup("<a></a>")
+        self.assertEqual(str, type(soup.prettify()))
+
+    def test_prettify_can_encode_data(self):
+        soup = self.soup("<a></a>")
+        self.assertEqual(bytes, type(soup.prettify("utf-8")))
+
+    def test_html_entity_substitution_off_by_default(self):
+        markup = "<b>Sacr\N{LATIN SMALL LETTER E WITH ACUTE} bleu!</b>"
+        soup = self.soup(markup)
+        encoded = soup.b.encode("utf-8")
+        self.assertEqual(encoded, markup.encode('utf-8'))
+
+    def test_encoding_substitution(self):
+        # Here's the <meta> tag saying that a document is
+        # encoded in Shift-JIS.
+        meta_tag = ('<meta content="text/html; charset=x-sjis" '
+                    'http-equiv="Content-type"/>')
+        soup = self.soup(meta_tag)
+
+        # Parse the document, and the charset apprears unchanged.
+        self.assertEqual(soup.meta['content'], 'text/html; charset=x-sjis')
+
+        # Encode the document into some encoding, and the encoding is
+        # substituted into the meta tag.
+        utf_8 = soup.encode("utf-8")
+        self.assertTrue(b"charset=utf-8" in utf_8)
+
+        euc_jp = soup.encode("euc_jp")
+        self.assertTrue(b"charset=euc_jp" in euc_jp)
+
+        shift_jis = soup.encode("shift-jis")
+        self.assertTrue(b"charset=shift-jis" in shift_jis)
+
+        utf_16_u = soup.encode("utf-16").decode("utf-16")
+        self.assertTrue("charset=utf-16" in utf_16_u)
+
+    def test_encoding_substitution_doesnt_happen_if_tag_is_strained(self):
+        markup = ('<head><meta content="text/html; charset=x-sjis" '
+                    'http-equiv="Content-type"/></head><pre>foo</pre>')
+
+        # Beautiful Soup used to try to rewrite the meta tag even if the
+        # meta tag got filtered out by the strainer. This test makes
+        # sure that doesn't happen.
+        strainer = SoupStrainer('pre')
+        soup = self.soup(markup, parse_only=strainer)
+        self.assertEqual(soup.contents[0].name, 'pre')
+
+class TestEncoding(SoupTest):
+    """Test the ability to encode objects into strings."""
+
+    def test_unicode_string_can_be_encoded(self):
+        html = "<b>\N{SNOWMAN}</b>"
+        soup = self.soup(html)
+        self.assertEqual(soup.b.string.encode("utf-8"),
+                          "\N{SNOWMAN}".encode("utf-8"))
+
+    def test_tag_containing_unicode_string_can_be_encoded(self):
+        html = "<b>\N{SNOWMAN}</b>"
+        soup = self.soup(html)
+        self.assertEqual(
+            soup.b.encode("utf-8"), html.encode("utf-8"))
+
+    def test_encoding_substitutes_unrecognized_characters_by_default(self):
+        html = "<b>\N{SNOWMAN}</b>"
+        soup = self.soup(html)
+        self.assertEqual(soup.b.encode("ascii"), b"<b>&#9731;</b>")
+
+    def test_encoding_can_be_made_strict(self):
+        html = "<b>\N{SNOWMAN}</b>"
+        soup = self.soup(html)
+        self.assertRaises(
+            UnicodeEncodeError, soup.encode, "ascii", errors="strict")
+
+    def test_decode_contents(self):
+        html = "<b>\N{SNOWMAN}</b>"
+        soup = self.soup(html)
+        self.assertEqual("\N{SNOWMAN}", soup.b.decode_contents())
+
+    def test_encode_contents(self):
+        html = "<b>\N{SNOWMAN}</b>"
+        soup = self.soup(html)
+        self.assertEqual(
+            "\N{SNOWMAN}".encode("utf8"), soup.b.encode_contents(
+                encoding="utf8"))
+
+    def test_deprecated_renderContents(self):
+        html = "<b>\N{SNOWMAN}</b>"
+        soup = self.soup(html)
+        self.assertEqual(
+            "\N{SNOWMAN}".encode("utf8"), soup.b.renderContents())
+
+    def test_repr(self):
+        html = "<b>\N{SNOWMAN}</b>"
+        soup = self.soup(html)
+        if PY3K:
+            self.assertEqual(html, repr(soup))
+        else:
+            self.assertEqual(b'<b>\\u2603</b>', repr(soup))
+
+class TestFormatter(SoupTest):
+
+    def test_default_attributes(self):
+        # Test the default behavior of Formatter.attributes().
+        formatter = Formatter()
+        tag = Tag(name="tag")
+        tag['b'] = 1
+        tag['a'] = 2
+
+        # Attributes come out sorted by name. In Python 3, attributes
+        # normally come out of a dictionary in the order they were
+        # added.
+        self.assertEqual([('a', 2), ('b', 1)], formatter.attributes(tag))
+
+        # This works even if Tag.attrs is None, though this shouldn't
+        # normally happen.
+        tag.attrs = None
+        self.assertEqual([], formatter.attributes(tag))
+        
+    def test_sort_attributes(self):
+        # Test the ability to override Formatter.attributes() to,
+        # e.g., disable the normal sorting of attributes.
+        class UnsortedFormatter(Formatter):
+            def attributes(self, tag):
+                self.called_with = tag
+                for k, v in sorted(tag.attrs.items()):
+                    if k == 'ignore':
+                        continue
+                    yield k,v
+
+        soup = self.soup('<p cval="1" aval="2" ignore="ignored"></p>')
+        formatter = UnsortedFormatter()
+        decoded = soup.decode(formatter=formatter)
+
+        # attributes() was called on the <p> tag. It filtered out one
+        # attribute and sorted the other two.
+        self.assertEqual(formatter.called_with, soup.p)
+        self.assertEqual('<p aval="2" cval="1"></p>', decoded)
+
+
+class TestNavigableStringSubclasses(SoupTest):
+
+    def test_cdata(self):
+        # None of the current builders turn CDATA sections into CData
+        # objects, but you can create them manually.
+        soup = self.soup("")
+        cdata = CData("foo")
+        soup.insert(1, cdata)
+        self.assertEqual(str(soup), "<![CDATA[foo]]>")
+        self.assertEqual(soup.find(text="foo"), "foo")
+        self.assertEqual(soup.contents[0], "foo")
+
+    def test_cdata_is_never_formatted(self):
+        """Text inside a CData object is passed into the formatter.
+
+        But the return value is ignored.
+        """
+
+        self.count = 0
+        def increment(*args):
+            self.count += 1
+            return "BITTER FAILURE"
+
+        soup = self.soup("")
+        cdata = CData("<><><>")
+        soup.insert(1, cdata)
+        self.assertEqual(
+            b"<![CDATA[<><><>]]>", soup.encode(formatter=increment))
+        self.assertEqual(1, self.count)
+
+    def test_doctype_ends_in_newline(self):
+        # Unlike other NavigableString subclasses, a DOCTYPE always ends
+        # in a newline.
+        doctype = Doctype("foo")
+        soup = self.soup("")
+        soup.insert(1, doctype)
+        self.assertEqual(soup.encode(), b"<!DOCTYPE foo>\n")
+
+    def test_declaration(self):
+        d = Declaration("foo")
+        self.assertEqual("<?foo?>", d.output_ready())
+
+    def test_default_string_containers(self):
+        # In some cases, we use different NavigableString subclasses for
+        # the same text in different tags.
+        soup = self.soup(
+            "<div>text</div><script>text</script><style>text</style>"
+        )
+        self.assertEqual(
+            [NavigableString, Script, Stylesheet],
+            [x.__class__ for x in soup.find_all(text=True)]
+        )
+
+        # The TemplateString is a little unusual because it's generally found
+        # _inside_ children of a <template> element, not a direct child of the
+        # <template> element.
+        soup = self.soup(
+            "<template>Some text<p>In a tag</p></template>Some text outside"
+        )
+        assert all(isinstance(x, TemplateString) for x in soup.template.strings)
+
+        # Once the <template> tag closed, we went back to using
+        # NavigableString.
+        outside = soup.template.next_sibling
+        assert isinstance(outside, NavigableString)
+        assert not isinstance(outside, TemplateString)
+
+class TestSoupSelector(TreeTest):
+
+    HTML = """
+<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01//EN"
+"http://www.w3.org/TR/html4/strict.dtd">
+<html>
+<head>
+<title>The title</title>
+<link rel="stylesheet" href="blah.css" type="text/css" id="l1">
+</head>
+<body>
+<custom-dashed-tag class="dashed" id="dash1">Hello there.</custom-dashed-tag>
+<div id="main" class="fancy">
+<div id="inner">
+<h1 id="header1">An H1</h1>
+<p>Some text</p>
+<p class="onep" id="p1">Some more text</p>
+<h2 id="header2">An H2</h2>
+<p class="class1 class2 class3" id="pmulti">Another</p>
+<a href="http://bob.example.org/" rel="friend met" id="bob">Bob</a>
+<h2 id="header3">Another H2</h2>
+<a id="me" href="http://simonwillison.net/" rel="me">me</a>
+<span class="s1">
+<a href="#" id="s1a1">span1a1</a>
+<a href="#" id="s1a2">span1a2 <span id="s1a2s1">test</span></a>
+<span class="span2">
+<a href="#" id="s2a1">span2a1</a>
+</span>
+<span class="span3"></span>
+<custom-dashed-tag class="dashed" id="dash2"/>
+<div data-tag="dashedvalue" id="data1"/>
+</span>
+</div>
+<x id="xid">
+<z id="zida"/>
+<z id="zidab"/>
+<z id="zidac"/>
+</x>
+<y id="yid">
+<z id="zidb"/>
+</y>
+<p lang="en" id="lang-en">English</p>
+<p lang="en-gb" id="lang-en-gb">English UK</p>
+<p lang="en-us" id="lang-en-us">English US</p>
+<p lang="fr" id="lang-fr">French</p>
+</div>
+
+<div id="footer">
+</div>
+"""
+
+    def setUp(self):
+        self.soup = BeautifulSoup(self.HTML, 'html.parser')
+
+    def assertSelects(self, selector, expected_ids, **kwargs):
+        el_ids = [el['id'] for el in self.soup.select(selector, **kwargs)]
+        el_ids.sort()
+        expected_ids.sort()
+        self.assertEqual(expected_ids, el_ids,
+            "Selector %s, expected [%s], got [%s]" % (
+                selector, ', '.join(expected_ids), ', '.join(el_ids)
+            )
+        )
+
+    assertSelect = assertSelects
+
+    def assertSelectMultiple(self, *tests):
+        for selector, expected_ids in tests:
+            self.assertSelect(selector, expected_ids)
+
+    def test_one_tag_one(self):
+        els = self.soup.select('title')
+        self.assertEqual(len(els), 1)
+        self.assertEqual(els[0].name, 'title')
+        self.assertEqual(els[0].contents, ['The title'])
+
+    def test_one_tag_many(self):
+        els = self.soup.select('div')
+        self.assertEqual(len(els), 4)
+        for div in els:
+            self.assertEqual(div.name, 'div')
+
+        el = self.soup.select_one('div')
+        self.assertEqual('main', el['id'])
+
+    def test_select_one_returns_none_if_no_match(self):
+        match = self.soup.select_one('nonexistenttag')
+        self.assertEqual(None, match)
+
+
+    def test_tag_in_tag_one(self):
+        els = self.soup.select('div div')
+        self.assertSelects('div div', ['inner', 'data1'])
+
+    def test_tag_in_tag_many(self):
+        for selector in ('html div', 'html body div', 'body div'):
+            self.assertSelects(selector, ['data1', 'main', 'inner', 'footer'])
+
+
+    def test_limit(self):
+        self.assertSelects('html div', ['main'], limit=1)
+        self.assertSelects('html body div', ['inner', 'main'], limit=2)
+        self.assertSelects('body div', ['data1', 'main', 'inner', 'footer'],
+                           limit=10)
+
+    def test_tag_no_match(self):
+        self.assertEqual(len(self.soup.select('del')), 0)
+
+    def test_invalid_tag(self):
+        self.assertRaises(SelectorSyntaxError, self.soup.select, 'tag%t')
+
+    def test_select_dashed_tag_ids(self):
+        self.assertSelects('custom-dashed-tag', ['dash1', 'dash2'])
+
+    def test_select_dashed_by_id(self):
+        dashed = self.soup.select('custom-dashed-tag[id=\"dash2\"]')
+        self.assertEqual(dashed[0].name, 'custom-dashed-tag')
+        self.assertEqual(dashed[0]['id'], 'dash2')
+
+    def test_dashed_tag_text(self):
+        self.assertEqual(self.soup.select('body > custom-dashed-tag')[0].text, 'Hello there.')
+
+    def test_select_dashed_matches_find_all(self):
+        self.assertEqual(self.soup.select('custom-dashed-tag'), self.soup.find_all('custom-dashed-tag'))
+
+    def test_header_tags(self):
+        self.assertSelectMultiple(
+            ('h1', ['header1']),
+            ('h2', ['header2', 'header3']),
+        )
+
+    def test_class_one(self):
+        for selector in ('.onep', 'p.onep', 'html p.onep'):
+            els = self.soup.select(selector)
+            self.assertEqual(len(els), 1)
+            self.assertEqual(els[0].name, 'p')
+            self.assertEqual(els[0]['class'], ['onep'])
+
+    def test_class_mismatched_tag(self):
+        els = self.soup.select('div.onep')
+        self.assertEqual(len(els), 0)
+
+    def test_one_id(self):
+        for selector in ('div#inner', '#inner', 'div div#inner'):
+            self.assertSelects(selector, ['inner'])
+
+    def test_bad_id(self):
+        els = self.soup.select('#doesnotexist')
+        self.assertEqual(len(els), 0)
+
+    def test_items_in_id(self):
+        els = self.soup.select('div#inner p')
+        self.assertEqual(len(els), 3)
+        for el in els:
+            self.assertEqual(el.name, 'p')
+        self.assertEqual(els[1]['class'], ['onep'])
+        self.assertFalse(els[0].has_attr('class'))
+
+    def test_a_bunch_of_emptys(self):
+        for selector in ('div#main del', 'div#main div.oops', 'div div#main'):
+            self.assertEqual(len(self.soup.select(selector)), 0)
+
+    def test_multi_class_support(self):
+        for selector in ('.class1', 'p.class1', '.class2', 'p.class2',
+            '.class3', 'p.class3', 'html p.class2', 'div#inner .class2'):
+            self.assertSelects(selector, ['pmulti'])
+
+    def test_multi_class_selection(self):
+        for selector in ('.class1.class3', '.class3.class2',
+                         '.class1.class2.class3'):
+            self.assertSelects(selector, ['pmulti'])
+
+    def test_child_selector(self):
+        self.assertSelects('.s1 > a', ['s1a1', 's1a2'])
+        self.assertSelects('.s1 > a span', ['s1a2s1'])
+
+    def test_child_selector_id(self):
+        self.assertSelects('.s1 > a#s1a2 span', ['s1a2s1'])
+
+    def test_attribute_equals(self):
+        self.assertSelectMultiple(
+            ('p[class="onep"]', ['p1']),
+            ('p[id="p1"]', ['p1']),
+            ('[class="onep"]', ['p1']),
+            ('[id="p1"]', ['p1']),
+            ('link[rel="stylesheet"]', ['l1']),
+            ('link[type="text/css"]', ['l1']),
+            ('link[href="blah.css"]', ['l1']),
+            ('link[href="no-blah.css"]', []),
+            ('[rel="stylesheet"]', ['l1']),
+            ('[type="text/css"]', ['l1']),
+            ('[href="blah.css"]', ['l1']),
+            ('[href="no-blah.css"]', []),
+            ('p[href="no-blah.css"]', []),
+            ('[href="no-blah.css"]', []),
+        )
+
+    def test_attribute_tilde(self):
+        self.assertSelectMultiple(
+            ('p[class~="class1"]', ['pmulti']),
+            ('p[class~="class2"]', ['pmulti']),
+            ('p[class~="class3"]', ['pmulti']),
+            ('[class~="class1"]', ['pmulti']),
+            ('[class~="class2"]', ['pmulti']),
+            ('[class~="class3"]', ['pmulti']),
+            ('a[rel~="friend"]', ['bob']),
+            ('a[rel~="met"]', ['bob']),
+            ('[rel~="friend"]', ['bob']),
+            ('[rel~="met"]', ['bob']),
+        )
+
+    def test_attribute_startswith(self):
+        self.assertSelectMultiple(
+            ('[rel^="style"]', ['l1']),
+            ('link[rel^="style"]', ['l1']),
+            ('notlink[rel^="notstyle"]', []),
+            ('[rel^="notstyle"]', []),
+            ('link[rel^="notstyle"]', []),
+            ('link[href^="bla"]', ['l1']),
+            ('a[href^="http://"]', ['bob', 'me']),
+            ('[href^="http://"]', ['bob', 'me']),
+            ('[id^="p"]', ['pmulti', 'p1']),
+            ('[id^="m"]', ['me', 'main']),
+            ('div[id^="m"]', ['main']),
+            ('a[id^="m"]', ['me']),
+            ('div[data-tag^="dashed"]', ['data1'])
+        )
+
+    def test_attribute_endswith(self):
+        self.assertSelectMultiple(
+            ('[href$=".css"]', ['l1']),
+            ('link[href$=".css"]', ['l1']),
+            ('link[id$="1"]', ['l1']),
+            ('[id$="1"]', ['data1', 'l1', 'p1', 'header1', 's1a1', 's2a1', 's1a2s1', 'dash1']),
+            ('div[id$="1"]', ['data1']),
+            ('[id$="noending"]', []),
+        )
+
+    def test_attribute_contains(self):
+        self.assertSelectMultiple(
+            # From test_attribute_startswith
+            ('[rel*="style"]', ['l1']),
+            ('link[rel*="style"]', ['l1']),
+            ('notlink[rel*="notstyle"]', []),
+            ('[rel*="notstyle"]', []),
+            ('link[rel*="notstyle"]', []),
+            ('link[href*="bla"]', ['l1']),
+            ('[href*="http://"]', ['bob', 'me']),
+            ('[id*="p"]', ['pmulti', 'p1']),
+            ('div[id*="m"]', ['main']),
+            ('a[id*="m"]', ['me']),
+            # From test_attribute_endswith
+            ('[href*=".css"]', ['l1']),
+            ('link[href*=".css"]', ['l1']),
+            ('link[id*="1"]', ['l1']),
+            ('[id*="1"]', ['data1', 'l1', 'p1', 'header1', 's1a1', 's1a2', 's2a1', 's1a2s1', 'dash1']),
+            ('div[id*="1"]', ['data1']),
+            ('[id*="noending"]', []),
+            # New for this test
+            ('[href*="."]', ['bob', 'me', 'l1']),
+            ('a[href*="."]', ['bob', 'me']),
+            ('link[href*="."]', ['l1']),
+            ('div[id*="n"]', ['main', 'inner']),
+            ('div[id*="nn"]', ['inner']),
+            ('div[data-tag*="edval"]', ['data1'])
+        )
+
+    def test_attribute_exact_or_hypen(self):
+        self.assertSelectMultiple(
+            ('p[lang|="en"]', ['lang-en', 'lang-en-gb', 'lang-en-us']),
+            ('[lang|="en"]', ['lang-en', 'lang-en-gb', 'lang-en-us']),
+            ('p[lang|="fr"]', ['lang-fr']),
+            ('p[lang|="gb"]', []),
+        )
+
+    def test_attribute_exists(self):
+        self.assertSelectMultiple(
+            ('[rel]', ['l1', 'bob', 'me']),
+            ('link[rel]', ['l1']),
+            ('a[rel]', ['bob', 'me']),
+            ('[lang]', ['lang-en', 'lang-en-gb', 'lang-en-us', 'lang-fr']),
+            ('p[class]', ['p1', 'pmulti']),
+            ('[blah]', []),
+            ('p[blah]', []),
+            ('div[data-tag]', ['data1'])
+        )
+
+    def test_quoted_space_in_selector_name(self):
+        html = """<div style="display: wrong">nope</div>
+        <div style="display: right">yes</div>
+        """
+        soup = BeautifulSoup(html, 'html.parser')
+        [chosen] = soup.select('div[style="display: right"]')
+        self.assertEqual("yes", chosen.string)
+
+    def test_unsupported_pseudoclass(self):
+        self.assertRaises(
+            NotImplementedError, self.soup.select, "a:no-such-pseudoclass")
+
+        self.assertRaises(
+            SelectorSyntaxError, self.soup.select, "a:nth-of-type(a)")
+
+    def test_nth_of_type(self):
+        # Try to select first paragraph
+        els = self.soup.select('div#inner p:nth-of-type(1)')
+        self.assertEqual(len(els), 1)
+        self.assertEqual(els[0].string, 'Some text')
+
+        # Try to select third paragraph
+        els = self.soup.select('div#inner p:nth-of-type(3)')
+        self.assertEqual(len(els), 1)
+        self.assertEqual(els[0].string, 'Another')
+
+        # Try to select (non-existent!) fourth paragraph
+        els = self.soup.select('div#inner p:nth-of-type(4)')
+        self.assertEqual(len(els), 0)
+
+        # Zero will select no tags.
+        els = self.soup.select('div p:nth-of-type(0)')
+        self.assertEqual(len(els), 0)
+
+    def test_nth_of_type_direct_descendant(self):
+        els = self.soup.select('div#inner > p:nth-of-type(1)')
+        self.assertEqual(len(els), 1)
+        self.assertEqual(els[0].string, 'Some text')
+
+    def test_id_child_selector_nth_of_type(self):
+        self.assertSelects('#inner > p:nth-of-type(2)', ['p1'])
+
+    def test_select_on_element(self):
+        # Other tests operate on the tree; this operates on an element
+        # within the tree.
+        inner = self.soup.find("div", id="main")
+        selected = inner.select("div")
+        # The <div id="inner"> tag was selected. The <div id="footer">
+        # tag was not.
+        self.assertSelectsIDs(selected, ['inner', 'data1'])
+
+    def test_overspecified_child_id(self):
+        self.assertSelects(".fancy #inner", ['inner'])
+        self.assertSelects(".normal #inner", [])
+
+    def test_adjacent_sibling_selector(self):
+        self.assertSelects('#p1 + h2', ['header2'])
+        self.assertSelects('#p1 + h2 + p', ['pmulti'])
+        self.assertSelects('#p1 + #header2 + .class1', ['pmulti'])
+        self.assertEqual([], self.soup.select('#p1 + p'))
+
+    def test_general_sibling_selector(self):
+        self.assertSelects('#p1 ~ h2', ['header2', 'header3'])
+        self.assertSelects('#p1 ~ #header2', ['header2'])
+        self.assertSelects('#p1 ~ h2 + a', ['me'])
+        self.assertSelects('#p1 ~ h2 + [rel="me"]', ['me'])
+        self.assertEqual([], self.soup.select('#inner ~ h2'))
+
+    def test_dangling_combinator(self):
+        self.assertRaises(SelectorSyntaxError, self.soup.select, 'h1 >')
+
+    def test_sibling_combinator_wont_select_same_tag_twice(self):
+        self.assertSelects('p[lang] ~ p', ['lang-en-gb', 'lang-en-us', 'lang-fr'])
+
+    # Test the selector grouping operator (the comma)
+    def test_multiple_select(self):
+        self.assertSelects('x, y', ['xid', 'yid'])
+
+    def test_multiple_select_with_no_space(self):
+        self.assertSelects('x,y', ['xid', 'yid'])
+
+    def test_multiple_select_with_more_space(self):
+        self.assertSelects('x,    y', ['xid', 'yid'])
+
+    def test_multiple_select_duplicated(self):
+        self.assertSelects('x, x', ['xid'])
+
+    def test_multiple_select_sibling(self):
+        self.assertSelects('x, y ~ p[lang=fr]', ['xid', 'lang-fr'])
+
+    def test_multiple_select_tag_and_direct_descendant(self):
+        self.assertSelects('x, y > z', ['xid', 'zidb'])
+
+    def test_multiple_select_direct_descendant_and_tags(self):
+        self.assertSelects('div > x, y, z', ['xid', 'yid', 'zida', 'zidb', 'zidab', 'zidac'])
+
+    def test_multiple_select_indirect_descendant(self):
+        self.assertSelects('div x,y,  z', ['xid', 'yid', 'zida', 'zidb', 'zidab', 'zidac'])
+
+    def test_invalid_multiple_select(self):
+        self.assertRaises(SelectorSyntaxError, self.soup.select, ',x, y')
+        self.assertRaises(SelectorSyntaxError, self.soup.select, 'x,,y')
+
+    def test_multiple_select_attrs(self):
+        self.assertSelects('p[lang=en], p[lang=en-gb]', ['lang-en', 'lang-en-gb'])
+
+    def test_multiple_select_ids(self):
+        self.assertSelects('x, y > z[id=zida], z[id=zidab], z[id=zidb]', ['xid', 'zidb', 'zidab'])
+
+    def test_multiple_select_nested(self):
+        self.assertSelects('body > div > x, y > z', ['xid', 'zidb'])
+
+    def test_select_duplicate_elements(self):
+        # When markup contains duplicate elements, a multiple select
+        # will find all of them.
+        markup = '<div class="c1"/><div class="c2"/><div class="c1"/>'
+        soup = BeautifulSoup(markup, 'html.parser')
+        selected = soup.select(".c1, .c2")
+        self.assertEqual(3, len(selected))
+
+        # Verify that find_all finds the same elements, though because
+        # of an implementation detail it finds them in a different
+        # order.
+        for element in soup.find_all(class_=['c1', 'c2']):
+            assert element in selected
Index: latest/Lib/site-packages/bs4/tests/__init__.py
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/latest/Lib/site-packages/bs4/tests/__init__.py b/latest/Lib/site-packages/bs4/tests/__init__.py
new file mode 100644
--- /dev/null	(date 1616411342110)
+++ b/latest/Lib/site-packages/bs4/tests/__init__.py	(date 1616411342110)
@@ -0,0 +1,1 @@
+"The beautifulsoup tests."
Index: latest/Lib/site-packages/bs4/builder/_html5lib.py
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/latest/Lib/site-packages/bs4/builder/_html5lib.py b/latest/Lib/site-packages/bs4/builder/_html5lib.py
new file mode 100644
--- /dev/null	(date 1616411342103)
+++ b/latest/Lib/site-packages/bs4/builder/_html5lib.py	(date 1616411342103)
@@ -0,0 +1,467 @@
+# Use of this source code is governed by the MIT license.
+__license__ = "MIT"
+
+__all__ = [
+    'HTML5TreeBuilder',
+    ]
+
+import warnings
+import re
+from bs4.builder import (
+    PERMISSIVE,
+    HTML,
+    HTML_5,
+    HTMLTreeBuilder,
+    )
+from bs4.element import (
+    NamespacedAttribute,
+    nonwhitespace_re,
+)
+import html5lib
+from html5lib.constants import (
+    namespaces,
+    prefixes,
+    )
+from bs4.element import (
+    Comment,
+    Doctype,
+    NavigableString,
+    Tag,
+    )
+
+try:
+    # Pre-0.99999999
+    from html5lib.treebuilders import _base as treebuilder_base
+    new_html5lib = False
+except ImportError as e:
+    # 0.99999999 and up
+    from html5lib.treebuilders import base as treebuilder_base
+    new_html5lib = True
+
+class HTML5TreeBuilder(HTMLTreeBuilder):
+    """Use html5lib to build a tree.
+
+    Note that this TreeBuilder does not support some features common
+    to HTML TreeBuilders. Some of these features could theoretically
+    be implemented, but at the very least it's quite difficult,
+    because html5lib moves the parse tree around as it's being built.
+
+    * This TreeBuilder doesn't use different subclasses of NavigableString
+      based on the name of the tag in which the string was found.
+
+    * You can't use a SoupStrainer to parse only part of a document.
+    """
+
+    NAME = "html5lib"
+
+    features = [NAME, PERMISSIVE, HTML_5, HTML]
+
+    # html5lib can tell us which line number and position in the
+    # original file is the source of an element.
+    TRACKS_LINE_NUMBERS = True
+    
+    def prepare_markup(self, markup, user_specified_encoding,
+                       document_declared_encoding=None, exclude_encodings=None):
+        # Store the user-specified encoding for use later on.
+        self.user_specified_encoding = user_specified_encoding
+
+        # document_declared_encoding and exclude_encodings aren't used
+        # ATM because the html5lib TreeBuilder doesn't use
+        # UnicodeDammit.
+        if exclude_encodings:
+            warnings.warn("You provided a value for exclude_encoding, but the html5lib tree builder doesn't support exclude_encoding.")
+        yield (markup, None, None, False)
+
+    # These methods are defined by Beautiful Soup.
+    def feed(self, markup):
+        if self.soup.parse_only is not None:
+            warnings.warn("You provided a value for parse_only, but the html5lib tree builder doesn't support parse_only. The entire document will be parsed.")
+        parser = html5lib.HTMLParser(tree=self.create_treebuilder)
+        self.underlying_builder.parser = parser
+        extra_kwargs = dict()
+        if not isinstance(markup, str):
+            if new_html5lib:
+                extra_kwargs['override_encoding'] = self.user_specified_encoding
+            else:
+                extra_kwargs['encoding'] = self.user_specified_encoding
+        doc = parser.parse(markup, **extra_kwargs)
+        
+        # Set the character encoding detected by the tokenizer.
+        if isinstance(markup, str):
+            # We need to special-case this because html5lib sets
+            # charEncoding to UTF-8 if it gets Unicode input.
+            doc.original_encoding = None
+        else:
+            original_encoding = parser.tokenizer.stream.charEncoding[0]
+            if not isinstance(original_encoding, str):
+                # In 0.99999999 and up, the encoding is an html5lib
+                # Encoding object. We want to use a string for compatibility
+                # with other tree builders.
+                original_encoding = original_encoding.name
+            doc.original_encoding = original_encoding
+        self.underlying_builder.parser = None
+            
+    def create_treebuilder(self, namespaceHTMLElements):
+        self.underlying_builder = TreeBuilderForHtml5lib(
+            namespaceHTMLElements, self.soup,
+            store_line_numbers=self.store_line_numbers
+        )
+        return self.underlying_builder
+
+    def test_fragment_to_document(self, fragment):
+        """See `TreeBuilder`."""
+        return '<html><head></head><body>%s</body></html>' % fragment
+
+
+class TreeBuilderForHtml5lib(treebuilder_base.TreeBuilder):
+    
+    def __init__(self, namespaceHTMLElements, soup=None,
+                 store_line_numbers=True, **kwargs):
+        if soup:
+            self.soup = soup
+        else:
+            from bs4 import BeautifulSoup
+            # TODO: Why is the parser 'html.parser' here? To avoid an
+            # infinite loop?
+            self.soup = BeautifulSoup(
+                "", "html.parser", store_line_numbers=store_line_numbers,
+                **kwargs
+            )
+        # TODO: What are **kwargs exactly? Should they be passed in
+        # here in addition to/instead of being passed to the BeautifulSoup
+        # constructor?
+        super(TreeBuilderForHtml5lib, self).__init__(namespaceHTMLElements)
+
+        # This will be set later to an html5lib.html5parser.HTMLParser
+        # object, which we can use to track the current line number.
+        self.parser = None
+        self.store_line_numbers = store_line_numbers
+        
+    def documentClass(self):
+        self.soup.reset()
+        return Element(self.soup, self.soup, None)
+
+    def insertDoctype(self, token):
+        name = token["name"]
+        publicId = token["publicId"]
+        systemId = token["systemId"]
+
+        doctype = Doctype.for_name_and_ids(name, publicId, systemId)
+        self.soup.object_was_parsed(doctype)
+
+    def elementClass(self, name, namespace):
+        kwargs = {}
+        if self.parser and self.store_line_numbers:
+            # This represents the point immediately after the end of the
+            # tag. We don't know when the tag started, but we do know
+            # where it ended -- the character just before this one.
+            sourceline, sourcepos = self.parser.tokenizer.stream.position()
+            kwargs['sourceline'] = sourceline
+            kwargs['sourcepos'] = sourcepos-1
+        tag = self.soup.new_tag(name, namespace, **kwargs)
+
+        return Element(tag, self.soup, namespace)
+
+    def commentClass(self, data):
+        return TextNode(Comment(data), self.soup)
+
+    def fragmentClass(self):
+        from bs4 import BeautifulSoup
+        # TODO: Why is the parser 'html.parser' here? To avoid an
+        # infinite loop?
+        self.soup = BeautifulSoup("", "html.parser")
+        self.soup.name = "[document_fragment]"
+        return Element(self.soup, self.soup, None)
+
+    def appendChild(self, node):
+        # XXX This code is not covered by the BS4 tests.
+        self.soup.append(node.element)
+
+    def getDocument(self):
+        return self.soup
+
+    def getFragment(self):
+        return treebuilder_base.TreeBuilder.getFragment(self).element
+
+    def testSerializer(self, element):
+        from bs4 import BeautifulSoup
+        rv = []
+        doctype_re = re.compile(r'^(.*?)(?: PUBLIC "(.*?)"(?: "(.*?)")?| SYSTEM "(.*?)")?$')
+
+        def serializeElement(element, indent=0):
+            if isinstance(element, BeautifulSoup):
+                pass
+            if isinstance(element, Doctype):
+                m = doctype_re.match(element)
+                if m:
+                    name = m.group(1)
+                    if m.lastindex > 1:
+                        publicId = m.group(2) or ""
+                        systemId = m.group(3) or m.group(4) or ""
+                        rv.append("""|%s<!DOCTYPE %s "%s" "%s">""" %
+                                  (' ' * indent, name, publicId, systemId))
+                    else:
+                        rv.append("|%s<!DOCTYPE %s>" % (' ' * indent, name))
+                else:
+                    rv.append("|%s<!DOCTYPE >" % (' ' * indent,))
+            elif isinstance(element, Comment):
+                rv.append("|%s<!-- %s -->" % (' ' * indent, element))
+            elif isinstance(element, NavigableString):
+                rv.append("|%s\"%s\"" % (' ' * indent, element))
+            else:
+                if element.namespace:
+                    name = "%s %s" % (prefixes[element.namespace],
+                                      element.name)
+                else:
+                    name = element.name
+                rv.append("|%s<%s>" % (' ' * indent, name))
+                if element.attrs:
+                    attributes = []
+                    for name, value in list(element.attrs.items()):
+                        if isinstance(name, NamespacedAttribute):
+                            name = "%s %s" % (prefixes[name.namespace], name.name)
+                        if isinstance(value, list):
+                            value = " ".join(value)
+                        attributes.append((name, value))
+
+                    for name, value in sorted(attributes):
+                        rv.append('|%s%s="%s"' % (' ' * (indent + 2), name, value))
+                indent += 2
+                for child in element.children:
+                    serializeElement(child, indent)
+        serializeElement(element, 0)
+
+        return "\n".join(rv)
+
+class AttrList(object):
+    def __init__(self, element):
+        self.element = element
+        self.attrs = dict(self.element.attrs)
+    def __iter__(self):
+        return list(self.attrs.items()).__iter__()
+    def __setitem__(self, name, value):
+        # If this attribute is a multi-valued attribute for this element,
+        # turn its value into a list.
+        list_attr = self.element.cdata_list_attributes
+        if (name in list_attr['*']
+            or (self.element.name in list_attr
+                and name in list_attr[self.element.name])):
+            # A node that is being cloned may have already undergone
+            # this procedure.
+            if not isinstance(value, list):
+                value = nonwhitespace_re.findall(value)
+        self.element[name] = value
+    def items(self):
+        return list(self.attrs.items())
+    def keys(self):
+        return list(self.attrs.keys())
+    def __len__(self):
+        return len(self.attrs)
+    def __getitem__(self, name):
+        return self.attrs[name]
+    def __contains__(self, name):
+        return name in list(self.attrs.keys())
+
+
+class Element(treebuilder_base.Node):
+    def __init__(self, element, soup, namespace):
+        treebuilder_base.Node.__init__(self, element.name)
+        self.element = element
+        self.soup = soup
+        self.namespace = namespace
+
+    def appendChild(self, node):
+        string_child = child = None
+        if isinstance(node, str):
+            # Some other piece of code decided to pass in a string
+            # instead of creating a TextElement object to contain the
+            # string.
+            string_child = child = node
+        elif isinstance(node, Tag):
+            # Some other piece of code decided to pass in a Tag
+            # instead of creating an Element object to contain the
+            # Tag.
+            child = node
+        elif node.element.__class__ == NavigableString:
+            string_child = child = node.element
+            node.parent = self
+        else:
+            child = node.element
+            node.parent = self
+
+        if not isinstance(child, str) and child.parent is not None:
+            node.element.extract()
+
+        if (string_child is not None and self.element.contents
+            and self.element.contents[-1].__class__ == NavigableString):
+            # We are appending a string onto another string.
+            # TODO This has O(n^2) performance, for input like
+            # "a</a>a</a>a</a>..."
+            old_element = self.element.contents[-1]
+            new_element = self.soup.new_string(old_element + string_child)
+            old_element.replace_with(new_element)
+            self.soup._most_recent_element = new_element
+        else:
+            if isinstance(node, str):
+                # Create a brand new NavigableString from this string.
+                child = self.soup.new_string(node)
+
+            # Tell Beautiful Soup to act as if it parsed this element
+            # immediately after the parent's last descendant. (Or
+            # immediately after the parent, if it has no children.)
+            if self.element.contents:
+                most_recent_element = self.element._last_descendant(False)
+            elif self.element.next_element is not None:
+                # Something from further ahead in the parse tree is
+                # being inserted into this earlier element. This is
+                # very annoying because it means an expensive search
+                # for the last element in the tree.
+                most_recent_element = self.soup._last_descendant()
+            else:
+                most_recent_element = self.element
+
+            self.soup.object_was_parsed(
+                child, parent=self.element,
+                most_recent_element=most_recent_element)
+
+    def getAttributes(self):
+        if isinstance(self.element, Comment):
+            return {}
+        return AttrList(self.element)
+
+    def setAttributes(self, attributes):
+        if attributes is not None and len(attributes) > 0:
+            converted_attributes = []
+            for name, value in list(attributes.items()):
+                if isinstance(name, tuple):
+                    new_name = NamespacedAttribute(*name)
+                    del attributes[name]
+                    attributes[new_name] = value
+
+            self.soup.builder._replace_cdata_list_attribute_values(
+                self.name, attributes)
+            for name, value in list(attributes.items()):
+                self.element[name] = value
+
+            # The attributes may contain variables that need substitution.
+            # Call set_up_substitutions manually.
+            #
+            # The Tag constructor called this method when the Tag was created,
+            # but we just set/changed the attributes, so call it again.
+            self.soup.builder.set_up_substitutions(self.element)
+    attributes = property(getAttributes, setAttributes)
+
+    def insertText(self, data, insertBefore=None):
+        text = TextNode(self.soup.new_string(data), self.soup)
+        if insertBefore:
+            self.insertBefore(text, insertBefore)
+        else:
+            self.appendChild(text)
+
+    def insertBefore(self, node, refNode):
+        index = self.element.index(refNode.element)
+        if (node.element.__class__ == NavigableString and self.element.contents
+            and self.element.contents[index-1].__class__ == NavigableString):
+            # (See comments in appendChild)
+            old_node = self.element.contents[index-1]
+            new_str = self.soup.new_string(old_node + node.element)
+            old_node.replace_with(new_str)
+        else:
+            self.element.insert(index, node.element)
+            node.parent = self
+
+    def removeChild(self, node):
+        node.element.extract()
+
+    def reparentChildren(self, new_parent):
+        """Move all of this tag's children into another tag."""
+        # print("MOVE", self.element.contents)
+        # print("FROM", self.element)
+        # print("TO", new_parent.element)
+
+        element = self.element
+        new_parent_element = new_parent.element
+        # Determine what this tag's next_element will be once all the children
+        # are removed.
+        final_next_element = element.next_sibling
+
+        new_parents_last_descendant = new_parent_element._last_descendant(False, False)
+        if len(new_parent_element.contents) > 0:
+            # The new parent already contains children. We will be
+            # appending this tag's children to the end.
+            new_parents_last_child = new_parent_element.contents[-1]
+            new_parents_last_descendant_next_element = new_parents_last_descendant.next_element
+        else:
+            # The new parent contains no children.
+            new_parents_last_child = None
+            new_parents_last_descendant_next_element = new_parent_element.next_element
+
+        to_append = element.contents
+        if len(to_append) > 0:
+            # Set the first child's previous_element and previous_sibling
+            # to elements within the new parent
+            first_child = to_append[0]
+            if new_parents_last_descendant is not None:
+                first_child.previous_element = new_parents_last_descendant
+            else:
+                first_child.previous_element = new_parent_element
+            first_child.previous_sibling = new_parents_last_child
+            if new_parents_last_descendant is not None:
+                new_parents_last_descendant.next_element = first_child
+            else:
+                new_parent_element.next_element = first_child
+            if new_parents_last_child is not None:
+                new_parents_last_child.next_sibling = first_child
+
+            # Find the very last element being moved. It is now the
+            # parent's last descendant. It has no .next_sibling and
+            # its .next_element is whatever the previous last
+            # descendant had.
+            last_childs_last_descendant = to_append[-1]._last_descendant(False, True)
+
+            last_childs_last_descendant.next_element = new_parents_last_descendant_next_element
+            if new_parents_last_descendant_next_element is not None:
+                # TODO: This code has no test coverage and I'm not sure
+                # how to get html5lib to go through this path, but it's
+                # just the other side of the previous line.
+                new_parents_last_descendant_next_element.previous_element = last_childs_last_descendant
+            last_childs_last_descendant.next_sibling = None
+
+        for child in to_append:
+            child.parent = new_parent_element
+            new_parent_element.contents.append(child)
+
+        # Now that this element has no children, change its .next_element.
+        element.contents = []
+        element.next_element = final_next_element
+
+        # print("DONE WITH MOVE")
+        # print("FROM", self.element)
+        # print("TO", new_parent_element)
+
+    def cloneNode(self):
+        tag = self.soup.new_tag(self.element.name, self.namespace)
+        node = Element(tag, self.soup, self.namespace)
+        for key,value in self.attributes:
+            node.attributes[key] = value
+        return node
+
+    def hasContent(self):
+        return self.element.contents
+
+    def getNameTuple(self):
+        if self.namespace == None:
+            return namespaces["html"], self.name
+        else:
+            return self.namespace, self.name
+
+    nameTuple = property(getNameTuple)
+
+class TextNode(Element):
+    def __init__(self, element, soup):
+        treebuilder_base.Node.__init__(self, None)
+        self.element = element
+        self.soup = soup
+
+    def cloneNode(self):
+        raise NotImplementedError
Index: latest/Lib/site-packages/bs4/builder/_htmlparser.py
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/latest/Lib/site-packages/bs4/builder/_htmlparser.py b/latest/Lib/site-packages/bs4/builder/_htmlparser.py
new file mode 100644
--- /dev/null	(date 1616411342105)
+++ b/latest/Lib/site-packages/bs4/builder/_htmlparser.py	(date 1616411342105)
@@ -0,0 +1,477 @@
+# encoding: utf-8
+"""Use the HTMLParser library to parse HTML files that aren't too bad."""
+
+# Use of this source code is governed by the MIT license.
+__license__ = "MIT"
+
+__all__ = [
+    'HTMLParserTreeBuilder',
+    ]
+
+from html.parser import HTMLParser
+
+try:
+    from html.parser import HTMLParseError
+except ImportError as e:
+    # HTMLParseError is removed in Python 3.5. Since it can never be
+    # thrown in 3.5, we can just define our own class as a placeholder.
+    class HTMLParseError(Exception):
+        pass
+
+import sys
+import warnings
+
+# Starting in Python 3.2, the HTMLParser constructor takes a 'strict'
+# argument, which we'd like to set to False. Unfortunately,
+# http://bugs.python.org/issue13273 makes strict=True a better bet
+# before Python 3.2.3.
+#
+# At the end of this file, we monkeypatch HTMLParser so that
+# strict=True works well on Python 3.2.2.
+major, minor, release = sys.version_info[:3]
+CONSTRUCTOR_TAKES_STRICT = major == 3 and minor == 2 and release >= 3
+CONSTRUCTOR_STRICT_IS_DEPRECATED = major == 3 and minor == 3
+CONSTRUCTOR_TAKES_CONVERT_CHARREFS = major == 3 and minor >= 4
+
+
+from bs4.element import (
+    CData,
+    Comment,
+    Declaration,
+    Doctype,
+    ProcessingInstruction,
+    )
+from bs4.dammit import EntitySubstitution, UnicodeDammit
+
+from bs4.builder import (
+    HTML,
+    HTMLTreeBuilder,
+    STRICT,
+    )
+
+
+HTMLPARSER = 'html.parser'
+
+class BeautifulSoupHTMLParser(HTMLParser):
+    """A subclass of the Python standard library's HTMLParser class, which
+    listens for HTMLParser events and translates them into calls
+    to Beautiful Soup's tree construction API.
+    """
+
+    # Strategies for handling duplicate attributes
+    IGNORE = 'ignore'
+    REPLACE = 'replace'
+    
+    def __init__(self, *args, **kwargs):
+        """Constructor.
+
+        :param on_duplicate_attribute: A strategy for what to do if a
+            tag includes the same attribute more than once. Accepted
+            values are: REPLACE (replace earlier values with later
+            ones, the default), IGNORE (keep the earliest value
+            encountered), or a callable. A callable must take three
+            arguments: the dictionary of attributes already processed,
+            the name of the duplicate attribute, and the most recent value
+            encountered.           
+        """
+        self.on_duplicate_attribute = kwargs.pop(
+            'on_duplicate_attribute', self.REPLACE
+        )
+        HTMLParser.__init__(self, *args, **kwargs)
+
+        # Keep a list of empty-element tags that were encountered
+        # without an explicit closing tag. If we encounter a closing tag
+        # of this type, we'll associate it with one of those entries.
+        #
+        # This isn't a stack because we don't care about the
+        # order. It's a list of closing tags we've already handled and
+        # will ignore, assuming they ever show up.
+        self.already_closed_empty_element = []
+
+    def error(self, msg):
+        """In Python 3, HTMLParser subclasses must implement error(), although
+        this requirement doesn't appear to be documented.
+
+        In Python 2, HTMLParser implements error() by raising an exception,
+        which we don't want to do.
+
+        In any event, this method is called only on very strange
+        markup and our best strategy is to pretend it didn't happen
+        and keep going.
+        """
+        warnings.warn(msg)
+        
+    def handle_startendtag(self, name, attrs):
+        """Handle an incoming empty-element tag.
+
+        This is only called when the markup looks like <tag/>.
+
+        :param name: Name of the tag.
+        :param attrs: Dictionary of the tag's attributes.
+        """
+        # is_startend() tells handle_starttag not to close the tag
+        # just because its name matches a known empty-element tag. We
+        # know that this is an empty-element tag and we want to call
+        # handle_endtag ourselves.
+        tag = self.handle_starttag(name, attrs, handle_empty_element=False)
+        self.handle_endtag(name)
+        
+    def handle_starttag(self, name, attrs, handle_empty_element=True):
+        """Handle an opening tag, e.g. '<tag>'
+
+        :param name: Name of the tag.
+        :param attrs: Dictionary of the tag's attributes.
+        :param handle_empty_element: True if this tag is known to be
+            an empty-element tag (i.e. there is not expected to be any
+            closing tag).
+        """
+        # XXX namespace
+        attr_dict = {}
+        for key, value in attrs:
+            # Change None attribute values to the empty string
+            # for consistency with the other tree builders.
+            if value is None:
+                value = ''
+            if key in attr_dict:
+                # A single attribute shows up multiple times in this
+                # tag. How to handle it depends on the
+                # on_duplicate_attribute setting.
+                on_dupe = self.on_duplicate_attribute
+                if on_dupe == self.IGNORE:
+                    pass
+                elif on_dupe in (None, self.REPLACE):
+                    attr_dict[key] = value
+                else:
+                    on_dupe(attr_dict, key, value)
+            else:
+                attr_dict[key] = value
+            attrvalue = '""'
+        #print("START", name)
+        sourceline, sourcepos = self.getpos()
+        tag = self.soup.handle_starttag(
+            name, None, None, attr_dict, sourceline=sourceline,
+            sourcepos=sourcepos
+        )
+        if tag and tag.is_empty_element and handle_empty_element:
+            # Unlike other parsers, html.parser doesn't send separate end tag
+            # events for empty-element tags. (It's handled in
+            # handle_startendtag, but only if the original markup looked like
+            # <tag/>.)
+            #
+            # So we need to call handle_endtag() ourselves. Since we
+            # know the start event is identical to the end event, we
+            # don't want handle_endtag() to cross off any previous end
+            # events for tags of this name.
+            self.handle_endtag(name, check_already_closed=False)
+
+            # But we might encounter an explicit closing tag for this tag
+            # later on. If so, we want to ignore it.
+            self.already_closed_empty_element.append(name)
+            
+    def handle_endtag(self, name, check_already_closed=True):
+        """Handle a closing tag, e.g. '</tag>'
+        
+        :param name: A tag name.
+        :param check_already_closed: True if this tag is expected to
+           be the closing portion of an empty-element tag,
+           e.g. '<tag></tag>'.
+        """
+        #print("END", name)
+        if check_already_closed and name in self.already_closed_empty_element:
+            # This is a redundant end tag for an empty-element tag.
+            # We've already called handle_endtag() for it, so just
+            # check it off the list.
+            #print("ALREADY CLOSED", name)
+            self.already_closed_empty_element.remove(name)
+        else:
+            self.soup.handle_endtag(name)
+
+    def handle_data(self, data):
+        """Handle some textual data that shows up between tags."""
+        self.soup.handle_data(data)
+
+    def handle_charref(self, name):
+        """Handle a numeric character reference by converting it to the
+        corresponding Unicode character and treating it as textual
+        data.
+
+        :param name: Character number, possibly in hexadecimal.
+        """
+        # XXX workaround for a bug in HTMLParser. Remove this once
+        # it's fixed in all supported versions.
+        # http://bugs.python.org/issue13633
+        if name.startswith('x'):
+            real_name = int(name.lstrip('x'), 16)
+        elif name.startswith('X'):
+            real_name = int(name.lstrip('X'), 16)
+        else:
+            real_name = int(name)
+
+        data = None
+        if real_name < 256:
+            # HTML numeric entities are supposed to reference Unicode
+            # code points, but sometimes they reference code points in
+            # some other encoding (ahem, Windows-1252). E.g. &#147;
+            # instead of &#201; for LEFT DOUBLE QUOTATION MARK. This
+            # code tries to detect this situation and compensate.
+            for encoding in (self.soup.original_encoding, 'windows-1252'):
+                if not encoding:
+                    continue
+                try:
+                    data = bytearray([real_name]).decode(encoding)
+                except UnicodeDecodeError as e:
+                    pass
+        if not data:
+            try:
+                data = chr(real_name)
+            except (ValueError, OverflowError) as e:
+                pass
+        data = data or "\N{REPLACEMENT CHARACTER}"
+        self.handle_data(data)
+
+    def handle_entityref(self, name):
+        """Handle a named entity reference by converting it to the
+        corresponding Unicode character and treating it as textual
+        data.
+
+        :param name: Name of the entity reference.
+        """
+        character = EntitySubstitution.HTML_ENTITY_TO_CHARACTER.get(name)
+        if character is not None:
+            data = character
+        else:
+            # If this were XML, it would be ambiguous whether "&foo"
+            # was an character entity reference with a missing
+            # semicolon or the literal string "&foo". Since this is
+            # HTML, we have a complete list of all character entity references,
+            # and this one wasn't found, so assume it's the literal string "&foo".
+            data = "&%s" % name
+        self.handle_data(data)
+
+    def handle_comment(self, data):
+        """Handle an HTML comment.
+
+        :param data: The text of the comment.
+        """
+        self.soup.endData()
+        self.soup.handle_data(data)
+        self.soup.endData(Comment)
+
+    def handle_decl(self, data):
+        """Handle a DOCTYPE declaration.
+
+        :param data: The text of the declaration.
+        """
+        self.soup.endData()
+        data = data[len("DOCTYPE "):]
+        self.soup.handle_data(data)
+        self.soup.endData(Doctype)
+
+    def unknown_decl(self, data):
+        """Handle a declaration of unknown type -- probably a CDATA block.
+
+        :param data: The text of the declaration.
+        """
+        if data.upper().startswith('CDATA['):
+            cls = CData
+            data = data[len('CDATA['):]
+        else:
+            cls = Declaration
+        self.soup.endData()
+        self.soup.handle_data(data)
+        self.soup.endData(cls)
+
+    def handle_pi(self, data):
+        """Handle a processing instruction.
+
+        :param data: The text of the instruction.
+        """
+        self.soup.endData()
+        self.soup.handle_data(data)
+        self.soup.endData(ProcessingInstruction)
+
+
+class HTMLParserTreeBuilder(HTMLTreeBuilder):
+    """A Beautiful soup `TreeBuilder` that uses the `HTMLParser` parser,
+    found in the Python standard library.
+    """
+    is_xml = False
+    picklable = True
+    NAME = HTMLPARSER
+    features = [NAME, HTML, STRICT]
+
+    # The html.parser knows which line number and position in the
+    # original file is the source of an element.
+    TRACKS_LINE_NUMBERS = True
+
+    def __init__(self, parser_args=None, parser_kwargs=None, **kwargs):
+        """Constructor.
+
+        :param parser_args: Positional arguments to pass into 
+            the BeautifulSoupHTMLParser constructor, once it's
+            invoked.
+        :param parser_kwargs: Keyword arguments to pass into 
+            the BeautifulSoupHTMLParser constructor, once it's
+            invoked.
+        :param kwargs: Keyword arguments for the superclass constructor.
+        """
+        # Some keyword arguments will be pulled out of kwargs and placed
+        # into parser_kwargs.
+        extra_parser_kwargs = dict()
+        for arg in ('on_duplicate_attribute',):
+            if arg in kwargs:
+                value = kwargs.pop(arg)
+                extra_parser_kwargs[arg] = value
+        super(HTMLParserTreeBuilder, self).__init__(**kwargs)
+        parser_args = parser_args or []
+        parser_kwargs = parser_kwargs or {}
+        parser_kwargs.update(extra_parser_kwargs)
+        if CONSTRUCTOR_TAKES_STRICT and not CONSTRUCTOR_STRICT_IS_DEPRECATED:
+            parser_kwargs['strict'] = False
+        if CONSTRUCTOR_TAKES_CONVERT_CHARREFS:
+            parser_kwargs['convert_charrefs'] = False
+        self.parser_args = (parser_args, parser_kwargs)
+        
+    def prepare_markup(self, markup, user_specified_encoding=None,
+                       document_declared_encoding=None, exclude_encodings=None):
+
+        """Run any preliminary steps necessary to make incoming markup
+        acceptable to the parser.
+
+        :param markup: Some markup -- probably a bytestring.
+        :param user_specified_encoding: The user asked to try this encoding.
+        :param document_declared_encoding: The markup itself claims to be
+            in this encoding.
+        :param exclude_encodings: The user asked _not_ to try any of
+            these encodings.
+
+        :yield: A series of 4-tuples:
+         (markup, encoding, declared encoding,
+          has undergone character replacement)
+
+         Each 4-tuple represents a strategy for converting the
+         document to Unicode and parsing it. Each strategy will be tried 
+         in turn.
+        """
+        if isinstance(markup, str):
+            # Parse Unicode as-is.
+            yield (markup, None, None, False)
+            return
+
+        # Ask UnicodeDammit to sniff the most likely encoding.
+        try_encodings = [user_specified_encoding, document_declared_encoding]
+        dammit = UnicodeDammit(markup, try_encodings, is_html=True,
+                               exclude_encodings=exclude_encodings)
+        yield (dammit.markup, dammit.original_encoding,
+               dammit.declared_html_encoding,
+               dammit.contains_replacement_characters)
+
+    def feed(self, markup):
+        """Run some incoming markup through some parsing process,
+        populating the `BeautifulSoup` object in self.soup.
+        """
+        args, kwargs = self.parser_args
+        parser = BeautifulSoupHTMLParser(*args, **kwargs)
+        parser.soup = self.soup
+        try:
+            parser.feed(markup)
+            parser.close()
+        except HTMLParseError as e:
+            warnings.warn(RuntimeWarning(
+                "Python's built-in HTMLParser cannot parse the given document. This is not a bug in Beautiful Soup. The best solution is to install an external parser (lxml or html5lib), and use Beautiful Soup with that parser. See http://www.crummy.com/software/BeautifulSoup/bs4/doc/#installing-a-parser for help."))
+            raise e
+        parser.already_closed_empty_element = []
+
+# Patch 3.2 versions of HTMLParser earlier than 3.2.3 to use some
+# 3.2.3 code. This ensures they don't treat markup like <p></p> as a
+# string.
+#
+# XXX This code can be removed once most Python 3 users are on 3.2.3.
+if major == 3 and minor == 2 and not CONSTRUCTOR_TAKES_STRICT:
+    import re
+    attrfind_tolerant = re.compile(
+        r'\s*((?<=[\'"\s])[^\s/>][^\s/=>]*)(\s*=+\s*'
+        r'(\'[^\']*\'|"[^"]*"|(?![\'"])[^>\s]*))?')
+    HTMLParserTreeBuilder.attrfind_tolerant = attrfind_tolerant
+
+    locatestarttagend = re.compile(r"""
+  <[a-zA-Z][-.a-zA-Z0-9:_]*          # tag name
+  (?:\s+                             # whitespace before attribute name
+    (?:[a-zA-Z_][-.:a-zA-Z0-9_]*     # attribute name
+      (?:\s*=\s*                     # value indicator
+        (?:'[^']*'                   # LITA-enclosed value
+          |\"[^\"]*\"                # LIT-enclosed value
+          |[^'\">\s]+                # bare value
+         )
+       )?
+     )
+   )*
+  \s*                                # trailing whitespace
+""", re.VERBOSE)
+    BeautifulSoupHTMLParser.locatestarttagend = locatestarttagend
+
+    from html.parser import tagfind, attrfind
+
+    def parse_starttag(self, i):
+        self.__starttag_text = None
+        endpos = self.check_for_whole_start_tag(i)
+        if endpos < 0:
+            return endpos
+        rawdata = self.rawdata
+        self.__starttag_text = rawdata[i:endpos]
+
+        # Now parse the data between i+1 and j into a tag and attrs
+        attrs = []
+        match = tagfind.match(rawdata, i+1)
+        assert match, 'unexpected call to parse_starttag()'
+        k = match.end()
+        self.lasttag = tag = rawdata[i+1:k].lower()
+        while k < endpos:
+            if self.strict:
+                m = attrfind.match(rawdata, k)
+            else:
+                m = attrfind_tolerant.match(rawdata, k)
+            if not m:
+                break
+            attrname, rest, attrvalue = m.group(1, 2, 3)
+            if not rest:
+                attrvalue = None
+            elif attrvalue[:1] == '\'' == attrvalue[-1:] or \
+                 attrvalue[:1] == '"' == attrvalue[-1:]:
+                attrvalue = attrvalue[1:-1]
+            if attrvalue:
+                attrvalue = self.unescape(attrvalue)
+            attrs.append((attrname.lower(), attrvalue))
+            k = m.end()
+
+        end = rawdata[k:endpos].strip()
+        if end not in (">", "/>"):
+            lineno, offset = self.getpos()
+            if "\n" in self.__starttag_text:
+                lineno = lineno + self.__starttag_text.count("\n")
+                offset = len(self.__starttag_text) \
+                         - self.__starttag_text.rfind("\n")
+            else:
+                offset = offset + len(self.__starttag_text)
+            if self.strict:
+                self.error("junk characters in start tag: %r"
+                           % (rawdata[k:endpos][:20],))
+            self.handle_data(rawdata[i:endpos])
+            return endpos
+        if end.endswith('/>'):
+            # XHTML-style empty tag: <span attr="value" />
+            self.handle_startendtag(tag, attrs)
+        else:
+            self.handle_starttag(tag, attrs)
+            if tag in self.CDATA_CONTENT_ELEMENTS:
+                self.set_cdata_mode(tag)
+        return endpos
+
+    def set_cdata_mode(self, elem):
+        self.cdata_elem = elem.lower()
+        self.interesting = re.compile(r'</\s*%s\s*>' % self.cdata_elem, re.I)
+
+    BeautifulSoupHTMLParser.parse_starttag = parse_starttag
+    BeautifulSoupHTMLParser.set_cdata_mode = set_cdata_mode
+
+    CONSTRUCTOR_TAKES_STRICT = True
Index: latest/Lib/site-packages/bs4/builder/_lxml.py
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/latest/Lib/site-packages/bs4/builder/_lxml.py b/latest/Lib/site-packages/bs4/builder/_lxml.py
new file mode 100644
--- /dev/null	(date 1616411342108)
+++ b/latest/Lib/site-packages/bs4/builder/_lxml.py	(date 1616411342108)
@@ -0,0 +1,332 @@
+# Use of this source code is governed by the MIT license.
+__license__ = "MIT"
+
+__all__ = [
+    'LXMLTreeBuilderForXML',
+    'LXMLTreeBuilder',
+    ]
+
+try:
+    from collections.abc import Callable # Python 3.6
+except ImportError as e:
+    from collections import Callable
+
+from io import BytesIO
+from io import StringIO
+from lxml import etree
+from bs4.element import (
+    Comment,
+    Doctype,
+    NamespacedAttribute,
+    ProcessingInstruction,
+    XMLProcessingInstruction,
+)
+from bs4.builder import (
+    FAST,
+    HTML,
+    HTMLTreeBuilder,
+    PERMISSIVE,
+    ParserRejectedMarkup,
+    TreeBuilder,
+    XML)
+from bs4.dammit import EncodingDetector
+
+LXML = 'lxml'
+
+def _invert(d):
+    "Invert a dictionary."
+    return dict((v,k) for k, v in list(d.items()))
+
+class LXMLTreeBuilderForXML(TreeBuilder):
+    DEFAULT_PARSER_CLASS = etree.XMLParser
+
+    is_xml = True
+    processing_instruction_class = XMLProcessingInstruction
+
+    NAME = "lxml-xml"
+    ALTERNATE_NAMES = ["xml"]
+
+    # Well, it's permissive by XML parser standards.
+    features = [NAME, LXML, XML, FAST, PERMISSIVE]
+
+    CHUNK_SIZE = 512
+
+    # This namespace mapping is specified in the XML Namespace
+    # standard.
+    DEFAULT_NSMAPS = dict(xml='http://www.w3.org/XML/1998/namespace')
+
+    DEFAULT_NSMAPS_INVERTED = _invert(DEFAULT_NSMAPS)
+
+    # NOTE: If we parsed Element objects and looked at .sourceline,
+    # we'd be able to see the line numbers from the original document.
+    # But instead we build an XMLParser or HTMLParser object to serve
+    # as the target of parse messages, and those messages don't include
+    # line numbers.
+    # See: https://bugs.launchpad.net/lxml/+bug/1846906
+    
+    def initialize_soup(self, soup):
+        """Let the BeautifulSoup object know about the standard namespace
+        mapping.
+
+        :param soup: A `BeautifulSoup`.
+        """
+        super(LXMLTreeBuilderForXML, self).initialize_soup(soup)
+        self._register_namespaces(self.DEFAULT_NSMAPS)
+
+    def _register_namespaces(self, mapping):
+        """Let the BeautifulSoup object know about namespaces encountered
+        while parsing the document.
+
+        This might be useful later on when creating CSS selectors.
+
+        :param mapping: A dictionary mapping namespace prefixes to URIs.
+        """
+        for key, value in list(mapping.items()):
+            if key and key not in self.soup._namespaces:
+                # Let the BeautifulSoup object know about a new namespace.
+                # If there are multiple namespaces defined with the same
+                # prefix, the first one in the document takes precedence.
+                self.soup._namespaces[key] = value
+
+    def default_parser(self, encoding):
+        """Find the default parser for the given encoding.
+
+        :param encoding: A string.
+        :return: Either a parser object or a class, which
+          will be instantiated with default arguments.
+        """
+        if self._default_parser is not None:
+            return self._default_parser
+        return etree.XMLParser(
+            target=self, strip_cdata=False, recover=True, encoding=encoding)
+
+    def parser_for(self, encoding):
+        """Instantiate an appropriate parser for the given encoding.
+
+        :param encoding: A string.
+        :return: A parser object such as an `etree.XMLParser`.
+        """
+        # Use the default parser.
+        parser = self.default_parser(encoding)
+
+        if isinstance(parser, Callable):
+            # Instantiate the parser with default arguments
+            parser = parser(
+                target=self, strip_cdata=False, recover=True, encoding=encoding
+            )
+        return parser
+
+    def __init__(self, parser=None, empty_element_tags=None, **kwargs):
+        # TODO: Issue a warning if parser is present but not a
+        # callable, since that means there's no way to create new
+        # parsers for different encodings.
+        self._default_parser = parser
+        if empty_element_tags is not None:
+            self.empty_element_tags = set(empty_element_tags)
+        self.soup = None
+        self.nsmaps = [self.DEFAULT_NSMAPS_INVERTED]
+        super(LXMLTreeBuilderForXML, self).__init__(**kwargs)
+        
+    def _getNsTag(self, tag):
+        # Split the namespace URL out of a fully-qualified lxml tag
+        # name. Copied from lxml's src/lxml/sax.py.
+        if tag[0] == '{':
+            return tuple(tag[1:].split('}', 1))
+        else:
+            return (None, tag)
+
+    def prepare_markup(self, markup, user_specified_encoding=None,
+                       exclude_encodings=None,
+                       document_declared_encoding=None):
+        """Run any preliminary steps necessary to make incoming markup
+        acceptable to the parser.
+
+        lxml really wants to get a bytestring and convert it to
+        Unicode itself. So instead of using UnicodeDammit to convert
+        the bytestring to Unicode using different encodings, this
+        implementation uses EncodingDetector to iterate over the
+        encodings, and tell lxml to try to parse the document as each
+        one in turn.
+
+        :param markup: Some markup -- hopefully a bytestring.
+        :param user_specified_encoding: The user asked to try this encoding.
+        :param document_declared_encoding: The markup itself claims to be
+            in this encoding.
+        :param exclude_encodings: The user asked _not_ to try any of
+            these encodings.
+
+        :yield: A series of 4-tuples:
+         (markup, encoding, declared encoding,
+          has undergone character replacement)
+
+         Each 4-tuple represents a strategy for converting the
+         document to Unicode and parsing it. Each strategy will be tried 
+         in turn.
+        """
+        is_html = not self.is_xml
+        if is_html:
+            self.processing_instruction_class = ProcessingInstruction
+        else:
+            self.processing_instruction_class = XMLProcessingInstruction
+
+        if isinstance(markup, str):
+            # We were given Unicode. Maybe lxml can parse Unicode on
+            # this system?
+            yield markup, None, document_declared_encoding, False
+
+        if isinstance(markup, str):
+            # No, apparently not. Convert the Unicode to UTF-8 and
+            # tell lxml to parse it as UTF-8.
+            yield (markup.encode("utf8"), "utf8",
+                   document_declared_encoding, False)
+
+        try_encodings = [user_specified_encoding, document_declared_encoding]
+        detector = EncodingDetector(
+            markup, try_encodings, is_html, exclude_encodings)
+        for encoding in detector.encodings:
+            yield (detector.markup, encoding, document_declared_encoding, False)
+
+    def feed(self, markup):
+        if isinstance(markup, bytes):
+            markup = BytesIO(markup)
+        elif isinstance(markup, str):
+            markup = StringIO(markup)
+
+        # Call feed() at least once, even if the markup is empty,
+        # or the parser won't be initialized.
+        data = markup.read(self.CHUNK_SIZE)
+        try:
+            self.parser = self.parser_for(self.soup.original_encoding)
+            self.parser.feed(data)
+            while len(data) != 0:
+                # Now call feed() on the rest of the data, chunk by chunk.
+                data = markup.read(self.CHUNK_SIZE)
+                if len(data) != 0:
+                    self.parser.feed(data)
+            self.parser.close()
+        except (UnicodeDecodeError, LookupError, etree.ParserError) as e:
+            raise ParserRejectedMarkup(e)
+
+    def close(self):
+        self.nsmaps = [self.DEFAULT_NSMAPS_INVERTED]
+
+    def start(self, name, attrs, nsmap={}):
+        # Make sure attrs is a mutable dict--lxml may send an immutable dictproxy.
+        attrs = dict(attrs)
+        nsprefix = None
+        # Invert each namespace map as it comes in.
+        if len(nsmap) == 0 and len(self.nsmaps) > 1:
+                # There are no new namespaces for this tag, but
+                # non-default namespaces are in play, so we need a
+                # separate tag stack to know when they end.
+                self.nsmaps.append(None)
+        elif len(nsmap) > 0:
+            # A new namespace mapping has come into play.
+
+            # First, Let the BeautifulSoup object know about it.
+            self._register_namespaces(nsmap)
+
+            # Then, add it to our running list of inverted namespace
+            # mappings.
+            self.nsmaps.append(_invert(nsmap))
+
+            # Also treat the namespace mapping as a set of attributes on the
+            # tag, so we can recreate it later.
+            attrs = attrs.copy()
+            for prefix, namespace in list(nsmap.items()):
+                attribute = NamespacedAttribute(
+                    "xmlns", prefix, "http://www.w3.org/2000/xmlns/")
+                attrs[attribute] = namespace
+
+        # Namespaces are in play. Find any attributes that came in
+        # from lxml with namespaces attached to their names, and
+        # turn then into NamespacedAttribute objects.
+        new_attrs = {}
+        for attr, value in list(attrs.items()):
+            namespace, attr = self._getNsTag(attr)
+            if namespace is None:
+                new_attrs[attr] = value
+            else:
+                nsprefix = self._prefix_for_namespace(namespace)
+                attr = NamespacedAttribute(nsprefix, attr, namespace)
+                new_attrs[attr] = value
+        attrs = new_attrs
+
+        namespace, name = self._getNsTag(name)
+        nsprefix = self._prefix_for_namespace(namespace)
+        self.soup.handle_starttag(name, namespace, nsprefix, attrs)
+
+    def _prefix_for_namespace(self, namespace):
+        """Find the currently active prefix for the given namespace."""
+        if namespace is None:
+            return None
+        for inverted_nsmap in reversed(self.nsmaps):
+            if inverted_nsmap is not None and namespace in inverted_nsmap:
+                return inverted_nsmap[namespace]
+        return None
+
+    def end(self, name):
+        self.soup.endData()
+        completed_tag = self.soup.tagStack[-1]
+        namespace, name = self._getNsTag(name)
+        nsprefix = None
+        if namespace is not None:
+            for inverted_nsmap in reversed(self.nsmaps):
+                if inverted_nsmap is not None and namespace in inverted_nsmap:
+                    nsprefix = inverted_nsmap[namespace]
+                    break
+        self.soup.handle_endtag(name, nsprefix)
+        if len(self.nsmaps) > 1:
+            # This tag, or one of its parents, introduced a namespace
+            # mapping, so pop it off the stack.
+            self.nsmaps.pop()
+
+    def pi(self, target, data):
+        self.soup.endData()
+        self.soup.handle_data(target + ' ' + data)
+        self.soup.endData(self.processing_instruction_class)
+
+    def data(self, content):
+        self.soup.handle_data(content)
+
+    def doctype(self, name, pubid, system):
+        self.soup.endData()
+        doctype = Doctype.for_name_and_ids(name, pubid, system)
+        self.soup.object_was_parsed(doctype)
+
+    def comment(self, content):
+        "Handle comments as Comment objects."
+        self.soup.endData()
+        self.soup.handle_data(content)
+        self.soup.endData(Comment)
+
+    def test_fragment_to_document(self, fragment):
+        """See `TreeBuilder`."""
+        return '<?xml version="1.0" encoding="utf-8"?>\n%s' % fragment
+
+
+class LXMLTreeBuilder(HTMLTreeBuilder, LXMLTreeBuilderForXML):
+
+    NAME = LXML
+    ALTERNATE_NAMES = ["lxml-html"]
+
+    features = ALTERNATE_NAMES + [NAME, HTML, FAST, PERMISSIVE]
+    is_xml = False
+    processing_instruction_class = ProcessingInstruction
+
+    def default_parser(self, encoding):
+        return etree.HTMLParser
+
+    def feed(self, markup):
+        encoding = self.soup.original_encoding
+        try:
+            self.parser = self.parser_for(encoding)
+            self.parser.feed(markup)
+            self.parser.close()
+        except (UnicodeDecodeError, LookupError, etree.ParserError) as e:
+            raise ParserRejectedMarkup(e)
+
+
+    def test_fragment_to_document(self, fragment):
+        """See `TreeBuilder`."""
+        return '<html><body>%s</body></html>' % fragment
Index: latest/Lib/site-packages/bs4/builder/__init__.py
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/latest/Lib/site-packages/bs4/builder/__init__.py b/latest/Lib/site-packages/bs4/builder/__init__.py
new file mode 100644
--- /dev/null	(date 1616411342101)
+++ b/latest/Lib/site-packages/bs4/builder/__init__.py	(date 1616411342101)
@@ -0,0 +1,519 @@
+# Use of this source code is governed by the MIT license.
+__license__ = "MIT"
+
+from collections import defaultdict
+import itertools
+import sys
+from bs4.element import (
+    CharsetMetaAttributeValue,
+    ContentMetaAttributeValue,
+    Stylesheet,
+    Script,
+    TemplateString,
+    nonwhitespace_re
+)
+
+__all__ = [
+    'HTMLTreeBuilder',
+    'SAXTreeBuilder',
+    'TreeBuilder',
+    'TreeBuilderRegistry',
+    ]
+
+# Some useful features for a TreeBuilder to have.
+FAST = 'fast'
+PERMISSIVE = 'permissive'
+STRICT = 'strict'
+XML = 'xml'
+HTML = 'html'
+HTML_5 = 'html5'
+
+
+class TreeBuilderRegistry(object):
+    """A way of looking up TreeBuilder subclasses by their name or by desired
+    features.
+    """
+    
+    def __init__(self):
+        self.builders_for_feature = defaultdict(list)
+        self.builders = []
+
+    def register(self, treebuilder_class):
+        """Register a treebuilder based on its advertised features.
+
+        :param treebuilder_class: A subclass of Treebuilder. its .features
+           attribute should list its features.
+        """
+        for feature in treebuilder_class.features:
+            self.builders_for_feature[feature].insert(0, treebuilder_class)
+        self.builders.insert(0, treebuilder_class)
+
+    def lookup(self, *features):
+        """Look up a TreeBuilder subclass with the desired features.
+
+        :param features: A list of features to look for. If none are
+            provided, the most recently registered TreeBuilder subclass
+            will be used.
+        :return: A TreeBuilder subclass, or None if there's no
+            registered subclass with all the requested features.
+        """
+        if len(self.builders) == 0:
+            # There are no builders at all.
+            return None
+
+        if len(features) == 0:
+            # They didn't ask for any features. Give them the most
+            # recently registered builder.
+            return self.builders[0]
+
+        # Go down the list of features in order, and eliminate any builders
+        # that don't match every feature.
+        features = list(features)
+        features.reverse()
+        candidates = None
+        candidate_set = None
+        while len(features) > 0:
+            feature = features.pop()
+            we_have_the_feature = self.builders_for_feature.get(feature, [])
+            if len(we_have_the_feature) > 0:
+                if candidates is None:
+                    candidates = we_have_the_feature
+                    candidate_set = set(candidates)
+                else:
+                    # Eliminate any candidates that don't have this feature.
+                    candidate_set = candidate_set.intersection(
+                        set(we_have_the_feature))
+
+        # The only valid candidates are the ones in candidate_set.
+        # Go through the original list of candidates and pick the first one
+        # that's in candidate_set.
+        if candidate_set is None:
+            return None
+        for candidate in candidates:
+            if candidate in candidate_set:
+                return candidate
+        return None
+
+# The BeautifulSoup class will take feature lists from developers and use them
+# to look up builders in this registry.
+builder_registry = TreeBuilderRegistry()
+
+class TreeBuilder(object):
+    """Turn a textual document into a Beautiful Soup object tree."""
+
+    NAME = "[Unknown tree builder]"
+    ALTERNATE_NAMES = []
+    features = []
+
+    is_xml = False
+    picklable = False
+    empty_element_tags = None # A tag will be considered an empty-element
+                              # tag when and only when it has no contents.
+    
+    # A value for these tag/attribute combinations is a space- or
+    # comma-separated list of CDATA, rather than a single CDATA.
+    DEFAULT_CDATA_LIST_ATTRIBUTES = {}
+
+    # Whitespace should be preserved inside these tags.
+    DEFAULT_PRESERVE_WHITESPACE_TAGS = set()
+
+    # The textual contents of tags with these names should be
+    # instantiated with some class other than NavigableString.
+    DEFAULT_STRING_CONTAINERS = {}
+    
+    USE_DEFAULT = object()
+
+    # Most parsers don't keep track of line numbers.
+    TRACKS_LINE_NUMBERS = False
+    
+    def __init__(self, multi_valued_attributes=USE_DEFAULT,
+                 preserve_whitespace_tags=USE_DEFAULT,
+                 store_line_numbers=USE_DEFAULT,
+                 string_containers=USE_DEFAULT,
+    ):
+        """Constructor.
+
+        :param multi_valued_attributes: If this is set to None, the
+         TreeBuilder will not turn any values for attributes like
+         'class' into lists. Setting this to a dictionary will
+         customize this behavior; look at DEFAULT_CDATA_LIST_ATTRIBUTES
+         for an example.
+
+         Internally, these are called "CDATA list attributes", but that
+         probably doesn't make sense to an end-user, so the argument name
+         is `multi_valued_attributes`.
+
+        :param preserve_whitespace_tags: A list of tags to treat
+         the way <pre> tags are treated in HTML. Tags in this list
+         are immune from pretty-printing; their contents will always be
+         output as-is.
+
+        :param string_containers: A dictionary mapping tag names to
+        the classes that should be instantiated to contain the textual
+        contents of those tags. The default is to use NavigableString
+        for every tag, no matter what the name. You can override the
+        default by changing DEFAULT_STRING_CONTAINERS.
+
+        :param store_line_numbers: If the parser keeps track of the
+         line numbers and positions of the original markup, that
+         information will, by default, be stored in each corresponding
+         `Tag` object. You can turn this off by passing
+         store_line_numbers=False. If the parser you're using doesn't 
+         keep track of this information, then setting store_line_numbers=True
+         will do nothing.
+        """
+        self.soup = None
+        if multi_valued_attributes is self.USE_DEFAULT:
+            multi_valued_attributes = self.DEFAULT_CDATA_LIST_ATTRIBUTES
+        self.cdata_list_attributes = multi_valued_attributes
+        if preserve_whitespace_tags is self.USE_DEFAULT:
+            preserve_whitespace_tags = self.DEFAULT_PRESERVE_WHITESPACE_TAGS
+        self.preserve_whitespace_tags = preserve_whitespace_tags
+        if store_line_numbers == self.USE_DEFAULT:
+            store_line_numbers = self.TRACKS_LINE_NUMBERS
+        self.store_line_numbers = store_line_numbers 
+        if string_containers == self.USE_DEFAULT:
+            string_containers = self.DEFAULT_STRING_CONTAINERS
+        self.string_containers = string_containers
+        
+    def initialize_soup(self, soup):
+        """The BeautifulSoup object has been initialized and is now
+        being associated with the TreeBuilder.
+
+        :param soup: A BeautifulSoup object.
+        """
+        self.soup = soup
+        
+    def reset(self):
+        """Do any work necessary to reset the underlying parser
+        for a new document.
+
+        By default, this does nothing.
+        """
+        pass
+
+    def can_be_empty_element(self, tag_name):
+        """Might a tag with this name be an empty-element tag?
+
+        The final markup may or may not actually present this tag as
+        self-closing.
+
+        For instance: an HTMLBuilder does not consider a <p> tag to be
+        an empty-element tag (it's not in
+        HTMLBuilder.empty_element_tags). This means an empty <p> tag
+        will be presented as "<p></p>", not "<p/>" or "<p>".
+
+        The default implementation has no opinion about which tags are
+        empty-element tags, so a tag will be presented as an
+        empty-element tag if and only if it has no children.
+        "<foo></foo>" will become "<foo/>", and "<foo>bar</foo>" will
+        be left alone.
+
+        :param tag_name: The name of a markup tag.
+        """
+        if self.empty_element_tags is None:
+            return True
+        return tag_name in self.empty_element_tags
+    
+    def feed(self, markup):
+        """Run some incoming markup through some parsing process,
+        populating the `BeautifulSoup` object in self.soup.
+
+        This method is not implemented in TreeBuilder; it must be
+        implemented in subclasses.
+
+        :return: None.
+        """
+        raise NotImplementedError()
+
+    def prepare_markup(self, markup, user_specified_encoding=None,
+                       document_declared_encoding=None, exclude_encodings=None):
+        """Run any preliminary steps necessary to make incoming markup
+        acceptable to the parser.
+
+        :param markup: Some markup -- probably a bytestring.
+        :param user_specified_encoding: The user asked to try this encoding.
+        :param document_declared_encoding: The markup itself claims to be
+            in this encoding.
+        :param exclude_encodings: The user asked _not_ to try any of
+            these encodings.
+
+        :yield: A series of 4-tuples:
+         (markup, encoding, declared encoding,
+          has undergone character replacement)
+
+         Each 4-tuple represents a strategy for converting the
+         document to Unicode and parsing it. Each strategy will be tried 
+         in turn.
+
+         By default, the only strategy is to parse the markup
+         as-is. See `LXMLTreeBuilderForXML` and
+         `HTMLParserTreeBuilder` for implementations that take into
+         account the quirks of particular parsers.
+        """
+        yield markup, None, None, False
+
+    def test_fragment_to_document(self, fragment):
+        """Wrap an HTML fragment to make it look like a document.
+
+        Different parsers do this differently. For instance, lxml
+        introduces an empty <head> tag, and html5lib
+        doesn't. Abstracting this away lets us write simple tests
+        which run HTML fragments through the parser and compare the
+        results against other HTML fragments.
+
+        This method should not be used outside of tests.
+
+        :param fragment: A string -- fragment of HTML.
+        :return: A string -- a full HTML document.
+        """
+        return fragment
+
+    def set_up_substitutions(self, tag):
+        """Set up any substitutions that will need to be performed on 
+        a `Tag` when it's output as a string.
+
+        By default, this does nothing. See `HTMLTreeBuilder` for a
+        case where this is used.
+
+        :param tag: A `Tag`
+        :return: Whether or not a substitution was performed.
+        """
+        return False
+
+    def _replace_cdata_list_attribute_values(self, tag_name, attrs):
+        """When an attribute value is associated with a tag that can
+        have multiple values for that attribute, convert the string
+        value to a list of strings.
+
+        Basically, replaces class="foo bar" with class=["foo", "bar"]
+
+        NOTE: This method modifies its input in place.
+
+        :param tag_name: The name of a tag.
+        :param attrs: A dictionary containing the tag's attributes.
+           Any appropriate attribute values will be modified in place.
+        """
+        if not attrs:
+            return attrs
+        if self.cdata_list_attributes:
+            universal = self.cdata_list_attributes.get('*', [])
+            tag_specific = self.cdata_list_attributes.get(
+                tag_name.lower(), None)
+            for attr in list(attrs.keys()):
+                if attr in universal or (tag_specific and attr in tag_specific):
+                    # We have a "class"-type attribute whose string
+                    # value is a whitespace-separated list of
+                    # values. Split it into a list.
+                    value = attrs[attr]
+                    if isinstance(value, str):
+                        values = nonwhitespace_re.findall(value)
+                    else:
+                        # html5lib sometimes calls setAttributes twice
+                        # for the same tag when rearranging the parse
+                        # tree. On the second call the attribute value
+                        # here is already a list.  If this happens,
+                        # leave the value alone rather than trying to
+                        # split it again.
+                        values = value
+                    attrs[attr] = values
+        return attrs
+
+class SAXTreeBuilder(TreeBuilder):
+    """A Beautiful Soup treebuilder that listens for SAX events.
+
+    This is not currently used for anything, but it demonstrates
+    how a simple TreeBuilder would work.
+    """
+
+    def feed(self, markup):
+        raise NotImplementedError()
+
+    def close(self):
+        pass
+
+    def startElement(self, name, attrs):
+        attrs = dict((key[1], value) for key, value in list(attrs.items()))
+        #print("Start %s, %r" % (name, attrs))
+        self.soup.handle_starttag(name, attrs)
+
+    def endElement(self, name):
+        #print("End %s" % name)
+        self.soup.handle_endtag(name)
+
+    def startElementNS(self, nsTuple, nodeName, attrs):
+        # Throw away (ns, nodeName) for now.
+        self.startElement(nodeName, attrs)
+
+    def endElementNS(self, nsTuple, nodeName):
+        # Throw away (ns, nodeName) for now.
+        self.endElement(nodeName)
+        #handler.endElementNS((ns, node.nodeName), node.nodeName)
+
+    def startPrefixMapping(self, prefix, nodeValue):
+        # Ignore the prefix for now.
+        pass
+
+    def endPrefixMapping(self, prefix):
+        # Ignore the prefix for now.
+        # handler.endPrefixMapping(prefix)
+        pass
+
+    def characters(self, content):
+        self.soup.handle_data(content)
+
+    def startDocument(self):
+        pass
+
+    def endDocument(self):
+        pass
+
+
+class HTMLTreeBuilder(TreeBuilder):
+    """This TreeBuilder knows facts about HTML.
+
+    Such as which tags are empty-element tags.
+    """
+
+    empty_element_tags = set([
+        # These are from HTML5.
+        'area', 'base', 'br', 'col', 'embed', 'hr', 'img', 'input', 'keygen', 'link', 'menuitem', 'meta', 'param', 'source', 'track', 'wbr',
+        
+        # These are from earlier versions of HTML and are removed in HTML5.
+        'basefont', 'bgsound', 'command', 'frame', 'image', 'isindex', 'nextid', 'spacer'
+    ])
+
+    # The HTML standard defines these as block-level elements. Beautiful
+    # Soup does not treat these elements differently from other elements,
+    # but it may do so eventually, and this information is available if
+    # you need to use it.
+    block_elements = set(["address", "article", "aside", "blockquote", "canvas", "dd", "div", "dl", "dt", "fieldset", "figcaption", "figure", "footer", "form", "h1", "h2", "h3", "h4", "h5", "h6", "header", "hr", "li", "main", "nav", "noscript", "ol", "output", "p", "pre", "section", "table", "tfoot", "ul", "video"])
+
+    # The HTML standard defines an unusual content model for these tags.
+    # We represent this by using a string class other than NavigableString
+    # inside these tags.
+    #
+    # I made this list by going through the HTML spec
+    # (https://html.spec.whatwg.org/#metadata-content) and looking for
+    # "metadata content" elements that can contain strings.
+    #
+    # TODO: Arguably <noscript> could go here but it seems
+    # qualitatively different from the other tags.
+    DEFAULT_STRING_CONTAINERS = {
+        'style': Stylesheet,
+        'script': Script,
+        'template': TemplateString,
+    }    
+    
+    # The HTML standard defines these attributes as containing a
+    # space-separated list of values, not a single value. That is,
+    # class="foo bar" means that the 'class' attribute has two values,
+    # 'foo' and 'bar', not the single value 'foo bar'.  When we
+    # encounter one of these attributes, we will parse its value into
+    # a list of values if possible. Upon output, the list will be
+    # converted back into a string.
+    DEFAULT_CDATA_LIST_ATTRIBUTES = {
+        "*" : ['class', 'accesskey', 'dropzone'],
+        "a" : ['rel', 'rev'],
+        "link" :  ['rel', 'rev'],
+        "td" : ["headers"],
+        "th" : ["headers"],
+        "td" : ["headers"],
+        "form" : ["accept-charset"],
+        "object" : ["archive"],
+
+        # These are HTML5 specific, as are *.accesskey and *.dropzone above.
+        "area" : ["rel"],
+        "icon" : ["sizes"],
+        "iframe" : ["sandbox"],
+        "output" : ["for"],
+        }
+
+    DEFAULT_PRESERVE_WHITESPACE_TAGS = set(['pre', 'textarea'])
+    
+    def set_up_substitutions(self, tag):
+        """Replace the declared encoding in a <meta> tag with a placeholder,
+        to be substituted when the tag is output to a string.
+
+        An HTML document may come in to Beautiful Soup as one
+        encoding, but exit in a different encoding, and the <meta> tag
+        needs to be changed to reflect this.
+
+        :param tag: A `Tag`
+        :return: Whether or not a substitution was performed.
+        """
+        # We are only interested in <meta> tags
+        if tag.name != 'meta':
+            return False
+
+        http_equiv = tag.get('http-equiv')
+        content = tag.get('content')
+        charset = tag.get('charset')
+
+        # We are interested in <meta> tags that say what encoding the
+        # document was originally in. This means HTML 5-style <meta>
+        # tags that provide the "charset" attribute. It also means
+        # HTML 4-style <meta> tags that provide the "content"
+        # attribute and have "http-equiv" set to "content-type".
+        #
+        # In both cases we will replace the value of the appropriate
+        # attribute with a standin object that can take on any
+        # encoding.
+        meta_encoding = None
+        if charset is not None:
+            # HTML 5 style:
+            # <meta charset="utf8">
+            meta_encoding = charset
+            tag['charset'] = CharsetMetaAttributeValue(charset)
+
+        elif (content is not None and http_equiv is not None
+              and http_equiv.lower() == 'content-type'):
+            # HTML 4 style:
+            # <meta http-equiv="content-type" content="text/html; charset=utf8">
+            tag['content'] = ContentMetaAttributeValue(content)
+
+        return (meta_encoding is not None)
+
+def register_treebuilders_from(module):
+    """Copy TreeBuilders from the given module into this module."""
+    this_module = sys.modules[__name__]
+    for name in module.__all__:
+        obj = getattr(module, name)
+
+        if issubclass(obj, TreeBuilder):
+            setattr(this_module, name, obj)
+            this_module.__all__.append(name)
+            # Register the builder while we're at it.
+            this_module.builder_registry.register(obj)
+
+class ParserRejectedMarkup(Exception):
+    """An Exception to be raised when the underlying parser simply
+    refuses to parse the given markup.
+    """
+    def __init__(self, message_or_exception):
+        """Explain why the parser rejected the given markup, either
+        with a textual explanation or another exception.
+        """
+        if isinstance(message_or_exception, Exception):
+            e = message_or_exception
+            message_or_exception = "%s: %s" % (e.__class__.__name__, str(e))
+        super(ParserRejectedMarkup, self).__init__(message_or_exception)
+            
+# Builders are registered in reverse order of priority, so that custom
+# builder registrations will take precedence. In general, we want lxml
+# to take precedence over html5lib, because it's faster. And we only
+# want to use HTMLParser as a last resort.
+from . import _htmlparser
+register_treebuilders_from(_htmlparser)
+try:
+    from . import _html5lib
+    register_treebuilders_from(_html5lib)
+except ImportError:
+    # They don't have html5lib installed.
+    pass
+try:
+    from . import _lxml
+    register_treebuilders_from(_lxml)
+except ImportError:
+    # They don't have lxml installed.
+    pass
Index: latest/Lib/site-packages/beautifulsoup4-4.9.3.dist-info/COPYING.txt
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/latest/Lib/site-packages/beautifulsoup4-4.9.3.dist-info/COPYING.txt b/latest/Lib/site-packages/beautifulsoup4-4.9.3.dist-info/COPYING.txt
new file mode 100644
--- /dev/null	(date 1616411342142)
+++ b/latest/Lib/site-packages/beautifulsoup4-4.9.3.dist-info/COPYING.txt	(date 1616411342142)
@@ -0,0 +1,27 @@
+Beautiful Soup is made available under the MIT license:
+
+ Copyright (c) 2004-2017 Leonard Richardson
+
+ Permission is hereby granted, free of charge, to any person obtaining
+ a copy of this software and associated documentation files (the
+ "Software"), to deal in the Software without restriction, including
+ without limitation the rights to use, copy, modify, merge, publish,
+ distribute, sublicense, and/or sell copies of the Software, and to
+ permit persons to whom the Software is furnished to do so, subject to
+ the following conditions:
+
+ The above copyright notice and this permission notice shall be
+ included in all copies or substantial portions of the Software.
+
+ THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND,
+ EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF
+ MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND
+ NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS
+ BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN
+ ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN
+ CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
+ SOFTWARE.
+
+Beautiful Soup incorporates code from the html5lib library, which is
+also made available under the MIT license. Copyright (c) 2006-2013
+James Graham and other contributors
Index: latest/Lib/site-packages/beautifulsoup4-4.9.3.dist-info/INSTALLER
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/latest/Lib/site-packages/beautifulsoup4-4.9.3.dist-info/INSTALLER b/latest/Lib/site-packages/beautifulsoup4-4.9.3.dist-info/INSTALLER
new file mode 100644
--- /dev/null	(date 1616411342894)
+++ b/latest/Lib/site-packages/beautifulsoup4-4.9.3.dist-info/INSTALLER	(date 1616411342894)
@@ -0,0 +1,1 @@
+pip
Index: latest/Lib/site-packages/beautifulsoup4-4.9.3.dist-info/LICENSE
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/latest/Lib/site-packages/beautifulsoup4-4.9.3.dist-info/LICENSE b/latest/Lib/site-packages/beautifulsoup4-4.9.3.dist-info/LICENSE
new file mode 100644
--- /dev/null	(date 1616411342144)
+++ b/latest/Lib/site-packages/beautifulsoup4-4.9.3.dist-info/LICENSE	(date 1616411342144)
@@ -0,0 +1,30 @@
+Beautiful Soup is made available under the MIT license:
+
+ Copyright (c) 2004-2019 Leonard Richardson
+
+ Permission is hereby granted, free of charge, to any person obtaining
+ a copy of this software and associated documentation files (the
+ "Software"), to deal in the Software without restriction, including
+ without limitation the rights to use, copy, modify, merge, publish,
+ distribute, sublicense, and/or sell copies of the Software, and to
+ permit persons to whom the Software is furnished to do so, subject to
+ the following conditions:
+
+ The above copyright notice and this permission notice shall be
+ included in all copies or substantial portions of the Software.
+
+ THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND,
+ EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF
+ MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND
+ NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS
+ BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN
+ ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN
+ CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
+ SOFTWARE.
+
+Beautiful Soup incorporates code from the html5lib library, which is
+also made available under the MIT license. Copyright (c) 2006-2013
+James Graham and other contributors
+
+Beautiful Soup depends on the soupsieve library, which is also made
+available under the MIT license. Copyright (c) 2018 Isaac Muse
diff --git a/venv/Lib/site-packages/tests/web_client/__init__.py b/venv/Lib/site-packages/tests/web_client/__init__.py
new file mode 100644
diff --git a/venv/Lib/site-packages/usp/objects/__init__.py b/venv/Lib/site-packages/usp/objects/__init__.py
new file mode 100644
diff --git a/venv/Lib/site-packages/usp/web_client/__init__.py b/venv/Lib/site-packages/usp/web_client/__init__.py
new file mode 100644
